<!DOCTYPE html>
<html lang="en">
<head>
    <title>Titanic Prediction | Kaggle</title>
    <meta charset="utf-8" />
    <meta name="robots" content="index, follow" />
    <meta name="turbolinks-cache-control" content="no-cache" />
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC" />
    <script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com" /><link rel="dns-prefetch" href="https://stats.g.doubleclick.net" /><link rel="dns-prefetch" href="https://js.intercomcdn.com" /><link rel="dns-prefetch" href="https://storage.googleapis.com/" />
    <link href="/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link rel="manifest" href="/static/json/manifest.json">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic" rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet" type='text/css'/>
        <link rel="canonical" href="/azmanvai/titanic-prediction" />                    <link rel="stylesheet" type="text/css" href="/static/assets/vendor.css?v=632d145d8598" />
        <link rel="stylesheet" type="text/css" href="/static/assets/app.css?v=9a450b84054a" />
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => d.deleteRule(x))};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12629138-1"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6"};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@kaggledatasets" />
    <meta name="og:url" content="https://kaggle.com/azmanvai/titanic-prediction" />
    <meta name="og:title" content="Titanic Prediction" />
    <meta name="og:description" content="Using data from Titanic: Machine Learning from Disaster" />
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/1711007-kg.jpg" />


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL-8dIqhEHDxJ1uZILY0Wv9mkYkxBkNuT374OrQaUUfd5RqudFA84WTuHtGL_zIgqR7OlKhuiTv7n2RSBwTO88advSNtmJt_nNlGv-VfwJxmIXJmly2gDowzeQIgtdACHUo',
        isAnonymous: true,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjAzNjkyMDYsIlVzZXJJZCI6MH0.XCKDe8yTT1j8nzQ0pICJGVgt7EbjCRIRxQ_QvOg8th0',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: false,
        
        
        
        
        
        
        
        
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript"
src="//www.googleadservices.com/pagead/conversion_async.js">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="/static/assets/vendor.js?v=4721d2c14786" data-turbolinks-track="reload"></script>
    <script src="/static/assets/app.js?v=6bcf0584652b" data-turbolinks-track="reload"></script>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async defer src="https://apis.google.com/js/api.js"
            onload="this.googleApiOnLoad=function(){};handleClientLoad()"
            onreadystatechange="if (this.readyState === 'complete') this.googleApiOnLoad()">
    </script>
</head>
<body data-turbolinks="true">
    <main>
        






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":735498,"title":"Titanic Prediction","forkParent":null,"currentRunId":2808947,"mostRecentRunId":2810782,"url":"/azmanvai/titanic-prediction","tags":[],"commentCount":0,"upvoteCount":1,"viewCount":74,"forkCount":0,"bestPublicScore":null,"author":{"id":1711007,"displayName":"Nor Azman Zakaria","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"azmanvai","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1711007-kg.jpg","profileUrl":"/azmanvai","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2018-03-15T03:17:08.74Z","selfLink":"/kernels/735498","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":null,"topicId":null,"readGroupId":null,"writeGroupId":null,"slug":"titanic-prediction"},"kernelBlob":{"id":6790717,"settings":{"dockerImageVersionId":47,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Titanic Prediction\u0022\nauthor: \u0022Nor Azman Zakaria\u0022\ndate: \u0022March 3, 2018\u0022\noutput: \n  html_document: \n    number_sections: yes\n    toc: yes\n---\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(lubridate)\n```\n\n# Introduction\nThis is my first data science competition after finishing the data science specialization. The problem is deifnitely \n\n# Data Load\nThe train.csv is saved into dataframe \u0027raw\u0027 and test.csv into \u0027submit\u0027. I use the name \u0027raw\u0027 knowing it will be cleaned and separate into train and test datasets and I didn\u0027t want to confuse with the test.csv dataset. \n```{r, echo = TRUE, warning=FALSE}\nraw \u003c- read.csv(\u0022train.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\nsubmit \u003c- read.csv(\u0022test.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\n```\n\nBelow is preview of both raw and submit datasets. Raw comes with 891 observations and 12 variables. Submit comes with 418 observations with 11 variables. The only difference is \u0027Survived\u0027 variable not included in Submit\n```{r, echo = TRUE}\ndim(raw); dim(submit)\nnames(raw); names(submit)\n```\n\n# Undertanding the variables\nPassengerId is a unique identifier for each passenger. A quick check yields no duplication\n```{r, echo = TRUE}\nsummary(raw$PassengerId)\nsum(duplicated(raw$PassengerId))\n```\n\nSurvived is and indication of survival where 0 = No and 1 = Yes. No missing values\n```{r, echo = TRUE}\nsummary(raw$Survived)\nsum(is.na(raw$Survived))\n```\n\nPclass represent ticket class where 1 = 1st, 2 = 2nd, 3 = 3rd. 1st = Upper, 2nd = Middle, 3rd = Lower. No missing values\n```{r, echo = TRUE}\nsummary(raw$Pclass)\nsum(is.na(raw$Pclass))\n```\n\nSex represents gender \u0022male\u0022 or \u0022female\u0022. No missing values\n```{r, echo = TRUE}\nstr(raw$Sex)\nsum(is.na(raw$Sex))\n```\n\nAge is age of passengers. Age is fractional if less than 1. No luck here with 177 missing values. We will decide on how to deal with this later.\n```{r, echo = TRUE}\nsummary(raw$Age)\nsum(is.na(raw$Age))\n```\n\nSibSp is the number of siblings or spouses abord the ship. Sibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc�s were ignored). No missing values\n```{r, echo = TRUE}\nsummary(raw$SibSp)\nsum(is.na(raw$SibSp))\n```\n\nParch is number of parents / children aboard the ship where Parent = mother, father\nChild = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore parch=0 for them. No missing values\n```{r, echo = TRUE}\nsummary(raw$Parch)\nsum(is.na(raw$Parch))\n```\n\nTicket is Ticket number\tfor each passenger. About 210 duplications found. No missing values\n```{r, echo = TRUE}\nstr(raw$Ticket)\nsum(duplicated(raw$Ticket))\nsum(is.na(raw$Ticket))\n```\n\nFare is passenger fare. No missing values. Wow kinda interesting to see some class 3 passengers paying the rate of class 1!!\n```{r, echo = TRUE}\nstr(raw$Fare)\nsum(is.na(raw$Fare))\ng \u003c- ggplot(raw, aes(x = factor(Pclass), y = Fare)) + geom_boxplot() + ylim(c(0, 200))\ng\n```\n\nCabin indicates cabin number. No luck here with 687 missing values. \n```{r, echo = TRUE}\nstr(raw$Cabin)\nsum(is.na(raw$Cabin))\n```\n\nEmbarked indicates the port of embarkation. C = Cherbourg, Q = Queenstown, S = Southampton. Only 2 missing values. We will deal with this. \n```{r, echo = TRUE}\nstr(raw$Embarked)\nsum(is.na(raw$Embarked))\n```\n\n\n\n# Data Preparation\nMy first take is always looking at missing values and decide whether to impute or simply discard them. Since we will be modifying the original dataset, I will create a new dataframe \u0027data\u0027\n\n## Formatting\nSex and Embarked should be assigned as factor. The rest looks fine at the moment\n```{r, echo=TRUE}\ndata \u003c- raw\ndata$Sex \u003c- as.factor(data$Sex)\ndata$Embarked \u003c- as.factor(data$Embarked)\ndata$Survived \u003c- as.factor(data$Survived)\nstr(data)\n```\n\n## Missing Values\nLets look at overall missing values again\n```{r, echo = TRUE}\nnas \u003c- apply(data, 2, function(x) sum(is.na(x)))\nnas\n```\n\nAge, Cabin and Embarked have missing values. Lets start with the easiest one, Embarked. Passenger 62 and 830 travelled alone with no siblings, spouse or other family members. Interestingly they share same ticket, fare and cabin. \n```{r, echo = TRUE}\nna \u003c- data[is.na(data$Embarked),]\nna\n```\n\nLets try to look at passengers with similar ticket numbers (starting with \u0022113\u0022) to guess the embarkation port. Out of 49 passengers, 42 embarked at Southampton and 7 from Cherbourg. If I have to make a guess it\u0027d be Southampton\n```{r, echo =TRUE}\nticket \u003c- grep(\u0022113\u0022, data$Ticket)  # find passengers with ticket number starting from 113xxx\nticket\nembark \u003c- data[ticket,]\nrownames(embark) \u003c- c(1: nrow(embark)) # reset row names\ntable(embark$Embarked)\n```\n\nLets fool around a bit and use ctree from party package to predict the port of embarkation for these two passengers. I exclude PassengerId, Name, Age and Cabin for this prediction\n```{r, echo = TRUE}\nset.seed(36)\nlibrary(party)\n\nembark$Ticket \u003c- as.numeric(embark$Ticket) #set ticket as numeric for this prediction only\n\ntrain.embark \u003c- embark[-c(6, 48), -c(1, 4, 6,11)]  #exclude passengers with missing port from training set\ntest.embark \u003c- embark[c(6, 48),-c(1, 4, 6)]        #passengers with missing port\nfit.ctree \u003c- ctree(Embarked~., data = train.embark)\npred.embark \u003c- predict(fit.ctree, test.embark)\npred.embark\n```\n\nAs expected, our simple prediction result is Southampton. So we going to assign \u0022S\u0022 (Southampton) for the 2 passengers and update \u0027data\u0027 \n```{r, echo = TRUE}\ndata$Embarked[62] \u003c- \u0022S\u0022\ndata$Embarked[830] \u003c- \u0022S\u0022\nstr(data)\n```\n\nThe next variable to tackle is Age. We have got to impute 177 missing values. \n```{r, echo = TRUE}\nsum(is.na(data$Age))\n```\n\nAgain lets try to predict the missing \u0027Age\u0027 using ctree from party package. We are going to use a temporary dataframe \u0027ages\u0027 for this prediction. We are going to exclude PassengerId, Name, Ticket and Cabin for this run.\n```{r, echo = TRUE}\nset.seed(456)\nlibrary(party)\nages \u003c- data\n\ntrain.age \u003c- ages[complete.cases(ages$Age),-c(1,4,9,11)]\ntest.age \u003c- ages[is.na(ages$Age), -c(1,4,6, 9,11)]\n\nfit.ctree \u003c- ctree(Age~., data = train.age)\npred.age \u003c- predict(fit.ctree, test.age)\nsummary(pred.age)\n```\n\nLets combine this Age prediction into the testing dataframe to see whether it makes any sense. I think its logical that any person below 18 years should be accompanied by their parents or siblings right? Lets take a look\n```{r echo=, warning=FALSE}\ntest.age$Age \u003c- round(pred.age,1)\ny \u003c- test.age[test.age$Age \u003c 20,]\ny\n```\nLooks ok since imputed Age below 18 have at least 1 SibSp or Parch. Also when compared against Pclass, the imputed range looks reasonable. Pclass 2 is a little suspect since Fares are lower than Pclass 3. \n```{r, echo = TRUE}\ng \u003c- ggplot(test.age, aes(x = factor(Pclass), y = Fare, color = Age)) + geom_point() + ggtitle(\u0022Imputed Age\u0022)\ng\n```\n\nSo we are going to use the predicted values for the missing values in Age\n```{r, echo = TRUE}\ndata$Age[is.na(data$Age)] \u003c- round(pred.age,1)\nsum(is.na(data$Age))\n```\n\nThe last variable to deal is Cabin. Since the proportion of missing data is too high, we are going to exclude the variable\n```{r, echo = TRUE}\nnas \u003c- apply(data, 2, function(x) sum(is.na(x)))\nnas/nrow(data)\ndata \u003c- data[,-c(1,11)]  #exclude PasengerId and Cabin\n```\n\n## Near Zero Variable\nWe need to test if there is any column with zero variance or near zero value. Everything is good here\n```{r, echo=TRUE}\nnzv \u003c- nearZeroVar(data, saveMetrics = TRUE, names = TRUE)\nnzv\n```\n\n## Feature Selection\nNow that our data is clean, we will choose features which make sense for the prediction. Lets take a look at Name. As expected there\u0027s a variety of characters. We could do more advanced analysis to find patterns or generate new features but I like to keep things simple. We will exclude Name for the initial run and go back again if needed.\n```{r, echo=TRUE}\nhead(data$Name)\ndata \u003c- data[,-3]\n```\n\nNext is Ticket. Again we could find patterns but to keep things simple, I\u0027ll just exclude Ticket for the initial run\n```{r, echo=TRUE}\nhead(data$Ticket)\ndata \u003c- data[,-7]\n```\n\nOur final data looks like this. Distribution of response is a bit skewed towards Survived = 0, but its not too alarming\n```{r, echo=TRUE}\nnames(data)\ntable(data$Survived)\n```\n\n## Splitting the data for training and testing\n```{r, echo=TRUE}\nindex \u003c- createDataPartition(data$Survived, p = 0.7, list = FALSE)\ntrain \u003c- data[index,]\ntest \u003c- data[-index,]\nx \u003c- train[,-1]\ny \u003c- train[,1]\n```\n\n# Model Selection\nFor the moment of truth, I will be testing several models without tuning. In general, there will be GLM, Decision Tree, Ensembled Trees and Naive Bayes\n\n## Generalized Linear Model\nThis is the classic method = \u0027glm\u0027 which can be used for both Regression and Classification. A model-specific variable importance metric is available but not used for this benchmark\n\n```{r glm, echo=TRUE, warning=FALSE}\n\ntime.glm \u003c- system.time(glm(Survived~., data = train, family = \u0022binomial\u0022))\nfit.glm\u003c- glm(Survived~., data = train, family = \u0022binomial\u0022) \npred.glm \u003c- predict(fit.glm, test, type = \u0022response\u0022)\npred.glm \u003c- ifelse(pred.glm \u003c 0.37, 0, 1)\nacc.glm \u003c- confusionMatrix(test$Survived, pred.glm)\nacc.glm\nglm \u003c- c(family = \u0022GLM\u0022, round(c(acc.glm$byClass, time.glm[3]),3))\nglm\n```\n\n## GLMNET \nMethod = \u0027glmnet\u0027 is an improved \u0027glm\u0027 method which includes regularization. It can be used for both Regression and Classification problems. Tuning parameters: alpha (Mixing Percentage) and lambda (Regularization Parameter). Required packages: glmnet, Matrix. A model-specific variable importance metric is available.\n\n```{r glmnet, echo=TRUE}\nlibrary(glmnet)\nlibrary(Matrix)\n\nxm \u003c- data.matrix(x)\ntestxm \u003c- data.matrix(test[,-1])\nym \u003c- as.numeric(y) - 1\ntestym \u003c- as.numeric(test$Survived) - 1\n\ntime.glmnet \u003c- system.time(cv.glmnet(xm, ym, nfolds = 10))\nfit.glmnet \u003c- cv.glmnet(xm, ym, nfolds = 10)\npred.glmnet \u003c- predict(fit.glmnet, testxm, s = fit.glmnet$lambda.min, type = \u0022response\u0022)\npred.glmnet \u003c- ifelse(pred.glmnet \u003c 0.36, 0, 1)\nacc.glmnet \u003c- confusionMatrix(testym, pred.glmnet)\nacc.glmnet\nglmnet \u003c- c(family = \u0022GLM\u0022, round(c(acc.glmnet$byClass, time.glmnet[3]), 3))\nglmnet\n```\n\n## Naive Bayes\n\n  method = \u0027naive_bayes\u0027\nType: Classification\n\nTuning parameters:\nfL (Laplace Correction)\nusekernel (Distribution Type)\nadjust (Bandwidth Adjustment)\nRequired packages: naivebayes\n\n```{r naivebayes, echo=FALSE, warning=FALSE}\nlibrary(naivebayes)\n\ntime.naivebayes \u003c- system.time(naive_bayes(x, y ))\nfit.naivebayes \u003c- naive_bayes(x, y)\npred.naivebayes \u003c- predict(fit.naivebayes, test)\nacc.naivebayes \u003c- confusionMatrix(test$Survived, pred.naivebayes)\n\nnaivebayes \u003c- c(family = \u0022Naive Bayes\u0022, round(c(acc.naivebayes$byClass, time.naivebayes[3]),3))\nacc.naivebayes; naivebayes\n```\n\n## Conditional Inference Tree\n\n  method = \u0027ctree\u0027\nType: Classification, Regression\n\nTuning parameters:\n\nmincriterion (1 - P-Value Threshold)\nRequired packages: party\n\n```{r ctree, echo=FALSE, warning=FALSE}\nlibrary(party)\n\n# some tuning\ncontrol \u003c- ctree_control(testtype = \u0022Teststatistic\u0022, mincriterion = 0.95, mtry = 0)\n\n# run model\ntime.ctree \u003c- system.time(ctree(Survived~., data = train, controls = control ))\nfit.ctree \u003c- ctree(Survived~., data = train, controls = control)\npred.ctree \u003c- predict(fit.ctree, test, type = \u0022response\u0022)\n\nacc.ctree \u003c- confusionMatrix(test$Survived, pred.ctree)\n\nctree \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.ctree$byClass, time.ctree[3]),3))\nctree\n```\n\n## CART\n\n  method = \u0027rpart\u0027\nType: Regression, Classification\n\nTuning parameters:\n\ncp (Complexity Parameter)\nRequired packages: rpart\n\nA model-specific variable importance metric is available.\n\n\n```{r rpart, echo=FALSE, warning=FALSE}\nlibrary(rpart)\n\n# run model\ntime.rpart \u003c- system.time(rpart(Survived ~ ., data = train, method = \u0022class\u0022))\nfit.rpart \u003c- rpart(Survived ~ ., data = train, method = \u0022class\u0022)\ncpmin \u003c- printcp(fit.rpart)\ncontrol \u003c- rpart.control(cp = 0.015, maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10, surrogatestyle = 0, maxdepth = 30)\nfit.rpart \u003c- rpart(Survived ~ ., data = train, method = \u0022class\u0022, control = control)\npred.rpart \u003c- predict(fit.rpart, test, type = \u0022class\u0022)\nacc.rpart \u003c- confusionMatrix(test$Survived, pred.rpart)\n\nrpart \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.rpart$byClass, time.rpart[3]),3))\nrpart\n\n```\n\n## Random Forest\nThis is random forest from the ranger package. I like this because of the speed. \n \n```{r ranger}\nlibrary(ranger)\n\n\ntime.ranger \u003c- system.time(csrf(Survived ~ ., training_data = train, test_data = test, params1 = list(num.trees = 300, mtry = 4), params2 = list(num.trees = 5)))\n#fit.ranger \u003c- ranger(Survived~., data = train)\n#pred.ranger \u003c- predict(fit.ranger, test)\n\ntune.ranger \u003c- csrf(Survived ~ ., training_data = train, test_data = test, params1 = list(num.trees = 300, mtry = 4), params2 = list(num.trees = 10))\nacc.ranger \u003c- confusionMatrix(tune.ranger, test$Survived)\nranger \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.ranger$byClass, time.ranger[3]),3))\nranger\n\n```\n\n## Random Forest\nHere I am using the randomForest package for the run. I tried some basic tuning to find the best mtry and it didn\u0027t change much compared to untuned model \n\n```{r randomForest, echo=FALSE, warning=FALSE}\nlibrary(randomForest)\n\n# some tuning\ncv.randomforest \u003c- rfcv(x, y, cv.fold = 10, scale = \u0022log\u0022, step = 0.5, recursive = TRUE)\ntune.randomforest \u003c- tuneRF(x, y, ntreeTry = 150, stepFactor = 2, doBest = TRUE)\n\n# run model\ntime.randomforest \u003c- system.time(tuneRF(x, y, ntreeTry = 150, stepFactor = 2, doBest = TRUE))\n\npred.randomforest \u003c- predict(tune.randomforest, test) \nacc.randomforest \u003c- confusionMatrix(pred.randomforest, test$Survived)\n\nrandomforest \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.randomforest$byClass, time.randomforest[3]),3))\nrandomforest\n\n```\n\n## Models Comparison\nYou can see ensembled trees like ranger and randomforest giving highest accuracy compared to the rest. However both models lack in specificity which is prediction of Survived = 1. The rpart model is best in specificity, and having a more balanced accuracy comparared to the former. I am tempted to stack rpart and ranger together to get the best of both worlds but I will leave that for another day.\n```{r comp, echo= FALSE}\ncomp \u003c- data.frame(rbind(glm, glmnet,  rpart, ctree, ranger, randomforest), stringsAsFactors = FALSE)\ncomp[,13] \u003c- as.numeric(comp[,13])\nc \u003c- comp[order(comp$Balanced.Accuracy, decreasing = TRUE), c(1,13,12, 2:5)]\nc\n```\n\n# Final Submission\nI am going to use randomForest for the submission. \n\n## Submission Data\nLets look at the submission dataset again. Everything looks similar to raw only without the Survived variable\n```{r, echo = TRUE}\nhead(submit)\nstr(submit)\n```\n\n## Missing Values\nLots of missing values in Cabin, Age and Fare. We won\u0027t be using Cabin so we will have to impute Age and Fare. I am going to use same method as per the train dataset to impute the missing values\n```{r, echo= TRUE}\nna \u003c- sum(is.na(submit))\nna\nnap \u003c- apply(submit, 2, function(x) sum(is.na(x)))\nnap\n```\n\nI will predict the missing \u0027Age\u0027 using ctree from party package. We are going to use a temporary dataframe \u0027ages\u0027 for this prediction. We are going to exclude PassengerId, Name, Ticket and Cabin for this run.\n```{r, echo = TRUE}\nlibrary(party)\nages2 \u003c- submit\nages2$Sex \u003c- as.factor(ages2$Sex)\nages2$Embarked \u003c- as.factor(ages2$Embarked)\n\ntrain.age2 \u003c- ages2[complete.cases(ages2$Age),-c(1,3, 8, 10)]  # complete Age\ntest.age2 \u003c- ages2[is.na(ages2$Age), -c(1,3, 8, 10)]           # missing Age\n\nfit.age2 \u003c- ctree(Age~., data = train.age2)\npred.age2 \u003c- predict(fit.age2, test.age2)\nsummary(pred.age2)\n```\n\nLets combine this Age prediction into the testing dataframe to see whether it makes any sense. I think its logical that any person below 18 years should be accompanied by their parents or siblings right? Lets take a look\n```{r echo=, warning=FALSE}\ntest.age2$Age \u003c- round(pred.age2,1)\ny2 \u003c- test.age2[test.age2$Age \u003c 18,]\ny2\n```\nLooks ok since imputed Age below 18 have at least 1 SibSp or Parch. Also when compared against Pclass, the imputed range looks reasonable. Pclass 3 is a little suspect since some Fares are higher than Pclass 1. \n```{r, echo = TRUE}\ng \u003c- ggplot(test.age2, aes(x = factor(Pclass), y = Fare, color = Age)) + geom_point() + ggtitle(\u0022Imputed Age\u0022)\ng\n```\n\nSo we are going to use the predicted values for the missing values in Age\n```{r, echo = TRUE}\nsubmit$Age[is.na(submit$Age)] \u003c- round(pred.age2,1)\nsum(is.na(submit$Age))\n```\n\nLast one is Fare. I am going to use the mean for this one. Lets look at the missing Fare. Passenger is male, Age 60.5, Pclass 3 and embarked at Southampton. We can use that info to calculate the mean\n```{r, echo = TRUE}\nfare \u003c- submit[is.na(submit$Fare),]\nfare\n\n```\n\nI am going to filter the data based on sex = male, Age \u003e 40, Pclass = 3 and embarked = S. Mean of fare is 20.6\n```{r, echo = TRUE}\nfare2 \u003c- submit[complete.cases(submit$Fare),]\nfare2 \u003c- fare2[fare2$Pclass == 3,]\nfare2 \u003c- fare2[fare2$Sex == \u0022male\u0022,]\nfare2 \u003c- fare2[fare2$Age \u003e= 40,]\nfare2 \u003c- fare2[fare2$Embarked == \u0022S\u0022,]\nmeanfare \u003c- mean(fare2$Fare)\nmeanfare\n```\n\nLets assign this fare to passenger 1044. We are ready to run our model!\n```{r, echo = TRUE}\nsubmit$Fare[submit$PassengerId == 1044] \u003c- meanfare\napply(submit, 2, function(x) sum(is.na(x)))\n```\n\n## The Prediction \nBefore running the final prediction, lets get the data in proper format. It should follow \u0027data\u0027\n```{r, echo=TRUE}\nsetdiff(names(submit), names(data))\n```\n\nI am going to exclude the above from submit\n```{r, echo = TRUE}\nnames(submit)\nsubmit \u003c- submit[,-c(1,3,8,10)]\nstr(data)\n```\n\nSet Sex and Embarked as factor\n```{r, echo = TRUE}\nsubmit$Sex \u003c- as.factor(submit$Sex)\nsubmit$Embarked \u003c- as.factor(submit$Embarked)\nstr(submit)\n```\n\nNow, for the moment of truth!\n```{r, echo = TRUE}\npred.randomforest \u003c- predict(tune.randomforest, submit) \npred.randomforest\nsubmit2 \u003c- read.csv(\u0022test.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\nsubmission \u003c- data.frame(PassengerId = submit2$PassengerId, Survived = pred.randomforest)\nsubmission\n```","dateCreated":"2018-03-15T03:17:08.21Z"},"kernelRun":{"id":2808947,"kernelId":735498,"status":"error","type":"batch","sourceType":"script","language":"rmarkdown","title":"Titanic Prediction","dateCreated":"2018-03-15T03:17:08.21Z","dateEvaluated":"2018-03-15T03:17:08.74Z","workerContainerPort":null,"workerUptimeSeconds":543455,"workerIPAddress":"172.16.5.7     ","scriptLanguageId":5,"scriptLanguageName":"RMarkdown","renderedOutputUrl":null,"commit":{"id":6790717,"settings":{"dockerImageVersionId":47,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Titanic Prediction\u0022\nauthor: \u0022Nor Azman Zakaria\u0022\ndate: \u0022March 3, 2018\u0022\noutput: \n  html_document: \n    number_sections: yes\n    toc: yes\n---\n\n```{r, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(lubridate)\n```\n\n# Introduction\nThis is my first data science competition after finishing the data science specialization. The problem is deifnitely \n\n# Data Load\nThe train.csv is saved into dataframe \u0027raw\u0027 and test.csv into \u0027submit\u0027. I use the name \u0027raw\u0027 knowing it will be cleaned and separate into train and test datasets and I didn\u0027t want to confuse with the test.csv dataset. \n```{r, echo = TRUE, warning=FALSE}\nraw \u003c- read.csv(\u0022train.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\nsubmit \u003c- read.csv(\u0022test.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\n```\n\nBelow is preview of both raw and submit datasets. Raw comes with 891 observations and 12 variables. Submit comes with 418 observations with 11 variables. The only difference is \u0027Survived\u0027 variable not included in Submit\n```{r, echo = TRUE}\ndim(raw); dim(submit)\nnames(raw); names(submit)\n```\n\n# Undertanding the variables\nPassengerId is a unique identifier for each passenger. A quick check yields no duplication\n```{r, echo = TRUE}\nsummary(raw$PassengerId)\nsum(duplicated(raw$PassengerId))\n```\n\nSurvived is and indication of survival where 0 = No and 1 = Yes. No missing values\n```{r, echo = TRUE}\nsummary(raw$Survived)\nsum(is.na(raw$Survived))\n```\n\nPclass represent ticket class where 1 = 1st, 2 = 2nd, 3 = 3rd. 1st = Upper, 2nd = Middle, 3rd = Lower. No missing values\n```{r, echo = TRUE}\nsummary(raw$Pclass)\nsum(is.na(raw$Pclass))\n```\n\nSex represents gender \u0022male\u0022 or \u0022female\u0022. No missing values\n```{r, echo = TRUE}\nstr(raw$Sex)\nsum(is.na(raw$Sex))\n```\n\nAge is age of passengers. Age is fractional if less than 1. No luck here with 177 missing values. We will decide on how to deal with this later.\n```{r, echo = TRUE}\nsummary(raw$Age)\nsum(is.na(raw$Age))\n```\n\nSibSp is the number of siblings or spouses abord the ship. Sibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc�s were ignored). No missing values\n```{r, echo = TRUE}\nsummary(raw$SibSp)\nsum(is.na(raw$SibSp))\n```\n\nParch is number of parents / children aboard the ship where Parent = mother, father\nChild = daughter, son, stepdaughter, stepson. Some children travelled only with a nanny, therefore parch=0 for them. No missing values\n```{r, echo = TRUE}\nsummary(raw$Parch)\nsum(is.na(raw$Parch))\n```\n\nTicket is Ticket number\tfor each passenger. About 210 duplications found. No missing values\n```{r, echo = TRUE}\nstr(raw$Ticket)\nsum(duplicated(raw$Ticket))\nsum(is.na(raw$Ticket))\n```\n\nFare is passenger fare. No missing values. Wow kinda interesting to see some class 3 passengers paying the rate of class 1!!\n```{r, echo = TRUE}\nstr(raw$Fare)\nsum(is.na(raw$Fare))\ng \u003c- ggplot(raw, aes(x = factor(Pclass), y = Fare)) + geom_boxplot() + ylim(c(0, 200))\ng\n```\n\nCabin indicates cabin number. No luck here with 687 missing values. \n```{r, echo = TRUE}\nstr(raw$Cabin)\nsum(is.na(raw$Cabin))\n```\n\nEmbarked indicates the port of embarkation. C = Cherbourg, Q = Queenstown, S = Southampton. Only 2 missing values. We will deal with this. \n```{r, echo = TRUE}\nstr(raw$Embarked)\nsum(is.na(raw$Embarked))\n```\n\n\n\n# Data Preparation\nMy first take is always looking at missing values and decide whether to impute or simply discard them. Since we will be modifying the original dataset, I will create a new dataframe \u0027data\u0027\n\n## Formatting\nSex and Embarked should be assigned as factor. The rest looks fine at the moment\n```{r, echo=TRUE}\ndata \u003c- raw\ndata$Sex \u003c- as.factor(data$Sex)\ndata$Embarked \u003c- as.factor(data$Embarked)\ndata$Survived \u003c- as.factor(data$Survived)\nstr(data)\n```\n\n## Missing Values\nLets look at overall missing values again\n```{r, echo = TRUE}\nnas \u003c- apply(data, 2, function(x) sum(is.na(x)))\nnas\n```\n\nAge, Cabin and Embarked have missing values. Lets start with the easiest one, Embarked. Passenger 62 and 830 travelled alone with no siblings, spouse or other family members. Interestingly they share same ticket, fare and cabin. \n```{r, echo = TRUE}\nna \u003c- data[is.na(data$Embarked),]\nna\n```\n\nLets try to look at passengers with similar ticket numbers (starting with \u0022113\u0022) to guess the embarkation port. Out of 49 passengers, 42 embarked at Southampton and 7 from Cherbourg. If I have to make a guess it\u0027d be Southampton\n```{r, echo =TRUE}\nticket \u003c- grep(\u0022113\u0022, data$Ticket)  # find passengers with ticket number starting from 113xxx\nticket\nembark \u003c- data[ticket,]\nrownames(embark) \u003c- c(1: nrow(embark)) # reset row names\ntable(embark$Embarked)\n```\n\nLets fool around a bit and use ctree from party package to predict the port of embarkation for these two passengers. I exclude PassengerId, Name, Age and Cabin for this prediction\n```{r, echo = TRUE}\nset.seed(36)\nlibrary(party)\n\nembark$Ticket \u003c- as.numeric(embark$Ticket) #set ticket as numeric for this prediction only\n\ntrain.embark \u003c- embark[-c(6, 48), -c(1, 4, 6,11)]  #exclude passengers with missing port from training set\ntest.embark \u003c- embark[c(6, 48),-c(1, 4, 6)]        #passengers with missing port\nfit.ctree \u003c- ctree(Embarked~., data = train.embark)\npred.embark \u003c- predict(fit.ctree, test.embark)\npred.embark\n```\n\nAs expected, our simple prediction result is Southampton. So we going to assign \u0022S\u0022 (Southampton) for the 2 passengers and update \u0027data\u0027 \n```{r, echo = TRUE}\ndata$Embarked[62] \u003c- \u0022S\u0022\ndata$Embarked[830] \u003c- \u0022S\u0022\nstr(data)\n```\n\nThe next variable to tackle is Age. We have got to impute 177 missing values. \n```{r, echo = TRUE}\nsum(is.na(data$Age))\n```\n\nAgain lets try to predict the missing \u0027Age\u0027 using ctree from party package. We are going to use a temporary dataframe \u0027ages\u0027 for this prediction. We are going to exclude PassengerId, Name, Ticket and Cabin for this run.\n```{r, echo = TRUE}\nset.seed(456)\nlibrary(party)\nages \u003c- data\n\ntrain.age \u003c- ages[complete.cases(ages$Age),-c(1,4,9,11)]\ntest.age \u003c- ages[is.na(ages$Age), -c(1,4,6, 9,11)]\n\nfit.ctree \u003c- ctree(Age~., data = train.age)\npred.age \u003c- predict(fit.ctree, test.age)\nsummary(pred.age)\n```\n\nLets combine this Age prediction into the testing dataframe to see whether it makes any sense. I think its logical that any person below 18 years should be accompanied by their parents or siblings right? Lets take a look\n```{r echo=, warning=FALSE}\ntest.age$Age \u003c- round(pred.age,1)\ny \u003c- test.age[test.age$Age \u003c 20,]\ny\n```\nLooks ok since imputed Age below 18 have at least 1 SibSp or Parch. Also when compared against Pclass, the imputed range looks reasonable. Pclass 2 is a little suspect since Fares are lower than Pclass 3. \n```{r, echo = TRUE}\ng \u003c- ggplot(test.age, aes(x = factor(Pclass), y = Fare, color = Age)) + geom_point() + ggtitle(\u0022Imputed Age\u0022)\ng\n```\n\nSo we are going to use the predicted values for the missing values in Age\n```{r, echo = TRUE}\ndata$Age[is.na(data$Age)] \u003c- round(pred.age,1)\nsum(is.na(data$Age))\n```\n\nThe last variable to deal is Cabin. Since the proportion of missing data is too high, we are going to exclude the variable\n```{r, echo = TRUE}\nnas \u003c- apply(data, 2, function(x) sum(is.na(x)))\nnas/nrow(data)\ndata \u003c- data[,-c(1,11)]  #exclude PasengerId and Cabin\n```\n\n## Near Zero Variable\nWe need to test if there is any column with zero variance or near zero value. Everything is good here\n```{r, echo=TRUE}\nnzv \u003c- nearZeroVar(data, saveMetrics = TRUE, names = TRUE)\nnzv\n```\n\n## Feature Selection\nNow that our data is clean, we will choose features which make sense for the prediction. Lets take a look at Name. As expected there\u0027s a variety of characters. We could do more advanced analysis to find patterns or generate new features but I like to keep things simple. We will exclude Name for the initial run and go back again if needed.\n```{r, echo=TRUE}\nhead(data$Name)\ndata \u003c- data[,-3]\n```\n\nNext is Ticket. Again we could find patterns but to keep things simple, I\u0027ll just exclude Ticket for the initial run\n```{r, echo=TRUE}\nhead(data$Ticket)\ndata \u003c- data[,-7]\n```\n\nOur final data looks like this. Distribution of response is a bit skewed towards Survived = 0, but its not too alarming\n```{r, echo=TRUE}\nnames(data)\ntable(data$Survived)\n```\n\n## Splitting the data for training and testing\n```{r, echo=TRUE}\nindex \u003c- createDataPartition(data$Survived, p = 0.7, list = FALSE)\ntrain \u003c- data[index,]\ntest \u003c- data[-index,]\nx \u003c- train[,-1]\ny \u003c- train[,1]\n```\n\n# Model Selection\nFor the moment of truth, I will be testing several models without tuning. In general, there will be GLM, Decision Tree, Ensembled Trees and Naive Bayes\n\n## Generalized Linear Model\nThis is the classic method = \u0027glm\u0027 which can be used for both Regression and Classification. A model-specific variable importance metric is available but not used for this benchmark\n\n```{r glm, echo=TRUE, warning=FALSE}\n\ntime.glm \u003c- system.time(glm(Survived~., data = train, family = \u0022binomial\u0022))\nfit.glm\u003c- glm(Survived~., data = train, family = \u0022binomial\u0022) \npred.glm \u003c- predict(fit.glm, test, type = \u0022response\u0022)\npred.glm \u003c- ifelse(pred.glm \u003c 0.37, 0, 1)\nacc.glm \u003c- confusionMatrix(test$Survived, pred.glm)\nacc.glm\nglm \u003c- c(family = \u0022GLM\u0022, round(c(acc.glm$byClass, time.glm[3]),3))\nglm\n```\n\n## GLMNET \nMethod = \u0027glmnet\u0027 is an improved \u0027glm\u0027 method which includes regularization. It can be used for both Regression and Classification problems. Tuning parameters: alpha (Mixing Percentage) and lambda (Regularization Parameter). Required packages: glmnet, Matrix. A model-specific variable importance metric is available.\n\n```{r glmnet, echo=TRUE}\nlibrary(glmnet)\nlibrary(Matrix)\n\nxm \u003c- data.matrix(x)\ntestxm \u003c- data.matrix(test[,-1])\nym \u003c- as.numeric(y) - 1\ntestym \u003c- as.numeric(test$Survived) - 1\n\ntime.glmnet \u003c- system.time(cv.glmnet(xm, ym, nfolds = 10))\nfit.glmnet \u003c- cv.glmnet(xm, ym, nfolds = 10)\npred.glmnet \u003c- predict(fit.glmnet, testxm, s = fit.glmnet$lambda.min, type = \u0022response\u0022)\npred.glmnet \u003c- ifelse(pred.glmnet \u003c 0.36, 0, 1)\nacc.glmnet \u003c- confusionMatrix(testym, pred.glmnet)\nacc.glmnet\nglmnet \u003c- c(family = \u0022GLM\u0022, round(c(acc.glmnet$byClass, time.glmnet[3]), 3))\nglmnet\n```\n\n## Naive Bayes\n\n  method = \u0027naive_bayes\u0027\nType: Classification\n\nTuning parameters:\nfL (Laplace Correction)\nusekernel (Distribution Type)\nadjust (Bandwidth Adjustment)\nRequired packages: naivebayes\n\n```{r naivebayes, echo=FALSE, warning=FALSE}\nlibrary(naivebayes)\n\ntime.naivebayes \u003c- system.time(naive_bayes(x, y ))\nfit.naivebayes \u003c- naive_bayes(x, y)\npred.naivebayes \u003c- predict(fit.naivebayes, test)\nacc.naivebayes \u003c- confusionMatrix(test$Survived, pred.naivebayes)\n\nnaivebayes \u003c- c(family = \u0022Naive Bayes\u0022, round(c(acc.naivebayes$byClass, time.naivebayes[3]),3))\nacc.naivebayes; naivebayes\n```\n\n## Conditional Inference Tree\n\n  method = \u0027ctree\u0027\nType: Classification, Regression\n\nTuning parameters:\n\nmincriterion (1 - P-Value Threshold)\nRequired packages: party\n\n```{r ctree, echo=FALSE, warning=FALSE}\nlibrary(party)\n\n# some tuning\ncontrol \u003c- ctree_control(testtype = \u0022Teststatistic\u0022, mincriterion = 0.95, mtry = 0)\n\n# run model\ntime.ctree \u003c- system.time(ctree(Survived~., data = train, controls = control ))\nfit.ctree \u003c- ctree(Survived~., data = train, controls = control)\npred.ctree \u003c- predict(fit.ctree, test, type = \u0022response\u0022)\n\nacc.ctree \u003c- confusionMatrix(test$Survived, pred.ctree)\n\nctree \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.ctree$byClass, time.ctree[3]),3))\nctree\n```\n\n## CART\n\n  method = \u0027rpart\u0027\nType: Regression, Classification\n\nTuning parameters:\n\ncp (Complexity Parameter)\nRequired packages: rpart\n\nA model-specific variable importance metric is available.\n\n\n```{r rpart, echo=FALSE, warning=FALSE}\nlibrary(rpart)\n\n# run model\ntime.rpart \u003c- system.time(rpart(Survived ~ ., data = train, method = \u0022class\u0022))\nfit.rpart \u003c- rpart(Survived ~ ., data = train, method = \u0022class\u0022)\ncpmin \u003c- printcp(fit.rpart)\ncontrol \u003c- rpart.control(cp = 0.015, maxcompete = 4, maxsurrogate = 5, usesurrogate = 2, xval = 10, surrogatestyle = 0, maxdepth = 30)\nfit.rpart \u003c- rpart(Survived ~ ., data = train, method = \u0022class\u0022, control = control)\npred.rpart \u003c- predict(fit.rpart, test, type = \u0022class\u0022)\nacc.rpart \u003c- confusionMatrix(test$Survived, pred.rpart)\n\nrpart \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.rpart$byClass, time.rpart[3]),3))\nrpart\n\n```\n\n## Random Forest\nThis is random forest from the ranger package. I like this because of the speed. \n \n```{r ranger}\nlibrary(ranger)\n\n\ntime.ranger \u003c- system.time(csrf(Survived ~ ., training_data = train, test_data = test, params1 = list(num.trees = 300, mtry = 4), params2 = list(num.trees = 5)))\n#fit.ranger \u003c- ranger(Survived~., data = train)\n#pred.ranger \u003c- predict(fit.ranger, test)\n\ntune.ranger \u003c- csrf(Survived ~ ., training_data = train, test_data = test, params1 = list(num.trees = 300, mtry = 4), params2 = list(num.trees = 10))\nacc.ranger \u003c- confusionMatrix(tune.ranger, test$Survived)\nranger \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.ranger$byClass, time.ranger[3]),3))\nranger\n\n```\n\n## Random Forest\nHere I am using the randomForest package for the run. I tried some basic tuning to find the best mtry and it didn\u0027t change much compared to untuned model \n\n```{r randomForest, echo=FALSE, warning=FALSE}\nlibrary(randomForest)\n\n# some tuning\ncv.randomforest \u003c- rfcv(x, y, cv.fold = 10, scale = \u0022log\u0022, step = 0.5, recursive = TRUE)\ntune.randomforest \u003c- tuneRF(x, y, ntreeTry = 150, stepFactor = 2, doBest = TRUE)\n\n# run model\ntime.randomforest \u003c- system.time(tuneRF(x, y, ntreeTry = 150, stepFactor = 2, doBest = TRUE))\n\npred.randomforest \u003c- predict(tune.randomforest, test) \nacc.randomforest \u003c- confusionMatrix(pred.randomforest, test$Survived)\n\nrandomforest \u003c- c(family = \u0022Decision trees\u0022, round(c(acc.randomforest$byClass, time.randomforest[3]),3))\nrandomforest\n\n```\n\n## Models Comparison\nYou can see ensembled trees like ranger and randomforest giving highest accuracy compared to the rest. However both models lack in specificity which is prediction of Survived = 1. The rpart model is best in specificity, and having a more balanced accuracy comparared to the former. I am tempted to stack rpart and ranger together to get the best of both worlds but I will leave that for another day.\n```{r comp, echo= FALSE}\ncomp \u003c- data.frame(rbind(glm, glmnet,  rpart, ctree, ranger, randomforest), stringsAsFactors = FALSE)\ncomp[,13] \u003c- as.numeric(comp[,13])\nc \u003c- comp[order(comp$Balanced.Accuracy, decreasing = TRUE), c(1,13,12, 2:5)]\nc\n```\n\n# Final Submission\nI am going to use randomForest for the submission. \n\n## Submission Data\nLets look at the submission dataset again. Everything looks similar to raw only without the Survived variable\n```{r, echo = TRUE}\nhead(submit)\nstr(submit)\n```\n\n## Missing Values\nLots of missing values in Cabin, Age and Fare. We won\u0027t be using Cabin so we will have to impute Age and Fare. I am going to use same method as per the train dataset to impute the missing values\n```{r, echo= TRUE}\nna \u003c- sum(is.na(submit))\nna\nnap \u003c- apply(submit, 2, function(x) sum(is.na(x)))\nnap\n```\n\nI will predict the missing \u0027Age\u0027 using ctree from party package. We are going to use a temporary dataframe \u0027ages\u0027 for this prediction. We are going to exclude PassengerId, Name, Ticket and Cabin for this run.\n```{r, echo = TRUE}\nlibrary(party)\nages2 \u003c- submit\nages2$Sex \u003c- as.factor(ages2$Sex)\nages2$Embarked \u003c- as.factor(ages2$Embarked)\n\ntrain.age2 \u003c- ages2[complete.cases(ages2$Age),-c(1,3, 8, 10)]  # complete Age\ntest.age2 \u003c- ages2[is.na(ages2$Age), -c(1,3, 8, 10)]           # missing Age\n\nfit.age2 \u003c- ctree(Age~., data = train.age2)\npred.age2 \u003c- predict(fit.age2, test.age2)\nsummary(pred.age2)\n```\n\nLets combine this Age prediction into the testing dataframe to see whether it makes any sense. I think its logical that any person below 18 years should be accompanied by their parents or siblings right? Lets take a look\n```{r echo=, warning=FALSE}\ntest.age2$Age \u003c- round(pred.age2,1)\ny2 \u003c- test.age2[test.age2$Age \u003c 18,]\ny2\n```\nLooks ok since imputed Age below 18 have at least 1 SibSp or Parch. Also when compared against Pclass, the imputed range looks reasonable. Pclass 3 is a little suspect since some Fares are higher than Pclass 1. \n```{r, echo = TRUE}\ng \u003c- ggplot(test.age2, aes(x = factor(Pclass), y = Fare, color = Age)) + geom_point() + ggtitle(\u0022Imputed Age\u0022)\ng\n```\n\nSo we are going to use the predicted values for the missing values in Age\n```{r, echo = TRUE}\nsubmit$Age[is.na(submit$Age)] \u003c- round(pred.age2,1)\nsum(is.na(submit$Age))\n```\n\nLast one is Fare. I am going to use the mean for this one. Lets look at the missing Fare. Passenger is male, Age 60.5, Pclass 3 and embarked at Southampton. We can use that info to calculate the mean\n```{r, echo = TRUE}\nfare \u003c- submit[is.na(submit$Fare),]\nfare\n\n```\n\nI am going to filter the data based on sex = male, Age \u003e 40, Pclass = 3 and embarked = S. Mean of fare is 20.6\n```{r, echo = TRUE}\nfare2 \u003c- submit[complete.cases(submit$Fare),]\nfare2 \u003c- fare2[fare2$Pclass == 3,]\nfare2 \u003c- fare2[fare2$Sex == \u0022male\u0022,]\nfare2 \u003c- fare2[fare2$Age \u003e= 40,]\nfare2 \u003c- fare2[fare2$Embarked == \u0022S\u0022,]\nmeanfare \u003c- mean(fare2$Fare)\nmeanfare\n```\n\nLets assign this fare to passenger 1044. We are ready to run our model!\n```{r, echo = TRUE}\nsubmit$Fare[submit$PassengerId == 1044] \u003c- meanfare\napply(submit, 2, function(x) sum(is.na(x)))\n```\n\n## The Prediction \nBefore running the final prediction, lets get the data in proper format. It should follow \u0027data\u0027\n```{r, echo=TRUE}\nsetdiff(names(submit), names(data))\n```\n\nI am going to exclude the above from submit\n```{r, echo = TRUE}\nnames(submit)\nsubmit \u003c- submit[,-c(1,3,8,10)]\nstr(data)\n```\n\nSet Sex and Embarked as factor\n```{r, echo = TRUE}\nsubmit$Sex \u003c- as.factor(submit$Sex)\nsubmit$Embarked \u003c- as.factor(submit$Embarked)\nstr(submit)\n```\n\nNow, for the moment of truth!\n```{r, echo = TRUE}\npred.randomforest \u003c- predict(tune.randomforest, submit) \npred.randomforest\nsubmit2 \u003c- read.csv(\u0022test.csv\u0022, sep = \u0022,\u0022 , strip.white = TRUE, stringsAsFactors = FALSE, header = TRUE, na.strings = \u0022\u0022)\nsubmission \u003c- data.frame(PassengerId = submit2$PassengerId, Survived = pred.randomforest)\nsubmission\n```","dateCreated":"2018-03-15T03:17:08.21Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e945524\u003c/disk_kb_free\u003e\u003cdocker_image_digest\u003e52937f97db1d60cc30110f82402aec2d3dec26569f3ae4239adbe334f10492ad\u003c/docker_image_digest\u003e\u003cdocker_image_id\u003esha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a\u003c/docker_image_id\u003e\u003cdocker_image_name\u003egcr.io/kaggle-images/rstats\u003c/docker_image_name\u003e\u003cexit_code\u003e1\u003c/exit_code\u003e\u003cfailure_message\u003eThe kernel returned an unsuccessful exit code (1).\u003c/failure_message\u003e\u003cinvalid_path_errors\u003eFalse\u003c/invalid_path_errors\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e9.44572291406803\u003c/run_time_seconds\u003e\u003csucceeded\u003eFalse\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageDigest":"52937f97db1d60cc30110f82402aec2d3dec26569f3ae4239adbe334f10492ad","dockerImageId":"sha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a","dockerImageName":"kaggle/rstats","diskKbFree":945524,"failureMessage":"The kernel returned an unsuccessful exit code (1).","exitCode":1,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":9.44572291406803,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":false,"wasKilled":false},"outputFilesTotalSizeBytes":0,"dockerImageVersionId":47,"usedCustomDockerImage":false},"author":{"id":1711007,"displayName":"Nor Azman Zakaria","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"azmanvai","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1711007-kg.jpg","profileUrl":"/azmanvai","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/azmanvai/titanic-prediction","collaborators":{"owner":{"userId":1711007,"groupId":null,"groupMemberCount":null,"profileUrl":"/azmanvai","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1711007-kg.jpg","name":"Nor Azman Zakaria","slug":"azmanvai","userTier":0,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022\\n\\nprocessing file: script.Rmd\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.477349865948781\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |                                                                 |   0%\\r  |                                                                       \\r  |.                                                                |   1%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 4.694392614997923\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.                                                                |   2%\\nlabel: unnamed-chunk-1 (with options) \\nList of 1\\n $ include: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 4.728433461976238\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..                                                               |   3%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.74922337604221\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..                                                               |   4%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.782839084044099\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-2 (with options) \\nList of 2\\n $ echo   :\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.909224980976433\n},{\n  \u0022data\u0022: \u0022 logi TRUE\\n $ warning: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.943720937008038\n},{\n  \u0022data\u0022: \u0022Quitting from lines 25-27 (script.Rmd) \\nError in file(file, \\\u0022rt\\\u0022) : cannot open the connection\\nCalls: render ... withVisible -\u003e eval -\u003e eval -\u003e read.csv -\u003e read.table -\u003e file\\nIn addition: Warning message:\\nIn file(file, \\\u0022rt\\\u0022) :\\n  cannot open file \u0027train.csv\u0027: No such file or directory\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 9.143552694004029\n},{\n  \u0022data\u0022: \u0022\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 9.1475785280345\n},{\n  \u0022data\u0022: \u0022Execution halted\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 9.17969911696855\n}]","outputFiles":[],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":735498,"kernelVersionId":2808947,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..xaBF7QZSwixDXhJAGO-CHg.2IJ_m5W0hE94CDb3N1UH14ukVEsCEeO63aUDo7DYNYpxhkiP4vyvyoxHFTYTM8bacR-0w7UdkQE_cYp7k7xX942uSCAR0htwVzq8Z8LPlVlXG49Sozs-DweocVldioFy9N0y8LmC6TZXqCR59tITp6B1dyGBo6BdUfZblHaAwux1ZvZY1_CWtiZW68rM2k5mWSD7j-4cw6upol3YmRP89jWGsbegcZWzzAp1mRXQS0EVjSHhnE2VLODJRprPnuJP5q8Lgdv7ZMaoCiB3Qc5Q929RCbKszqppZfCOXCaJNM7slVJ1OSuaA_RvNK9jgH2KWjI20aP08bfaJ21385dM2SmNZ5GUrwYps0jArmcTub5B1DE9Zx6OTJhGrvdIBnlT_1Pq2IJoxZhncUbkILAI9nf2HEzxjwuNIur7M_VhjHuOmd6iZd-iek4AbPhnVTtKGwpLpuE3OXmxmghA2DoTTA.sHzs8DXGHOZFqgbk6jvpTA","scope":"azmanvai/titanic-prediction"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","sourceUrl":"/c/titanic","slug":"titanic","lastUpdated":"2012-09-28T21:13:33.55Z","overview":"Start here! Predict survival on the Titanic and get familiar with ML basics","sourceType":"competition","sourceVersionType":null,"sourceId":3136,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":"text/html","deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":26502,"dataset":null,"competition":{"competitionId":3136,"dataviewToken":null,"scope":"c/titanic"},"kernel":null,"previewsDisabled":true},"type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"id":63842,"blobFileId":37991,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/gender_submission.csv","creationDate":"2017-02-01T01:49:18Z","isDummy":false,"size":3258,"fullPath":"../input/gender_submission.csv","previewUrl":"kernels/competition-preview/3136?relativePath=gender_submission.csv","downloadUrl":"/c/titanic/download/gender_submission.csv","fileType":".csv","contentLength":3258,"contentType":"text/csv","contentMD5":"MNEHO5ZKXYFUMexgOg3jUw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n"},{"order":1,"originalType":"","type":"boolean","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"gender_submission.csv","description":"892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,0\n901,0\n902,0\n903,0\n904,1\n905,0a\n906,1\n907,0\n908,0\n909,0\n910,0\n911,0\n912,1\n913,0\n914,0\n915,0\n916,1\n917,0\n918,0\n919,0\n920,0\n921,0\n922,0\n923,0\n924,0\n925,0\n926,1\n927,0\n928,0\n929,0\n930,0\n931,1\n932,0\n933,0\n934,0\n935,0\n936,1\n937,0\n938,0\n939,0\n940,1\n941,0\n942,1\n943,0\n944,0\n945,1\n946,0\n947,0\n948,0\n949,0\n950,0\n951,1\n952,0\n953,0\n954,0\n955,0\n956,1\n957,0\n958,0\n959,0\n960,0\n961,1\n962,\n963,0\n964,0\n965,0\n966,1\n967,1\n968,0\n969,0\n970,0\n971,0\n972,0\n973,1\n974,0\n975,0\n976,0\n977,0\n978,0\n979,0\n980,0\n981,0\n982,0\n983,0\n984,0\n985,0\n986,0\n987,0\n988,1\n989,0\n990,0\n991,0\n992,1\n993,0\n994,0\n995,0\n996,0\n997,0\n998,0\n999,0\n1000,0\n1001,0\n1002,0\n1003,0\n1004,0\n1005,0\n1006,1\n1007,0\n1008,0\n1009,0\n1010,1\n1011,0\n1012,0\n1013,0\n1014,1\n1015,0\n1016,0\n1017,0\n1018,0\n1019,0\n1020,0\n1021,0\n1022,0\n1023,0\n1024,0\n1025,0\n1026,0\n1027,0\n1028,0\n1029,0\n1030,0\n1031,0\n1032,0\n1033,1\n1034,1\n1035,0\n1036,0\n1037,0\n1038,1\n1039,0\n1040,0\n1041,0\n1042,1\n1043,0\n1044,0\n1045,0\n1046,0\n1047,0\n1048,1\n1049,0\n1050,0\n1051,0\n1052,0\n1053,0\n1054,0\n1055,0\n1056,0\n1057,0\n1058,1\n1059,0\n1060,0\n1061,0\n1062,0\n1063,0\n1064,0\n1065,0\n1066,0\n1067,0\n1068,0\n1069,1\n1070,0\n1071,1\n1072,0\n1073,1\n1074,1\n1075,0\n1076,1\n1077,0\n1078,0\n1079,0\n1080,1\n1081,0\n1082,0\n1083,0\n1084,0\n1085,0\n1086,0\n1087,0\n1088,1\n1089,0\n1090,0\n1091,0\n1092,0\n1093,0\n1094,1\n1095,0\n1096,0\n1097,0\n1098,0\n1099,0\n1100,0\n1101,0\n1102,0\n1103,0\n1104,1\n1105,0\n1106,0\n1107,0\n1108,0\n1109,1\n1110,1\n1111,0\n1112,0\n1113,0\n1114,0\n1115,0\n1116,0\n1117,0\n1118,0\n1119,0\n1120,0\n1121,0\n1122,1\n1123,0\n1124,0\n1125,0\n1126,1\n1127,0\n1128,1\n1129,0\n1130,0\n1131,1\n1132,0\n1133,0\n1134,1\n1135,0\n1136,0\n1137,1\n1138,0\n1139,0\n1140,0\n1141,0\n1142,0\n1143,0\n1144,1\n1145,0\n1146,0\n1147,0\n1148,0\n1149,0\n1150,0\n1151,0\n1152,0\n1153,0\n1154,0\n1155,0\n1156,0\n1157,0\n1158,0\n1159,0\n1160,0\n1161,0\n1162,1\n1163,0\n1164,1\n1165,0\n1166,0\n1167,0\n1168,0\n1169,0\n1170,0\n1171,0\n1172,0\n1173,0\n1174,0\n1175,0\n1176,0\n1177,0\n1178,0\n1179,1\n1180,0\n1181,0\n1182,0\n1183,0\n1184,0\n1185,1\n1186,0\n1187,0\n1188,0\n1189,0\n1190,1\n1191,0\n1192,0\n1193,0\n1194,0\n1195,0\n1196,0\n1197,0\n1198,1\n1199,0\n1200,1\n1201,0\n1202,0\n1203,0\n1204,0\n1205,0\n1206,1\n1207,0\n1208,1\n1209,0\n1210,0\n1211,0\n1212,0\n1213,0\n1214,0\n1215,0\n1216,1\n1217,0\n1218,0\n1219,1\n1220,0\n1221,0\n1222,0\n1223,0\n1224,0\n1225,0\n1226,0\n1227,0\n1228,0\n1229,0\n1230,0\n1231,0\n1232,0\n1233,0\n1234,1\n1235,1\n1236,0\n1237,0\n1238,0\n1239,0\n1240,0\n1241,0\n1242,1\n1243,0\n1244,1\n1245,1\n1246,0\n1247,0\n1248,1\n1249,0\n1250,0\n1251,0\n1252,1\n1253,0\n1254,0\n1255,0\n1256,1\n1257,1\n1258,0\n1259,0\n1260,0\n1261,0\n1262,0\n1263,1\n1264,0\n1265,0\n1266,1\n1267,1\n1268,0\n1269,0\n1270,1\n1271,0\n1272,0\n1273,0\n1274,0\n1275,0\n1276,0\n1277,1\n1278,0\n1279,0\n1280,0\n1281,0\n1282,1\n1283,0\n1284,0\n1285,0\n1286,0\n1287,1\n1288,0\n1289,1\n1290,0\n1291,0\n1292,1\n1293,0\n1294,0\n1295,1\n1296,0\n1297,0\n1298,0\n1299,1\n1300,0\n1301,0\n1302,0\n1303,1\n1304,0\n1305,0\n1306,1\n1307,0\n1308,0\n1309,0"},{"id":63841,"blobFileId":2613,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/test.csv","creationDate":"2013-06-28T13:40:24.227Z","isDummy":false,"size":28629,"fullPath":"../input/test.csv","previewUrl":"kernels/competition-preview/3136?relativePath=test.csv","downloadUrl":"/c/titanic/download/test.csv","fileType":".csv","contentLength":28629,"contentType":"text/csv","contentMD5":"dTO4Lq5LWCYQy9aKpjawFw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"1"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"1"},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"the name of the passenger"},{"order":3,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":null},{"order":4,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":null},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"of siblings / spouses aboard the Titanic"},{"order":6,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"of parents / children aboard the Titanic"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":"Ticket number"},{"order":8,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":"Passenger fare"},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":"Cabin number"},{"order":10,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"Port of Embarkation"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"test.csv","description":"test data to check the accuracy of the model created\n"},{"id":63840,"blobFileId":2307,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/train.csv","creationDate":"2013-06-28T13:40:25.23Z","isDummy":false,"size":61194,"fullPath":"../input/train.csv","previewUrl":"kernels/competition-preview/3136?relativePath=train.csv","downloadUrl":"/c/titanic/download/train.csv","fileType":".csv","contentLength":61194,"contentType":"text/csv","contentMD5":"IwnMXwR4Ltm7YBbZ9OOBzw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":891},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"type should be integers"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"Survived or Not "},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"Class of Travel"},{"order":3,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"Name of Passenger"},{"order":4,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":"Gender"},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":"Age of Passengers"},{"order":6,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"Number of Sibling/Spouse aboard"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"Number of Parent/Child aboard"},{"order":8,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":null},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":null},{"order":10,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":null},{"order":11,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"train.csv","description":"contains data \n"}],"name":"Titanic: Machine Learning from Disaster","description":"\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe data has been split into two groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etraining set (train.csv)\u003c/li\u003e\n\u003cli\u003etest set (test.csv)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cb\u003e The training set \u003c/b\u003eshould be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use \u003ca href=\u0022https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\u0022 target=\u0022_blank\u0022\u003e feature engineering \u003c/a\u003eto create new features.\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eThe test set \u003c/b\u003eshould be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\u003c/p\u003e\n\u003cp\u003eWe also include \u003cb\u003egender_submission.csv\u003c/b\u003e, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\u003c/p\u003e\n\u003ch3\u003eData Dictionary\u003c/h3\u003e\n\u003ctable style=\u0022width: 100%;\u0022\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003cth\u003e\u003cb\u003eVariable\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eDefinition\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eKey\u003c/b\u003e\u003c/th\u003e\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esurvival\u003c/td\u003e\n\u003ctd\u003eSurvival\u003c/td\u003e\n\u003ctd\u003e0 = No, 1 = Yes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epclass\u003c/td\u003e\n\u003ctd\u003eTicket class\u003c/td\u003e\n\u003ctd\u003e1 = 1st, 2 = 2nd, 3 = 3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esex\u003c/td\u003e\n\u003ctd\u003eSex\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAge\u003c/td\u003e\n\u003ctd\u003eAge in years\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esibsp\u003c/td\u003e\n\u003ctd\u003e# of siblings / spouses aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eparch\u003c/td\u003e\n\u003ctd\u003e# of parents / children aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eticket\u003c/td\u003e\n\u003ctd\u003eTicket number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003efare\u003c/td\u003e\n\u003ctd\u003ePassenger fare\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecabin\u003c/td\u003e\n\u003ctd\u003eCabin number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eembarked\u003c/td\u003e\n\u003ctd\u003ePort of Embarkation\u003c/td\u003e\n\u003ctd\u003eC = Cherbourg, Q = Queenstown, S = Southampton\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eVariable Notes\u003c/h3\u003e\n\u003cp\u003e\u003cb\u003epclass\u003c/b\u003e: A proxy for socio-economic status (SES)\u003cbr /\u003e 1st = Upper\u003cbr /\u003e 2nd = Middle\u003cbr /\u003e 3rd = Lower\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eage\u003c/b\u003e: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003esibsp\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Sibling = brother, sister, stepbrother, stepsister\u003cbr /\u003e Spouse = husband, wife (mistresses and fiancés were ignored)\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eparch\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Parent = mother, father\u003cbr /\u003e Child = daughter, son, stepdaughter, stepson\u003cbr /\u003e Some children travelled only with a nanny, therefore parch=0 for them.\u003c/p\u003e"}],"versions":[{"id":2808947,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2018-03-15T03:17:08.21Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":515,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":1,"failureMessage":"The kernel returned an unsuccessful exit code (1).","isValidStatus":true,"runTimeSeconds":9.44572291406803,"succeeded":false,"timeoutExceeded":false,"usedAllSpace":false},"status":"error","title":"Titanic Prediction","url":"/azmanvai/titanic-prediction?scriptVersionId=2808947","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null}],"categories":{"categories":[],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/2808947","submission":null,"menuLinks":[{"href":"/azmanvai/titanic-prediction/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/azmanvai/titanic-prediction/data","text":"Data","title":"Data","tab":"data","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/azmanvai/titanic-prediction/comments","text":"Comments","title":"Comments","tab":"comments","count":0,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null},{"href":"/azmanvai/titanic-prediction/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/azmanvai/titanic-prediction/versions","text":"Versions","title":"Versions","tab":"versions","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/azmanvai/titanic-prediction/forks","text":"Forks","title":"Forks","tab":"forks","count":0,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/2808947","text":"Fork Script","title":"Fork Script","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":"kernels","reportEventType":"anonymousKernelForkCreation"},"voteButton":{"totalVotes":1,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=735498","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1711007-kg.jpg","displayName":"Nor Azman Zakaria","profileUrl":"/azmanvai","tier":"Novice","tierInt":0,"userId":1711007,"userName":"azmanvai"}],"currentUserInfo":null,"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"Titanic: Machine Learning from Disaster","parentUrl":"/c/titanic","thumbnailImageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"canSeeCopyAndEditText":true,"simplifiedViewer":false,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="/azmanvai/titanic-prediction" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL-8dIqhEHDxJ1uZILY0Wv9mkYkxBkNuT374OrQaUUfd5RqudFA84WTuHtGL_zIgqR7OlKhuiTv7n2RSBwTO88advSNtmJt_nNlGv-VfwJxmIXJmly2gDowzeQIgtdACHUo" /></form>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async crossorigin="anonymous" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>&copy; 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="/team">Our Team</a>
            <a href="/terms">Terms</a>
            <a href="/privacy">Privacy</a>
            <a href="/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>




    </main>
</body>
</html>
