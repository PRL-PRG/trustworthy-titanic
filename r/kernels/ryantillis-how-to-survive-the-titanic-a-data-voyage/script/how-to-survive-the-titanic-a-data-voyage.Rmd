---
title: "How to Survive the Titanic - A Data Voyage"
author: <a href="http://www.ryantillis.com"> Ryan Tillis </a>
date: "11/10/2016"
output: 
html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.height = 2.5)
library(dplyr)
library(data.table)
library(ggplot2)
library(DT)
library(plotly)
library(mice)
library(stringi)
```

## Synopsis

The goal is to predict titanic survivors from a dataset that features the passenger's class, name, sex, age, number of siblings/spouses aboard, number of parents/child aboard, ticket number, fare, and the embarking port. Check out my app that displays the results in a fun way. This data set has been looked at many times, and has Random Forest written all over it. The goal is to provide a brief data exploration with exploratory visualizations, feature discrimination, and predictive modeling.

##Exploring the Variables
We start by loading the data and examing the first 6 rows.
```{r loading}

##Include length of name metric
##Include Pictures for class selection
##Make Fare input dependent on class
#Picture of deck
train <- read.csv("../input/train.csv")
test <- read.csv("../input/train.csv")
train <- as.data.table(train)
test. <- as.data.table(test)
names(train)
```
<hr>
##Class
<gr>
The class variable has 3 distinct levels. The largest group is in class 3 with a close split between classes 1 and 2, slightly more in class 1.

```{r Pclass}
train$Pclass <- as.factor(train$Pclass)
summary(train$Pclass)
```

Most people are in 3rd class (coach), and although it might be cheap...it doesn't fare well. From this chart alone it seems that 3rd class passenger are nearly 3 times more likely not to make it.

```{r chart1, echo = FALSE}
ggplot(train, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge')# + scale_col_manual(colors()[78], colors()[16], colors()[55])
```

<hr>
##Name
<hr>

Average length of a name is 27 characters with a max of 82.
```{r Name, echo = FALSE}
summary(sapply(as.character(unique(train$Name)),nchar))#Summary of lengths of name
```
Most people are just plain Mr and Mrs, but there are some special titles that might be interesting for prediction.
```{r Tsplit, echo = FALSE}
train$Title <- gsub('(.*, )|(\\..*)', '', train$Name)

# Show titles by sex
table(train$Sex, train$Title)
```
<hr>
##Sex
<hr>
Nearly twice as many men
```{r sexs, echo = FALSE}
summary(train$Sex)#Almost twice as many men
```

```{r sexc, echo = FALSE}
sb <- ggplot(train, aes(x=Sex)) + geom_bar(fill=c(colors()[542], colors()[121]), col=c(colors()[543], colors()[123]), lwd = 2)+labs(x="Class")
sb
```
<hr>
##Age
<hr>
Average age around 30 years old with 177 NA's. Need to find a way to impute these values.
```{r age, echo = FALSE, warning = FALSE}
summary(train$Age) #177 NA's, Median age is 28 aka born in 1884 (start of input), 

ap <- ggplot(train, aes(x=Age))+geom_density(adjust=.5)
ap
```
<hr>
##Siblings and Spouses
<hr>
Most people are going it alone. The median is 0, and only about 1/4 of people are with siblings or spouses.

```{r SibSp, include = FALSE}
unique(train$SibSp)
```

```{r sib2}
train$SibSp <- as.integer(train$SibSp) #possibly alone vs with family variable 
summary(train$SibSp) #median is 0
```

There are 283 people who have sibling and/or spouses on board.

```{r sib3, echo = FALSE}
dim(train[SibSp > 0,])
```

The remaining 608 are going stag into that good night.

```{r sib4, echo = FALSE}
dim(train[SibSp == 0,])
```

```{r sibplots, echo=FALSE}
ggplot(train, aes(x = SibSp, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:7)) +
  labs(x = 'SibSp')
```
These charts suggests that the only beneficial configuration is to have 1 sibling or spouse. They are the only group which is more likely to survive. This could be indicative of single mothers, or perhaps of couples although Jack and Rose are a formidable counter to that proposition.
```{r sibp, echo=FALSE}
ggplot(train, aes(x = SibSp, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:7)) +
  labs(x = 'SibSp')+ ylim(0,115)
```
<hr>
##Parents and Children
<hr>
Again, the data suggests that most people are making the voyage alone.
```{r Parch, echo = FALSE}
summary(train$Parch)
```
There are 213 people traveling with their children or parents
```{r p1, echo=FALSE}
dim(train[Parch > 0,])
```
The other 678 are by themselves.
```{r p2,echo=FALSE}
dim(train[Parch == 0,])
```

This first chart shows the overwhelming disadvantage of traveling alone.

```{r p3, echo=FALSE}
ggplot(train, aes(x = Parch, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:7)) +
  labs(x = 'Parch')
```

This one shows that have 1-3 children/parents is potential beneficial.

```{r p4, echo = FALSE}
ggplot(train, aes(x = Parch, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:7)) +
  labs(x = 'Parch')+ ylim(0,65)
```
<hr>
##Ticket
<hr>
There are 681 unique ticket identifiers. The tickets have prefix identifiers and limited initial digits which might encode more information about the passenger.
```{r Ticket, echo = FALSE}
length(unique(train$Ticket)) #Create Ticket pre and ticket num and LINE value all as non-integers
tt <- data.table(names(summary(train$Ticket)),summary(train$Ticket))
names(tt) <- c("Ticket", "Count")
setorder(tt, -Count)
```

```{r tplot, echo = FALSE}
datatable(tt)
#Use ticket to predict cabin

train$FL <- stri_extract_first_regex(train$Ticket, "[A-Z]+") #Grabs first Text occurence
train$FT <- stri_extract_first_regex(train$Ticket, "[0-9][0-9]+") #Grabs ticket number
train[is.na(train$FL),]$FL <- "NA"
```

###Decoding the Tickets

This graph shows that some of the tickt prefix's are associated with higher prices. The fare should already account for this variance, so unless we can find another relationship with the prefix then it is not worthwhile to include this variable. 
```{r plot, echo = FALSE}
tpref <- train[!train$FL=="NA",]
gg <- ggplot(aes(y = Fare, x = FL), data = tpref) + geom_boxplot() + labs(title="Ticket Prefix")
gg
```

This confirms that the ticket encodes more information, but for it to be useful will have to dig deeper. the plot below shows that those with the ticket prefix PC are considerably more likely to survive. This graph is confounded by the price of the ticket. Some of the prefixes are intriguing. A, CA, SOTON, and W have extremely high casualty rates relative to all the others.


```{r ticketplot, echo = FALSE}
p2 <- ggplot(aes(x = FL, fill = factor(Survived)), data = tpref) + geom_bar(stat='count', position='dodge') + labs(title="Ticket Prefix")
p2

```

If we dig a little further, what do these prefixes have in common? If we look at the length of the numerical components of the tickets we find something interesting...The suffixes I mentioned about generally have shorter ticket numbers. The max is 2 less, and the median is 2 less. This is particularly interesting because there are tickets without prefixs that also have shorter tickets, so maybe we have something good.

```{r dig}
tfix <- tpref[tpref$FL %in% c("A", "CA", "Soton", "W"),]
summary(sapply(as.character(train$FT),nchar))
summary(sapply(as.character(tfix$FT), nchar))
```

We'll come back to this later once we wrap up this decoding.

```{r numlength}
train$ticketlength <- sapply(as.character(train$FT),nchar)
```

```{r plot23, echo = FALSE}
s1 <- ggplot(aes(x = factor(ticketlength), fill = factor(Survived)), data = train) + geom_bar(stat='count', position='dodge') + labs(title="Ticket Number Length")
s1

f1 <- ggplot(aes(x = factor(ticketlength), y=Fare, fill = factor(Survived)), data = train) + geom_boxplot() + labs(title="Ticket Number Length")
f1
```

At this risk of going a step too far, let's look at the individual ticket numbers. The premise is that they are non random, and potentially encode passenger location data which could effect the survival outcome. Price breakdown are included alongside to check for confounding effect.

To me, it looks like there are interesting effects happening for the first 5 digits. The great news is that we don't have to fully understand it...that's where machine learning comes in.

```{r plot2, echo = FALSE, fig.height=20}
library(gridExtra)
train$one <- sapply(train$FT, function(x){substr(x,1,1)})
train$two <- sapply(train$FT, function(x){substr(x,2,2)})
train$three <- sapply(train$FT, function(x){substr(x,3,3)})
train$four <- sapply(train$FT, function(x){substr(x,4,4)})
train$five <- sapply(train$FT, function(x){substr(x,5,5)})
train$six <- sapply(train$FT, function(x){substr(x,6,6)})
train$seven <- sapply(train$FT, function(x){substr(x,7,7)})

train$one <- as.factor(train$one)
train$two <- as.factor(train$two)
train$three <- as.factor(train$three)
train$four <- as.factor(train$four)
train$five <- as.factor(train$five)
train$six <- as.factor(train$six)
train$seven <- as.factor(train$seven)

onep <- ggplot(aes(y = Fare, x = factor(one)), data = train) + geom_boxplot() + labs(title="First Digit Price")
ones <- ggplot(aes(x = factor(one), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Second Digit Survival")


twop <- ggplot(aes(y = Fare, x = factor(two)), data = train) + geom_boxplot() + labs(title="Second Digit Price")
twos <- ggplot(aes(x = factor(two), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Second Digit Survival")

threep <- ggplot(aes(y = Fare, x = factor(three)), data = train) + geom_boxplot() + labs(title="Third Digit Price")
threes <- ggplot(aes(x = factor(three), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Third Digit Survival")


fourp <- ggplot(aes(y = Fare, x = factor(four)), data = train) + geom_boxplot() + labs(title="Fourth Digit Price")
fours <- ggplot(aes(x = factor(four), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Fourth Digit Survival")

fivep <- ggplot(aes(y = Fare, x = factor(five)), data = train) + geom_boxplot() + labs(title="Fifth Digit Price")
fives <- ggplot(aes(x = factor(five), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Fifth Digit Survival")


sixp <- ggplot(aes(y = Fare, x = factor(six)), data = train) + geom_boxplot() + labs(title="Sixth Digit Price")
sixs <- ggplot(aes(x = factor(six), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Sixth Digit Survival")

sevenp <- ggplot(aes(y = Fare, x = factor(seven)), data = train) + geom_boxplot() + labs(title="Seventh Digit Price")
sevens <- ggplot(aes(x = factor(seven), fill = factor(Survived)), data = train) + geom_bar(stat='count') + labs(title="Seventh Digit Survival")

grid.arrange(onep,ones,twop,twos, threep, threes, fourp, fours, fivep, fives, sixp, sixs, sevenp, sevens, ncol=2, nrow =7)
```
<hr>
##Fare
<hr>
Apparently on the Titanic, only men get free rides. 
```{r unFare}
train[Fare==0]$Sex
```

There are 248 unique ticket prices.

```{r fthis, echo = FALSE}
length(unique(train$Fare)) #248 unique ticket prices, suggests 248 cabin assignment, use 
```

As expected, first class is way more expensive. 

```{r fw, echo=FALSE}
train %>% group_by(Pclass) %>% summarise_each(funs(min, max, mean, median),Fare) 
```

Turns out women pay $24 more on average per ticket. Not cool, Titanic.

```{r fthat, echo = FALSE}
train %>% group_by(Sex) %>% summarise_each(funs(min, max, mean, median),Fare) #Women pay way more for same (start of input)
#train %>% group_by(Sex, Pclass) %>% summarise_each(funs(min, max, mean, median),Fare) #Women pay way more for same (start of input)
```

<hr>
##Cabin
<hr>

There are 163 declared cabin values with 148 unique, a lot are missing. It's possible that the cabin information can be imputed based on ticket number, embarking port, and class.
```{r cabin, echo = FALSE}
sum(!substring(train$Cabin, 1, 1) == "")#Fill in cabin data
datatable(data.frame(summary(train$Cabin))) # is it safe to impute cabin data?
```

###Decoding Cabin Data

Creating a cabin letter variable.
```{r CabinLetter}
train$CL <- substring(train$Cabin, 1, 1)
train$CL <- as.factor(train$CL)
unique(train$CL)
```

The subset is disproportionately 1st class and from Cherbourg and Southampton.
```{r Csum}
summary(train[!substring(train$Cabin, 1, 1) == "",]$Embarked)
summary(train[!substring(train$Cabin, 1, 1) == "",]$Pclass)

```

First graph shows B and C cabins are more expensive.

```{r cabinsplit, echo = FALSE}

cabins <- train[!substring(train$Cabin, 1, 1) == "",]
cabins$PCL <- interaction(cabins$Pclass, cabins$CL)
gg <- ggplot(aes(y = Fare, x = CL, fill = factor(Survived)), data = cabins) + geom_boxplot()
gg
```

Second graph shows there may be some interesting relationships here for survival. It's important to remember that this subset is already more likely to survive because of their first class status.

```{r cabinsplit2, echo=FALSE}
g2 <- ggplot(aes(x = CL, fill = factor(Survived)), data = cabins) + geom_bar(stat='count')
g2
```

Based on the data, it seems difficult to accurately impute the cabin assignments for the rest of the dataset. Instead, let's create a  
binary variable for "assigned room" or "not assigned". This could potentially account for more variance in the initial dataset. One hypothesis is that the people who have room assignment had some standing or status and got priority choice, which may be reflected relative to their survival. 

```{r cabinbin}
#train$Assigned <- 0
#train[!substring(train$Cabin, 1, 1) == "",]$Assigned <- 1
```

<hr>
##Embarked
<hr>
There are 3 departure locations, most people are from Southampton then Cherbourg and Queenstown.
```{r Embarked, echo = FALSE}
unique(train$Embarked)
summary(train$Embarked)
```

There are 2 missing values for embarking point. Which brings us to imputation.

```{r miss, echo = FALSE}
#Missing Values
datatable(train[Embarked=="",])
```
<hr>
## Imputation
<hr>

The only missing values are in the Cabin, Age, and Embarked columns.
```{r pressure, echo = FALSE}
apply(train=="",2, sum)
apply(is.na(train),2, sum)
```

```{r pr, results = 'hide'}
train <- as.data.frame(train)
#Imputing the missing age values with the MICE package
impute <- mice(train[, !names(train) %in% c('PassengerId','Name','Ticket','Cabin','Survived', 'Assigned','FL','FT','ticketlength','one','two','three','four','five','six','seven')], method='rf')

trained_mouse <- complete(impute)
```

```{r pplot, echo = FALSE, warning = FALSE}
#Plotting Histograms
ap <- ggplot(train, aes(x=Age))+geom_density(adjust=.5)+labs(title="Original Data")
ap
mp <- ggplot(trained_mouse, aes(x=Age))+geom_density(adjust=.5)+labs(title="Imputed Data")
mp
```

Since the results are reasonably well matched, we can replace the original column with the imputed values.

```{r replace1}
train$Age <- trained_mouse$Age
```
<hr>
##The Curious Case of the Missing Cabin
<hr>
Now we are on to those 2 missing Embarked values. The first thing I thought to check with the cabin value. From the data, all cabins that begin in B embarked from either Southampton or Charbourg.
```{r Missing Cabin}
unique(train[grep("*^B", train$Cabin),]$Embarked)
```

The tickets cost $80, which is very close to the mean Fare of S passengers in B cabins

```{r cab, echo = FALSE}
train[grep("*^B", train$Cabin),] %>% group_by(Embarked) %>% summarize_each(funs(mean),Fare)
```

However, fare is closer to the median Fare of C passengers.

```{r mcab, echo = FALSE}
train[grep("*^B", train$Cabin),] %>% group_by(Embarked) %>% summarize_each(funs(median),Fare)
```

So, what seems like an innocent isolated missing value is actually an interesting question about imputing based on the mean or the median.

```{r bark, echo = FALSE}
bark <- train[grep("*^B", train$Cabin),] %>% group_by(Embarked)
bark <- bark[!bark$Embarked=="",]
#Also, there a 72.4% change of any passenger embarking from Southampton
ggplot(bark, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='red', linetype='dashed', lwd=2)
```

It might seem to make sense to impute by the median of C fares because that is the nearest value. However, if we look back at the Fare section we see that there's a 72.4% chance that any given passenger embarked from S.


```{r split, echo = FALSE}
summary(train$Embarked)
bark2 <- train[!train$Embarked=="",]
ggplot(bark2, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
    colour='red', linetype='dashed', lwd=2)
summary(train[grep("*^B", train$Cabin),]$Embarked)
```

Ultimately, I decided to go with 'S' and see where that gets us. 

```{r replace}
train$Embarked[c(62, 830)] <- 'S'
```

