
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ## ---- message = FALSE------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ## Load all the library required one by one
> 
> library('ggplot2') 
Warning message:
package ‘ggplot2’ was built under R version 3.6.2 
> library('caret') 
Loading required package: lattice
> library('dplyr') 

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
package ‘dplyr’ was built under R version 3.6.2 
> library('randomForest') 
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:dplyr’:

    combine

The following object is masked from ‘package:ggplot2’:

    margin

> library('rpart')
> library('rpart.plot')
> library('car')
Loading required package: carData

Attaching package: ‘car’

The following object is masked from ‘package:dplyr’:

    recode

Warning messages:
1: package ‘car’ was built under R version 3.6.2 
2: package ‘carData’ was built under R version 3.6.2 
> library('e1071')
> 
> 
> ##Lets Load raw data in the orginal form by setting stringsAsFactors = F
> 
> train.tit <- read.csv('../input/train.csv', stringsAsFactors = F)
> test.tit  <- read.csv('../input/test.csv', stringsAsFactors = F)
> test.tit$Survived <- NA
> 
> ##Combine both test and train
> full_titanic <- rbind(train.tit, test.tit)
> 
> ##Check the structure
> str(full_titanic)
'data.frame':	1309 obs. of  12 variables:
 $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
 $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
 $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Name       : chr  "Braund, Mr. Owen Harris" "Cumings, Mrs. John Bradley (Florence Briggs Thayer)" "Heikkinen, Miss. Laina" "Futrelle, Mrs. Jacques Heath (Lily May Peel)" ...
 $ Sex        : chr  "male" "female" "female" "female" ...
 $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
 $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Ticket     : chr  "A/5 21171" "PC 17599" "STON/O2. 3101282" "113803" ...
 $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Cabin      : chr  "" "C85" "" "C123" ...
 $ Embarked   : chr  "S" "C" "S" "S" ...
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###is there any Missing obesrvation
> colSums(is.na(full_titanic))
PassengerId    Survived      Pclass        Name         Sex         Age 
          0         418           0           0           0         263 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          0           0           0           1           0           0 
> 
> ####Empty data
> colSums(full_titanic=='')
PassengerId    Survived      Pclass        Name         Sex         Age 
          0          NA           0           0           0          NA 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          0           0           0          NA        1014           2 
> 
> ##Summary shows, Age missing 263 value, Cabin too having lot of missing value and embarked just 2
> 
> ###Lets replace Embarked by most frequest observation 
> 
> table(full_titanic$Embarked)

      C   Q   S 
  2 270 123 914 
> full_titanic$Embarked[full_titanic$Embarked==""]="S"
> table(full_titanic$Embarked)

  C   Q   S 
270 123 916 
> 
> ##As Age and Cabin has too many missing value, will check it during analysis Phase
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ###Check the length and see how many varibles of them we can move to factor for our analysis
> 
> apply(full_titanic,2, function(x) length(unique(x)))
PassengerId    Survived      Pclass        Name         Sex         Age 
       1309           3           3        1307           2          99 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          7           8         929         282         187           3 
> 
> 
> ###will convert the below varible into factor for ananlysis
> 
> cols=c("Survived","Pclass","Sex","Embarked")
> for (i in cols){
+   full_titanic[,i]=as.factor(full_titanic[,i])
+ }
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ## Hypothesis is that,  Rich folks survival rate is much better than poor folks, Does any diffrence in the Titanic?  
> 
> ###Visualize P class which is the best proxy for Rich and Poor  
> 
> ggplot(full_titanic[1:891,],aes(x = Pclass,fill=factor(Survived))) +
+ geom_bar() +
+ ggtitle("Pclass v/s Survival Rate")+
+ xlab("Pclass") +
+ ylab("Total Count") +
+ labs(fill = "Survived")  
> 
> ##No diffrences in the Titanic too, First class Survival rate is far more better than the 3rd class  
> ##No doubt Rich peope having better Survival rate than the poor
> 
> # Visualize the 3-way relationship of sex, pclass, and survival
> ggplot(full_titanic[1:891,], aes(x = Sex, fill = Survived)) +
+ geom_bar() +
+ facet_wrap(~Pclass) + 
+ ggtitle("3D view of sex, pclass, and survival") +
+ xlab("Sex") +
+ ylab("Total Count") +
+ labs(fill = "Survived")
> 
> ##In the all the class female Survival rate is better than Men
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> head(full_titanic$Name)
[1] "Braund, Mr. Owen Harris"                            
[2] "Cumings, Mrs. John Bradley (Florence Briggs Thayer)"
[3] "Heikkinen, Miss. Laina"                             
[4] "Futrelle, Mrs. Jacques Heath (Lily May Peel)"       
[5] "Allen, Mr. William Henry"                           
[6] "Moran, Mr. James"                                   
> ##Lets extract the title and check if we have predictive power in that
> names <- full_titanic$Name
> title <-  gsub("^.*, (.*?)\\..*$", "\\1", names)
> 
> full_titanic$title <- title
> 
> table(title)
title
        Capt          Col          Don         Dona           Dr     Jonkheer 
           1            4            1            1            8            1 
        Lady        Major       Master         Miss         Mlle          Mme 
           1            2           61          260            2            1 
          Mr          Mrs           Ms          Rev          Sir the Countess 
         757          197            2            8            1            1 
> 
> ###MISS, Mrs, Master and Mr are taking more numbers
> 
> ###Better to group Other titles into bigger basket by checking gender and survival rate to aviod any overfitting
> 
> 
> full_titanic$title[full_titanic$title == 'Mlle']        <- 'Miss' 
> full_titanic$title[full_titanic$title == 'Ms']          <- 'Miss'
> full_titanic$title[full_titanic$title == 'Mme']         <- 'Mrs' 
> full_titanic$title[full_titanic$title == 'Lady']          <- 'Miss'
> full_titanic$title[full_titanic$title == 'Dona']          <- 'Miss'
> 
> ## I am afraid creating a new varible with small data can causes a overfit
> ## However, My thinking is that combining below feauter into original variable may loss some predictive power as they are all army folks, doctor and nobel peoples 
> 
> full_titanic$title[full_titanic$title == 'Capt']        <- 'Officer' 
> full_titanic$title[full_titanic$title == 'Col']        <- 'Officer' 
> full_titanic$title[full_titanic$title == 'Major']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Dr']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Rev']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Don']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Sir']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'the Countess']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Jonkheer']   <- 'Officer'
> 
> 
> # Lets check who among Mr, Master, Miss having a better survival rate
>  ggplot(full_titanic[1:891,],aes(x = title,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Title V/S Survival rate")+
+   xlab("Title") +
+   ylab("Total Count") +
+   labs(fill = "Survived") 
> 
> ##In the titanic you are Mr then there is less chance of survival, Miss and Mrs having better survival rate then Master and Officer 
> 
> 
> ### Visualize the 3-way of relationship of Title, Pclass, and Survival
> 
> ggplot(full_titanic[1:891,], aes(x = title, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~Pclass) + 
+   ggtitle("3-way relationship of Title, Pclass, and Survival") +
+   xlab("Title") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ##Master in 1st and 2nd class has 100% Survival where has Mrs and Miss having 90% chance of Survival in 1st and 2nd class 
> ##Since Title mostly depending on Age (except few cases), I will use title in place of age which has 263 missing observation
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> # Lets create a Family size using Sibsp and Parch
> 
> full_titanic$FamilySize <-full_titanic$SibSp + full_titanic$Parch + 1
> 
> full_titanic$FamilySized[full_titanic$FamilySize == 1]   <- 'Single'
> full_titanic$FamilySized[full_titanic$FamilySize < 5 & full_titanic$FamilySize >= 2]   <- 'Small'
> full_titanic$FamilySized[full_titanic$FamilySize >= 5]   <- 'Big'
> 
> full_titanic$FamilySized=as.factor(full_titanic$FamilySized)
> 
> 
> ###Lets Visualize the Survival rate by Family size 
> ggplot(full_titanic[1:891,],aes(x = FamilySized,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Family Size V/S Survival Rate") +
+   xlab("FamilySize") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ###Big Family in Titanic having worst survival rate then Smaller and Alone
> 
> ####Why Big Family has a probelm?, Check in the below visualization
> 
> ggplot(full_titanic[1:891,], aes(x = FamilySized, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~title) + 
+   ggtitle("3D View of Fmily Size, Title and Survival rate") +
+   xlab("family.size") +
+   ylab("Total Count") +
+   ylim(0,300) +
+   labs(fill = "Survived")
Warning message:
Removed 1 rows containing missing values (geom_bar). 
> 
> ##You are a Master in the Big Family your Survival rate is absolutely nill even though overall survival rate of master is very good
> 
> ###I am very surprised to see Single coming out to be bulk, however there is chance that, they could come with friends or servants
> ##I though to extract those unique number using same ticket number distributed.
> 
> 
> ##Engineer features based on all the passengers with the same ticket
> ticket.unique <- rep(0, nrow(full_titanic))
> tickets <- unique(full_titanic$Ticket)
> 
> for (i in 1:length(tickets)) {
+   current.ticket <- tickets[i]
+   party.indexes <- which(full_titanic$Ticket == current.ticket)
+   
+   
+   for (k in 1:length(party.indexes)) {
+     ticket.unique[party.indexes[k]] <- length(party.indexes)
+   }
+ }
> 
> full_titanic$ticket.unique <- ticket.unique
> 
> 
> full_titanic$ticket.size[full_titanic$ticket.unique == 1]   <- 'Single'
> full_titanic$ticket.size[full_titanic$ticket.unique < 5 & full_titanic$ticket.unique>= 2]   <- 'Small'
> full_titanic$ticket.size[full_titanic$ticket.unique >= 5]   <- 'Big'
> 
> ##Lets check the Ticket size through grpah
> ggplot(full_titanic[1:891,],aes(x = ticket.size,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("ticket.Size VS Survival")+
+   xlab("ticket.size") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ##Lets check the Ticket and title size through grpah
> ggplot(full_titanic[1:891,], aes(x = ticket.size, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~title) + 
+   ggtitle("3D View of Ticket, Title and Survival rate") +
+   xlab("ticket.size") +
+   ylab("Total Count") +
+   ylim(0,300) +
+   labs(fill = "Survived")
Warning message:
Removed 1 rows containing missing values (geom_bar). 
>   
> ##We can't see huge diffrence b/w ticket size and Family Size, May be we will use any one of them which is contributing more
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###is there any association between Survial rate and where he get into the Ship.   
>  ggplot(full_titanic[1:891,],aes(x = Embarked,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Embarked vs Survival") +
+   xlab("Embarked") +
+   ylab("Total Count") +
+   labs(fill = "Survived") 
> 
> ##Lets further divide the grpah by Pclass
> ggplot(full_titanic[1:891,], aes(x = Embarked, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~Pclass) + 
+   ggtitle("Pclass vs Embarked vs survival") +
+   xlab("Embarked") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ##Haha..I don't think there is a correlation between Survival rate and Embarked 
> 
> ##There is a lot of Missing value in Cabin, i dont think its good idea to use that
> ##As mentioned earlier will use Title inplace of Age 
> ##Fare is definitelly correlate with Pclass..so i am not going to use that too
> 
> full_titanic$ticket.size <- as.factor(full_titanic$ticket.size)
> full_titanic$title <- as.factor(full_titanic$title)
> 
> ##From the Explortory anlysis part we have decided to use below variables for our model building 
> 
> ##"Pclass", "title","Sex","Embarked","FamilySized","ticket.size"
> 
> ##Any redaundant varible among above will drop in the course of analysis
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###lets prepare and keep data in the proper format
> 
> feauter1<-full_titanic[1:891, c("Pclass", "title","Sex","Embarked","FamilySized","ticket.size")]
> response <- as.factor(train.tit$Survived)
> feauter1$Survived=as.factor(train.tit$Survived)
> 
> 
> ###For Cross validation purpose will keep 20% of data aside from my orginal train set
> ##This is just to check how well my data works for unseen data
> set.seed(500)
> ind=createDataPartition(feauter1$Survived,times=1,p=0.8,list=FALSE)
> train_val=feauter1[ind,]
> test_val=feauter1[-ind,]
> 
> ####check the proprtion of Survival rate in orginal training data, current traing and testing data
> round(prop.table(table(train.tit$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> round(prop.table(table(train_val$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> round(prop.table(table(test_val$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> 
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ##Random forest is for more better than Single tree however single tree is very easy to use and illustrate
> set.seed(1234)
> Model_DT=rpart(Survived~.,data=train_val,method="class")
> 
> 
> rpart.plot(Model_DT,extra =  3,fallen.leaves = T)
> 
> ###Surprise, Check out the plot,  our Single tree model is using only Title, Pclass and Ticket.size and vomited rest
> ###Lets Predict train data and check the accuracy of single tree
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> PRE_TDT=predict(Model_DT,data=train_val,type="class")
> confusionMatrix(PRE_TDT,train_val$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 412  86
         1  28 188
                                          
               Accuracy : 0.8403          
                 95% CI : (0.8114, 0.8665)
    No Information Rate : 0.6162          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6484          
                                          
 Mcnemar's Test P-Value : 9.37e-08        
                                          
            Sensitivity : 0.9364          
            Specificity : 0.6861          
         Pos Pred Value : 0.8273          
         Neg Pred Value : 0.8704          
             Prevalence : 0.6162          
         Detection Rate : 0.5770          
   Detection Prevalence : 0.6975          
      Balanced Accuracy : 0.8112          
                                          
       'Positive' Class : 0               
                                          
> 
> #####Accuracy is 0.8375
> ####Not at all bad using Single tree and just 3 feauters
> 
> ##There is chance of overfitting in Single tree, So I will go for cross validation using '10 fold techinque'
> set.seed(1234)
> cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10)
> 
> # Control
> ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
+                        index = cv.10)
> 
> ##Train the data
> Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
+                    trControl = ctrl)
> 
> 
> ##Check the accurcay
> ##Accurcay using 10 fold cross validation of Single tree is 0.8139 
> ##Seems Overfitted earlier using Single tree, there our accurcay rate is 0.83
> 
> # check the variable imporatnce, is it the same as in Single tree?
> rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)
> 
> ##Yes, there is no change in the imporatnce of variable
> 
> 
> ###Lets cross validate the accurcay using data that kept aside for testing purpose
> PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
> confusionMatrix(PRE_VDTS,test_val$Survived)
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 94 20
         1 15 48
                                          
               Accuracy : 0.8023          
                 95% CI : (0.7359, 0.8582)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 7.432e-08       
                                          
                  Kappa : 0.5762          
                                          
 Mcnemar's Test P-Value : 0.499           
                                          
            Sensitivity : 0.8624          
            Specificity : 0.7059          
         Pos Pred Value : 0.8246          
         Neg Pred Value : 0.7619          
             Prevalence : 0.6158          
         Detection Rate : 0.5311          
   Detection Prevalence : 0.6441          
      Balanced Accuracy : 0.7841          
                                          
       'Positive' Class : 0               
                                          
> 
> ###There it is, How exactly our train data and test data matches in accuracy (0.8192)
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> set.seed(1234)
> rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
> rf.1

Call:
 randomForest(x = train_val[, -7], y = train_val[, 7], ntree = 1000,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 1000
No. of variables tried at each split: 2

        OOB estimate of  error rate: 16.11%
Confusion matrix:
    0   1 class.error
0 407  33   0.0750000
1  82 192   0.2992701
> varImpPlot(rf.1)
> 
> ####Random Forest accurcay rate is 82.91 which is 1% better than the decison  tree
> ####Lets remove 2 redaundant varibles and do the modeling again
> train_val1=train_val[,-4:-5]
> test_val1=test_val[,-4:-5]
> 
> set.seed(1234)
> rf.2 <- randomForest(x = train_val1[,-5],y=train_val1[,5], importance = TRUE, ntree = 1000)
> rf.2

Call:
 randomForest(x = train_val1[, -5], y = train_val1[, 5], ntree = 1000,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 1000
No. of variables tried at each split: 2

        OOB estimate of  error rate: 17.09%
Confusion matrix:
    0   1 class.error
0 389  51   0.1159091
1  71 203   0.2591241
> varImpPlot(rf.2)
> 
> ###Can see the Magic now, increase in accuracy by just removing 2 varibles, accuracy now is 84.03 
> 
> ##Even though random forest is so power full we accept the model only after cross validation
> 
> 
> set.seed(2348)
> cv10_1 <- createMultiFolds(train_val1[,5], k = 10, times = 10)
> 
> # Set up caret's trainControl object per above.
> ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
+                       index = cv10_1)
> 
> 
> 
> set.seed(1234)
> rf.5<- train(x = train_val1[,-5], y = train_val1[,5], method = "rf", tuneLength = 3,
+               ntree = 1000, trControl =ctrl_1)
> 
> rf.5
Random Forest 

714 samples
  4 predictor
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 
Summary of sample sizes: 643, 643, 642, 643, 642, 642, ... 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
  2     0.8267195  0.6282674
  3     0.8256025  0.6259203
  4     0.8211228  0.6155793

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 2.
> 
> ##Cross validation give us the accurcay rate of .8393
> 
> ###Lets Predict the test data 
> 
> pr.rf=predict(rf.5,newdata = test_val1)
> 
> confusionMatrix(pr.rf,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 100  17
         1   9  51
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 3.506e-12       
                                          
                  Kappa : 0.6825          
                                          
 Mcnemar's Test P-Value : 0.1698          
                                          
            Sensitivity : 0.9174          
            Specificity : 0.7500          
         Pos Pred Value : 0.8547          
         Neg Pred Value : 0.8500          
             Prevalence : 0.6158          
         Detection Rate : 0.5650          
   Detection Prevalence : 0.6610          
      Balanced Accuracy : 0.8337          
                                          
       'Positive' Class : 0               
                                          
> 
> ####accuracy rate is 0.8192, lower than what we have expected  
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###Before going to model lets tune the cost Parameter
> 
> set.seed(1274)
> liner.tune=tune.svm(Survived~.,data=train_val1,kernel="linear",cost=c(0.01,0.1,0.2,0.5,0.7,1,2,3,5,10,15,20,50,100))
> 
> liner.tune

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
 cost
  0.5

- best performance: 0.1863263 

> 
> ###best perforamnce when cost=3 and accuracy rate is 82.7
> 
> 
> ###Lets get a best.liner model  
> best.linear=liner.tune$best.model
> 
> ##Predict Survival rate using test data
> 
> best.test=predict(best.linear,newdata=test_val1,type="class")
> confusionMatrix(best.test,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 102  19
         1   7  49
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 3.506e-12       
                                          
                  Kappa : 0.6789          
                                          
 Mcnemar's Test P-Value : 0.03098         
                                          
            Sensitivity : 0.9358          
            Specificity : 0.7206          
         Pos Pred Value : 0.8430          
         Neg Pred Value : 0.8750          
             Prevalence : 0.6158          
         Detection Rate : 0.5763          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8282          
                                          
       'Positive' Class : 0               
                                          
> 
> ###Linear model accuracy is 0.8136
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> 
> ######Lets go to non liner SVM, Radial Kerenl
> set.seed(1274)
> 
> rd.poly=tune.svm(Survived~.,data=train_val1,kernel="radial",gamma=seq(0.1,5))
> 
> summary(rd.poly)

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
 gamma
   2.1

- best performance: 0.1723787 

- Detailed performance results:
  gamma     error dispersion
1   0.1 0.1793818 0.07488403
2   1.1 0.1766041 0.07504011
3   2.1 0.1723787 0.06347706
4   3.1 0.1751956 0.06111433
5   4.1 0.1751956 0.06111433

> best.rd=rd.poly$best.model
> 
> ###Non Linear Kerenel giving us a better accuray 
> 
> ##Lets Predict test data
> pre.rd=predict(best.rd,newdata = test_val1)
> 
> confusionMatrix(pre.rd,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 98 17
         1 11 51
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 4.229e-11       
                                          
                  Kappa : 0.66            
                                          
 Mcnemar's Test P-Value : 0.3447          
                                          
            Sensitivity : 0.8991          
            Specificity : 0.7500          
         Pos Pred Value : 0.8522          
         Neg Pred Value : 0.8226          
             Prevalence : 0.6158          
         Detection Rate : 0.5537          
   Detection Prevalence : 0.6497          
      Balanced Accuracy : 0.8245          
                                          
       'Positive' Class : 0               
                                          
> 
> ####Accurcay of test data using Non Liner model is 0.81
> ####it could be due to we are using smaller set of sample for testing data
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> contrasts(train_val1$Sex)
       male
female    0
male      1
> contrasts(train_val1$Pclass)
  2 3
1 0 0
2 1 0
3 0 1
> 
> ##The above shows how the varible coded among themself
> 
> ##Lets run Logistic regression model
> log.mod <- glm(Survived ~ ., family = binomial(link=logit), 
+                data = train_val1)
> ###Check the summary
> summary(log.mod)

Call:
glm(formula = Survived ~ ., family = binomial(link = logit), 
    data = train_val1)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.3057  -0.6037  -0.4163   0.5910   2.9010  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
(Intercept)        15.2687   535.4118   0.029    0.977    
Pclass2            -1.2513     0.3035  -4.123 3.73e-05 ***
Pclass3            -2.0792     0.2632  -7.900 2.79e-15 ***
titleMiss         -14.4739   535.4118  -0.027    0.978    
titleMr            -3.3519     0.5297  -6.328 2.48e-10 ***
titleMrs          -14.1159   535.4118  -0.026    0.979    
titleOfficer       -3.4576     0.8180  -4.227 2.37e-05 ***
Sexmale           -14.0305   535.4116  -0.026    0.979    
ticket.sizeSingle   1.7907     0.3956   4.526 6.00e-06 ***
ticket.sizeSmall    1.7550     0.3790   4.630 3.66e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 612.70  on 704  degrees of freedom
AIC: 632.7

Number of Fisher Scoring iterations: 12

> confint(log.mod)
Waiting for profiling to be done...
                       2.5 %     97.5 %
(Intercept)       -93.577086         NA
Pclass2            -1.856074 -0.6645044
Pclass3            -2.604921 -1.5714594
titleMiss                 NA 94.3697051
titleMr            -4.426245 -2.3405610
titleMrs                  NA 94.7241620
titleOfficer       -5.149130 -1.9119238
Sexmale                   NA 94.9285419
ticket.sizeSingle   1.035252  2.5896481
ticket.sizeSmall    1.026807  2.5167892
There were 45 warnings (use warnings() to see them)
> 
> ###Predict train data
> train.probs <- predict(log.mod, data=train_val1,type =  "response")
> table(train_val1$Survived,train.probs>0.5)
   
    FALSE TRUE
  0   390   50
  1    73  201
> 
> (395+204)/(395+204+70+45)
[1] 0.8389356
> 
> ###Logistic regression predicted train data with accuracy rate of 0.83 
> 
> test.probs <- predict(log.mod, newdata=test_val1,type =  "response")
> table(test_val1$Survived,test.probs>0.5)
   
    FALSE TRUE
  0   102    7
  1    18   50
> 
> (97+47)/(97+12+21+47)
[1] 0.8135593
> 
> ###Accuracy rate of teat data is 0.8135..
> 
> 
> proc.time()
   user  system elapsed 
 83.972   2.860  87.159 
