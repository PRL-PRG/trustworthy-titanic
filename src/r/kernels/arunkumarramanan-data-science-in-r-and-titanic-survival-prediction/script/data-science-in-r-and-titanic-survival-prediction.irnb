{"cells":[{"metadata":{"_uuid":"f0d88ea705af5855933e9f5b2c0accaed95dbddb"},"cell_type":"markdown","source":"# Awesome Data Science Tutorials with R and Titanic Survival Prediction\n\n       This kernel contains Titanic Survival Prediction and a curated list of R tutorials and packages for Data Science, NLP and Machine Learning. This also serves as a reference guide for several common data analysis tasks.\n\n> #### **Credits**: Thanks to **Megan L. Risdal** for Exploring Survival on the Titanic in R, **Ujjwal Karn** and other contributers for such wonderful work\n\n### Here are some of *my kernel notebooks* for **Machine Learning and Data Science** as follows, An ***Upvote*** to the kernel is very much appreciated if you *like* them\n\n> * [Awesome ML Frameworks and MNIST Classification](https://www.kaggle.com/arunkumarramanan/awesome-machine-learning-ml-frameworks)\n> * [Awesome Data Science for Beginners with Titanic Exploration](https://kaggle.com/arunkumarramanan/awesome-data-science-for-beginners)\n> * [Tensorflow Tutorial and House Price Prediction](https://www.kaggle.com/arunkumarramanan/tensorflow-tutorial-and-examples)\n> * [Practical Machine Learning with PyTorch](https://www.kaggle.com/arunkumarramanan/practical-machine-learning-with-pytorch)\n> * [Awesome Deep Learning Basics and Resources](https://www.kaggle.com/arunkumarramanan/awesome-deep-learning-resources)\n> * [Awesome Computer Vision Resources (TBU)](https://www.kaggle.com/arunkumarramanan/awesome-computer-vision-resources-to-be-updated)\n> * [Data Scientist's Toolkits - Awesome Data Science Resources](https://www.kaggle.com/arunkumarramanan/data-scientist-s-toolkits-awesome-ds-resources)\n> * [Data Science with Python - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/data-science-with-python-awesome-tutorials)\n> * [Machine Learning and Deep Learning - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/awesome-deep-learning-ml-tutorials)\n> * [Machine Learning Engineer's Toolkit with Roadmap](https://www.kaggle.com/arunkumarramanan/machine-learning-engineer-s-toolkit-with-roadmap) \n> * [Awesome TensorFlow and PyTorch Resources](https://www.kaggle.com/arunkumarramanan/awesome-tensorflow-and-pytorch-resources)\n> * [Hands-on ML with scikit-learn and TensorFlow](https://www.kaggle.com/arunkumarramanan/hands-on-ml-with-scikit-learn-and-tensorflow)\n> * [Awesome Data Science IPython Notebooks](https://www.kaggle.com/arunkumarramanan/awesome-data-science-ipython-notebooks)\n> * [Data Science and Machine Learning Cheetcheets](https://www.kaggle.com/arunkumarramanan/data-science-and-machine-learning-cheatsheets)\n> * [Data Science with R - Awesome Tutorials](https://www.kaggle.com/arunkumarramanan/data-science-with-r-awesome-tutorials)"},{"metadata":{"_uuid":"9129b46c3f64d3e20491c8790b6a56fa9ad02ed6"},"cell_type":"markdown","source":"# Titanic Survival Prediction based on [Exploring Survival on the Titanic](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic) (TBU)\n\n# Introduction\n\nUsing `randomForest` to create a model predicting survival on the Titanic.\n\n* Feature engineering\n* Missing value imputation\n* Prediction!\n\n## Load and check data"},{"metadata":{"trusted":true,"_uuid":"37053a771d9887d9d3c4dbe1beae1cfa5f3bd2af"},"cell_type":"code","source":"# Load packages\nlibrary('ggplot2') # visualization\nlibrary('ggthemes') # visualization\nlibrary('scales') # visualization\nlibrary('dplyr') # data manipulation\nlibrary('mice') # imputation\nlibrary('randomForest') # classification algorithm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b59382f9f49cb2f87e07d257005a0356907c5d88"},"cell_type":"markdown","source":"Now that our packages are loaded, let's read in and take a peek at the data."},{"metadata":{"trusted":true,"_uuid":"d9ab13d1b9f96f0b0fda3eb1a347bf054399577f"},"cell_type":"code","source":"train <- read.csv('../input/train.csv', stringsAsFactors = F)\ntest  <- read.csv('../input/test.csv', stringsAsFactors = F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e84c2c4adcec37e48024dd1e4ec0c65086b4cf8"},"cell_type":"code","source":"full  <- bind_rows(train, test) # bind training & test data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b90a35a7e51c19dd615c2f29d26c50474c5d497f"},"cell_type":"code","source":"# check data\nstr(full)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88de49efc42dc1af9e1a84486a22ed1d725a0160"},"cell_type":"markdown","source":"We've got a sense of our variables, their class type, and the first few observations of each. We know we're working with 1309 observations of 12 variables. To make things a bit more explicit since a couple of the variable names aren't 100% illuminating, here's what we've got to deal with:\n\nVariable Name | Description\n--------------|-------------\nSurvived      | Survived (1) or died (0)\nPclass        | Passenger's class\nName          | Passenger's name\nSex           | Passenger's sex\nAge           | Passenger's age\nSibSp         | Number of siblings/spouses aboard\nParch         | Number of parents/children aboard\nTicket        | Ticket number\nFare          | Fare\nCabin         | Cabin\nEmbarked      | Port of embarkation\n\n# Feature Engineering\n## What's in a name?\n\nThe first variable which catches my attention is **passenger name** because we can break it down into additional meaningful variables which can feed predictions or be used in the creation of additional new variables. For instance, **passenger title** is contained within the passenger name variable and we can use **surname** to represent families. Let's do some **feature engineering**!"},{"metadata":{"trusted":true,"_uuid":"574e9e0cc46960b6f981c207260bae71d1b2c9e6"},"cell_type":"code","source":"# Grab title from passenger names\nfull$Title <- gsub('(.*, )|(\\\\..*)', '', full$Name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f64af2251c1d058932ae1489977e5f80beff53e"},"cell_type":"code","source":"# Show title counts by sex\ntable(full$Sex, full$Title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e68f7873d81345d72d43cece3bcf37342e89ca98"},"cell_type":"code","source":"# Titles with very low cell counts to be combined to \"rare\" level\nrare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27a29ddc7846c1be1d044ce9eb3efe268654d0a0"},"cell_type":"code","source":"# Also reassign mlle, ms, and mme accordingly\nfull$Title[full$Title == 'Mlle']        <- 'Miss' \nfull$Title[full$Title == 'Ms']          <- 'Miss'\nfull$Title[full$Title == 'Mme']         <- 'Mrs' \nfull$Title[full$Title %in% rare_title]  <- 'Rare Title'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3337975fa24c5f29dc107596dca719851672c038"},"cell_type":"code","source":"# Show title counts by sex again\ntable(full$Sex, full$Title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05eb362f34d7e06f7090f12938e35ef75374f2c9"},"cell_type":"code","source":"# Finally, grab surname from passenger name\nfull$Surname <- sapply(full$Name,  \n                      function(x) strsplit(x, split = '[,.]')[[1]][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af41f70bc262f6bd7aade602554460b184ada3d8"},"cell_type":"code","source":"cat(paste('We have <b>', nlevels(factor(full$Surname)), '</b> unique surnames. I would be interested to infer ethnicity based on surname --- another time.'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a110580034598702201755928be9d85a067ce6cd"},"cell_type":"markdown","source":"## Do families sink or swim together?\n\nNow that we've taken care of splitting passenger name into some new variables, we can take it a step further and make some new family variables. First we're going to make a **family size** variable based on number of siblings/spouse(s) (maybe someone has more than one spouse?) and number of children/parents. \n"},{"metadata":{"trusted":true,"_uuid":"ce969e4748b95ecd188a4797928a4d149aa1439f"},"cell_type":"code","source":"# Create a family size variable including the passenger themselves\nfull$Fsize <- full$SibSp + full$Parch + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08e7dcf1815dc219cd0b61b1122d65964bbd3477"},"cell_type":"code","source":"# Create a family variable \nfull$Family <- paste(full$Surname, full$Fsize, sep='_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3e95df51d5e0f009bf4332afc7f96768c3fbe99"},"cell_type":"code","source":"# Discretize family size\nfull$FsizeD[full$Fsize == 1] <- 'singleton'\nfull$FsizeD[full$Fsize < 5 & full$Fsize > 1] <- 'small'\nfull$FsizeD[full$Fsize > 4] <- 'large'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d561ab573fcd49396b7ee637da28f13184f0e955"},"cell_type":"markdown","source":"## Treat a few more variables ...\n\nWhat's left? There's probably some potentially useful information in the **passenger cabin** variable including about their **deck**. Let's take a look."},{"metadata":{"trusted":true,"_uuid":"a8dbfb3d08d30f0341c403fb3f7e8c61a3ef64fa"},"cell_type":"code","source":"# This variable appears to have a lot of missing values\nfull$Cabin[1:28]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe17376fbfcaf31ee79a71a3cf8940b4ba5049b"},"cell_type":"code","source":"# The first character is the deck. For example:\nstrsplit(full$Cabin[2], NULL)[[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f204ab94dc162e668312952bb085128f51965442"},"cell_type":"code","source":"# Create a Deck variable. Get passenger deck A - F:\nfull$Deck<-factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde4978db63045a9a72b5b4374f6f833f9bf5654"},"cell_type":"code","source":"# This variable appears to have a lot of missing values\nfull$Cabin[1:28]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e0a1a0b1f6ee83e524d471c12457e5b7b3a3f52"},"cell_type":"code","source":"# The first character is the deck. For example:\nstrsplit(full$Cabin[2], NULL)[[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfc51d020161260fbafd1ca8fc6af35ff5048260"},"cell_type":"code","source":"# Create a Deck variable. Get passenger deck A - F:\nfull$Deck<-factor(sapply(full$Cabin, function(x) strsplit(x, NULL)[[1]][1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf5d3c9c2de38384bc19619e88d441143a21dbf4"},"cell_type":"markdown","source":"# Missingness\n\nNow we're ready to start exploring missing data and rectifying it through imputation. There are a number of different ways we could go about doing this. Given the small size of the dataset, we probably should not opt for deleting either entire observations (rows) or variables (columns) containing missing values. We're left with the option of either replacing missing values with a sensible values given the distribution of the data, e.g., the mean, median or mode. Finally, we could go with prediction. We'll use both of the two latter methods and I'll rely on some data visualization to guide our decisions.\n\n## Sensible value imputation"},{"metadata":{"trusted":true,"_uuid":"c6bff228f93d44192bdd7534839f0cfdf3eeabda"},"cell_type":"code","source":"# Passengers 62 and 830 are missing Embarkment\nfull[c(62, 830), 'Embarked']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98ebd6c05d68de256f7b3f558a574e5063b6f84b"},"cell_type":"code","source":"cat(paste('We will infer their values for **embarkment** based on present data that we can imagine may be relevant: **passenger class** and **fare**. We see that they paid<b> $', full[c(62, 830), 'Fare'][[1]][1], '</b>and<b> $', full[c(62, 830), 'Fare'][[1]][2], '</b>respectively and their classes are<b>', full[c(62, 830), 'Pclass'][[1]][1], '</b>and<b>', full[c(62, 830), 'Pclass'][[1]][2], '</b>. So from where did they embark?'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68d178feb6d4f575660b0ccfb5e7048771468b01"},"cell_type":"code","source":"# Get rid of our missing passenger IDs\nembark_fare <- full %>%\n  filter(PassengerId != 62 & PassengerId != 830)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc1a07972a6fa5ca50af4e2922a511a52a558b2c"},"cell_type":"code","source":"# Since their fare was $80 for 1st class, they most likely embarked from 'C'\nfull$Embarked[c(62, 830)] <- 'C'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb7fc7b04e181eaba3ef3b27d6eed8d731f7d363"},"cell_type":"code","source":"# Show row 1044\nfull[1044, ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2474171669fb905d3b7788c5ebeeef01b3d81996"},"cell_type":"code","source":"# Replace missing fare value with median fare for class/embarkment\nfull$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caf5c7d8fd86a430e98ba23b238ccca59d295b5a"},"cell_type":"markdown","source":"## Predictive imputation\n\nFinally, as we noted earlier, there are quite a few missing **Age** values in our data. We are going to get a bit more fancy in imputing missing age values. Why? Because we can. We will create a model predicting ages based on other variables."},{"metadata":{"trusted":true,"_uuid":"ec753399e1b5aa917ebdeb40a77a931201f2f8b4"},"cell_type":"code","source":"sum(is.na(full$Age))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca1ff9a0313f9294a3fcaa2e3c2a64c410cd5c01"},"cell_type":"markdown","source":"We could definitely use `rpart` (recursive partitioning for regression) to predict missing ages, but I'm going to use the `mice` package for this task just for something different. You can read more about multiple imputation using chained equations in r [here](http://www.jstatsoft.org/article/view/v045i03/v45i03.pdf) (PDF). Since we haven't done it yet, I'll first factorize the factor variables and then perform mice imputation."},{"metadata":{"trusted":true,"_uuid":"869d236c4e99724d5b3c6f2497f902305227c691"},"cell_type":"code","source":"# Make variables factors into factors\nfactor_vars <- c('PassengerId','Pclass','Sex','Embarked',\n                 'Title','Surname','Family','FsizeD')\n\nfull[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4ea0021ce9f9207398f1c3210b9e01c0ea59b3b"},"cell_type":"code","source":"# Set a random seed\nset.seed(129)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b089443ff7c1fc7f2b9b1380ac7694192c641e30"},"cell_type":"code","source":"# Perform mice imputation, excluding certain less-than-useful variables:\nmice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived')], method='rf') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3582dcbd3988c36e121655ccf7ee67584dd9a544"},"cell_type":"code","source":"# Save the complete output \nmice_output <- complete(mice_mod)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c33a80099bf6f604938b71931c2561d0e5f104af"},"cell_type":"code","source":"# Replace Age variable from the mice model.\nfull$Age <- mice_output$Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff8c608ddee2cb5f9ca2454935f956d19c214c50"},"cell_type":"code","source":"# Show new number of missing Age values\nsum(is.na(full$Age))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49438844e8467ef5e7b1016c78b3b76f2689da17"},"cell_type":"code","source":"# Create the column child, and indicate whether child or adult\nfull$Child[full$Age < 18] <- 'Child'\nfull$Child[full$Age >= 18] <- 'Adult'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c25cdf6527cba2146c6817b7db6b239629f28cc"},"cell_type":"code","source":"# Show counts\ntable(full$Child, full$Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed6a72d7a8e309005ee6cae9d769311054b59f85"},"cell_type":"code","source":"# Adding Mother variable\nfull$Mother <- 'Not Mother'\nfull$Mother[full$Sex == 'female' & full$Parch > 0 & full$Age > 18 & full$Title != 'Miss'] <- 'Mother'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5bb41b7034fb52af19822372e960e13da13c3ae"},"cell_type":"code","source":"# Show counts\ntable(full$Mother, full$Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1866b89aeda6b8def3cec2418c7cede88d7d8428"},"cell_type":"code","source":"# Finish by factorizing our two new factor variables\nfull$Child  <- factor(full$Child)\nfull$Mother <- factor(full$Mother)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1444a593caf0c8904ef52479be4fc33818852dbd"},"cell_type":"markdown","source":"# Prediction\n\nAt last we're ready to predict who survives among passengers of the Titanic based on variables that we carefully curated and treated for missing values. For this, we will rely on the `randomForest` classification algorithm; we spent all that time on imputation, after all.\n\n## Split into training & test sets\n\nOur first step is to split the data back into the original test and training sets.\n"},{"metadata":{"trusted":true,"_uuid":"7e645184834ee69dc0bbfe61966634e0779207b5"},"cell_type":"code","source":"# Split the data back into a train set and a test set\ntrain <- full[1:891,]\ntest <- full[892:1309,]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7b91cfcac2c860c66686a0596ab88e305fce5e9"},"cell_type":"markdown","source":"## Building the model \n\nWe then build our model using `randomForest` on the training set."},{"metadata":{"trusted":true,"_uuid":"a2864957bf265c98f0f90810c369c0cfa821084a"},"cell_type":"code","source":"# Set a random seed\nset.seed(754)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"256c5946a01543cb4350e8a0f49617a454a823da"},"cell_type":"code","source":"# Build the model (note: not all possible variables are used)\nrf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + \n                                            Fare + Embarked + Title + \n                                            FsizeD + Child + Mother,\n                                            data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9265c88b54e34719b11ca8afb588a88dd57ffff9"},"cell_type":"code","source":"# Show model error\nplot(rf_model, ylim=c(0,0.36))\nlegend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"826b92b5e8a274f732fbcdd3b28787c67f0bdd65"},"cell_type":"markdown","source":"The black line shows the overall error rate which falls below 20%. \nThe red and green lines show the error rate for 'died' and 'survived' respectively. We can see that right now we're much more successful predicting death than we are survival. What does that say about me, I wonder?\n\n## Variable importance\n\nLet's look at relative variable importance by plotting the mean decrease in Gini calculated across all trees."},{"metadata":{"trusted":true,"_uuid":"b11b4e770ac3ea20b74e78085d8f3f9cc5088b6f"},"cell_type":"code","source":"# Get importance\nimportance    <- importance(rf_model)\nvarImportance <- data.frame(Variables = row.names(importance), \n                            Importance = round(importance[ ,'MeanDecreaseGini'],2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3cbbef27cbbf362c7672856783ea33d3afc084b"},"cell_type":"code","source":"# Create a rank variable based on importance\nrankImportance <- varImportance %>%\n  mutate(Rank = paste0('#',dense_rank(desc(Importance))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31cd9450a82732ba53c9d105268060cc5617b146"},"cell_type":"code","source":"# Use ggplot2 to visualize the relative importance of variables\nggplot(rankImportance, aes(x = reorder(Variables, Importance), \n    y = Importance, fill = Importance)) +\n  geom_bar(stat='identity') + \n  geom_text(aes(x = Variables, y = 0.5, label = Rank),\n    hjust=0, vjust=0.55, size = 4, colour = 'red') +\n  labs(x = 'Variables') +\n  coord_flip() + \n  theme_few()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e82784fb75246a8c43f8dae34b3af63e2070af7d"},"cell_type":"markdown","source":"Whoa, glad we made our title variable! It has the highest relative importance out of all of our predictor variables. I think I'm most surprised to see that passenger class fell to `r rankImportance[rankImportance$Variable == 'Pclass', ]$Rank`, but maybe that's just bias coming from watching the movie Titanic too many times as a kid.\n\n## Prediction!\n\nWe're ready for the final step --- making our prediction! When we finish here, we could iterate through the preceding steps making tweaks as we go or fit the data using different models or use different combinations of variables to achieve better predictions. But this is a good starting (and stopping) point for me now."},{"metadata":{"trusted":true,"_uuid":"337b8d95c518ae83504ebb2c4cf1f8ba935b7501"},"cell_type":"code","source":"# Predict using the test set\nprediction <- predict(rf_model, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6efd61f4db8587acaca50567f1a40a9cdcf9d86"},"cell_type":"code","source":"# Save the solution to a dataframe with two columns: PassengerId and Survived (prediction)\nsolution <- data.frame(PassengerID = test$PassengerId, Survived = prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e01fc79a4100bf3dae927ebe4b50a03b3ece8304"},"cell_type":"code","source":"# Write the solution to file\nwrite.csv(solution, file = 'rf_mod_Solution.csv', row.names = F)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31a16e83710d606ebfb477ace39e23f5f7faa179"},"cell_type":"markdown","source":"## License \n\nThis kernel has been released under the [Apache 2.0](http://www.apache.org/licenses/LICENSE-2.0) open source license."},{"metadata":{"_uuid":"1cc9a9d2e3906a71e1658317e4439862ab5cc174","_execution_state":"idle","trusted":false},"cell_type":"markdown","source":"# Awesome Data Science Tutorials with R\n   \n    A curated list of R tutorials for Data Science, NLP and Machine Learning\n\n## Learning R\n- Online Courses\n    - [tryR on Codeschool](http://tryr.codeschool.com/)\n    - [Introduction to R for Data Science - Microsoft | edX](https://www.edx.org/course/introduction-r-data-science-microsoft-dat204x?gclid=CLiyoPb448wCFRJxvAod-RoLsA)\n    - [Introduction to R on DataCamp](https://www.datacamp.com/courses/free-introduction-to-r)\n    - [Data Analysis with R](https://www.udacity.com/course/data-analysis-with-r--ud651)\n- [**Free resources for learning R**](http://stats.stackexchange.com/questions/138/free-resources-for-learning-r)\n- [R for Data Science - Hadley Wickham](http://r4ds.had.co.nz/)\n- [Advanced R - Hadley Wickham](http://adv-r.had.co.nz/)\n- [swirl: Learn R, in R](http://swirlstats.com/)\n- [Data Analysis and Visualization Using R](http://varianceexplained.org/RData/)\n- [**MANY R PROGRAMMING TUTORIALS**](http://www.listendata.com/p/r-programming-tutorials.html)\n- [**A Handbook of Statistical Analyses Using R**](https://cran.r-project.org/web/packages/HSAUR/vignettes/Ch_introduction_to_R.pdf), Find Other Chapters\n- [**Cookbook for R**](http://www.cookbook-r.com/)\n- [Learning R in 7 simple steps](http://www.datasciencecentral.com/profiles/blogs/learning-r-in-seven-simple-steps)\n\n## More Resources\n- [Awesome-R Repository on GitHub](https://github.com/qinwf/awesome-R)\n- [R Reference Card: Cheatsheet](https://cran.r-project.org/doc/contrib/Short-refcard.pdf)\n- [R bloggers: blog aggregator](http://www.r-bloggers.com/)\n- [R Resources on  GitHub](https://github.com/binga/DataScienceArsenal/blob/master/r-resources.md)\n- [Awesome R resources](https://github.com/ujjwalkarn/awesome-R)\n- [Data Mining with R](https://github.com/ujjwalkarn/Data-Mining-With-R)\n- [Rob J Hyndman's R Blog](http://robjhyndman.com/hyndsight/r/)\n- [Simple R Tricks and Tools](http://robjhyndman.com/hyndsight/simpler/) [(Video)](https://www.youtube.com/watch?v=Toc__W7L2Qo)\n- [RStudio GitHub Repo](https://github.com/rstudio/)\n- [Tidying Messy Data in R](http://www.dataschool.io/tidying-messy-data-in-r/) [Video](https://vimeo.com/33727555)\n- [Baseball Research with R](http://www.hardballtimes.com/a-short-ish-introduction-to-using-r-for-baseball-research)\n- [600 websites about R](http://www.datasciencecentral.com/profiles/blogs/600-websites-about-r)\n- [Implementation of 17 classification algorithms in R](http://www.datasciencecentral.com/profiles/blogs/implemetation-of-17-classification-algorithms-in-r)\n- [Cohort Analysis and LifeCycle Grids mixed segmentation with R](http://analyzecore.com/2015/04/01/cohort-analysis-and-lifecycle-grids-mixed-segmentation-with-r/)\n- [Using R and Tableau](http://www.tableau.com/learn/whitepapers/using-r-and-tableau)\n- [COMPREHENSIVE VIEW ON CRAN PACKAGES](http://www.docfoc.com/cran-pdf)\n- [Using R for Statistical Tables and Plotting Distributions](http://math.arizona.edu/~jwatkins/R-01.pdf)\n- [Extended Model Formulas in R: Multiple Parts and Multiple Responses](https://cran.r-project.org/web/packages/Formula/vignettes/Formula.pdf)\n- [R vs Python: head to head data analysis](https://www.dataquest.io/blog/python-vs-r/?utm_content=buffer55639&utm_medium=social&utm_source=linkedin.com&utm_campaign=buffer)\n- [**R for Data Science: Hadley Wickham's Book**](http://r4ds.had.co.nz/)\n- [**R Study Group at UPenn**](https://www.ling.upenn.edu/~joseff/rstudy/index.html)\n- [Program-Defined Functions in R](http://dni-institute.in/blogs/extracting-data-from-facebook-using-r/)\n\n## Important Questions\n- [**In R, why is bracket better than `subset`?**](http://stackoverflow.com/questions/9860090/in-r-why-is-better-than-subset)\n- [**Subsetting Data in R**](http://www.statmethods.net/management/subset.html)\n- [**Vectorization in R: Why?**](http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html)\n- [**Quickly reading very large tables as dataframes in R**](http://stackoverflow.com/questions/1727772/quickly-reading-very-large-tables-as-dataframes-in-r)\n- [**Using R to show data**](http://www.sr.bham.ac.uk/~ajrs/R/r-show_data.html)\n- [How can I view the source code for a function?](http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function?lq=1)\n- [How to make a great R reproducible example?](https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example)\n- [**R Grouping functions: sapply vs. lapply vs. apply. vs. tapply vs. by vs. aggregate**](https://stackoverflow.com/questions/3505701/r-grouping-functions-sapply-vs-lapply-vs-apply-vs-tapply-vs-by-vs-aggrega)\n- [**Tricks to manage the available memory in an R session**](https://stackoverflow.com/questions/1358003/tricks-to-manage-the-available-memory-in-an-r-session)\n- [Difference between Assignment operators '=' and '<-' in R](https://stackoverflow.com/questions/1741820/assignment-operators-in-r-and)\n- [What is the difference between require() and library()?](https://stackoverflow.com/questions/5595512/what-is-the-difference-between-require-and-library)\n- [How can I view the source code for a function?](https://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function)\n- [How can I change fonts for graphs in R?](https://stackoverflow.com/questions/27689222/changing-fonts-for-graphs-in-r/)\n\n## Common DataFrame Operations\n- [Create an empty data.frame](https://stackoverflow.com/questions/10689055/create-an-empty-data-frame)\n- [Sort a dataframe by column(s)](https://stackoverflow.com/questions/1296646/how-to-sort-a-dataframe-by-columns)\n- [Merge/Join data frames (inner, outer, left, right)](https://stackoverflow.com/questions/1299871/how-to-join-merge-data-frames-inner-outer-left-right)\n- [Drop data frame columns by name](https://stackoverflow.com/questions/4605206/drop-data-frame-columns-by-name)\n- [Remove rows with NAs in data.frame](https://stackoverflow.com/questions/4862178/remove-rows-with-nas-in-data-frame)\n- [Quickly reading very large tables as dataframes in R](https://stackoverflow.com/questions/1727772/quickly-reading-very-large-tables-as-dataframes-in-r)\n- [Drop factor levels in a subsetted data frame](https://stackoverflow.com/questions/1195826/drop-factor-levels-in-a-subsetted-data-frame)\n- [Convert R list to data frame](https://stackoverflow.com/questions/4227223/r-list-to-data-frame)\n- [Convert data.frame columns from factors to characters](https://stackoverflow.com/questions/2851015/convert-data-frame-columns-from-factors-to-characters)\n- [Extracting specific columns from a data frame](https://stackoverflow.com/questions/10085806/extracting-specific-columns-from-a-data-frame)\n\n## Caret Package in R\n- [Ensembling Models with caret](http://stats.stackexchange.com/questions/27361/stacking-ensembling-models-with-caret)\n- [Model Training and Tuning](http://topepo.github.io/caret/training.html)\n- [Caret Model List](http://topepo.github.io/caret/modelList.html)\n- [relationship-between-data-splitting-and-traincontrol](http://stackoverflow.com/questions/14968874/caret-relationship-between-data-splitting-and-traincontrol)\n- [Specify model generation parameters](http://stackoverflow.com/questions/10498477/carettrain-specify-model-generation-parameters?lq=1)\n- [Tutorial](https://www.r-project.org/nosvn/conferences/useR-2013/Tutorials/kuhn/user_caret_2up.pdf), [Paper](www.jstatsoft.org/article/view/v028i05/v28i05.pdf)\n- [Ensembling models with R](http://amunategui.github.io/blending-models/), [Ensembling Regression Models in R](http://stats.stackexchange.com/questions/26790/ensembling-regression-models)\n\n## R Cheatsheets\n- [R Reference Card](https://cran.r-project.org/doc/contrib/Short-refcard.pdf)\n- [R Reference Card 2.0](https://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf)\n- [Data Wrangling in R](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)\n- [ggplot2 Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/08/ggplot2-cheatsheet.pdf)\n- [Shiny Cheatsheet](http://shiny.rstudio.com/images/shiny-cheatsheet.pdf)\n- [devtools Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/06/devtools-cheatsheet.pdf)\n- [markdown Cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf), [reference](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf)\n- [Data Exploration Cheatsheet](http://www.analyticsvidhya.com/blog/2015/10/cheatsheet-11-steps-data-exploration-with-codes/)\n\n## Reference Slides\n- [R Reference Card](https://cran.r-project.org/doc/contrib/Baggott-refcard-v2.pdf)\n- [Association Rule Mining](https://78462f86-a-e2d7344e-s-sites.googlegroups.com/a/rdatamining.com/www/docs/RDataMining-slides-association-rules.pdf?attachauth=ANoY7crD9hRI7333KWhK0TVPsS1VfgWoW4BuIsmL8B0NANfntEOq6QbcwJk-aCRUy2N6CmUeJsyrlOOd5bo1CqRUYXkEbSl1JbTniVbb-GSR3cyTt9Qq6xB3ZasMEdACaS9j1fZDiLVn_zLFbrF--aJM7gAu54JwRBhvKuQPOPyeMTosWcTmmrJdRNWH4ZqD5kYEJlmHDcXB8Bp-DWbUxZG2T8sAGbcHGUqkPTTJ_u03wvKyw5MGMrGU7q4xIyyUmBas_PqEDi6q&attredirects=0)\n- [Time Series Analysis](https://78462f86-a-e2d7344e-s-sites.googlegroups.com/a/rdatamining.com/www/docs/RDataMining-slides-time-series-analysis.pdf?attachauth=ANoY7cphtFEj6IMGuupE5ygQn5flMH5-QPE4yNgJ9fYv3WqfY0qU8LWGgiECZKs6P63Rhx5Nml8lQXQnX7QH7OZm1hoi_Kl0m9sLOAC0tc4sQipWC8DprQVoYSDyw0EdeJfZWAQor0AyjMWeFHPY6nqxIGAaj4arrwZcnR1dYC7nQK4dTVQM80ARrN5Yzq9rNbGic30X-xKwNQxOXL4fO54ThpzmNB4wLKv5geo_hDqPkwtKBmNR7u_kGPOymJHGvxP3nr02aJsB&attredirects=0)\n- [Data Exploration and Visualisation](https://78462f86-a-e2d7344e-s-sites.googlegroups.com/a/rdatamining.com/www/docs/RDataMining-slides-data-exploration-visualization.pdf?attachauth=ANoY7cpqnCTmCv1omsIoKmefAn8q6M_j4Hizv_1enJlu3nRPIxIhzjBlf-9B_sIxMxpUx-XN5cAw74GUr18Dn0EcaiIm9MVeCtqT-2dcPNo0dfhRJvnb5J8EHKBX_w7Y6mYgb7UAoIUbjdmVGR9VCIfJf6PGQqAlupywcb1yGbT4pv61bQzOzrU4-eICfgHmORdi8YgBqscyT2ThaKHPSeGXD0dd3g08pGN3bY70MKM02ZaqarewbII91KTNH1-zmELEcvatl_sMxmGgNnIDm6MaxEWQ1pIrTQ%3D%3D&attredirects=0)\n- [Regression and Classification](https://78462f86-a-e2d7344e-s-sites.googlegroups.com/a/rdatamining.com/www/docs/RDataMining-slides-regression-classification.pdf?attachauth=ANoY7cq0yqcj_65pafTfUqHazTYvp4E4r-5OB1kLv3swVKJhVydaJ0YU5yEPiOciQC0k_P1QzO6z1vD0r9E05KU8y7Mn6NTesQOOq_mmwlMqAe7D2mnqkHZBqFT6tk2hJ3g3fK40mvfyU5ggoGMxMYn9nVhihKwcIYJy9A8zlbFo4r9a35kpTDr6jJjAw5eQwSEMe-bvT5iyZuyMS7QS-tvlgHjJ40ZGhPro7GcWXfb7qqaPeTe9NyeU7MxAy2Z_lAzxn0vSnqe6&attredirects=0)\n- [Text Mining on Twitter Data](https://78462f86-a-e2d7344e-s-sites.googlegroups.com/a/rdatamining.com/www/docs/RDataMining-slides-text-mining.pdf?attachauth=ANoY7cquEwmhHFNHxiKNhv6C2wquNdaib8A_BeTRFaGFXZ2deivENdTK-GS7mSZjermC7b_-L6KtCWhfF1ZOzOF9XaLkIaw6InCEnjdO1fWUhJFujaGwwbcbExJKEVuMmwlBX_SDUFZYgjuTbIb2llgKRMQc3Dd241HNZHTvGVuPG26vHKN_jU_WoEj7uIilRJWFTDvNrZWGWrvImWr0aCNou56qAB-zmBG_cvRS4QOQroiEetLpR7k%3D&attredirects=0)\n\n## Using R for Multivariate Analysis\n- [Little Book of R for Multivariate Analysis!](http://little-book-of-r-for-multivariate-analysis.readthedocs.io/en/latest/)\n- [THE FREQPARCOORD PACKAGE FOR MULTIVARIATE VISUALIZATION](https://matloff.wordpress.com/2014/03/30/the-freqparcoord-package-for-multivariate-visualization/)\n- [Use of freqparcoord for Regression Diagnostics](http://www.r-bloggers.com/use-of-freqparcoord-for-regression-diagnostics/)\n\n## Time Series Analysis\n- [**Time Series Forecasting (Online Book)**](https://www.otexts.org/fpp)\n- [**A Little Book of Time Series Analysis in R**](http://a-little-book-of-r-for-time-series.readthedocs.org/en/latest/src/timeseries.html)\n- [Quick R: Time Series and Forecasting](http://www.statmethods.net/advstats/timeseries.html)\n- [Components of Time Series Data](https://www.linkedin.com/pulse/component-time-series-data-jeffrey-strickland-ph-d-cmsp)\n- [Unobserved Component Models using R](https://www.linkedin.com/pulse/unobserved-component-models-r-jeffrey-strickland-ph-d-cmsp)\n- [The Holt-Winters Forecasting Method](http://webarchive.nationalarchives.gov.uk/20080726235635/http://statistics.gov.uk/iosmethodology/downloads/Annex_B_The_Holt-Winters_forecasting_method.pdf)\n- [**CRAN Task View: Time Series Analysis**](https://cran.r-project.org/web/views/TimeSeries.html)\n\n## Bayesian Inference\n- [Packages for Bayesian Inference](https://github.com/ujjwalkarn/awesome-R#bayesian)\n- [Bayesian Inference in R: Video](https://www.youtube.com/watch?v=fiWIK7ONX3U)\n- [R and Bayesian Statistics](http://www.r-bloggers.com/r-and-bayesian-statistics/)\n\n## Machine Learning using R\n- [Machine Learning with R](https://github.com/jhashanti/Machine-Learning-with-R)\n- [Using R for Multivariate Analysis (Online Book)](http://little-book-of-r-for-multivariate-analysis.readthedocs.org/en/latest/src/multivariateanalysis.html)\n- [CRAN Task View: Machine Learning & Statistical Learning](https://cran.r-project.org/web/views/MachineLearning.html)\n- [Machine Learning Using R (Online Book)](https://www.otexts.org/sfml)\n- [Linear Regression and Regularization Code](http://rpubs.com/justmarkham/linear-regression-salary)\n- [Cheatsheet](http://www.analyticsvidhya.com/blog/2015/09/full-cheatsheet-machine-learning-algorithms/)\n- [**Multinomial and Ordinal Logistic Regression in R**](http://www.analyticsvidhya.com/blog/2016/02/multinomial-ordinal-logistic-regression/)\n- [**Evaluating Logistic Regression Models in R**](https://www.r-bloggers.com/evaluating-logistic-regression-models/)\n \n## Neural Networks in R\n- [Visualizing Neural Nets in R](https://beckmw.wordpress.com/2013/11/14/visualizing-neural-networks-in-r-update/)\n- [nnet package](http://stackoverflow.com/questions/21788817/r-nnet-with-a-simple-example-of-2-classes-with-2-variables)\n- [Fitting a neural network in R; neuralnet package](http://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/)\n- [Neural Networks with R – A Simple Example](http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/)\n- [NeuralNetTools 1.0.0 now on CRAN](https://beckmw.wordpress.com/tag/neural-network/)\n- [Introduction to Neural Networks in R](http://www.louisaslett.com/Courses/Data_Mining/ST4003-Lab5-Introduction_to_Neural_Networks.pdf)\n- [Step by Step Neural Networks using R](https://bicorner.com/2015/05/13/neural-networks-using-r/)\n- [**R for Deep Learning**](http://www.parallelr.com/r-deep-neural-network-from-scratch/)\n- [Neural Networks using package neuralnet](http://www.di.fc.ul.pt/~jpn/r/neuralnets/neuralnets.html), [Paper](https://journal.r-project.org/archive/2010-1/RJournal_2010-1_Guenther+Fritsch.pdf)\n\n## Sentiment Analysis\n- [Different Approaches](https://drive.google.com/open?id=0By_wg-rXnp_6U1JLNVA3cnAxZ3M)\n- [**Sentiment analysis with machine learning in R**](http://datascienceplus.com/sentiment-analysis-with-machine-learning-in-r/)\n- [**First shot: Sentiment Analysis in R**](http://andybromberg.com/sentiment-analysis/)\n- [qdap package](https://github.com/trinker/qdap), [code](http://stackoverflow.com/questions/22774913/estimating-document-polarity-using-rs-qdap-package-without-sentsplit)\n- [sentimentr package](https://github.com/trinker/sentimentr)\n- [tm.plugin.sentiment package](https://github.com/mannau/tm.plugin.sentiment)\n- [Packages other than sentiment](http://stackoverflow.com/questions/15194436/is-there-any-other-package-other-than-sentiment-to-do-sentiment-analysis-in-r)\n- [Sentiment Analysis and Opinion Mining](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)\n- [tm_term_score](http://www.inside-r.org/packages/cran/tm/docs/tm_term_score)\n- [**vaderSentiment Paper**](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf), [**vaderSentiment code**](https://github.com/cjhutto/vaderSentiment)\n\n## Imputation in R\n- [**Imputation in R**](http://stackoverflow.com/questions/13114812/imputation-in-r)\n- [Imputation with Random Forests](http://stats.stackexchange.com/questions/49270/imputation-with-random-forests)\n- [How to Identify and Impute Multiple Missing Values using R](http://www.unt.edu/rss/class/Jon/Benchmarks/MissingValueImputation_JDS_Nov2010.pdf)\n- MICE\n    - [error in implementation of random forest in mice r package](http://stackoverflow.com/questions/23974026/error-in-implementation-of-random-forest-in-mice-r-package)\n    - [mice.impute.rf {mice}](http://www.inside-r.org/packages/cran/mice/docs/mice.impute.rf)\n\n## NLP and Text Mining in R\n- [**What algorithm I need to find n-grams?**](http://stackoverflow.com/questions/8161167/what-algorithm-i-need-to-find-n-grams)\n- [NLP R Tutorial](http://www.r-bloggers.com/natural-language-processing-tutorial/)\n- [Introduction to the tm Package Text Mining in R](https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf)\n- [Adding stopwords in R tm](http://stackoverflow.com/questions/18446408/adding-stopwords-in-r-tm)\n- [Text Mining](http://www.r-bloggers.com/text-mining/)\n- [Word Stemming in R](http://www.omegahat.net/Rstem/stemming.pdf)\n- [**Classification of Documents using Text Mining Package “tm”**](http://web.letras.up.pt/bhsmaia/EDV/apresentacoes/Bradzil_Classif_withTM.pdf)\n- [Text mining tools techniques and applications](http://slidegur.com/doc/1830649/text-mining)\n- [Text Mining: Overview,Applications and Issues ](http://www3.cs.stonybrook.edu/~cse634/G8present.pdf)\n- [**Text Mining pdf**](http://www3.cs.stonybrook.edu/~cse634/presentations/TextMining.pdf)\n- [Text Mining Another pdf](http://www.stat.columbia.edu/~madigan/W2025/notes/IntroTextMining.pdf)\n- [Good PPT](http://studylib.net/doc/5800473/topic7-textmining)\n- [**Scraping Twitter and Web Data Using R**](http://www.nyu.edu/projects/politicsdatalab/localdata/workshops/twitter.pdf)\n\n## Visualisation in R\n- [ggplot2 tutorial](http://www.ling.upenn.edu/~joseff/avml2012/)\n- [SHINY EXAMPLES](https://github.com/rstudio/shiny-examples)\n- [**Top 50 ggplot2 Visualizations**](http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html)\n- [Comprehensive Guide to Data Visualization in  R](http://www.analyticsvidhya.com/blog/2015/07/guide-data-visualization-r/)\n- [Interactive visualizations with R – a minireview](http://www.r-bloggers.com/interactive-visualizations-with-r-a-minireview/)\n- [Beginner's guide to R: Painless data visualization](http://www.computerworld.com/article/2497304/business-intelligence-beginner-s-guide-to-r-painless-data-visualization.html)\n- [Data Visualization in R with ggvis](https://www.datacamp.com/courses/ggvis-data-visualization-r-tutorial)\n- [Multiple Visualization Articles in R](http://www.r-statistics.com/tag/visualization/)\n\n## Statistics with R\n- [Using R for Biomedical Statistics (Online Book)](http://a-little-book-of-r-for-biomedical-statistics.readthedocs.org/en/latest/src/biomedicalstats.html)\n- [Elementary Statistics with R](http://www.r-tutor.com/elementary-statistics)\n- [A Hands-on Introduction to Statistics with R](https://www.datacamp.com/introduction-to-statistics)\n- [Quick R: Basic Statistics](http://www.statmethods.net/stATS/index.html)\n- [Quick R: Descriptive Statistics](http://www.statmethods.net/stats/descriptives.html)\n- [Explore Statistics with R | edX](https://www.edx.org/course/explore-statistics-r-kix-kiexplorx-0)\n\n## Useful R Packages\n- [**TIDY DATA HADLEY PAPER**](https://www.jstatsoft.org/article/view/v059i10)\n    - Package ‘tidyr’: tidyr is an evolution of reshape2. It's design specifically for data tidying (not general reshaping or aggregating) and works well with dplyr data pipelines.   \n- [BROOM](https://github.com/dgrtwo/broom)\n- [**plyr, stringr, reshape2 tutorial**](http://www.dataschool.io/tidying-messy-data-in-r/) [Video](https://vimeo.com/33727555), [CODE](https://github.com/justmarkham/tidy-data)\n- dplyr\n    - [Code Files in this Repo](https://github.com/ujjwalkarn/DataScienceR/tree/master/Intro%20to%20dplyr)\n    - [dplyr tutorial 1](http://www.dataschool.io/dplyr-tutorial-for-faster-data-manipulation-in-r/), [dplyr tutorial 2](http://www.dataschool.io/dplyr-tutorial-part-2/)\n    - [Do your \"data janitor work\" like a boss with dplyr](http://www.gettinggeneticsdone.com/2014/08/do-your-data-janitor-work-like-boss.html)\n- ggplot2\n    - [ggplot2 tutorial](http://www.ling.upenn.edu/~joseff/avml2012/)\n    - [Good Tutorial!](https://github.com/jennybc/ggplot2-tutorial)\n    - [Introduction to ggplot2](https://speakerdeck.com/karthik/introduction-to-ggplot2), [GitHub](https://github.com/karthik/ggplot-lecture)\n    - [A quick introduction to ggplot()](http://www.noamross.net/blog/2012/10/5/ggplot-introduction.html)\n    - [R Graphics cookbook](http://www.cookbook-r.com/Graphs/index.html)\n    - [ggplot2 Version of Figures in “Lattice: Multivariate Data Visualization with R” ](https://learnr.wordpress.com/2009/06/28/ggplot2-version-of-figures-in-lattice-multivariate-data-visualization-with-r-part-1/)\n- [A speed test comparison of plyr, data.table, and dplyr](http://www.r-statistics.com/2013/09/a-speed-test-comparison-of-plyr-data-table-and-dplyr/)\n- data.table\n    - [Introduction to the data.table package in R](https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.pdf)   \n    - [Fast summary statistics in R with data.table](http://blog.yhat.com/posts/fast-summary-statistics-with-data-dot-table.html)\n- Other Packages\n    - Package 'e1071'\n    - Package ‘AppliedPredictiveModeling’\n    - Package ‘stringr’: stringr is a set of simple wrappers that make R's string functions more consistent, simpler and easier to use.\n    - Package ‘stringdist’: Implements an approximate string matching version of R's native 'match' function. Can calculate various string distances based on edits (damerau-levenshtein, hamming, levenshtein, optimal sting alignment), qgrams or heuristic metrics\n    - Package ‘FSelector’: This package provides functions for selecting attributes from a given dataset \n    - [Ryacas – an R interface to the yacas computer algebra system](https://cran.r-project.org/web/packages/Ryacas/vignettes/Ryacas.pdf)\n    - [Scatterplot3d – an R package for Visualizing Multivariate Data](https://cran.r-project.org/web/packages/scatterplot3d/vignettes/s3d.pdf)\n    - [tm.plugin.webmining intro](https://cran.r-project.org/web/packages/tm.plugin.webmining/vignettes/ShortIntro.pdf)\n    - [Solving Differential Equations in R - ODE examples](https://cran.r-project.org/web/packages/diffEq/vignettes/ODEinR.pdf)\n    - [Structural Equation Modeling With the sem Package in R](http://socserv.socsci.mcmaster.ca/jfox/Misc/sem/SEM-paper.pdf)\n    - [prettyScree - prettyGraphs](http://www.inside-r.org/packages/cran/prettyGraphs/docs/prettyScree)\n\n## Market Basket Analysis in R\n- [Market Basket Analysis with R](http://www.salemmarafi.com/code/market-basket-analysis-with-r/)\n- [Step by Step explanation of Market Basket](http://dni-institute.in/blogs/market-basket-analysis-step-by-step-approach-using-r/)"},{"metadata":{"_uuid":"8206ceb4c420e7049203b08a14668ce56223ab76"},"cell_type":"markdown","source":"## Credits (Reference)\n\n> * [Exploring Survival on the Titanic](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic)\n> * [Ujjwal Karn](https://github.com/ujjwalkarn/DataScienceR)\n> * [GitHub Awesome Lists Topic](https://github.com/topics/awesome)\n\n## License\n\n[![CC0](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/cc-zero.svg)](https://creativecommons.org/publicdomain/zero/1.0/)\n\n### Please ***UPVOTE*** my kernel if you like it or wanna fork it.\n\n##### Feedback: If you have any ideas or you want any other content to be added to this curated list, please feel free to make any comments to make it better.\n#### I am open to have your *feedback* for improving this ***kernel***\n###### Hope you enjoyed this kernel!\n\n### Thanks for visiting my *Kernel* and please *UPVOTE* to stay connected and follow up the *further updates!*"}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}