
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## ----message=FALSE, warning=FALSE------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> library(randomForest) # random Forest
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.
> library(party)        # conditional inference trees and forests
Loading required package: grid
Loading required package: mvtnorm
Loading required package: modeltools
Loading required package: stats4
Loading required package: strucchange
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

Loading required package: sandwich
Warning messages:
1: package ‘party’ was built under R version 3.6.2 
2: package ‘zoo’ was built under R version 3.6.2 
> library(e1071)        # support vector machine
> library(mice)         # multiple imputation

Attaching package: ‘mice’

The following objects are masked from ‘package:base’:

    cbind, rbind

Warning message:
package ‘mice’ was built under R version 3.6.2 
> library(ggplot2)      # nice plots

Attaching package: ‘ggplot2’

The following object is masked from ‘package:randomForest’:

    margin

Warning message:
package ‘ggplot2’ was built under R version 3.6.2 
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> trainData <- read.csv('../input/train.csv')
> testData <- read.csv('../input/test.csv')
> allData <- rbind(trainData[,-2],testData)
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> str(allData)
'data.frame':	1309 obs. of  11 variables:
 $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
 $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Name       : Factor w/ 1307 levels "Abbing, Mr. Anthony",..: 109 191 358 277 16 559 520 629 417 581 ...
 $ Sex        : Factor w/ 2 levels "female","male": 2 1 1 1 2 2 2 2 1 1 ...
 $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
 $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Ticket     : Factor w/ 929 levels "110152","110413",..: 524 597 670 50 473 276 86 396 345 133 ...
 $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Cabin      : Factor w/ 187 levels "","A10","A14",..: 1 83 1 57 1 1 131 1 1 1 ...
 $ Embarked   : Factor w/ 4 levels "","C","Q","S": 4 2 4 4 4 3 4 4 4 2 ...
> nrow(allData[!complete.cases(allData),])
[1] 264
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> md.pattern(allData)
     PassengerId Pclass Name Sex SibSp Parch Ticket Cabin Embarked Fare Age    
1045           1      1    1   1     1     1      1     1        1    1   1   0
263            1      1    1   1     1     1      1     1        1    1   0   1
1              1      1    1   1     1     1      1     1        1    0   1   1
               0      0    0   0     0     0      0     0        0    1 263 264
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> # correlation
> cor(allData[!is.na(allData$Fare),]$Pclass,allData[!is.na(allData$Fare),]$Fare)
[1] -0.5586287
> # boxplot
> ggplot(data = allData,aes(x=factor(Pclass),y=Fare,fill=factor(Pclass))) + geom_boxplot(notch = FALSE)
Warning message:
Removed 1 rows containing non-finite values (stat_boxplot). 
> # replace missing
> allData[is.na(allData$Fare),]$Fare <-  median(allData[allData$Pclass==3,]$Fare,na.rm = TRUE)
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> allData$Title <- sub('.*, (\\w+)\\. .*','\\1',allData$Name)
> allData[!(allData$Title %in% c('Miss','Mr','Mrs','Master')),]$Title <- 'Respected'
> table(allData$Sex,allData$Title)
        
         Master Miss  Mr Mrs Respected
  female      0  260   0 197         9
  male       61    0 757   0        25
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> for (ttl in levels(factor(allData$Title))){
+   allData[(is.na(allData$Age)) & (allData$Title == ttl),]$Age <- 
+     median(allData[allData$Title==ttl,]$Age,na.rm = TRUE)
+ }
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> sum(is.na(allData))
[1] 0
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> allData$FamilySize <- allData$Parch + allData$SibSp +1
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> myfeatures <- c('Pclass','Sex','Age','Fare','Embarked','Title','FamilySize')
> allData$Pclass <- factor(allData$Pclass) # as factor
> allData$Title <- factor(allData$Title)   # as factor
> train <- cbind(allData[1:nrow(trainData),myfeatures],trainData['Survived'])
> test <- allData[(nrow(trainData)+1):nrow(allData),myfeatures]
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> set.seed(66)
> fit.tune <- tune.randomForest(factor(Survived)~.,data = train,mtry=c(2:5),ntree = c(500,1000,1500,2000))
> summary(fit.tune)

Parameter tuning of ‘randomForest’:

- sampling method: 10-fold cross validation 

- best parameters:
 mtry ntree
    3   500

- best performance: 0.1605368 

- Detailed performance results:
   mtry ntree     error dispersion
1     2   500 0.1639076 0.05070633
2     3   500 0.1605368 0.04318014
3     4   500 0.1661673 0.04281438
4     5   500 0.1762547 0.04812445
5     2  1000 0.1616604 0.04872435
6     3  1000 0.1616729 0.04903205
7     4  1000 0.1684020 0.03910070
8     5  1000 0.1751311 0.04787214
9     2  1500 0.1627715 0.04754971
10    3  1500 0.1639076 0.04388475
11    4  1500 0.1706492 0.04044946
12    5  1500 0.1773783 0.04834644
13    2  2000 0.1639076 0.04786005
14    3  2000 0.1627840 0.04845362
15    4  2000 0.1695256 0.04101349
16    5  2000 0.1751311 0.04698487

> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> fit.rf <- fit.tune$best.model
> mean(fit.rf$predicted==train$Survived)
[1] 0.8327722
> varImpPlot(fit.rf)
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> set.seed(66)
> fit.cf <- cforest(factor(Survived)~., data=train,
+                    controls = cforest_unbiased(ntree=2000, mtry=3))
> fit.cf

	 Random Forest using Conditional Inference Trees

Number of trees:  2000 

Response:  factor(Survived) 
Inputs:  Pclass, Sex, Age, Fare, Embarked, Title, FamilySize 
Number of observations:  891 

> pred.cf <- predict(fit.cf)
> mean(pred.cf==train$Survived)
[1] 0.8608305
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> set.seed(66)
> #fit.tune <- tune.svm(factor(Survived)~.,data=train, kernel="radial",
> #                      gamma=10^(-2:2),cost=10^(-2:4))
> #fit.svm <- fit.tune$best.model
> fit.svm <- svm(factor(Survived)~.,data=train,
+                kernel="radial",gamma=0.1,cost=1)
> summary(fit.svm)

Call:
svm(formula = factor(Survived) ~ ., data = train, kernel = "radial", 
    gamma = 0.1, cost = 1)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  1 

Number of Support Vectors:  398

 ( 200 198 )


Number of Classes:  2 

Levels: 
 0 1



> mean(fit.svm$fitted==train$Survived)
[1] 0.8372615
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> kagglePred <- function(myfit,test,filename,...){
+   mypred <- predict(myfit,test,...)
+   myresult <- data.frame(PassengerID = testData$PassengerId,
+                         Survived = mypred)
+   write.csv(myresult,file=filename,row.names=FALSE)
+ }
> 
> 
> ## --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> kagglePred(fit.rf,test,'rf.csv')
> kagglePred(fit.cf,test,'cf.csv',OOB=TRUE,type="response")
Error in data.frame(PassengerID = testData$PassengerId, Survived = mypred) : 
  arguments imply differing number of rows: 418, 891
Calls: kagglePred -> data.frame
Execution halted
