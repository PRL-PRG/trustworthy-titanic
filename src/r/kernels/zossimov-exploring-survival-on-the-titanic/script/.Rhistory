}
getModelRowNames = function(model, var) {
controlVariables = 4
rownames = c(dimnames(summary(model)$coefficients)[[1]][1:(1 + controlVariables)], names(summary(var)))
names(rownames) = rownames
rownames[["(Intercept)"]] = "Intercept"
rownames[["lmax_commit_age"]] = "log age"
rownames[["ltins"]] = "log size"
rownames[["ldevs"]] = "log devs"
rownames[["lcommits"]] = "log commits"
rownames
}
calculateModel = function(dataset, dataset_name) {
X = summarizeByLanguage(dataset)
X$max_commit_age[X$max_commit_age == 0] <- 1
#Y = logTransform(X, log10, log)
Y = logTransform(X, log, log)
#Y <- Y %>% group_by(language) %>% sample_n(nprojects)
# fit the negative binomial regression
weights = contr.Weights(Y$language)
nbfit = glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language, contrasts = list(language = contr.Weights(Y$language)), data=Y)
nbfit_r = glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r, contrasts = list(language_r = contr.Weights(Y$language_r)), data=Y)
# combine them into single result table
result = combineModels(nbfit, nbfit_r, Y$language)
result$pVal = round(result$pVal, digits = 3)
result$name = rownames(result)
result$dataset = dataset_name
result$signifficant = result$pVal <= 0.05 # orly?
result
}
setwd("~/dejacodeDocker")
#------------------------SMART THINGY----------------------------------#
inputs = c('stars.csv',
'experienced_authors_ratio.csv',
'experienced_authors.csv',
'commits.csv',
'mean_commit_message_sizes.csv',
'issues.csv',
'mean_changes_in_commits.csv')
for (f in inputs){
d = load_dataset(paste('./artifact-inputs/', f, sep = ''))
print(f)
d = fix_commit_age(d)
d = fix_too_small_groups(d)
nrow(d %>% group_by(project, language) %>% dplyr::summarize(n=n()) %>% filter(n < 20))
model = calculateModel(d, "ours")
write.csv(model[c("coef", "pVal")], file = paste('./outputs/', f, sep = ''))
}
#-------------------RUN PYTHON
#install.packages("reticulate")
library(readr)
library(car)
library("data.table")
library("assertthat")
library("fst")
library(stringr)
library(plyr)
library("ggplot2")
library(ggrepel)
library(scales)
library(xtable)
library(MASS)
library(gplots)
library(dplyr)
library(gridExtra)
library(grid)
library(tidyr)
library("reticulate")
load_dataset = function(path) {
result = read_delim(path, delim=',', escape_double=FALSE, escape_backslash=TRUE, quote="\"")
#firstCol = colnames(result)[[1]]
#if (substr(firstCol,1,1) == "#")
#  colnames(result)[[1]] = substring(firstCol, 2)
result = result %>% select(language, project, sha, files, devs = committer, commit_date, commit_age, insertion, deletion, isbug)
result$language = as.factor(result$language)
invisible(result)
}
fix_commit_age = function(dataset) {
dataset %>% group_by(project) %>% mutate(min_date = min(commit_date)) %>% mutate(commit_age = as.integer((commit_date - min_date)/(24 * 3600))) %>% select(-c(min_date))
}
fix_too_small_groups = function(dataset) {
dataset %>% group_by(project, language) %>% mutate(n = n()) %>% filter(n > 20) %>% select(-c(n))
}
summarizeByLanguage = function(what) {
what %>%
group_by(project, language) %>%
dplyr::summarize(
commits = n_distinct(sha),
tins = sum(insertion),
max_commit_age = max(commit_age),
bcommits = sum(isbug),
#domain = unique(domain),
devs = n_distinct(devs)
)
}
logTransform = function(what, log1 = log, log2 = log) {
data.frame(
language = what$language,
ldevs = log1(what$devs),
lcommits=log1(what$commits),
ltins=log2(what$tins),
lmax_commit_age=log1(what$max_commit_age),
lbcommits=log2(what$bcommits + 0.5*(what$bcommits==0)),
bcommits=what$bcommits,
#combined=factor(what$combined),
#domain=factor(what$domain),
#domain_r = relevel(what$domain, rev(levels(what$domain))[1]),
language_r = relevel(what$language, rev(levels(what$language))[1]),
commits = what$commits
#combined_r = relevel(what$combined, rev(levels(what$combined))[1])
)
}
logTransformTest = function(dat) {
data.frame(
language = dat$language,
ldevs = log(dat$devs),
lcommits=log(dat$commits),
ltins=log(dat$tins),
lmax_commit_age=log(dat$max_commit_age),
lbcommits=log(dat$bcommits + 0.5*(what$bcommits==0)),
bcommits=dat$bcommits,
#combined=factor(what$combined),
#domain=factor(what$domain),
#domain_r = relevel(what$domain, rev(levels(what$domain))[1]),
language_r = relevel(dat$language, rev(levels(dat$language))[1]),
commits = dat$commits
)
}
# Weighted contrasts as described and used by the authors of the original paper
contr.Weights <- function(fac)
{
fDist=summary(fac)
fSum=contr.sum(levels(fac))
fSum[nrow(fSum),] = -fDist[1:ncol(fSum)]/fDist[length(fDist)]
fSum
}
# Takes the glm model and the releveled second model for the last observation and combines them together returning a single data frame
combineModels = function(model, model_r, var, pValAdjust = "none") {
controlVariables = 4
s = summary(model)$coefficients
s_r = summary(model_r)$coefficients
rownames = getModelRowNames(model, var)
coef = round(c(s[,1], s_r[controlVariables + 2, 1]), 2)
se = round(c(s[,2], s_r[controlVariables + 2, 2]), 2)
pVal = c(s[,4], s_r[controlVariables + 2, 4])
if (pValAdjust == "bonferroni" || pValAdjust == "fdr")
pVal[(controlVariables + 2):length(pVal)] = p.adjust(pVal[(controlVariables + 2):length(pVal)], pValAdjust)
#pVal = round(pVal, 3)
names(coef) = rownames
data.frame(
coef,
se,
pVal
)
}
getModelRowNames = function(model, var) {
controlVariables = 4
rownames = c(dimnames(summary(model)$coefficients)[[1]][1:(1 + controlVariables)], names(summary(var)))
names(rownames) = rownames
rownames[["(Intercept)"]] = "Intercept"
rownames[["lmax_commit_age"]] = "log age"
rownames[["ltins"]] = "log size"
rownames[["ldevs"]] = "log devs"
rownames[["lcommits"]] = "log commits"
rownames
}
calculateModel = function(dataset, dataset_name) {
X = summarizeByLanguage(dataset)
X$max_commit_age[X$max_commit_age == 0] <- 1
#Y = logTransform(X, log10, log)
Y = logTransform(X, log, log)
#Y <- Y %>% group_by(language) %>% sample_n(nprojects)
# fit the negative binomial regression
weights = contr.Weights(Y$language)
nbfit = glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language, contrasts = list(language = contr.Weights(Y$language)), data=Y)
nbfit_r = glm.nb(bcommits~lmax_commit_age+ltins+ldevs+lcommits+language_r, contrasts = list(language_r = contr.Weights(Y$language_r)), data=Y)
# combine them into single result table
result = combineModels(nbfit, nbfit_r, Y$language)
result$pVal = round(result$pVal, digits = 3)
result$name = rownames(result)
result$dataset = dataset_name
result$signifficant = result$pVal <= 0.05 # orly?
result
}
setwd("~/dejacodeDocker")
#------------------------SMART THINGY----------------------------------#
inputs = c('stars.csv',
'experienced_authors_ratio.csv',
'experienced_authors.csv',
'commits.csv',
'mean_commit_message_sizes.csv',
'issues.csv',
'mean_changes_in_commits.csv')
for (f in inputs){
d = load_dataset(paste('./artifact-inputs/', f, sep = ''))
print(f)
d = fix_commit_age(d)
d = fix_too_small_groups(d)
nrow(d %>% group_by(project, language) %>% dplyr::summarize(n=n()) %>% filter(n < 20))
model = calculateModel(d, "ours")
write.csv(model[c("coef", "pVal")], file = paste('./outputs/', f, sep = ''))
}
#-------------------RUN PYTHON
# Set the path to the Python executable file
use_python("./plotClean.py")
setwd("~/trustworthy_titanic")
dirs = list.dirs(path = './r/kernels', full.names = FALSE, recursive = FALSE)
#dirs = rev(dirs)
dirs
detach.packages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(pack)
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "test.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
names = c()
for (dir in dirs)
{
print(dir)
d = paste("~~/titanic/notebooks/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
start_time <- Sys.time()
rcmd("BATCH", f.name, timeout = 300)
end_time <- Sys.time()
t = end_time - start_time;
t = as.numeric(t, units = "secs")
print(t)
n = cbind(dir, t)
names = rbind(names, n)
}
setwd("~/trustworthy_titanic")
dirs = list.dirs(path = './r/kernels', full.names = FALSE, recursive = FALSE)
#dirs = rev(dirs)
for (dir in dirs)
{
#try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
#)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(c('back', pack))
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(c('base', pack))
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(c('base', pack))
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(c('base', pack))
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
get.libs <- function(filepath){
pack = c()
f.l = readLines(filepath)
for (ln in f.l)
{
if (grepl('^library', ln)) pack = c(pack, ln)
}
return(c('base', pack))
}
for (dir in dirs)
{
try(
{
print(dir)
detach.packages()
library(NCmisc)
library(jsonlite)
library(stringr)
d = paste("~/trustworthy_titanic/r/kernels/",dir, sep="")
d = paste(d, "/script", sep="")
print(d)
setwd(d)
f.name <- list.files(path = ".", pattern = "\\.R$", full.names = TRUE, recursive = TRUE, ignore.case = TRUE)
libs = get.libs(f.name)
lapply(libs, write, "test.R", append=TRUE)
lapply(libs, write, "libraries.txt", append=TRUE)
sys.source("test.R")
file.remove("test.R")
file.remove("test.txt")
lst <- list.functions.in.file(f.name, alphabetic = TRUE)
exportJSON <- toJSON(lst)
write(exportJSON, paste(str_remove(f.name, ".R"), ".json", sep=""))
#rm(list=setdiff(ls(), "dirs")) #will clear all objects includes hidden objects.
#gc()
}
)
}
