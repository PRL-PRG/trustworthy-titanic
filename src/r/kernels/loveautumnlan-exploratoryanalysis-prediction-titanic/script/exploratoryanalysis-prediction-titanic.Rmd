---
title: "Data exploration, virsulization and machine learning"
author: "Abby Chen"
date: "Nov. 2016"
output: html_document
---

#1.Introduction

This is my first time to script a project on Kaggle. Before I actually start my own analysis, I read several report shared by other people, who gave me lot of inspiration on this project.

##1.1 Background

The sinking of the Titanic is one of the most infamous shipwrecks in history. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others. There is an way to predict what sorts of people were likely to survive


##1.2 Objectives and Approaches

The main objective is to predict who were more likely to survive the sinking of Titanic. Analysis was done on both training data and testing data, includes three main parts:Data exploratory, Data visualization and Data analysis, which refers to machine learning here

#2. Data Exploratory
##2.1 Data import
```{r}
t_test <- read.csv("../input/test.csv", header=T)
t_train <- read.csv("../input/train.csv",header=T)
# Rename test string for easier understanding
t_train$Survived_ <- as.factor(with(t_train, 
                                    ifelse(Survived=="1","Survived", 
                                           ifelse(Survived==0,"Died","N/A"))))
#combine the data and check the structure 
t_test[,c("Survived","Survived_")] <- NA
t_full <- rbind(t_train,t_test)  
str(t_full) #check data structure
```
The full data file includes 1309 observations and 12 variables, with **Survived** as the response/dependent variable. Let's look at how is overall survival rate
```{r}
prop.table(table(t_train$Survived_))
```
So only 38% of passengers survived the disaster in the given data set. We know the general rescue rule is 'women and child first', we don't have child information, but will create latter. Now how is the survival rate on women?
```{r}
prop.table(table(t_train$Survived_[which(t_train$Sex=='female')]))

```
Okay, over 74% of women survived the disaster, which is double than average. 
In given data sets, although it doesn't include child information, but we can get information from age. However, before creating child variable, let's look how many passengers missing age

```{r}
sapply(t_full, function(x) sum(is.na(x)))
sapply(t_full,function(x) sum((x)=="")) #count variable with blank value
t_full[is.na(t_full$Fare),]#Which passenger missing Fare ?
```
We have 263 passenger missing age, 1 passenger missing Fare, 1014 passengers have empty Cabin information and two passengers have empty Embarked value.Before we deal with missing values, another main obstacle is outlier, which brings bias of your calculation, so should be treated first!

##2.2 Outlier detection and treatment
To detect outlier, one of best way to show the data on plots. Here I use embarked as an example:

```{r warning=FALSE, message=FALSE, result='hide'}
library(ggplot2) #visualization
library(gridExtra) # multi-panel plot
library(dplyr) #data manipulation
```

```{r warning=FALSE}
ggplot(t_full, aes(factor(Embarked),Fare,fill=factor(Pclass)))+
  geom_boxplot()+ ggtitle("Fare by Embarked and Pclass")
```

It looks like we have outliers, but in fact the four passengers are all in the first class and departed from the same place, so those numbers seem reasonable to me, not need to change.Let's continue to deal with missing values.

##2.2 Missing Fare imputation
Passenger 1044 has NA fare, he is in the third class and embarked in S, so replace value with median fare from the same group
```{r}
t_full$Fare[is.na(t_full$Fare)] <- median(t_full$Fare[which(t_full$Pclass=="3" & t_full$Embarked=="S")],na.rm=T)

```
## 2.3 Missing embarked impurtation
```{r}
t_full[t_full[,"Embarked"]=='',] 
```
Passenger 61 and 830 had empty embarked information, one of them is Mrs.George, let's see if Mr George was on the list
```{r}
t_full$Name <- as.character(t_full$Name)
str <- grep("George Nelson",t_full$Name,perl=T)
select_row <- t_full[str,c("Name","Embarked")]
select_row
```
Unfortunately there are not Mr George in record, so I'm going to impute empty Embarked with values from first class and from same fare range

```{r}
E_F<- with(t_full[t_full$Fare<500,], 
           aggregate(Fare,list(Embarked=Embarked,Pclass=Pclass),
                                                mean,na.rm=T)) #exclude fares higher than 500 to avoid skewed result
E_F 
```
In the first class, Passenger 61 and 830 had fare closest to passenger embarked from S, so replace the blank Embarked with S
```{r}
t_full$Embarked[c(62,830)]="S"
t_full$Embarked <- factor(t_full$Embarked) #drop useless factor levels
```
##2.4 Missing Age imputaiton
Here I'll use MICE package in R, which imputing missing values from a distribution specifically designed for each missing datapoint. Mice is also capable of handling different types of variables

```{r warning=FALSE, message=FALSE, result='hide'}
library(mice)
library(lattice) 
```

```{r}
imp_ <- mice(t_full[,c('Pclass','Sex','SibSp','Parch','Fare','Embarked','Age')],
             m=5, method='pmm', seed=500)  #Impute the missing values
print(imp_) #print the result

#Diagnostic checking: Imputation should be values that close to observation when they are not missing
p1<- xyplot(imp_, Age ~ Pclass,pch = 20, cex = 1.4)
p2<- densityplot(imp_)
grid.arrange(p1,p2,nrow=1,ncol=2)
stripplot(imp_, pch = 20, cex = 1.2)

```

What we would like to see is that the shape of the magenta points (imputed) matches the shape of the blue ones (observed)
The default rounds is 5, most people use pooled result from all imputations when fitting a regression model. But in here I'm going to compare each imputation with original data, and choose the one with most similarity distribution with original data distribution

```{r}
imp_output1 <- complete(imp_,1)
imp_output2 <- complete(imp_,2) 
imp_output3 <- complete(imp_,3) 
imp_output4 <- complete(imp_,4) 
imp_output5 <- complete(imp_,5) 
par(mfrow=c(2,3))
hist(t_full$Age,  main = 'Original Age', xlab = "Age",col='blue')
hist(imp_output1$Age,  main = 'Imputed1 Age', xlab = "Age",col='pink')
hist(imp_output2$Age,  main = 'Imputed2 Age', xlab = "Age",col='pink')
hist(imp_output3$Age,  main = 'Imputed3 Age', xlab = "Age",col='pink')
hist(imp_output4$Age,  main = 'Imputed4 Age', xlab = "Age",col='pink')
hist(imp_output5$Age,  main = 'Imputed5 Age', xlab = "Age",col='pink')
```

Looks the second imputation age distribution is closest to the original distribution, so let's replace with the third impute output
```{r}
t_full$Age <- imp_output2$Age
```
##2.3 Feature engineering
###2.3.1 Child
Having imputed missing age, now I can start to look at whether a passenger is child or not
```{r}
child <- with(t_full, ifelse(Age < 18, "Y","N"))
t_full$Child <- as.factor(child)
```
###2.3.2 Title 
Title gives information on marital status, professional, academic qualification and etc., here I will difference passengers with honorific title and ordinal tile, and see how survival differ on title types
```{r}
#Split full name into title, first name and last name
name <- data.frame(do.call(rbind, strsplit(as.vector(t_full$Name), split = "[,.]")))
head(name)
t_full$Title<- sub(' ','',name$X2)

#join the three columns back to original dataset
H_title <- c('Capt','Col','Don','Dona','Dr','Jonkheer','Lady','Major','Rev','Sir','the Countess')
O_title <- c('Master','Miss','Mlle','Mme','Mr','Mrs','Ms','Mrs','Ms')
Title <- with(t_full,
              ifelse(Title %in% H_title,'Honorific_title',
                     ifelse(Title %in% O_title,'Ordinal_title','other')))

#How survival rate differ on title?
t_full$Title <- as.factor(Title)
prop.table(table(t_full$Survived_, t_full$Title),2)
```
Looks passenger of ordinal title had higher survival rate than passenger with honorific title, but the difference is not much big

#3. Data visulization
Graph the data before actually start to analysis the data will help you discover data pattern and trend

```{r warning=FALSE, message=FALSE, result='hide'}
library(reshape2)
library(scales)
```

```{r}
#Divided data back into training and testing
t_train <- t_full[!is.na(t_full$Survived),]
t_test <- t_full[is.na(t_full$Survived),]
```
##3.1 Survival rate on one factor level
Here I will show the proportion of people survived, proportion will give a more straight way to make comparison instead of using actually numbers of survival. 

```{r}
attach(t_train)

#calcute the proportion
Gender_S <- melt(prop.table(table(Sex,Survived_),1))
Child_S <- melt(prop.table(table(Child,Survived_),1))
Title_S <- with(t_train,  melt(prop.table(table(Title,Survived_),1)))
Pclass_S <- melt(prop.table(table(Pclass,Survived_),1))
Embarked_S <- melt(prop.table(table(Embarked,Survived_),1))
SibSp_S <- with(t_train, melt(prop.table(table(SibSp,Survived_),1)))

#Use plot to show the result
p1 <- ggplot(Gender_S)+geom_bar(aes(Sex, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("Gender vs. Survived")+xlab("")+ylab("%")
p2<- ggplot(Child_S)+geom_bar(aes(Child, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("Child vs. Survived")+xlab("")+ylab("%")
p3<- ggplot(Title_S)+geom_bar(aes(Title, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("Title vs. Survived")+xlab("")+ylab("%")
p4<-ggplot(Pclass_S)+geom_bar(aes(Pclass, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("Pclass vs. Survived")+xlab("")+ylab("%")
p5 <-ggplot(Embarked_S)+geom_bar(aes(Embarked, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("Embarked vs. Survived")+xlab("")+ylab("%")
p6 <-ggplot(SibSp_S)+geom_bar(aes(SibSp, value,fill=factor(Survived_)),stat="identity")+
  ggtitle("SibSp vs. Survived")+xlab("")+ylab("%")
p7<- ggplot(t_train, aes(x=Age, fill=factor(Survived_)))+
  geom_histogram(position="dodge",binwidth=1.5) +
  ggtitle ("Age vs. Survived") +xlab("Age")
p8<- ggplot(t_train[Fare<500,], aes(factor(Survived), Fare, fill = factor(Survived_))) +
  geom_boxplot() + ggtitle ("Fare(less than 500) vs. Survived")+xlab("")

grid.arrange(p1,p2,p3,p4,nrow=2,ncol=2)
grid.arrange(p5,p6,p7,p8,nrow=2,ncol=2)
```
From charts above, looks those survived were:female, Child, with original tile, in the higher class, travel with 1-2 family members, paid higher fare for the ticket and depart from embarkation point C

##3.2 Survival rate on two factors level
```{r}
a<-prop.table(table(Sex,Survived_,Embarked),c(1,3))
# calculate the proportation of survival across gender and embarked
b<- melt(a)#convert values into a molten data frame
b$Freq <-  paste(round(b$value*100,digits=1),"%",sep="") #change the format to percentage
p9<- ggplot(b, aes(x=Embarked, y=value, fill=factor(Survived_))) +  geom_bar(stat="identity") + 
  facet_wrap(~Sex,ncol=2) + ggtitle("Survival on Gender and Embarked")+
  xlab("Embarked") +  ylab("%")
p9

b2<- melt(prop.table(table(Sex,Survived,Pclass),c(1,3)))
b2$Freq <-  paste(round(b2$value*100,digits=1),"%",sep="")
p10<- ggplot(b2, aes(x=Pclass, y=value, fill=factor(Survived))) + 
  geom_bar(stat="identity") +   facet_wrap(~Sex,ncol=2) +
  ggtitle("Survival on Gender and Class")+xlab("Pclass") + ylab("%")
p10
```

On two factors level, almost all female in the upper class survived, most of female departed from embarkation point C survived

#4. Prediction - Machine learning
Three methods are applied to build different trees, results are compared here to illustrate which one generates a higher prediction accuracy
In order to make the comparison available, giving training data is randomly split into training and testing, so that I can calculate the prediction accuracy rate
```{r}
set.seed(100)
dt <- sample(nrow(t_train),nrow(t_train)*0.8) 
t_train_model <- t_train[dt,]
t_train_test <- t_train[-dt,]
```
##4.1 Classification tree
```{r message=FALSE,results='hide'}
library(rpart) #rpart has good ability to handle missing, since we have a lot of missing values
library(rpart.plot)
```
```{r}
set.seed(231)
tree.train <- rpart(factor(Survived_) ~ 
                      Pclass + Sex + Age + Child+ SibSp + Parch + Fare + Embarked + Title ,
                    data=t_train_model,method="class")
#illustrate the result
par(mfrow=c(1,1))
rpart.plot(tree.train, 
           box.col=c("#FF6666", "#33CCCC")[tree.train$frame$yval],cex=0.8)
```

Because the tree force each observation to be grouped, so a simple issue with decision tree is overfitting, which bring a low prediction ability. So prune the tree is recommended

```{r}
tree.train$cptable 
# Normally, we select a tree size that minimizes the cross-validated error, which is 'Xerror'
# Let's automate the selection
tree.prun<- prune(tree.train, cp=tree.train$cptable[which.min(tree.train$cptable[,"xerror"]),"CP"])
# show the pruned tree using following code
#rpart.plot(tree.prun, box.col=c("#FF6666", "#33CCCC")[tree.prun$frame$yval])
```

how is the prediction ?
```{r}
pr.yhat = predict(tree.prun,newdata=t_train_test,type="class") 
sum(t_train_test$Survived_==pr.yhat) / nrow(t_train_test) 

```

It generate a 81.6% prediction accuracy. Also you can call "summary()" to generate the summary report, which gives a more detail explanation on the tree

##4.2 Random forest
One of advantages of random forest is the robustness, because every tree is grow on a random selection of variables, so not only it solves the problem of overfitting but also it is very flexible

```{r message=FALSE,results='hide'}
library(randomForest) 
```

```{r}
set.seed(122)

rf.train <- randomForest(factor(Survived_) ~ 
                           Pclass + Sex + Age + Child+ SibSp + Parch + Fare + Embarked + Title,
                         data=t_train_model, mtry=3,importance=TRUE) 
plot(rf.train)
legend('topright', colnames(rf.train$err.rate), col=1:3, fill=1:3)
```

The output suggests the model is better at predicting died than survived
Let's look at the importance of the factors when doing prediction

```{r}
varImpPlot(rf.train)
```

It generate consistent variable importance result as previous: the most important three variables are Sex, Fare and Age; While passenger title is the least important variable at prediction
Let's look at how random forest performs at prediction
```{r}
rf.yhat = predict(rf.train,newdata=t_train_test,type="class") 
sum(t_train_test$Survived_==rf.yhat) / nrow(t_train_test) 
```

The overall prediction accuracy is 86%, which is 4% higher than classification tree!

##4.3 Bagging
```{r}
set.seed(221)
bag.train <- randomForest(factor(Survived) ~ 
                            Pclass + Sex + Age + Child+ SibSp + Parch + Fare + Embarked + Title,
                          data=t_train_model, mtry=9,importance=TRUE) 
plot(bag.train)
legend('topright', colnames(rf.train$err.rate), col=1:3, fill=1:3)

varImpPlot(bag.train)#generate the importance of variables
```

It suggests that the model using bagging is also better at predict died than survived.
What's the importance of the factors?
```{r}
bag.yhat = predict(bag.train,newdata=t_train_test,type="class") 
sum(t_train_test$Survived==bag.yhat) / nrow(t_train_test) 
```
The model using bagging has 81% prediction accuracy, slightly lower than other two methods

So, to sum up, classification tree gives a good visualization on how the decision is been made, while random forest performs better at prediction.
The final step is use random forest to predict giving testing data

#5. Final prediciton
```{r}
set.seed(122)
rf.train <- randomForest(factor(Survived) ~ 
                           Pclass + Sex + Age + Child+ SibSp + Parch + Fare + Embarked + Title,
                         data=t_train, mtry=3,importance=TRUE) 

rf.yhat = predict(rf.train,newdata=t_test,type="class") 

# Save the solution to a dataframe
Prediction <- data.frame(PassengerID = t_test$PassengerId, Survived = rf.yhat)

# Output the file
write.csv(Prediction, file = 'rf_prediction.csv', row.names = F)
```
