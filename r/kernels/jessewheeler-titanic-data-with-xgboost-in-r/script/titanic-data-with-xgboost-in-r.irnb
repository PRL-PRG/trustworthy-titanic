{"cells":[{"metadata":{"_uuid":"83abf0bb03ca8091467c3b3c5bb200e4cc85d5e2","_execution_state":"idle","trusted":true},"cell_type":"code","source":"library(tidyverse)\nlibrary(xgboost)\nlist.files(path = \"../input\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f0e682b5a9db61c72698a40598cc56c5eba5eee"},"cell_type":"code","source":"train_data = read.csv('../input/train.csv', na.strings = c(\"\", \" \", \"NA\"))\ntest_data  = read.csv('../input/test.csv',  na.strings = c(\"\", \" \", \"NA\"))\ntrain_data$Train  <- TRUE\ntest_data$Train  <- FALSE\ntest_tmp  <- test_data\ntest_tmp$Survived = FALSE\n\n# combine all of the data \nall_data = rbind(train_data, test_tmp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9da608807b2d10d2008854dea5591ade91a3d905"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_uuid":"40aad607c7d3132c931e150db23e83e814e8dc9f"},"cell_type":"markdown","source":"We will do some feature engineering to get the most out of these data as possible. If you are at all familiar with this problem, you will know that there are not many observations, and some of the observations have missing values. Because of this, it is extremely important that we try to get all of the information out of what we do have as we can."},{"metadata":{"_uuid":"4521fb1e9b29e4bab29e3ebfcdf7f9da062f3060"},"cell_type":"markdown","source":"First, if you take a look at the names, there are some titles included like Mr., Mrs., Master, etc. While Mr. probably won't be an important variable for us (because we already have imformation about males and their ages), other title imformation might be important (like how important was that person, as rude and judgemental as that sounds). "},{"metadata":{"trusted":true,"_uuid":"d9d570ba093a9ae3b28b4f041eeac91ab3553df1"},"cell_type":"code","source":"all_data$Title <- gsub('(.*, )|([.].*)', '', all_data$Name) # Get ride of anything that ends in a comma or anything that starts with a period\n\n# Just to check how many people we have with each title\nall_data %>%\n    group_by(Title, Sex) %>%\n    summarize(n = n()) %>%\n    arrange(Title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e320ee55db748cb69ca485b36c55c9b56fa1c272"},"cell_type":"markdown","source":"Notice that there are several different categories for essentially the same thing (like Miss, Ms and Mlle). Let's combine these categories. Additionally, there are some categories with very few people in them; this typically isn't very good for classification purposes because it can be challanging to generalize (for example, there is only one captin on the boat and he happens to be in our training set; if we use captin as a predictor variable or it's own class then it won't generalize to the test set because there probably aren't any more captins in that set)."},{"metadata":{"trusted":true,"_uuid":"5f0982b06b8ed9554f1b4529d887ccb794448f51"},"cell_type":"code","source":"all_data$Title[all_data$Title == 'Mlle']  <- 'Miss'\nall_data$Title[all_data$Title == 'Ms']    <- 'Miss'\nall_data$Title[all_data$Title == 'Mme']   <- 'Mrs'\n\nspecial_people  <- c('Capt', 'Col', 'Dona', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Rev', 'Sir', 'the Countess', 'Don')\nall_data$Title[all_data$Title %in% special_people]  <- 'Special'\n# all_data$Title[all_data$Title == 'Dr' & all_data$Sex == 'male']    <- 'Mr'\n# all_data$Title[all_data$Title == 'Dr' & all_data$Sex == 'female']  <- 'Mrs'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b6f871b0e7967992cc1276fe0e0ed1d2511e6f0"},"cell_type":"markdown","source":"Now lets take another look at the different titles that we have:"},{"metadata":{"trusted":true,"_uuid":"8baa31c7e00f90e7dad19962968f028b0b11ac9d"},"cell_type":"code","source":"all_data %>%\n    group_by(Title, Sex) %>%\n    summarize(n = n()) %>%\n    arrange(Title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f264f5bc3bb113c98aef3cee5ee5afdbeb53cc4"},"cell_type":"markdown","source":"Something else that might be useful is to use the surnames of the passengers somehow. I have heard that others have done this successfully, but I will not try that for now (maybe later). "},{"metadata":{"trusted":true,"_uuid":"fbc4f92d013a8dbee02210cca48c4d468bc79e7f"},"cell_type":"code","source":"all_data$Name %>%\n    gsub(',.*$','', .) -> all_data$Surname\n\ncat('Unique number of surnames: ',nlevels(factor(all_data$Surname)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8244eaca38a628c4caaea5089f51a318686477d8"},"cell_type":"markdown","source":"Another feature that we could look at is Family Size. We can just get the family size by adding the SibSp and Parch variables together. This is probably where we could incorporate the surname data as well; we could augment the family size based off of people with the same last names or staying in Cabins that are the same or close to eachother. Again, I think that I'm going to skip that for now. "},{"metadata":{"trusted":true,"_uuid":"78c2834dcd9cb20b0ca8e4f00d19d9979971e80d"},"cell_type":"code","source":"all_data %>%\n    mutate(Fam_Size = SibSp + Parch + 1) -> all_data\n\nnames(all_data) # veiw results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9b03f4ae8318ddbb1579b56f66692559501cfcd"},"cell_type":"markdown","source":"Since we have finished that, I will go ahead and remove the variables that most likely won't help us with the classification:"},{"metadata":{"trusted":true,"_uuid":"83fe855b003b1b5112712980794d9255f3528d33"},"cell_type":"code","source":"all_data %>%\n    select(-c(PassengerId, Name, Ticket, Cabin, Surname)) -> all_data\n\nhead(all_data) # veiw results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7de753dda690de23163139d0ec0736ecb388b1e8"},"cell_type":"markdown","source":"Now I will make all of the categorical variables as factors rather than characters"},{"metadata":{"trusted":true,"_uuid":"17d68c8e9894fddb675bcceba84008c41ecabcf1"},"cell_type":"code","source":"factor_vars <- c('Pclass','Sex','Embarked',\n                 'Title')\n\nall_data[factor_vars] <- lapply(all_data[factor_vars], function(x) as.factor(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d48c47f6c6516a5e9684d5c55b5d480a5573b189"},"cell_type":"markdown","source":"For the algorithm to be more efficient, it is a good idea to create dummy-variables (or one-hot-encodings). This should help speed up the algorithms. There is a really good package to do this automatically for us calld fastDummies. The function I will use is called dummy_cols and it automatically turns all factor variables or character variables into dummy variables (or one-hot-encodings). You can additionally specify which columns to do this to if you don't want to do this to all of your columns. The aurgument *remove_most_frequent_dummy = TRUE* just removes one of the dummy variables. This is a good idea because keeping all of the one-hot-encodings would be keeping too-much information; knowing all of the categories but one allows you to know the other category."},{"metadata":{"trusted":true,"_uuid":"3e426a7ebae764579d4929352a0fe10e0ad2ae0f"},"cell_type":"code","source":"all_data %>%\n    fastDummies::dummy_cols(remove_most_frequent_dummy = TRUE) %>%\n    select(-c(Pclass, Sex, Embarked, Title)) -> all_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"705dd1a9f5eceee5fc50512d53626d9f61192e78"},"cell_type":"markdown","source":"As I said before, there are a lot of missing data. We could either try to delete those observations with missing data. This sometimes works just fine if we have lots of data and few missing points, but that isn't the case here. Another option is to do data Imputation, which can be done in many different ways. My usual favorite is by using a Random Forest to predict the missing values. When messing with these data, I tried several other methods by artificailly creating some missing data and checking which imputation method was the best and for me missForest worked the best."},{"metadata":{"trusted":true,"_uuid":"33e207d0599b5bc2046dd28834730fac31b93e9c"},"cell_type":"code","source":"library(missForest)\n\nset.seed(555)\nall_data_mf <- missForest(all_data[, -9], maxiter = 100)\n                                \nall_data_mf$ximp$Train <- all_data$Train\n                           \nall_data_mf$ximp %>%\n    filter(Train) %>%\n    select(-Train) -> train_mf\n\nall_data_mf$ximp %>%\n    filter(!Train) %>%\n    select(-Train) -> test_mf\n\nrownames(test_mf) <- test_data$PassengerId","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e12a7f23e83a01ee7be2b558ea4e1f04526f4e7"},"cell_type":"markdown","source":"Finally I think we have the input we need to train some classification algorithms:"},{"metadata":{"trusted":true,"_uuid":"6fd3ed15fcf22bdc51ae162e054fe18ea7c7b603"},"cell_type":"code","source":"train_mf %>%\n    select(-Survived) %>%\n    as.matrix() -> input_x\n\ntrain_mf$Survived <- factor(train_mf$Survived)\ninput_y <- train_mf$Survived\n\ntest_mf %>%\n    as.matrix() -> test_x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ca0e2be81afa64c6d53ecc1d9319d1454db725e"},"cell_type":"markdown","source":"# Random Forests (no tunning)"},{"metadata":{"_uuid":"41257b075bcb16796a97730b75c057dfada280aa"},"cell_type":"markdown","source":"I really like the Random Forests algorithm because even with little to no tunning we get pretty good results. I'm just going to pull this one off of the shelf and see how well it does. "},{"metadata":{"trusted":true,"_uuid":"0fee3441742cc5a24224b7967a9f42c4dea28e37"},"cell_type":"code","source":"library(randomForest)\nrf  <- randomForest(x = input_x,\n                    y = input_y,\n                    ntree = 1001,\n                    importance = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db0574ae37d5357a1ac6fad04cad35689363c465"},"cell_type":"code","source":"varImpPlot(rf, main=\"Variable Importance Plots\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ef165b2c69dc373fc063b137e3c13abbeec910"},"cell_type":"markdown","source":"According to the Random Forest, the most important variable in this problem is whether or not the passenger was a female, and the second most important was age. This seems to be inline with the movie - women and children first. We can now look to see how these variables affected the classification: "},{"metadata":{"trusted":true,"_uuid":"e9063d82a4c231c298f04992ce01557287e321ba"},"cell_type":"code","source":"partialPlot(rf, x.var = Age, pred.data = input_x, which.class = 1)\npartialPlot(rf, x.var = Sex_female, pred.data = input_x, which.class = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4af351538be32c146efc220745cbb334a38e9cf1"},"cell_type":"markdown","source":"Well that doesn't look great. It looks like there is some serious over-fitting to the age variable. To fix this, we might want to just break the age variable up into several different categories. Lets take a look at the distribution of this variable to help us decide where to make the cut-off."},{"metadata":{"trusted":true,"_uuid":"3c4e63448390852b70df348765378f3eeb439b15"},"cell_type":"code","source":"head(all_data_mf$ximp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0de8c4d7fe1ccfce82b91a9732a20e8c832149a"},"cell_type":"code","source":"ggplot(all_data_mf$ximp, aes(x = Age, fill = factor(Survived))) + \n    facet_wrap(~Sex_female) + \n    geom_histogram()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10de9c3f4f164471ca5beedbafdaf16fcb7574ba"},"cell_type":"markdown","source":"There is deffinitely some interesting things going on with Age, and it may be due to the fact that we had to impute so many of its values. It seems to me that there is a natural cut-off of Age around 15(ish) years old. I'll use that as a cut-off. Additionally, it seems like being over 40 is advantageous as well so those will be my cut-offs."},{"metadata":{"trusted":true,"_uuid":"a06e254eaeb446490dc76b0e29136b99e9b8dd21"},"cell_type":"code","source":"all_data_mf$ximp$Age_Group[all_data_mf$ximp$Age <= 19] <- 'child'\nall_data_mf$ximp$Age_Group[all_data_mf$ximp$Age >= 40] <- 'old'\nall_data_mf$ximp$Age_Group[all_data_mf$ximp$Age > 19 & all_data_mf$ximp$Age < 40] <- 'adult'\n\nhead(all_data_mf$ximp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"346af4ecaf0883f967a3e6b4e372e7be054852fe"},"cell_type":"code","source":"all_data_mf$ximp$Age_Group_old[all_data_mf$ximp$Age_Group == 'old'] <- 1\nall_data_mf$ximp$Age_Group_old[all_data_mf$ximp$Age_Group != 'old'] <- 0\n\nall_data_mf$ximp$Age_Group_child[all_data_mf$ximp$Age_Group == 'child'] <- 1\nall_data_mf$ximp$Age_Group_child[all_data_mf$ximp$Age_Group != 'child'] <- 0\n\nall_data_mf$ximp %>%\n    select(-c(Age, Age_Group)) -> all_data_mf$ximp\n\nhead(all_data_mf$ximp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"409a561be62979e4eb92b4125616d944d6f440f7"},"cell_type":"markdown","source":"Now I just want to make sure that the data I use has all of these changes, so I will just copy what I have done before below:"},{"metadata":{"trusted":true,"_uuid":"5db22eb359f5e741dcae372353c0f7c0673ae4ee"},"cell_type":"code","source":"all_data_mf$ximp %>%\n    filter(Train) %>%\n    select(-Train) -> train_mf\n\nall_data_mf$ximp %>%\n    filter(!Train) %>%\n    select(-Train) -> test_mf\n\nrownames(test_mf) <- test_data$PassengerId\n\ntrain_mf %>%\n    select(-Survived) %>%\n    as.matrix() -> input_x\n\ntrain_mf$Survived <- factor(train_mf$Survived)\ninput_y <- train_mf$Survived\n\ntest_mf %>%\n    as.matrix() -> test_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6a4e25b8a37d865a3172318557dceb1a1af7b03"},"cell_type":"code","source":"rf  <- randomForest(x = input_x,\n                    y = input_y,\n                    ntree = 1001,\n                    importance = TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51bade51c7ac425cf8034b6e090e5a339fd912eb"},"cell_type":"code","source":"varImpPlot(rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15af46473a8c2fca3f9b4314a606ced66ff3664d"},"cell_type":"code","source":"partialPlot(rf, x.var = Age_Group_child, pred.data = input_x, which.class = 1)\npartialPlot(rf, x.var = Age_Group_old, pred.data = input_x, which.class = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bf41310b9865d7b15e7c48fb05ad0b909c7f461"},"cell_type":"code","source":"rf_predictions <- data.frame(PassengerId = rownames(test_x), Survived = as.numeric(as.character(predict(rf, test_x))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eb740376ed33dc0390111464c24a875afbbb303"},"cell_type":"code","source":"rf_predictions %>%\n    group_by(Survived) %>%\n    summarize(n = n(), p = n() / nrow(test_x))\n\nwrite.csv(rf_predictions, file = 'rf_Solution.csv', row.names = F)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d73c0e0bec02a245011fb87b5cd88abac1fc106a"},"cell_type":"markdown","source":"# Tunning XGBoost model with Caret"},{"metadata":{"_uuid":"3ac1fc05ce325b8bc72e31bbbe7a57633d12299e"},"cell_type":"markdown","source":"## Round 1"},{"metadata":{"_uuid":"455c34abd37eb332171a891e579f939a06ebaf3d"},"cell_type":"markdown","source":"I have created all of these rounds of tunning because that is a great way to solve a general problem similar to this one, but if you look at the plots that I have created it looks like there really isn't any improvement with each round. Still, here is the process:"},{"metadata":{"_uuid":"99be4ef1eaa507dcf6363eb7eb59e10763403ceb"},"cell_type":"markdown","source":"First we are going to search for an initial depth and eta to start our training"},{"metadata":{"trusted":true,"_uuid":"b216cc8bf99b07a298e452bad91d62d4273a1743"},"cell_type":"code","source":"library(caret)\nxgb_grid = expand.grid(\n    nrounds = seq(from = 200, to = 1000, by = 100),\n    max_depth = c(2, 3, 4, 5, 6),\n    eta = c(0.025, 0.05, 0.1, 0.3),\n    gamma = 0,\n    colsample_bytree = 1,\n    min_child_weight = 1,\n    subsample = 1\n)\n\nxgb_trcontrol = trainControl(\n    method = \"repeatedcv\",\n    number = 5,\n    repeats = 3,\n    allowParallel = TRUE,\n)\n\nxgb_train = train(\n    x = input_x,\n    y = input_y,\n    trControl = xgb_trcontrol,\n    tuneGrid = xgb_grid,\n    method = 'xgbTree'\n)\n\nplot_fit <- function(x) {\n  ggplot(x) +\n    coord_cartesian(ylim = c(0.6, 1))\n}\n\nplot_fit(xgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"630fcc75b06419c928e0b013484abc8be765ffd0"},"cell_type":"code","source":"xgb_train$bestTune\n# nrounds=800, max_depth=3, eta=0.025, gamma=0, colsample_bytree=1, min_child_weight=1 subsample=1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"daa95dc82c182e59a98c06525bc720143c85bae3"},"cell_type":"markdown","source":"## Round 2"},{"metadata":{"_uuid":"10ae02755142a69ce5c6c2fdc750435e66582cf5"},"cell_type":"markdown","source":"Now the tunning I will focus on is min_child_weight"},{"metadata":{"trusted":true,"_uuid":"4d2558471b23075902723798770b9e6437e4fc40"},"cell_type":"code","source":"xgb_grid = expand.grid(\n    nrounds = seq(from = 200, to = 1000, by = 100),\n    max_depth = (xgb_train$bestTune$max_depth - 1):(xgb_train$bestTune$max_depth + 1),\n    eta = xgb_train$bestTune$eta,\n    gamma = 0,\n    colsample_bytree = 1,\n    min_child_weight = c(1, 2, 3),\n    subsample = 1\n)\n\nxgb_train = train(\n    x = input_x,\n    y = input_y,\n    trControl = xgb_trcontrol,\n    tuneGrid = xgb_grid,\n    method = 'xgbTree'\n)\n\nplot_fit(xgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0a8c7095c473ddbaccadd607ea56bde405ed2af"},"cell_type":"code","source":"xgb_train$bestTune\n# nrounds=500, max_depth=4, eta=0.1, gamma=0.2, colsample_bytree=0.45, min_child_weight=1 subsample=.5\n# new nrounds=400, max_depth=3, eta=0.1, gamma=0.6, colsample_bytree=0.45, min_child_weight=1 subsample=.5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7ec5a9af45fcd02a6041788840a21c3dd93ef8c"},"cell_type":"markdown","source":"## Round 3"},{"metadata":{"_uuid":"2e26d29899c7daa49c962d64303b9d249b5eef73"},"cell_type":"markdown","source":"This round will focus on subsampling both row and column"},{"metadata":{"trusted":true,"_uuid":"d7f61f9cd619b59ef3e476b9126eca302231e11b"},"cell_type":"code","source":"xgb_grid = expand.grid(\n    nrounds = seq(from = xgb_train$bestTune$nrounds - 50, to = xgb_train$bestTune$nrounds + 50, by = 50),\n    max_depth = xgb_train$bestTune$max_depth,\n    eta = xgb_train$bestTune$eta,\n    gamma = 0,\n    colsample_bytree = c(0.4, 0.6, 0.8, 1.0),\n    min_child_weight = xgb_train$bestTune$min_child_weight,\n    subsample = c(.5, .7, .9, 1)\n)\n\nxgb_train = train(\n    x = input_x,\n    y = input_y,\n    trControl = xgb_trcontrol,\n    tuneGrid = xgb_grid,\n    method = 'xgbTree'\n)\n\nplot_fit(xgb_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"895eeedd3cf87fe3aecbd4317a7cfc38353b9037"},"cell_type":"markdown","source":"## Round 4"},{"metadata":{"_uuid":"b465db1f98134f00c9c2e2ed13cac1fc17132a34"},"cell_type":"markdown","source":"Now we will focus on the penalty paramenter gamma"},{"metadata":{"trusted":true,"_uuid":"3e396e3294b2fb288a1923c49a9c3a375f5ea782"},"cell_type":"code","source":"xgb_grid = expand.grid(\n    nrounds = seq(from = xgb_train$bestTune$nrounds - 25, to = xgb_train$bestTune$nrounds + 25, by = 25),\n    max_depth = xgb_train$bestTune$max_depth,\n    eta = xgb_train$bestTune$eta,\n    gamma = c(0, 0.05, 0.1, 0.25, 0.5, 0.75, 1),\n    colsample_bytree = xgb_train$bestTune$colsample_bytree,\n    min_child_weight = xgb_train$bestTune$min_child_weight,\n    subsample = xgb_train$bestTune$subsample\n)\n\nxgb_train = train(\n    x = input_x,\n    y = input_y,\n    trControl = xgb_trcontrol,\n    tuneGrid = xgb_grid,\n    method = 'xgbTree'\n)\n\nplot_fit(xgb_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9de3d911089900cd4fec36197e9a2a1c22bbe69"},"cell_type":"markdown","source":"## Round 5"},{"metadata":{"_uuid":"cee954ab8e126e9a505e6163818327440e8c0b66"},"cell_type":"markdown","source":"Final Tweaks to the eta and number of rounds"},{"metadata":{"trusted":true,"_uuid":"4ca7b8fcea5715b6d8074eb3df5760eccc54d85b"},"cell_type":"code","source":"xgb_grid = expand.grid(\n    nrounds = seq(from = 100, to=5000, by = 100),\n    max_depth = xgb_train$bestTune$max_depth,\n    eta = c(0.01, 0.015, 0.025, 0.05, 0.1),\n    gamma = xgb_train$bestTune$gamma,\n    colsample_bytree = xgb_train$bestTune$colsample_bytree,\n    min_child_weight = xgb_train$bestTune$min_child_weight,\n    subsample = xgb_train$bestTune$subsample\n)\n\nxgb_train = train(\n    x = input_x,\n    y = input_y,\n    trControl = xgb_trcontrol,\n    tuneGrid = xgb_grid,\n    method = 'xgbTree'\n)\n\nplot_fit(xgb_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ab3e5222ef2ecc792568b4d774dd6e8167b3cc7"},"cell_type":"markdown","source":"## Fit the Model"},{"metadata":{"trusted":true,"_uuid":"73d167da8e5376db39649a7ffdaa928f9e9ee431"},"cell_type":"code","source":"final_grid <- expand.grid(\n  nrounds = xgb_train$bestTune$nrounds,\n  eta = xgb_train$bestTune$eta,\n  max_depth = xgb_train$bestTune$max_depth,\n  gamma = xgb_train$bestTune$gamma,\n  colsample_bytree = xgb_train$bestTune$colsample_bytree,\n  min_child_weight = xgb_train$bestTune$min_child_weight,\n  subsample = xgb_train$bestTune$subsample\n)\n\nxgb_model <- caret::train(\n  x = input_x,\n  y = input_y,\n  trControl = xgb_trcontrol,\n  tuneGrid = final_grid,\n  method = \"xgbTree\",\n  verbose = TRUE\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f7d76323b66c8b7f32c30480ba69f1cbca47fd3"},"cell_type":"code","source":"predictions <- data.frame(test_data$PassengerId, as.numeric(as.character(predict(xgb_model, test_x))))\nnames(predictions) <- c('PassengerId', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aec064f62f04bfd28a2620b5347f95bc575ef9b"},"cell_type":"code","source":"head(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3be3fecb80d3526f6907a49492596e57b30eb6a"},"cell_type":"code","source":"write.csv(predictions, file = 'xgb_Solution.csv', row.names = F)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}