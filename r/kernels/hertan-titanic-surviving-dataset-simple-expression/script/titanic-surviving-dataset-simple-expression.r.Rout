
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> 
> library('dplyr') # Data proceesing

Attaching package: â€˜dplyrâ€™

The following objects are masked from â€˜package:statsâ€™:

    filter, lag

The following objects are masked from â€˜package:baseâ€™:

    intersect, setdiff, setequal, union

Warning message:
package â€˜dplyrâ€™ was built under R version 3.6.2 
> library('randomForest') # Model creating
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: â€˜randomForestâ€™

The following object is masked from â€˜package:dplyrâ€™:

    combine

> library('ggplot2') # Data visualization

Attaching package: â€˜ggplot2â€™

The following object is masked from â€˜package:randomForestâ€™:

    margin

Warning message:
package â€˜ggplot2â€™ was built under R version 3.6.2 
> library('mice') # Imputation

Attaching package: â€˜miceâ€™

The following objects are masked from â€˜package:baseâ€™:

    cbind, rbind

Warning message:
package â€˜miceâ€™ was built under R version 3.6.2 
> 
> # First of all, get the data:)
> 
> path <- "../input/"
> train.df <- read.csv(paste0(path,"train.csv"), na.strings=c(""), stringsAsFactors = FALSE)
> test.df <- read.csv(paste0(path,"test.csv"), na.strings=c(""), stringsAsFactors = FALSE)
> 
> all.df <- bind_rows(train.df,test.df)
> 
> # factorizing features
> all.df$Survived <- as.factor(all.df$Survived)
> all.df$Pclass <- as.factor(all.df$Pclass)
> all.df$Sex <- as.factor(all.df$Sex)
> all.df$Embarked <- as.factor(all.df$Embarked)
> # we will try to infer meaningful info from the features below, so using character data type for them
> all.df$Cabin <- as.character(all.df$Cabin)
> all.df$Name <- as.character(all.df$Name)
> all.df$Ticket <- as.character(all.df$Ticket)
> 
> #separating train and test data inside the combined data
> all.df$Set <- 'Train'
> all.df[892:1309,]$Set <- 'Test'
> 
> 
> 
> 
> 
> 
> # DATA EXPLORATION
> 
> 
> #Extracting Titles from Name Feature, it will be a significant feature
> title <- sapply (all.df$Name, function(x) substr(x, grep(",",unlist(strsplit(x, ""))) + 2, which(strsplit(x, "")[[1]]==".") -1))
> 
>     
> #correction
> title[title=='Mlle'] <- 'Miss'
> title[title=='Ms'] <- 'Miss'
> title[title=='Mme'] <- 'Mrs'
> 
> rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
+                 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
> title[title %in% rare_title] <- 'Rare'  # we combine all rare titles into one class
> title <- as.factor(title)
> all.df$Title <- title
> 
> # As you can see, it seems to be a good indicator  
> ggplot(all.df[all.df$Set=='Train',], aes(Title, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("Title") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("Title vs Survived")   
>   
> 
> 
> 
> 
> 
> 
> # Create a new feature RelativeNumber
> all.df$RelativeNumber <- all.df$SibSp + all.df$Parch + 1
> 
> ggplot(all.df[all.df$Set=='Train',], aes(RelativeNumber, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("RelativeNumber") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("RelativeNumber vs Survived")
> 
> # To have 1-3 relative is the highest chance to be survived according to the graph
> # So we create a new feature named as FamilySize from RelativeNumber 
> 
> all.df$FamilySize[all.df$RelativeNumber==1] <- 'single'
> all.df$FamilySize[all.df$RelativeNumber>1 & all.df$RelativeNumber<5] <- 'small'
> all.df$FamilySize[all.df$RelativeNumber>4] <- 'large'
> all.df$FamilySize <- as.factor(all.df$FamilySize)
> 
> 
> 
> 
> 
> # There are a lot of NA values for Cabin values, 
> # however I think cabin info is an important factor for surviving,
> # so I create a new feature CabinInfo including the NA values as a separate a class
> all.df$CabinInfo <- NA
> all.df[is.na(all.df$Cabin), ]$CabinInfo <- 'NA'
> all.df[!is.na(all.df$Cabin), ]$CabinInfo <- substr(all.df[!is.na(all.df$Cabin), ]$Cabin,1,1)
> all.df[all.df$CabinInfo == 'T', ]$CabinInfo <- 'NA'  # there is only one passenger with cabin 'T', for this reason we add it to 'NA' cabin
> all.df[all.df$CabinInfo == 'G', ]$CabinInfo <- 'NA' # there are also very few G class, so we add it to 'NA' as well.
> 
> 
> ggplot(all.df[all.df$Set=='Train',], aes(CabinInfo, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("CabinInfo") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("CabinInfo vs Survived")
> 
> #According to the above graph, to group B, D, E into one class and A, C, F into another class will be more meaningful.
> 
> all.df[all.df$CabinInfo == 'B', ]$CabinInfo <- 'BDE'
> all.df[all.df$CabinInfo == 'D', ]$CabinInfo <- 'BDE'
> all.df[all.df$CabinInfo == 'E', ]$CabinInfo <- 'BDE'
> all.df[all.df$CabinInfo == 'A', ]$CabinInfo <- 'ACF'
> all.df[all.df$CabinInfo == 'C', ]$CabinInfo <- 'ACF'
> all.df[all.df$CabinInfo == 'F', ]$CabinInfo <- 'ACF'
> all.df$CabinInfo <- as.factor(all.df$CabinInfo)
> 
> # IMPUTATION
> 
> # Before the imputation, I wanted to extract some important features like 'Title' 
> # which I believe that it has an effect on age
> 
> # use mice package for assigning proper values for the missing age values, it gives better results than decision tree
> mice_model <- mice(all.df[,  c('Age','Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title',  
+                         'RelativeNumber', 'FamilySize')], method='rf', printFlag = FALSE) 
Warning message:
Number of logged events: 50 
> mice_output <- complete(mice_model)
> 
> all.df[is.na(all.df$Age), 'Age'] <- mice_output[which(is.na(all.df$Age)),'Age']
> all.df$Age <- round(all.df$Age)
> 
> 
> # There is one NA value for Fare column, we find the PClass, Embarked and Title of the related passenger
> na.fare <- all.df[which(is.na(all.df$Fare)),] # passanger with id 1044 does not have Fare info
> all.df$Fare[1044] <- median(all.df[all.df$Pclass == 3 & all.df$Embarked == 'S' & all.df$Title == 'Mr',]$Fare, na.rm = TRUE)
> 
> # There are 2 NA values for Embarked column
> na.embarked <- all.df[which(is.na(all.df$Embarked)),] # 62 and 830 passenger id do not have Embarked info
> # They both paid same fare(80) and travelled in same Pclass (1)  and same cabin (B28), we can understand that they are together
> 
> C_Fare <- mean(all.df[all.df$Embarked == 'C', ]$Fare, na.rm = T) # 62.46$
> S_Fare <- mean(all.df[all.df$Embarked == 'S', ]$Fare, na.rm = T) # 27.39$
> Q_Fare <- mean(all.df[all.df$Embarked == 'Q', ]$Fare, na.rm = T) # 12.40$
> 
> # So they both are most probably embarked from Cherbourg 
> # Passengers embarked from Cherbourg pay 62$ averagely, which is the nearest one what they pay 
> all.df$Embarked[62] <- as.factor('C')
> all.df$Embarked[830] <- as.factor('C')
> 
> 
> # So we completed the imputation part, again continue to extract new features
> 
> # analyzing interaction between fare and pclass columns, they are strongly related 
> 
> train.class3 <- all.df[all.df$Pclass==3 & all.df$Set=='Train',]
> train.class2 <- all.df[all.df$Pclass==2 & all.df$Set=='Train',]
> train.class1 <- all.df[all.df$Pclass==1 & all.df$Set=='Train',]
> 
> ggplot(train.class3, aes(y=train.class3$Pclass, x=train.class3$Fare)) + 
+ geom_point(aes(color=train.class3$Survived), position = "jitter") +
+ xlab("Fare") + ylab("Pclass") +
+ geom_vline(aes(xintercept=10), colour='black', linetype='dashed', lwd=1) +
+ geom_vline(aes(xintercept=20), colour='black', linetype='dashed', lwd=1) +
+ scale_color_discrete(name = "Survived") +
+ ggtitle("Pclass1 vs Fare vs Survived")
Warning messages:
1: Use of `train.class3$Survived` is discouraged. Use `Survived` instead. 
2: Use of `train.class3$Fare` is discouraged. Use `Fare` instead. 
3: Use of `train.class3$Pclass` is discouraged. Use `Pclass` instead. 
> 
> ggplot(train.class2, aes(y=train.class2$Pclass, x=train.class2$Fare)) + 
+ xlab("Fare") + ylab("Pclass") +
+ scale_color_discrete(name = "Survived") + 
+ geom_point(aes(color=train.class2$Survived), position = "jitter") +
+ geom_vline(aes(xintercept=20), colour='black', linetype='dashed', lwd=1) +
+ ggtitle("Pclass2 vs Fare vs Survived")
Warning messages:
1: Use of `train.class2$Survived` is discouraged. Use `Survived` instead. 
2: Use of `train.class2$Fare` is discouraged. Use `Fare` instead. 
3: Use of `train.class2$Pclass` is discouraged. Use `Pclass` instead. 
> 
> ggplot(train.class1, aes(y=train.class1$Pclass, x=train.class1$Fare)) +
+ xlab("Fare") + ylab("Pclass") +
+ scale_color_discrete(name = "Survived") + 
+ geom_point(aes(color=train.class1$Survived), position = "jitter") +
+ geom_vline(aes(xintercept=50), colour='black', linetype='dashed', lwd=1) +
+ geom_vline(aes(xintercept=120), colour='black', linetype='dashed', lwd=1) +
+ ggtitle("Pclass3 vs Fare vs Survived")
Warning messages:
1: Use of `train.class1$Survived` is discouraged. Use `Survived` instead. 
2: Use of `train.class1$Fare` is discouraged. Use `Fare` instead. 
3: Use of `train.class1$Pclass` is discouraged. Use `Pclass` instead. 
> 
> 
> # we create a new feature which represent the relation between fare, pclass and surviving
> 
> all.df$Class.fare.level[all.df$Pclass==3 & all.df$Fare < 10] <- 'P3_1'
> all.df$Class.fare.level[all.df$Pclass==3 & all.df$Fare >= 10 & all.df$Fare < 20] <- 'P3_2'
> all.df$Class.fare.level[all.df$Pclass==3 & all.df$Fare >= 20] <- 'P3_3'
> all.df$Class.fare.level[all.df$Pclass==2 & all.df$Fare < 20] <- 'P2_1'
> all.df$Class.fare.level[all.df$Pclass==2 & all.df$Fare >= 20] <- 'P2_2'
> all.df$Class.fare.level[all.df$Pclass==1 & all.df$Fare < 50] <- 'P1_1'
> all.df$Class.fare.level[all.df$Pclass==1 & all.df$Fare >= 50 & all.df$Fare < 120] <- 'P1_2'
> all.df$Class.fare.level[all.df$Pclass==1 & all.df$Fare >= 120] <- 'P1_3'
> 
> all.df$Class.fare.level <- as.factor(all.df$Class.fare.level)
> 
> ## analyzing the relation between age, sex and survived columns 
> train.female <- all.df[all.df$Sex == 'female' & all.df$Set=='Train',]
> train.male <- all.df[all.df$Sex == 'male' & all.df$Set=='Train',]
> 
> # female (Age vs Survived)
> age.survived.female <- table(train.female$Age, train.female$Survived)
> age.survived.female <- cbind(age.survived.female, age.survived.female[,1]/(age.survived.female[,1] + age.survived.female[,2]))
> age.survived.female.df <- data.frame(age.survived.female)
> age.survived.female.df <- cbind(age.survived.female.df, rownames(age.survived.female.df))
> colnames(age.survived.female.df) <- c('not_survived','survived','death_rate','age')
> age.survived.female.df <- cbind(age.survived.female.df, total = age.survived.female.df$not_survived + age.survived.female.df$survived )
> 
> # male (Age vs Survived)
> age.survived.male <- table(train.male$Age, train.male$Survived)
> age.survived.male <- cbind(age.survived.male, age.survived.male[,1]/(age.survived.male[,1] + age.survived.male[,2]))
> age.survived.male.df <- data.frame(age.survived.male)
> age.survived.male.df <- cbind(age.survived.male.df, rownames(age.survived.male.df))
> colnames(age.survived.male.df) <- c('not_survived','survived','death_rate','age')
> age.survived.male.df <- cbind(age.survived.male.df, total = age.survived.male.df$not_survived + age.survived.male.df$survived )
> 
> # just look at the age.survived.female data frame
> glimpse(age.survived.female.df)
Rows: 61
Columns: 5
$ not_survived [3m[90m<dbl>[39m[23m 0, 4, 2, 1, 0, 1, 0, 1, 4, 2, 2, 0, 0, 4, 0, 3, 2, 7, 0,â€¦
$ survived     [3m[90m<dbl>[39m[23m 5, 3, 1, 5, 4, 1, 1, 1, 0, 0, 0, 1, 2, 4, 4, 8, 6, 11, 8â€¦
$ death_rate   [3m[90m<dbl>[39m[23m 0.0000000, 0.5714286, 0.6666667, 0.1666667, 0.0000000, 0â€¦
$ age          [3m[90m<fct>[39m[23m 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1â€¦
$ total        [3m[90m<dbl>[39m[23m 5, 7, 3, 6, 4, 2, 1, 2, 4, 2, 2, 1, 2, 8, 4, 11, 8, 18, â€¦
> 
> 
> 
> # Visualizing the data frame will be much more helpful to understand, two seperate graph for female and male
> 
> ggplot(data=age.survived.female.df, aes(y=age.survived.female.df$death_rate, x=age.survived.female.df$age)) + geom_point(size = age.survived.female.df$total, alpha=0.3) + 
+   geom_hline(aes(yintercept=0.50), colour='red', linetype='dashed', lwd=1) +
+   xlab("Age") + ylab("Death Rate")
Warning messages:
1: Use of `age.survived.female.df$age` is discouraged. Use `age` instead. 
2: Use of `age.survived.female.df$death_rate` is discouraged. Use `death_rate` instead. 
> 
> 
> 
> ggplot(data=age.survived.male.df, aes(y=age.survived.male.df$death_rate, x=age.survived.male.df$age)) + geom_point(size = age.survived.male.df$total, alpha=0.3) + 
+   geom_hline(aes(yintercept=0.50), colour='red', linetype='dashed', lwd=1) +
+   xlab("Age") + ylab("Death Rate") 
Warning messages:
1: Use of `age.survived.male.df$age` is discouraged. Use `age` instead. 
2: Use of `age.survived.male.df$death_rate` is discouraged. Use `death_rate` instead. 
> 
> # May be it is not a good idea to approach from the abovementionded view,
> # I want to add pclass information and assess age, sex and pclass together
> 
> # Pclass vs Age vs Sex vs Survived
> ggplot(all.df[all.df$Set=='Train', ], aes(y=all.df[all.df$Set=='Train', ]$Pclass, x=all.df[all.df$Set=='Train', ]$Age)) +
+ facet_wrap(~ Sex) +
+ xlab("Age") + ylab("Pclass") +
+ scale_color_discrete(name = "Survived") + 
+ geom_point(aes(color=all.df[all.df$Set=='Train', ]$Survived), position = "jitter") +
+ geom_vline(aes(xintercept=10), colour='black', linetype='dashed', lwd=1) +
+ geom_vline(aes(xintercept=40), colour='black', linetype='dashed', lwd=1) +
+ ggtitle("Pclass vs Age vs Sex vs Survived")
> 
> # now we are looking at the relation between age, sex and pclass, in terms of the light of the above graphs
> all.df$Class.sex.age.level <- NA
> all.df[all.df$Age<=10 & all.df$Sex=='female' & all.df$Pclass==1, ]$Class.sex.age.level <- 'cF1'
> all.df[all.df$Age<=10 & all.df$Sex=='male' & all.df$Pclass==1, ]$Class.sex.age.level <- 'cM1'
> all.df[all.df$Age<=10 & all.df$Sex=='female' & all.df$Pclass==2, ]$Class.sex.age.level <- 'cF2'
> all.df[all.df$Age<=10 & all.df$Sex=='male' & all.df$Pclass==2, ]$Class.sex.age.level <- 'cM2'
> all.df[all.df$Age<=10 & all.df$Sex=='female' & all.df$Pclass==3, ]$Class.sex.age.level <- 'cF3'
> all.df[all.df$Age<=10 & all.df$Sex=='male' & all.df$Pclass==3, ]$Class.sex.age.level <- 'cM3'
> 
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='female' & all.df$Pclass==1, ]$Class.sex.age.level <- 'aF1'
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='male' & all.df$Pclass==1, ]$Class.sex.age.level <- 'aM1'
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='female' & all.df$Pclass==2, ]$Class.sex.age.level <- 'aF2'
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='male' & all.df$Pclass==2, ]$Class.sex.age.level <- 'aM2'
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='female' & all.df$Pclass==3, ]$Class.sex.age.level <- 'aF3'
> all.df[all.df$Age>10 & all.df$Age<=40 & all.df$Sex=='male' & all.df$Pclass==3, ]$Class.sex.age.level <- 'aM3'
> 
> all.df[all.df$Age>40 & all.df$Sex=='female' & all.df$Pclass==1, ]$Class.sex.age.level <- 'oF1'
> all.df[all.df$Age>40 & all.df$Sex=='male' & all.df$Pclass==1, ]$Class.sex.age.level <- 'oM1'
> all.df[all.df$Age>40 & all.df$Sex=='female' & all.df$Pclass==2, ]$Class.sex.age.level <- 'oF2'
> all.df[all.df$Age>40 & all.df$Sex=='male' & all.df$Pclass==2, ]$Class.sex.age.level <- 'oM2'
> all.df[all.df$Age>40 & all.df$Sex=='female' & all.df$Pclass==3, ]$Class.sex.age.level <- 'oF3'
> all.df[all.df$Age>40 & all.df$Sex=='male' & all.df$Pclass==3, ]$Class.sex.age.level <- 'oM3'
> 
> # after investigating each class, I decided to combine all classes together 
> # with insignificant surviving rates and too few amounts
> all.df[all.df$Class.sex.age.level %in% c('aF3','aM1','cF1', 'cF3', 'cM1', 'cM3'),]$Class.sex.age.level <- 'other'
> 
> all.df$Class.sex.age.level <- as.factor(all.df$Class.sex.age.level)
> 
> ggplot(all.df[all.df$Set=='Train',], aes(Class.sex.age.level, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("Class.sex.age.level") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("Class.sex.age.level vs Survived")
> 
> 
> 
> # Another importanf factor for surviving is definitely travelling with a family(group) or alone
> 
> # First of all, we extract surname info from name column
> all.df$Surname <- sapply(all.df$Name, function(x) strsplit(x, split = '[,.]')[[1]][1])
> 
> # Forming a new data frame which includes passenger info which share same ticket and cabin
> # To calculate the frequencies of same cabin and same ticket number
> # is a very important parameter to indicate that people are travelling together 
> 
> # dplyr is a very useful package, especially if you are familiar with sql
> 
> # another useful method is ave method, you can simply calculate cabin and ticket frequencies
> #all.df$Ticket.Frequency <- ave(seq(nrow(all.df)), all.df$Ticket, FUN=length)
> #all.df$Cabin.Frequency <- ave(seq(nrow(all.df)), all.df$Cabin, FUN=length)
> 
> passenger_stats <- all.df %>% group_by(Surname, RelativeNumber, Ticket, Cabin) %>%
+ summarize(family.size = n(), unknown = sum(is.na(Survived)), 
+           survived.info = sum(as.numeric(Survived)-1, na.rm=T), death.info = family.size -(unknown + survived.info)
+            ) 
`summarise()` regrouping output by 'Surname', 'RelativeNumber', 'Ticket' (override with `.groups` argument)
> 
> all.df <- cbind(all.df, all.df %>% left_join(passenger_stats, c('Surname', 'RelativeNumber', 'Ticket', 'Cabin')) %>%
+ select('family.size','unknown', 'survived.info', 'death.info') )
> 
>  
> 
> all.df$Travelling.together <- NA
> all.df[all.df$family.size==1,]$Travelling.together <- 'alone'
> # if we do not know whether the people inside the group survived or not survived, then we can not infer any thing by using Travelling.together feature
> all.df[all.df$family.size>1 & all.df$survived.info==0 & all.df$death.info==0 ,]$Travelling.together <- 'no_info'
> 
> # For train set
> # Calculating the surviving rate in the group, excluding the passenger himself/herself
> for (i in 1:891){
+     if( (all.df$family.size[i]>1) & (all.df$survived.info[i]>0 | all.df$death.info[i]>0)  ) {
+        if( all.df$Survived[i] ==1 ){
+ all.df[i,]$Travelling.together <- round( (all.df$survived.info[i]-1)/(all.df$family.size[i]-1), 2)
+       }else{
+ all.df[i,]$Travelling.together <- round( all.df$survived.info[i]/(all.df$family.size[i]-1), 2)          
+        }
+         }
+ }
> 
> # For test set 
> for (i in 892:1309){
+     if( (all.df$family.size[i]>1) & (all.df$survived.info[i]>0 | all.df$death.info[i]>0) ) {      
+ all.df[i,]$Travelling.together <- round( (all.df$survived.info[i]/all.df$family.size[i]), 2)
+         }
+ }
> 
> 
> # Surviving rate in the groups for train data
> ggplot(all.df[all.df$Set=='Train',], aes(Travelling.together, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("Travelling.together") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("Train Travelling.together vs Survived")
>    
> # Surviving rate in the groups for test data
> ggplot(all.df[all.df$Set=='Test',], aes(Travelling.together)) + 
+   geom_bar(stat = "count")+
+   xlab("Travelling.together") +
+   ylab("Count") +
+   ggtitle("Test Travelling.together vs Survived")
> 
> 
> # I decide to seperate the Travelling.together feature into 3 groups
> # One of them is 0, the other one is alone and I define all other classes into one class
> 
> all.df[!(all.df$Travelling.together %in% c('alone','0','no_info')) , ]$Travelling.together <- 'survived_in_group'
> 
> all.df$Travelling.together <- as.factor(all.df$Travelling.together)
> 
> ggplot(all.df[all.df$Set=='Train',], aes(Travelling.together, fill = Survived)) + 
+   geom_bar(stat = "count")+
+   xlab("Travelling.together") +
+   ylab("Count") +
+   scale_fill_discrete(name = "Survived") + 
+   ggtitle("Train Travelling.together vs Survived")
>    
> # Surviving rate in the groups for test data
> ggplot(all.df[all.df$Set=='Test',], aes(Travelling.together)) + 
+   geom_bar(stat = "count")+
+   xlab("Travelling.together") +
+   ylab("Count") +
+   ggtitle("Test Travelling.together vs Survived")
> 
> 
> # We basically formed new features from the given information
> # And now we use them while creating the model
> # you can try different algorithms, 
> # there a lot of options (decision tree, random forest, logistic regression, svm, naive bayes, xgboost etc.) 
> # I used random forest in this kernel, additionally you can change the default values of the parameters, but do not expect big diferences generally:)
> 
> feature.set <- c('Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'FamilySize', 'CabinInfo', 
+                  'Class.fare.level', 'Class.sex.age.level', 'Travelling.together')
> 
> # selecting only the features which will be used in the model
> all.df.model.input <- all.df[, feature.set]
> 
> # seperating the data as train and test set
> train.df <- all.df.model.input[1:891,]
> test.df <- all.df.model.input[892:1309,]
> 
> 
> fit.model.randomforest <- randomForest(Survived ~ .,
+                                        data = train.df, importance = TRUE, keep.forest=TRUE)
> 
> 
> 
> 
> 
> # making predictions using the created rf model
> pred <- predict(fit.model.randomforest, test.df[,-1], 
+                 type = "class")
> 
> predictions <- data.frame(c(892:1309), pred)
> names(predictions) <- c("PassengerId","Survived")
> write.csv(predictions, "rf_model_prediction.csv", row.names = FALSE)
> 
> # As an useful property of random forest package, we can observe the importance of features used in the model
> 
> importance    <- importance(fit.model.randomforest)
> Feature.importance <- data.frame(Features = row.names(importance), 
+                             Importance = round(importance[ ,'MeanDecreaseAccuracy'],2))
> 
> Feature.importance <- Feature.importance %>% mutate(Rank=dense_rank(desc(Importance)))
> 
> ggplot(Feature.importance, aes(x = reorder(Features, Importance), 
+                            y = Importance, fill = Importance)) +
+ geom_bar(stat='identity') + 
+ geom_text(aes(x = Features, label = Rank),
+ size = 5, y= 0.5, colour = 'red') +
+ labs(x = 'Features') +
+ coord_flip() 
> 
> 
> proc.time()
   user  system elapsed 
  6.398   0.373   6.807 
