
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> ## Importing packages
> 
> # This R environment comes with all of CRAN and many other helpful packages preinstalled.
> # You can see which packages are installed by checking out the kaggle/rstats docker image: 
> # https://github.com/kaggle/docker-rstats
> 
> library(tidyverse) # metapackage with lots of helpful functions
── [1mAttaching packages[22m ────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──
[32m✓[39m [34mggplot2[39m 3.3.2     [32m✓[39m [34mpurrr  [39m 0.3.4
[32m✓[39m [34mtibble [39m 3.0.1     [32m✓[39m [34mdplyr  [39m 1.0.2
[32m✓[39m [34mtidyr  [39m 1.1.0     [32m✓[39m [34mstringr[39m 1.4.0
[32m✓[39m [34mreadr  [39m 1.3.1     [32m✓[39m [34mforcats[39m 0.5.0
── [1mConflicts[22m ───────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
[31mx[39m [34mdplyr[39m::[32mfilter()[39m masks [34mstats[39m::filter()
[31mx[39m [34mdplyr[39m::[32mlag()[39m    masks [34mstats[39m::lag()
Warning messages:
1: package ‘ggplot2’ was built under R version 3.6.2 
2: package ‘tibble’ was built under R version 3.6.2 
3: package ‘tidyr’ was built under R version 3.6.2 
4: package ‘purrr’ was built under R version 3.6.2 
5: package ‘dplyr’ was built under R version 3.6.2 
> 
> dados = read.csv('../input/train.csv', sep = ',', header = T)
> 
> # Survived x Fare
> library(ggplot2)
> 
> g = ggplot(data = dados, aes(group = Survived, y = Fare, x = Survived))
> g + geom_boxplot(fill = 'lightblue') + xlab("Sobrevivente (1 = sobrevivente)") + ylab("Preço da passagem (limitado a $200)") + ylim(c(0,200))
Warning message:
Removed 20 rows containing non-finite values (stat_boxplot). 
> 
> 
> # Média de Fare 
> dados %>% group_by(Survived) %>% summarise('media' = mean(Fare))
`summarise()` ungrouping output (override with `.groups` argument)
[90m# A tibble: 2 x 2[39m
  Survived media
     [3m[90m<int>[39m[23m [3m[90m<dbl>[39m[23m
[90m1[39m        0  22.1
[90m2[39m        1  48.4
> 
> # Usando o classificador simples: se Fare > 35, survived = 1
> ypred = ifelse(dados$Fare > 35, 1, 0)
> 
> # Obtendo a matriz de confusão
> library(caret)
Loading required package: lattice

Attaching package: ‘caret’

The following object is masked from ‘package:purrr’:

    lift

> confusionMatrix(factor(ypred), factor(dados$Survived), positive = '1')
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 474 219
         1  75 123
                                          
               Accuracy : 0.67            
                 95% CI : (0.6381, 0.7009)
    No Information Rate : 0.6162          
    P-Value [Acc > NIR] : 0.0004803       
                                          
                  Kappa : 0.2423          
                                          
 Mcnemar's Test P-Value : < 2.2e-16       
                                          
            Sensitivity : 0.3596          
            Specificity : 0.8634          
         Pos Pred Value : 0.6212          
         Neg Pred Value : 0.6840          
             Prevalence : 0.3838          
         Detection Rate : 0.1380          
   Detection Prevalence : 0.2222          
      Balanced Accuracy : 0.6115          
                                          
       'Positive' Class : 1               
                                          
> 
> # Testando a acurácia de vários pontos de corte
> tmin = min(dados$Fare)
> tmax = max(dados$Fare)
> 
> # Número de pontos de corte para testar (entre tmin e tmax)
> npontos = 1000
> pontos = seq(from = tmin, to = tmax, length.out = npontos)
> 
> res = as.data.frame(matrix(ncol=4, nrow=0))
> for(i in 1:npontos) {
+     t = pontos[i]
+     ypred = ifelse(dados$Fare < t, 0, 1)
+     m = confusionMatrix(factor(ypred), factor(dados$Survived))
+     a = m$overall['Accuracy']
+     tb = m$table
+     p = tb[2,2] / sum(tb[,2])
+     r = tb[2, 1] / sum(tb[,1])
+     res[i, 1] = t
+     res[i, 2] = a
+     res[i, 3] = p
+     res[i, 4] = r
+ }
Warning message:
In confusionMatrix.default(factor(ypred), factor(dados$Survived)) :
  Levels are not in the same order for reference and data. Refactoring data to match.
> colnames(res) = c("corte", "acuracia", "tpr", "fpr")
> 
> resFare = res
> # Ponto ótimo
> topt = res[which.max(res$acuracia),1]
> print(paste0("Corte ótimo = ", topt))
[1] "Corte ótimo = 50.7713621621622"
> 
> # ROC curve
> g = ggplot(data = res, aes(y = tpr, x = fpr))
> g + geom_line() + geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), color = "blue", linetype = 'dashed') +
+ xlab('Taxa de falsos positivos (frequência de alarme falso)') + ylab('Taxa de verdadeiros positivos (recall)') +
+ ggtitle("ROC - Fare")
> 
> # Plotando os resultados
> g = ggplot(data = res, aes(x = corte, y = acuracia))
> g + geom_line() + xlab('Ponto de corte') + ylab('Acurácia')
> 
> g = ggplot(data = res[which(res$corte < 100),], aes(x = corte, y = acuracia))
> g + geom_line() + geom_point() + xlab('Ponto de corte') + ylab('Acurácia') +
+ geom_vline(xintercept = topt, colour = 'red', linetype = 'dashed')
> 
> # Repetindo para Parch
> g = ggplot(data = dados, aes(group = Survived, y = Parch, x = Survived))
> g + geom_boxplot(fill = 'lightblue') + xlab("Sobrevivente (1 = sobrevivente)") + ylab("Parentes a bordo") 
> 
> # Testando a acurácia de vários pontos de corte
> tmin = min(dados$Parch)
> tmax = max(dados$Parch)
> 
> # Número de pontos de corte para testar (entre tmin e tmax)
> npontos = 1000
> pontos = seq(from = tmin, to = tmax, length.out = npontos)
> 
> res = as.data.frame(matrix(ncol=2, nrow=0))
> for(i in 1:npontos) {
+     t = pontos[i]
+     ypred = ifelse(dados$Parch < t, 0, 1)
+     m = confusionMatrix(factor(ypred), factor(dados$Survived))
+     a = m$overall['Accuracy']
+     tb = m$table
+     p = tb[2,2] / sum(tb[,2])
+     r = tb[2, 1] / sum(tb[,1])
+     res[i, 1] = t
+     res[i, 2] = a
+     res[i, 3] = p
+     res[i, 4] = r
+ }
Warning message:
In confusionMatrix.default(factor(ypred), factor(dados$Survived)) :
  Levels are not in the same order for reference and data. Refactoring data to match.
> colnames(res) = c("corte", "acuracia", "tpr", "fpr")
> 
> resParch = res
> # Ponto ótimo
> topt = res[which.max(res$acuracia),1]
> print(paste0("Corte ótimo = ", topt))
[1] "Corte ótimo = 0.00600600600600601"
> 
> # ROC curve
> g = ggplot(data = res, aes(y = tpr, x = fpr))
> g + geom_line() + geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), color = "blue", linetype = 'dashed') +
+ xlab('Taxa de falsos positivos (frequência de alarme falso)') + ylab('Taxa de verdadeiros positivos (recall)') +
+ ggtitle("ROC - Parch")
> 
> # Plotando os resultados
> g = ggplot(data = res, aes(x = corte, y = acuracia))
> g + geom_line() + xlab('Ponto de corte') + ylab('Acurácia') + geom_point()
> 
> 
> 
> # ROC Parch x Fare
> dfRoc = rbind(cbind.data.frame(variavel = rep('Fare', nrow(resFare)), tpr = resFare$tpr, fpr = resFare$fpr), cbind.data.frame(variavel = rep('Parch', nrow(resParch)), tpr = resParch$tpr, fpr = resParch$fpr))
> 
> g = ggplot(data = dfRoc, aes(y = tpr, x = fpr, color = variavel))
> g + geom_line() + geom_segment(aes(x = 0, y = 0, xend = 1, yend = 1), color = "blue", linetype = 'dashed') +
+ xlab('Taxa de falsos positivos (frequência de alarme falso)') + ylab('Taxa de verdadeiros positivos (recall)') +
+ ggtitle("ROC")
> 
> # Gráfico Parch x Fare
> g = ggplot(data =dados, aes(x = Parch, y = Fare, color = factor(Survived)))
> g + geom_point() + guides(color = F)
> 
> g = ggplot(data =dados, aes(x = Parch, y = Fare, color = factor(Survived)))
> g + geom_point() + guides(color = F) + geom_hline(yintercept = 50.77, color = 'red', linetype = 'dashed')
> 
> g = ggplot(data =dados, aes(x = Parch, y = Fare, color = factor(Survived)))
> g + geom_point() + guides(color = F) + geom_hline(yintercept = 50.77, color = 'red', linetype = 'dashed') +
+ geom_vline(xintercept = 0.5, color = 'blue', linetype = 'dashed' )
> 
> # Calculando a proporção de sobreviventes em cada região
> dados %>% subset(Fare < 50.77 & Parch == 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.2772964
> dados %>% subset(Fare < 50.77 & Parch > 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.4709677
> dados %>% subset(Fare >= 50.77 & Parch == 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.7227723
> dados %>% subset(Fare >= 50.77 & Parch > 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.6206897
> 
> 
> # Ponto de corte ótimo para cada região
> tmin = min(dados$Parch)
> tmax = max(dados$Parch)
> 
> # Número de pontos de corte para testar (entre tmin e tmax)
> npontos = 1000
> pontos = seq(from = tmin, to = tmax, length.out = npontos)
> 
> tmp = dados %>% subset(Fare < 50.77)
> res = as.data.frame(matrix(ncol=2, nrow=0))
> for(i in 1:npontos) {
+     t = pontos[i]
+     ypred = ifelse(tmp$Parch < t, 0, 1)
+     m = confusionMatrix(factor(ypred), factor(tmp$Survived))
+     a = m$overall['Accuracy']
+     res[i, 1] = t
+     res[i, 2] = a
+ }
Warning message:
In confusionMatrix.default(factor(ypred), factor(tmp$Survived)) :
  Levels are not in the same order for reference and data. Refactoring data to match.
> colnames(res) = c("corte", "acuracia")
> 
> # Ponto ótimo
> topt1 = res[which.max(res$acuracia),1]
> print(paste0("Corte ótimo = ", topt1))
[1] "Corte ótimo = 5.003003003003"
> 
> tmp = dados %>% subset(Fare >= 50.77)
> res = as.data.frame(matrix(ncol=2, nrow=0))
> for(i in 1:npontos) {
+     t = pontos[i]
+     ypred = ifelse(tmp$Parch < t, 0, 1)
+     m = confusionMatrix(factor(ypred), factor(tmp$Survived))
+     a = m$overall['Accuracy']
+     res[i, 1] = t
+     res[i, 2] = a
+ }
There were 50 or more warnings (use warnings() to see the first 50)
> colnames(res) = c("corte", "acuracia")
> 
> # Ponto ótimo
> topt2 = res[which.max(res$acuracia),1]
> print(paste0("Corte ótimo = ", topt2))
[1] "Corte ótimo = 0"
> 
> # Gráfico da região de decisão
> g = ggplot(data =dados, aes(x = Parch, y = Fare, color = factor(Survived)))
> g + geom_point() + guides(color = F) + geom_hline(yintercept = 50.77, color = 'red', linetype = 'dashed') +
+  geom_segment(aes(x = 5.5, y = -1, xend = 5.5, yend = 50.77), color = "blue", linetype = 'dashed') +
+ geom_segment(aes(x = 0.5, y = 50.77, xend = 0.5, yend = 550), color = "blue", linetype = 'dashed') +
+ scale_y_continuous(expand = c(0, 0))
> 
> # Calculando a proporção de sobreviventes em cada região
> dados %>% subset(Fare < 50.77 & Parch <= 5) %>% summarise(p = sum(Survived) / n())
          p
1 0.3187415
> dados %>% subset(Fare < 50.77 & Parch > 5) %>% summarise(p = sum(Survived) / n())
  p
1 0
> dados %>% subset(Fare >= 50.77 & Parch == 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.7227723
> dados %>% subset(Fare >= 50.77 & Parch > 0) %>% summarise(p = sum(Survived) / n())
          p
1 0.6206897
> 
> # Árvore
> library(rpart)
> library(rpart.plot)
> 
> dados$Survived = as.factor(dados$Survived)
> 
> # Treinando uma árvore com apenas três variáveis
> mod1 = rpart(Survived ~ Sex + Age + Pclass, data = dados)
> 
> # Visualizando a árvore resultante
> rpart.plot(mod1)
> 
> # Resumo do processo de treinamento
> summary(mod1)
Call:
rpart(formula = Survived ~ Sex + Age + Pclass, data = dados)
  n= 891 

          CP nsplit rel error    xerror       xstd
1 0.44444444      0 1.0000000 1.0000000 0.04244576
2 0.02339181      1 0.5555556 0.5555556 0.03574957
3 0.01461988      2 0.5321637 0.5847953 0.03641573
4 0.01169591      4 0.5029240 0.5672515 0.03602071
5 0.01000000      6 0.4795322 0.5584795 0.03581795

Variable importance
   Sex Pclass    Age 
    70     18     12 

Node number 1: 891 observations,    complexity param=0.4444444
  predicted class=0  expected loss=0.3838384  P(node) =1
    class counts:   549   342
   probabilities: 0.616 0.384 
  left son=2 (577 obs) right son=3 (314 obs)
  Primary splits:
      Sex    splits as  RL,       improve=124.426300, (0 missing)
      Pclass < 2.5  to the right, improve= 43.781830, (0 missing)
      Age    < 6.5  to the right, improve=  8.814172, (177 missing)

Node number 2: 577 observations,    complexity param=0.02339181
  predicted class=0  expected loss=0.1889081  P(node) =0.647587
    class counts:   468   109
   probabilities: 0.811 0.189 
  left son=4 (553 obs) right son=5 (24 obs)
  Primary splits:
      Age    < 6.5  to the right, improve=10.78893, (124 missing)
      Pclass < 1.5  to the right, improve=10.01914, (0 missing)

Node number 3: 314 observations,    complexity param=0.01461988
  predicted class=1  expected loss=0.2579618  P(node) =0.352413
    class counts:    81   233
   probabilities: 0.258 0.742 
  left son=6 (144 obs) right son=7 (170 obs)
  Primary splits:
      Pclass < 2.5  to the right, improve=31.163130, (0 missing)
      Age    < 12   to the left,  improve= 1.891684, (53 missing)
  Surrogate splits:
      Age < 18.5 to the left,  agree=0.564, adj=0.049, (0 split)

Node number 4: 553 observations
  predicted class=0  expected loss=0.1681736  P(node) =0.620651
    class counts:   460    93
   probabilities: 0.832 0.168 

Node number 5: 24 observations
  predicted class=1  expected loss=0.3333333  P(node) =0.02693603
    class counts:     8    16
   probabilities: 0.333 0.667 

Node number 6: 144 observations,    complexity param=0.01461988
  predicted class=0  expected loss=0.5  P(node) =0.1616162
    class counts:    72    72
   probabilities: 0.500 0.500 
  left son=12 (12 obs) right son=13 (132 obs)
  Primary splits:
      Age < 38.5 to the right, improve=3.875163, (42 missing)

Node number 7: 170 observations
  predicted class=1  expected loss=0.05294118  P(node) =0.1907969
    class counts:     9   161
   probabilities: 0.053 0.947 

Node number 12: 12 observations
  predicted class=0  expected loss=0.08333333  P(node) =0.01346801
    class counts:    11     1
   probabilities: 0.917 0.083 

Node number 13: 132 observations,    complexity param=0.01169591
  predicted class=1  expected loss=0.4621212  P(node) =0.1481481
    class counts:    61    71
   probabilities: 0.462 0.538 
  left son=26 (117 obs) right son=27 (15 obs)
  Primary splits:
      Age < 5.5  to the right, improve=1.777778, (42 missing)

Node number 26: 117 observations,    complexity param=0.01169591
  predicted class=1  expected loss=0.4871795  P(node) =0.1313131
    class counts:    57    60
   probabilities: 0.487 0.513 
  left son=52 (8 obs) right son=53 (109 obs)
  Primary splits:
      Age < 12   to the left,  improve=3.900498, (42 missing)

Node number 27: 15 observations
  predicted class=1  expected loss=0.2666667  P(node) =0.01683502
    class counts:     4    11
   probabilities: 0.267 0.733 

Node number 52: 8 observations
  predicted class=0  expected loss=0  P(node) =0.008978676
    class counts:     8     0
   probabilities: 1.000 0.000 

Node number 53: 109 observations
  predicted class=1  expected loss=0.4495413  P(node) =0.1223345
    class counts:    49    60
   probabilities: 0.450 0.550 

> 
> # Vamos avaliar o ganho de previsão a cada novo split da árvore
> # Esse ganho é chamado "complexity parameter" (CP)
> printcp(mod1)

Classification tree:
rpart(formula = Survived ~ Sex + Age + Pclass, data = dados)

Variables actually used in tree construction:
[1] Age    Pclass Sex   

Root node error: 342/891 = 0.38384

n= 891 

        CP nsplit rel error  xerror     xstd
1 0.444444      0   1.00000 1.00000 0.042446
2 0.023392      1   0.55556 0.55556 0.035750
3 0.014620      2   0.53216 0.58480 0.036416
4 0.011696      4   0.50292 0.56725 0.036021
5 0.010000      6   0.47953 0.55848 0.035818
> 
> # Visualizando a relação entre complexidade do modelo e erro de previsão
> # Eixo horizontal: complexidade
> # Eixo vertical: média e desvio padrão do erro no cross-validation
> plotcp(mod1)
> 
> # Podando a árvore: escolhemos um valor c de CP, e eliminamos todos os splits que não tenham ganho de qualidade de no mínimo c
> # Um método usual é escolher como corte para o CP o valor que forneceu o mínimo erro de cross-validation (coluna xerror da cptable)
> # Neste caso, o menor erro de cross validation foi no mínimo valor de cp; portanto a poda não terá efeito
> pmod = prune(mod1, mod1$cptable[which.min(mod1$cptable[,"xerror"]),"CP"])
> rpart.plot(pmod)
> 
> # Para efeito de teste, vamos podar a árvore com um valor maior de complexidade
> pmod = prune(mod1, 0.02)
> rpart.plot(pmod)
> 
> # Vamos observar agora as previsões da árvore
> # O método predict vai fornecer a previsão do modelo
> # No caso da classificação binária, a previsão é uma probabilidade (P(y = 0) ou P(y=1))
> prob = predict(mod1, dados %>% select(c(Age, Sex, Pclass)))
> 
> # Modelo com mais variáveis
> mod2 = rpart(Survived ~ Sex + Age + Pclass + SibSp + Parch + Fare, data = dados)
> prob2 = predict(mod2, dados %>% select(c(Age, Sex, Pclass, Parch, SibSp, Fare)))
> 
> mod3 = rpart(Survived ~ Sex + Age + Pclass + SibSp + Parch + Fare + Embarked, data = dados)
> prob3 = predict(mod3, dados)
> 
> # Pergunta: a parrtir de qual valor da probabilidade de y = 1 devemos classificar o indivíduo como sobrevivente?
> # Vamos observar o que acontece na curva ROC
> # Utilizaremos o pacote AUC
> library(AUC)
Error in library(AUC) : there is no package called ‘AUC’
Execution halted
