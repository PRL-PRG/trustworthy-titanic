{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n## 초기화\nrm(list=ls())\n## 패키지 불러오기\nlibrary('dplyr')\nlibrary('tree')\nlibrary('ggplot2')\n## 데이터 불러오기\ngetwd()\nsetwd('C:\\\\Users\\\\bangseongwan\\\\Desktop\\\\캐글 스터디\\\\1회차')\ntrain <- read.csv('train.csv')\ntest <- read.csv('test.csv')\n## 전체 데이터셋 만들기\nfull <- bind_rows(train,test)\ntail(full)\n## 변수 factor로 만들기\nfull$Survived <- as.factor(full$Survived)\nfull$Pclass <- as.factor(full$Pclass)\nfull$Ticket <- as.factor(full$Ticket)\nfull$Cabin <- as.factor(full$Cabin)\nfull$Embarked <- as.factor(full$Embarked)\n## 다시 train test 데이터 생성\nindex.train <- 1:600\nindex.validation <- 601:nrow(train)\nindex.test <- (nrow(train)+1):nrow(full)\ntrain <- full[index.train,]\nvalidation <- full[index.validation,]\ntest <- full[index.test,]\n## 데이터 탐색을 위해 단순 트리 모형 적합\n## 변수는 종속 변수, index 변수, factor 변수면서 factor가 32개 넘는 변수를 제외한다.\nmodel.tree <- tree(Survived~Pclass+Sex+Age+SibSp+Parch+Fare+Embarked,data=train)\nplot(model.tree)\ntext(model.tree,pretty=0)\npost.tree <- predict(model.tree,select(validation,Pclass,Sex,Age,SibSp,Parch,Fare,Embarked))\npred.tree <- ifelse(post.tree[,1]>0.5,0,1)\n## 예측율 계산\nsum(validation$Survived == pred.tree)/length(pred.tree)\ntable(validation$Survived,pred.tree)\n## 결론 : Sex, Pclass, Age, SibSp 이 영향력 있다고 판단\n## 결측치 확인\nsum(is.na(full))\nsum(is.na(select(full,Sex)))\nsum(is.na(select(full,Pclass)))\nsum(is.na(select(full,Age)))\nsum(is.na(select(full,SibSp)))\n## 딥러닝을 위한 table 만들기\nfull.deep <- select(full,c(Survived,Sex,Pclass,SibSp))\ntrain.deep <- full.deep[index.train,]\nvalidation.deep <- full.deep[index.validation,]\ntest.deep <- full.deep[index.test,]\n## h2o패키지\n# 환경변수 설정\nSys.setenv(\"JAVA_HOME\"='C:\\\\Program Files\\\\Java\\\\jdk1.8.0_161')\nSys.setenv(\"PATH\" = paste(Sys.getenv(\"PATH\"), \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_161\", sep = \":\"))\n# 이전 버전의 h2o    패키지가 있다면, 이전 h2o는 삭제\nif (\"package:h2o\" %in% search()) { detach(\"package:h2o\", unload=TRUE) }\nif (\"h2o\" %in% rownames(installed.packages())) { remove.packages(\"h2o\") }\n# h2o 설치를 위한    의존성 패키지들    설치\npkgs <- c(\"RCurl\",\"jsonlite\")\nfor (pkg in pkgs) {\n  if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }\n}\n# 가장 최신버전의  h2o 설치하기 (source 타입)\ninstall.packages(\"h2o\", type=\"source\", repos=\"http://h2o-release.s3.amazonaws.com/h2o/rel-wheeler/4/R\")\nrequire(h2o)\n# h2o 시작\nh2o.init()\n# h2o 파일 올리기\nfull.h2o <- as.h2o(full.deep)\ntrain.h2o <- as.h2o(train.deep)\nvalidation.h2o <- as.h2o(validation.deep)\ntest.h2o <- as.h2o(select(test.deep,c(Sex,Pclass,SibSp)))\nh2o.ls()\n# target/feature 설정\ntarget <- \"Survived\"\nfeatures <- names(full.deep)[!names(full.deep) %in% target]\n# h2o glm model\nmodel.glm <- h2o.glm(x=features,y=target,training_frame = train.h2o,model_id='glm_model',family='binomial')\npred.glm <- h2o.predict(model.glm,newdata=validation.h2o)\npred.glm$predict\ntable(validation.deep$Survived,as.vector(pred.glm$predict))\nsum(validation.deep$Survived==as.vector(pred.glm$predict))/nrow(validation.deep)\n# h2o randomforest model\nmodel.rf <- h2o.randomForest(x=features,y=target,training_frame = train.h2o,model_id = 'rf_model',ntrees = 100)\npred.rf <- h2o.predict(model.rf,newdata = validation.h2o)\ntable(validation.deep$Survived,as.vector(pred.rf$predict))\nsum(validation.deep$Survived==as.vector(pred.rf$predict))/nrow(validation.deep)\n\n## 3가지 방법의 테스트 셋 예측 비교\npred.glm2 <- h2o.predict(model.glm,newdata=test.h2o)\npred.glm2$predict\npred.rf2 <- h2o.predict(model.rf,newdata=test.h2o)\npred.rf2$predict\ncbind(as.vector(pred.glm2$predict),as.vector(pred.rf2$predict))\nsum(as.vector(pred.glm2$predict)==as.vector(pred.rf2$predict))\n\n## csv파일로 내보내기\nwrite.csv(as.vector(pred.glm2$predict),file='titanic.csv',row.names=F)\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","version":"3.4.2","name":"R","pygments_lexer":"r","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}