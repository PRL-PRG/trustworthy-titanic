Objective:
The objective of the analysis is to build and train a machine learning model to predict the survival of a passenger based on some  factors. Here the chosen machine learning model is "Random Forest". The random forest model building is carried in

1. Dataset Understanding
2. Data cleaning and processing
3. Exploratory data analysis
4. Model Training
5. Model Evaluation
6. Prediction on test dataset

```{r}
library(mice) #For Missing Value imputation
library(MASS) 
library(ggplot2)
library(grid)
library(gridExtra)
library(randomForest)
library(e1071)
library(caret)
```
Dataset Understanding:
  The given dataset is in "csv" format in the name of "Titanic.csv". The dataset is loaded in to the variable "input" and all the string columns are loaded as character column which would be suitable to process them.
```{r}
input=read.csv("../input/train.csv",stringsAsFactors = FALSE)
str(input)
```
It can be seen that there are 12 column in the dataset. Our target variable would be "Survived" which have two values {0,1} indicating
    0-Not survived
    1-Survived
"Survived" variable is in "int" type which will be converted into factor variable in subsequent steps.Apart from "Survived" columns we have 11 other variables which could be used as predictors in our model. It can be seen that there are some missing values and "NA" Values in the dataset.

```{r}
head(input)
```
Let we get the summary of the given dataset to understand each variables.
```{r}
summary(input)
```
From the summary we can see that there are 177 NA values in Age variable. Though cabin variable and embarked variable has missing values as blank cells they were not shown. Total number of missing values in those column can be found by  replacing blanck cells with "NA"and then using "apply" and "sum" function as follows,

```{r}
input[input==""]=NA
print("Total count of missing values in each column:")
apply(apply(input,2,is.na),2,sum)
```
It  canb  be seen that Age,Cabin and Embarked variables have missing values. Cabin has more number of missing values.These missing values can be found by using MICE package. Before that some of the features/predictor are processed into meaningful values which could be used in finding missing values for better results.

Feature engineering:

"Name" Column:
It can be seen that there is a column "Name" in the dataset having names of each passenger. These individual names may not useful for prediction but titles in each names (eg.Mr., Mrs.,) can given better insights into the passenger profile and can be used for model building.
```{r}
input$Title <- gsub('(.*, )|(\\..*)', '', input$Name)
table(input$Title)
```
The title in each name is extracted using gsub function and regex and stored in a new column called "Title". Then the distinct title obtained from the names are displayed.

It can be seen that only 'Mr.','Mrs.','Miss.','Master." are prominent titles. We could group synonyoms titles and lables others as "Others" as follows,

```{r}
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')

# Also reassign mlle, ms, and mme accordingly
input$Title[input$Title == 'Mlle']        <- 'Miss' 
input$Title[input$Title == 'Ms']          <- 'Miss'
input$Title[input$Title == 'Mme']         <- 'Mrs' 
input$Title[input$Title %in% rare_title]  <- 'Others'
head(input)
```
Now the "Title" features is generated which could be useful for exploratory analysis. We could generate some other new features from existing one to have better insights as follows,
1. Deck of the passenger can be found by using the first character of his cabin number
2. Family size of each passesnger who boarded together can be found by using sum of number of sibling/spouse aboard("Sibsp" variable) and number of parent or children aboard("Parch" variable)
3. Variable indicating whether he was in the ship alone or with his family by using family size variable

```{r}
input$Deck=substr(input$Cabin,1,1)
input$fsize=input$SibSp+input$Parch
input$with_family=ifelse(input$fsize==0,0,1)
head(input)
```
With new feature engineered from existing columns we could then predict and fill the missing values. Before missing value imputation the character variable are converted into factor variables where levels could be used for better prediction than characters. 
```{r}
input_features=input[,c("Survived","Pclass","Sex","Age","SibSp","Parch","Fare","Embarked","Title","Deck","fsize","with_family")]
factor_vars <- c("Survived","Pclass","Sex","Embarked","Title","Deck","with_family")
input_features[factor_vars] <- lapply(input_features[factor_vars], function(x) as.factor(x))
str(input_features)
```
We could see that Survived,Pclass,Sex,Embarked,Title,Deck,With_family variables are converted to factors. Now missing values imputation is done with "random forest" as imputation method as it could work well with precition involving categorical variables.
New complete dataset is stored in the name of "dat" as follows,

```{r}
set.seed(129)
imp=mice(input_features,m=5, meth='rf')
dat=complete(imp)
summary(imp)
```
we could use "apply" and "sum" function to check whether all missing values are imputed or not. We could see that thre is no more missing values in any variables.

```{r}
print("Total number of missing values in each column")
apply(apply(dat,2,is.na),2,sum)
```
To check the quality of imputation we could see the distribution of variable "Age" before and after imputation. The histogram of the "Age" variable for before and after imputation is ploted as follows,
```{r}
par(mfrow =c(1,2))
hist(input_features$Age,main= "Before imputation")
hist(dat$Age,main="After imputation")
```
We could see that the distribution remains same which means the imputation is good. With missing values trated and the features engineered now we could go for exploratory analysis of the data set.


Exploratory analysis:         

The histogram of the numeric variable in our dataset are plotted.It can be seen from the family size histogram majority of people went without family in the ship and majority of the people travelled in the low fare section which could be inferred from the "Fare" histogram.
```{r}
par(mfrow =c(1,3))
hist(dat$Age)
hist(dat$Fare)
hist(dat$fsize)
```
Survival with respect to Sex
```{r}
p21=ggplot(dat, aes(Sex, fill = factor(Survived))) + geom_histogram(stat="count")
p22=ggplot(dat, aes(Sex, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
grid.arrange(p21,p22, ncol = 2)
```
It can be seen from the chart that Female were survied more than the male and also survial rate within each gender is more in "Female" than "Male"

Survival with respect to Passenger class:
```{r}
p11=ggplot(dat, aes(Pclass, fill = factor(Survived))) + geom_histogram(stat="count")
p12=ggplot(dat, aes(Pclass, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
grid.arrange(p11,p12, ncol = 2)
```
It can be seen that lot of people travelled in "Class 3" and number of people saved are nearly equal in all class. But survival rate of passengers in "Class 1" is higher than others.

Survival with respect to Port of Embarkation:
It can be seen that more number of people embarked from the "Port Southampton" into the ship and less number of people embarked from  "Port Queenstown"
```{r}
ggplot(dat, aes(Embarked, fill = factor(Survived))) + geom_histogram(stat="count")
```
Survival with respect to DecK:
It can be seen that only very small number of people were in "Deck T" and none of them survived followed by "Deck F" which has less survival rate than remaining decks.

```{r}
p41=ggplot(dat, aes(Deck, fill = factor(Survived))) + geom_histogram(stat="count")
p42=ggplot(dat, aes(Deck, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
grid.arrange(p41,p42, ncol = 2)
```
Survival with respect to title:
It can be seen from the plot that females(i.e. with title Miss,Mrs.) survived more followed by Children(Master). Only of less proportion of males only survived.
```{r}
p51=ggplot(dat, aes(Title, fill = factor(Survived))) + geom_histogram(stat="count")
p52=ggplot(dat, aes(Title, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
grid.arrange(p51,p52, ncol = 2)
```
Survival of families:
It can be seen from the below charts that survival rate of people with family is high. But people belonging to family having size more than 3 have lower survival rate. So People belonging to 2 or 3 member family have more survival rate than others.

```{r}
p61=ggplot(dat, aes(with_family, fill = factor(Survived))) + geom_histogram(stat="count")
p62=ggplot(dat, aes(with_family, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
p63=ggplot(dat, aes(fsize, fill = factor(Survived))) + geom_histogram(stat="count")
p64=ggplot(dat, aes(fsize, fill = factor(Survived))) + geom_bar(position="fill")+labs(y="Proportion")
grid.arrange(p61,p62,p63,p64,ncol = 2)
```
It can be seen from the below chart that majority of passengers embarked from PORT "Cherbourg" were in Class 1 and Class 3. Majority of passengers embarked from Port "Queenstown" and "Southampton" were in Class 3. Major proportion of male embarked from Port Southampton in Class 3. Now we could get more insight when we dig deep into Passenger classes.

```{r}
ggplot(dat, aes(Survived, fill = factor(Survived))) + geom_histogram(stat="count") + facet_grid(Embarked~Pclass)#
```
The chart below shows proportion of male and female survived for each class within each deck.More number of class 1 people seems to survive than other class people in the same deck.

```{r}
ggplot(dat, aes(Survived, fill = factor(Survived))) + geom_histogram(stat="count") + facet_grid(Deck~Pclass)#
```
This could be further proved by "Test of Association" between Pclass and survived variable using Chi-Sq test as follows,
```{r}
chisq.test(dat$Survived,dat$Pclass)
```
As p-value is less than 0.05 significance level, It is proved that there is significant association between class of passenger to survival.


Model building:
Now we split the data in the ratio 70:30.i.e. 70% of the data as train data and 30% data as test data.

```{r}
set.seed(123)
train_size=floor(0.70*nrow(dat))
train_ind=sample(seq_len(nrow(dat)),size = train_size)
train=dat[train_ind,]
test=dat[-train_ind,]
print("Train dataset dimension:")
dim(train)
print("Test dataset Dimension:")
dim(test)
```
Now build the random forest model over the train data with Survived as the target variable. The resulting random model has error rate of 19.42% .
```{r}
rf.model=randomForest(Survived~.,data = train,importance=TRUE)
rf.model
```
The importance of each variable in the classification is show below, It could be seen that Fare variable has high importance.
```{r}
varImpPlot(rf.model)
```
Prediction:
  Now the random forest model developed is used to predict the Survival of passenger ion each test dataset using predict method as follows,
```{r}
rf.pred=predict(rf.model,newdata=test)
rf.pred
```
Now the confusion matrix is generated based on the prediction output and the survived variable on test dataset. It can be seen from the confusion matrix and corresponding statistics that the model has 86.19% accuracy in test dataset.

```{r}
confusionMatrix(rf.pred,test$Survived)
```
