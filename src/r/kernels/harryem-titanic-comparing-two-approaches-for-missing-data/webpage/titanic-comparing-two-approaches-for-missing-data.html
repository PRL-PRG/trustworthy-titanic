<!DOCTYPE html>
<html lang="en">
<head>
    <title>Titanic: Comparing Two Approaches for Missing Data | Kaggle</title>
    <meta charset="utf-8" />
    <meta name="robots" content="index, follow" />
    <meta name="turbolinks-cache-control" content="no-cache" />
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC" />
    <script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com" /><link rel="dns-prefetch" href="https://stats.g.doubleclick.net" /><link rel="dns-prefetch" href="https://js.intercomcdn.com" /><link rel="dns-prefetch" href="https://storage.googleapis.com/" />
    <link href="/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link rel="manifest" href="/static/json/manifest.json">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic" rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet" type='text/css'/>
        <link rel="canonical" href="/harryem/titanic-comparing-two-approaches-for-missing-data" />                    <link rel="stylesheet" type="text/css" href="/static/assets/vendor.css?v=632d145d8598" />
        <link rel="stylesheet" type="text/css" href="/static/assets/app.css?v=1d00932a7505" />
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => d.deleteRule(x))};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12629138-1"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6"};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@kaggledatasets" />
    <meta name="og:url" content="https://kaggle.com/harryem/titanic-comparing-two-approaches-for-missing-data" />
    <meta name="og:title" content="Titanic: Comparing Two Approaches for Missing Data" />
    <meta name="og:description" content="Using data from Titanic: Machine Learning from Disaster" />
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/1185558-kg.png" />


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL_RBXBbKp1Hkkq137HIa00TdJbQrDR91tzOK00RUpQoLYpUKQAhdsJpa_ug8UqtywH6khIwE3fOCaNxNw1slMdgyuwwgXlD2oqrJKGPVgLZ-8dz8dFIq60oRtO9dRNIccs',
        isAnonymous: true,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjAzNTM3NDEsIlVzZXJJZCI6MH0.SO4zbQ7o8NDXDbng2Dj0y7FgyFuYY5u_wNUGSjvJ9ec',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: false,
        
        
        
        
        
        
        
        
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript"
src="//www.googleadservices.com/pagead/conversion_async.js">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="/static/assets/vendor.js?v=4721d2c14786" data-turbolinks-track="reload"></script>
    <script src="/static/assets/app.js?v=1a3cd8c35fe7" data-turbolinks-track="reload"></script>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async defer src="https://apis.google.com/js/api.js"
            onload="this.googleApiOnLoad=function(){};handleClientLoad()"
            onreadystatechange="if (this.readyState === 'complete') this.googleApiOnLoad()">
    </script>
</head>
<body data-turbolinks="true">
    <main>
        






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":456649,"title":"Titanic: Comparing Two Approaches for Missing Data","forkParent":null,"currentRunId":1815671,"mostRecentRunId":1815671,"url":"/harryem/titanic-comparing-two-approaches-for-missing-data","tags":[{"name":"research","slug":"research","url":"/tags/research"},{"name":"data cleaning","slug":"data-cleaning","url":"/tags/data-cleaning"},{"name":"data visualization","slug":"data-visualization","url":"/tags/data-visualization"},{"name":"model comparison","slug":"model-comparison","url":"/tags/model-comparison"}],"commentCount":0,"upvoteCount":2,"viewCount":872,"forkCount":1,"bestPublicScore":null,"author":{"id":1185558,"displayName":"Harry Emeric","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"harryem","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1185558-kg.png","profileUrl":"/harryem","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2017-11-27T07:05:43.56Z","selfLink":"/kernels/456649","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":null,"topicId":71430,"readGroupId":null,"writeGroupId":null,"slug":"titanic-comparing-two-approaches-for-missing-data"},"kernelBlob":{"id":7399347,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0027Titanic: Comparing Two Approaches for Missing Data\u0027\nauthor: \u0022Harry Emeric\u0022\ndate: \u002227 November, 2017\u0022\noutput:\n  html_document:\n    number_sections: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: united\n    highlight: tango\n---\n\n# Introduction\n\nHere I build on my previous Kernel (please see link below) to compare two different approaches to dealing with missing data. The first approach is to impute missing data, for example making a prediction from the available variables. The second method is to train a separate model for each comination of missing fields we observe in the dataset. My aim is to see which approach has higher predictive accuracy. I made a start on this previously by doing this just for the \u0022Age\u0022 variable, and found that it did not improve accuracy, although this could be due to lost information by binning \u0022Age\u0022 into brackets. In this work I look to generalise this approach to all variables.\n\nhttps://www.kaggle.com/harryem/feature-engineering-on-the-titanic-for-0-81339\n\n## The problem\n\nGiven test features $X_{TEST} \\in /R^{n * k}$ is a matrix of n test examples and k features and vector $y_{TEST} \\in \\{0,1\\}^n$ classifying survived (1) or did not survive (0), our aim is to estimate a function f such that $y = f(x)$ which minimises misclassification, that is $$ min \\sum_{i=1}^{n}(y_i - f(x_i))^2$$ where $f(x_i)$ is the prediction for the ith test example and $y_i$ is the ith classification, which is known only by the Kaggle administrators.\n\n## Loading libraries and data\n\nLoading libraries\n\n```{r,message=FALSE}\nlibrary(ggplot2) #charting\nlibrary(scales) #charting\nlibrary(grid) #charting\nlibrary(plyr) #data wrangling\nlibrary(dplyr) #data wrangling\nlibrary(tidyr) #data wrangling\nlibrary(Hmisc) #data wrangling\nlibrary(mice) #imputing variables\nlibrary(randomForest) #modelling\nlibrary(caret) #modelling\n\n\ntraindata \u003c- read.csv(\u0027../input/train.csv\u0027, stringsAsFactors = F)\ntestdata \u003c- read.csv(\u0027../input/test.csv\u0027, stringsAsFactors = F)\n\nc(object.size(traindata),object.size(testdata))\n\ntestdata$Survived \u003c- \u0022NA\u0022\nmerged \u003c- rbind(traindata,testdata)\n\nlength(unique(merged$PassengerId)) == length(merged$PassengerId) # check no duped entries\n```\n\nThe data is small so performance shouldn\u0027t be an issue. \n\nI want to combine training and test sets because this makes it easier to perform the # same operations on both sets\n\n# Initial Data Wrangling and Exploratory Data Analysis\n\nFor detailed impormation about features check here https://www.kaggle.com/c/titanic/data\n\n```{r}\nhead(merged)\ncolSums(is.na(merged))\ncolSums(merged==\u0022\u0022)\n```\n\nThere is missing data in the Age, Fare, Cabin and Embarked varibles, and the aim of this piece is to explore and contrast various ways of approaching this issue.\n\nWe need to add a field classifying which data are missing for each element.\n\n```{r}\na \u003c- colSums(is.na(testdata))+colSums(testdata==\u0022\u0022)\na \u003c- names(a[is.na(a)|a!=0])\na\n\nmissing \u003c- c()\n\nfor (i in a) {\n  missing \u003c- paste(missing,as.integer(!is.na(merged[i])^!merged[i]==\u0022\u0022),sep=\u0022\u0022)\n                 }\n\nmerged[missing==\u0022100\u0022,] \n\n#There is only one example of this combination and its in the test set. I will discuss this later.\n\ntable(missing)\nmerged$Missing \u003c- missing\n```\n\n0 means missing and 1 means observed, so for example \u0022100\u0022 means Age was observed, Fare and Cabin were not.\n\nThere are five different combinations of missing variables in the data, so the approach will be train a separate model for each of these five possibilities\n\n\nFirst let\u0027s review the charts of survivor trends by age, class, gender.\n\n## Class \u0026 Sex\n\n```{r}\nmerged$Pclass \u003c- as.factor(merged$Pclass)\nmerged$Sex \u003c- as.factor(merged$Sex)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = \u0022dodge\u0022) + labs(fill = \u0022Survived\u0022,title=\u0022Survivor split by ticket class\u0022)\n\ndftemp \u003c- merged[1:891,] %\u003e%\n    group_by(Pclass) %\u003e%\n    summarise(Survive = sum(Survived == 1) / n(),\n              DidNotSurvive = sum(Survived == 0) / n()) %\u003e%\n    gather(key = Group,value = Surv,Survive:DidNotSurvive)\n\ngn \u003c- ggplot(dftemp, aes(x = Pclass,\n                            y = Surv, \n                            fill = as.factor(Group))) + \n    geom_bar(position = \u0022dodge\u0022,stat = \u0022identity\u0022) + \n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \u0022Proportion Survived\u0022,title=\u0022Survivor split by ticket class - Normalized\u0022) +\n    theme(legend.title=element_blank(), plot.title = element_text(size=14))\n\n\nvp \u003c- viewport(width = 0.3, height = 0.3, x = 0.85,\n     y = 0.85)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = \u0022fill\u0022) + facet_wrap(~Sex) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by ticket class and gender\u0022)\ng + theme(plot.title = element_text(size=14))\n```\n\nAs expected, higher class of ticket and female gender seem to be good positive predictors of survival.\n\n## Age\n\nI would like to segment by age and create a new feature for age bracket for visualisation, and to see if this improves model performance relative to using individual ages.\n\n```{r}\nqplot(merged$Age,fill=I(\u0022red\u0022),xlab = \u0022Age\u0022)\n\nagebrackets \u003c- c(0,13,18,30,55)\nmerged$Agebracket \u003c- findInterval(merged$Age,agebrackets)\n\nagetable \u003c- data.frame(Agebracket=c(1,2,3,4,5),Age_range=c(\u0022\u003c13\u0022,\u002213-17\u0022,\u002218-29\u0022,\u002230-54\u0022,\u002255+\u0022))\nmerged \u003c- join(merged,agetable,by=\u0022Agebracket\u0022)\nmerged$Agebracket \u003c- as.factor(merged$Agebracket)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos=\u0022dodge\u0022) + labs(fill = \u0022Survived\u0022,title=\u0022Survivor split by age group\u0022) + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\ndftemp \u003c- merged[1:891,] %\u003e%\n    group_by(Age_range) %\u003e%\n    summarise(Survive = sum(Survived == 1) / n(),\n              DidNotSurvive = sum(Survived == 0) / n()) %\u003e%\n    gather(key = Group,value = Surv,Survive:DidNotSurvive)\n\ngn \u003c- ggplot(dftemp, aes(x = Age_range,\n                            y = Surv, \n                            fill = as.factor(Group))) + \n    geom_bar(position = \u0022dodge\u0022,stat = \u0022identity\u0022) + \n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \u0022Proportion Survived\u0022,title=\u0022Survivor split by age group - Normalized\u0022) +\n    theme(legend.title=element_blank(),plot.title = element_text(size=14))\n\nvp \u003c- viewport(width = 0.3, height = 0.3, x = 0.85,\n     y = 0.85)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by age and gender - Normalized\u0022) + facet_wrap(~Sex)\ng + theme(plot.title = element_text(size=14))\n```\n\nAge bracket seems to give a lot of information, with youger generally having a better chance\nof survival. Interestingly elderly women has a very good chance of survival whereas elderly men\nhad a very bad chance so it looks like this is a useful division.\n\n\n# Feature Engineering, Cleaning and Completing the Data\n\nI now need to impute the missing data for that analysis, as I already have the pre imputation field \u0022Missing\u0022 I can subset the data based on the what was originally missing. Each new feature is based off a single feature in the original data, so we can map that according to the \u0022Missing\u0022 field.\n\nThe Cabin variable has many missing entries. I\u0027m guessing this isn\u0027t just missing data, but that a lot of people didn\u0027t have a Cabin. So I shall turning this into a 2 factor variable, has / does not have cabin.\n\nIn my previous work I binned some of the variables together for fear of overfitting. However I saw little evidence of overfitting, for example that regularizing the logistic regression model provided very little improvement. As such I will avoid binning variables such as Age and Title, apart from for visualisation purposes.\n\n## Cabin\n\n```{r}\nhead(merged$Cabin,30)\nlength(unique(merged$Cabin))/length(merged$Cabin) ## only 14% are unique so there are a lot shared.\nmerged$Cabin[28] # this looks strange, multiple cabins on one ticket\nsubset(merged,Cabin == \u0022C23 C25 C27\u0022) # it was one family, the Fortunes\n\nmerged$HasCabin \u003c- as.factor(!(merged$Cabin==\u0022\u0022))\n\ng \u003c- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar()\ng \u003c- g +facet_wrap(~Pclass) + labs(title=\u0022Survivor split by class and Cabin\u0022) + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\ngn \u003c- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ngn \u003c- gn +facet_wrap(~Pclass) +labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Cabin - Normalized\u0022) + theme(plot.title = element_text(size=14))\n\nvp \u003c- viewport(width = 0.35, height = 0.35, x = 0.85,\n     y = 0.8)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\n```\n\nAs expected few people in Class 2 and 3 had cabins, but actually those who did had a good chance of \nsurvival. Helping to capture the smaller number who survived from lower classes should be very additive.\n\n## Fare\n\n```{r}\nqplot(merged$Fare,bins=150,fill=I(\u0022red\u0022),xlab = \u0022Fare\u0022)\n```\n\nThere doesn\u0027t seem to be natural brackets here unlike age, so I will just\nsplit in equal groups. There is one missing entry for Fare, I will impute\nthe average Fare for his Pclass.\n\n```{r}\na \u003c- subset(merged,is.na(merged$Fare))\na\nmerged[a[,1],]$Fare \u003c- mean(subset(merged,Pclass==3)$Fare,na.rm=TRUE)\n\nmerged$Farebracket \u003c- as.factor(cut2(merged$Fare,g=5))\n\ng \u003c- ggplot(merged[1:891,], aes(x=Farebracket,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ng \u003c- g +facet_wrap(~Pclass) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Fare Bracket - Normalized\u0022)\ng \u003c- g + theme(axis.text.x = element_text(angle = 90, hjust = 1),plot.title = element_text(size=14))\ng \n\nsubset(merged,Fare==0)\n```\n\nThis is more useful than expected, it does seem to split out the survivors within\na class quite nicely. There were 17 people who paid 0 fare including some in first\nclass - I don\u0027t think its worth creating a separate category here though.\n\nOne group paid over $500.\n\n```{r}\nhead(order(merged$Fare,decreasing = TRUE))\nmerged[259,]\n\nsubset(merged,Fare==merged$Fare[259])\n```\n\n```{r}\ng \u003c- ggplot(merged[1:891,],aes(x=Fare,y=Age,shape=factor(Survived),color=factor(Survived))) + geom_point() + scale_shape_manual(values=c(1,3)) + xlim(0, 300)\n\ng \u003c- g +facet_wrap(~Pclass) + labs(fill=\u0022Survived\u0022,title=\u0022Survival scatterplot of Fare and Age, Split by Class\u0022) + theme(plot.title = element_text(size=14))\ng\n```\n\nThis is a useful chart and shows some clustering of survivors in Class 2 who have low Age and Fare.\n\n## Title\n\n\n```{r}\nmerged$Title \u003c- gsub(\u0027(.*, )|(\\\\..*)\u0027, \u0027\u0027, merged$Name)\n\ncount(merged,Title)\n\nmerged$Title \u003c- as.factor(merged$Title)\n\na \u003c- count(merged,Title)\n\na \u003c- a[a$n\u003e2,]$Title\ndftemp \u003c- merged[1:891,]\ndftemp \u003c- dftemp[dftemp$Title %in% a,]\n\ng \u003c- ggplot(dftemp, aes(x=Title,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ng \u003c- g +facet_wrap(~Pclass) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Title - Normalized\u0022) + theme(plot.title = element_text(size=14))\ng\n```\n\nThis does appear to be useful on the normalized scale.\n\n## Name\n\nThis added very little to my prior analysis so I will omit here.\n\n## Ticketsize variable\n\nCreate a variable for number of people on a single tickt to give a count for group size.\n\n```{r}\nmerged \u003c- ddply(merged,.(Ticket),transform,Ticketsize=length(Ticket))\nmerged$Ticketsize \u003c- as.factor(merged$Ticketsize)\nmerged \u003c- merged[order(merged$PassengerId),] # ddply mixes up order\n```\n\n## Embarked\n\nMove the two cases where this is unmarked to the modal case, \u0022S\u0022\n\n```{r}\ncount(merged,Embarked)\nsubset(merged,Embarked == \u0022\u0022)\nmerged[c(62,830),\u0022Embarked\u0022] \u003c- \u0022S\u0022\nmerged$Embarked \u003c- as.factor(merged$Embarked)\n```\n\n## Age\n\nTo begin with, I want to use the mice library to impute the missing ages. Then I want to check if we get improvement by splitting data as explained above. One issue with using other variables to impute missing data is that the variables used in that model are then double counted for those entries.\n\n```{r}\nm1 \u003c- merged[, !names(merged) %in% c(\u0022Agebracket\u0022,\u0022Age_range\u0022)]\nmice_ages \u003c- mice(m1[, !names(m1) %in% c(\u0027PassengerId\u0027,\u0027Name\u0027,\u0027Ticket\u0027,\u0027Cabin\u0027,\u0027Family\u0027,\u0027Surname\u0027,\u0027Survived\u0027,\u0027Missing\u0027)], method=\u0027rf\u0027,seed = 1234)\nmice_out \u003c- mice::complete(mice_ages)\n\nmerged$Age \u003c- mice_out$Age\nmerged$Agebracket \u003c- findInterval(merged$Age,agebrackets)\nmerged \u003c- join(merged,agetable,by=\u0022Agebracket\u0022)\n\ncolSums(is.na(merged))+colSums(merged==\u0022\u0022)\n\n```\n\n# Model Fitting and Comparison\n\nFirst split the data back into training/ CV and set we use for submission,\n\n```{r}\nmergedtrain \u003c- merged[1:891,]\nmergedtest \u003c- merged[892:1309,]\nmergedtrain$Survived \u003c- as.factor(traindata$Survived)\n\nset.seed(414)\ninTrain\u003c- createDataPartition(y=mergedtrain$Survived,p=0.75, list=FALSE)\ntrain \u003c- mergedtrain[inTrain,]\ntest \u003c- mergedtrain[-inTrain,]\n```\n\nFor each of these comparisons I will use random forest models as these were the best performing models in my prior analysis.\n\n## Age Variable and the effect of Grouping\n\n```{r}\nset.seed(414)\n\nrf_agegroups \u003c- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Agebracket + HasCabin + Ticketsize + Embarked + Title,\n                       data = mergedtrain ,na.action = na.pass,nodesize=20)\n\nrf_agegroups\n\nrf_age \u003c- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Age + HasCabin + Ticketsize + Embarked + Title,\n                       data = mergedtrain ,na.action = na.pass,nodesize=20)\n\nrf_age\nrf_age$confusion\nvarImpPlot(rf_age)\nimportance(rf_age)\n```\n\nIt appears that grouping ages has a negative effect on performance, but only slightly.\n\n## Generalised Model fit based on which variables are missing.\n\nThis approach references Goodfellow et al. \u0022Deep Learning\u0022, information can be found on page 98 under the section entitled \u0022Classification with missing inputs\u0022.\n\nhttp://www.deeplearningbook.org/contents/ml.html\n\nFor each combination of missing variables, contained in the \u0022Missing\u0022 field, I train a random forest model, and then predict on the test set using the model relevant to each test example\u0027s \u0022Missing\u0022\u0022 combination.\n\n```{r}\n\nunique(merged$Missing)\n\ndftemp \u003c- mergedtrain[,c(\u0022Survived\u0022,\u0022Pclass\u0022,\u0022Sex\u0022,\u0022Fare\u0022,\u0022Age\u0022,\u0022HasCabin\u0022,\u0022Ticketsize\u0022,\u0022Embarked\u0022,\u0022Title\u0022,\u0022Missing\u0022)]\n\nrf110 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022HasCabin\u0022)],dftemp$Missing==\u0022110\u0022))\n\nrf111 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c()],dftemp$Missing==\u0022111\u0022))\n\nrf010 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022Age\u0022,\u0022HasCabin\u0022)],dftemp$Missing==\u0022010\u0022))\n\nrf011 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022Age\u0022)],dftemp$Missing==\u0022011\u0022))\n\nrf100 \u003c- rf111\n\nrf110$confusion\nrf111$confusion\nrf010$confusion\nrf011$confusion\n```\n\nThere are no training examples for the Missing = 100 example in the test set; as its one example I will just use the imputed value for HasCabin and Fare and treat it the same as the Missing = 111 model.\n\n# Evaluation and submission\n\nI predict each test example depending on which combination of variables were observed.\n\n```{r}\np110 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022110\u0022,])\np111 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022111\u0022,])\np010 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022010\u0022,])\np011 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022011\u0022,])\np100 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022100\u0022,])\n```\n\n# Evaluation and submission\n\nFinally, I prepare the submission file to send to Kaggle.\n\n```{r}\nsubmission \u003c- rbind(data.frame(PassengerId=names(p110),Survived=p110),data.frame(PassengerId=names(p111),Survived=p111),data.frame(PassengerId=names(p010),Survived=p010),data.frame(PassengerId=names(p011),Survived=p011),data.frame(PassengerId=names(p100),Survived=p100))\n\nif(!file.exists(\u0022./predictions.csv\u0022)) {\n        write.csv(submission, file = \u0022./predictions.csv\u0022,row.names = F)}\n```\n\nThis submission obtained 0.79425 accuracy, which is a decent amount worse than the 0.81339 I obtained from imputing variables and running a single random forest model. Lookined at some of the individual confusion matrices for the models, I expect this is because the training data isn\u0027t large enough to split into so many partitions. I would be interested to see how this approach performs on a larger dataset.","dateCreated":"2017-11-27T07:05:43.427Z"},"kernelRun":{"id":1815671,"kernelId":456649,"status":"complete","type":"batch","sourceType":"script","language":"rmarkdown","title":"Titanic: Comparing Two Approaches for Missing Data","dateCreated":"2017-11-27T07:05:43.427Z","dateEvaluated":"2017-11-27T07:05:43.56Z","workerContainerPort":null,"workerUptimeSeconds":279858,"workerIPAddress":"172.16.1.3     ","scriptLanguageId":5,"scriptLanguageName":"RMarkdown","renderedOutputUrl":"https://www.kaggleusercontent.com/kf/1815671/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..vkUZ0oF-zfVQvSTtH-UMXA._PSN-HKOsZAYomERSfxnSbenl5E-IgM0m-Sq1fqb8Q9sMSn4LRo99CIoJI2KAH1SnIOz6OdRVha4tK3VqdyVwV2vpVXUpgbJa2LVGXmUGImr2LxVKgoIsHknqyymQ2S_Kx1kBfa-L6eouz_sCB8kY5UvqifA-cdIWFe_7JzEclrxkC1_9y_RXXE5hV2R95Pc.uCxuqG4pRf9FWbtPH6JZ5A/__results__.html","commit":{"id":7399347,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0027Titanic: Comparing Two Approaches for Missing Data\u0027\nauthor: \u0022Harry Emeric\u0022\ndate: \u002227 November, 2017\u0022\noutput:\n  html_document:\n    number_sections: true\n    toc: true\n    fig_width: 7\n    fig_height: 4.5\n    theme: united\n    highlight: tango\n---\n\n# Introduction\n\nHere I build on my previous Kernel (please see link below) to compare two different approaches to dealing with missing data. The first approach is to impute missing data, for example making a prediction from the available variables. The second method is to train a separate model for each comination of missing fields we observe in the dataset. My aim is to see which approach has higher predictive accuracy. I made a start on this previously by doing this just for the \u0022Age\u0022 variable, and found that it did not improve accuracy, although this could be due to lost information by binning \u0022Age\u0022 into brackets. In this work I look to generalise this approach to all variables.\n\nhttps://www.kaggle.com/harryem/feature-engineering-on-the-titanic-for-0-81339\n\n## The problem\n\nGiven test features $X_{TEST} \\in /R^{n * k}$ is a matrix of n test examples and k features and vector $y_{TEST} \\in \\{0,1\\}^n$ classifying survived (1) or did not survive (0), our aim is to estimate a function f such that $y = f(x)$ which minimises misclassification, that is $$ min \\sum_{i=1}^{n}(y_i - f(x_i))^2$$ where $f(x_i)$ is the prediction for the ith test example and $y_i$ is the ith classification, which is known only by the Kaggle administrators.\n\n## Loading libraries and data\n\nLoading libraries\n\n```{r,message=FALSE}\nlibrary(ggplot2) #charting\nlibrary(scales) #charting\nlibrary(grid) #charting\nlibrary(plyr) #data wrangling\nlibrary(dplyr) #data wrangling\nlibrary(tidyr) #data wrangling\nlibrary(Hmisc) #data wrangling\nlibrary(mice) #imputing variables\nlibrary(randomForest) #modelling\nlibrary(caret) #modelling\n\n\ntraindata \u003c- read.csv(\u0027../input/train.csv\u0027, stringsAsFactors = F)\ntestdata \u003c- read.csv(\u0027../input/test.csv\u0027, stringsAsFactors = F)\n\nc(object.size(traindata),object.size(testdata))\n\ntestdata$Survived \u003c- \u0022NA\u0022\nmerged \u003c- rbind(traindata,testdata)\n\nlength(unique(merged$PassengerId)) == length(merged$PassengerId) # check no duped entries\n```\n\nThe data is small so performance shouldn\u0027t be an issue. \n\nI want to combine training and test sets because this makes it easier to perform the # same operations on both sets\n\n# Initial Data Wrangling and Exploratory Data Analysis\n\nFor detailed impormation about features check here https://www.kaggle.com/c/titanic/data\n\n```{r}\nhead(merged)\ncolSums(is.na(merged))\ncolSums(merged==\u0022\u0022)\n```\n\nThere is missing data in the Age, Fare, Cabin and Embarked varibles, and the aim of this piece is to explore and contrast various ways of approaching this issue.\n\nWe need to add a field classifying which data are missing for each element.\n\n```{r}\na \u003c- colSums(is.na(testdata))+colSums(testdata==\u0022\u0022)\na \u003c- names(a[is.na(a)|a!=0])\na\n\nmissing \u003c- c()\n\nfor (i in a) {\n  missing \u003c- paste(missing,as.integer(!is.na(merged[i])^!merged[i]==\u0022\u0022),sep=\u0022\u0022)\n                 }\n\nmerged[missing==\u0022100\u0022,] \n\n#There is only one example of this combination and its in the test set. I will discuss this later.\n\ntable(missing)\nmerged$Missing \u003c- missing\n```\n\n0 means missing and 1 means observed, so for example \u0022100\u0022 means Age was observed, Fare and Cabin were not.\n\nThere are five different combinations of missing variables in the data, so the approach will be train a separate model for each of these five possibilities\n\n\nFirst let\u0027s review the charts of survivor trends by age, class, gender.\n\n## Class \u0026 Sex\n\n```{r}\nmerged$Pclass \u003c- as.factor(merged$Pclass)\nmerged$Sex \u003c- as.factor(merged$Sex)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = \u0022dodge\u0022) + labs(fill = \u0022Survived\u0022,title=\u0022Survivor split by ticket class\u0022)\n\ndftemp \u003c- merged[1:891,] %\u003e%\n    group_by(Pclass) %\u003e%\n    summarise(Survive = sum(Survived == 1) / n(),\n              DidNotSurvive = sum(Survived == 0) / n()) %\u003e%\n    gather(key = Group,value = Surv,Survive:DidNotSurvive)\n\ngn \u003c- ggplot(dftemp, aes(x = Pclass,\n                            y = Surv, \n                            fill = as.factor(Group))) + \n    geom_bar(position = \u0022dodge\u0022,stat = \u0022identity\u0022) + \n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \u0022Proportion Survived\u0022,title=\u0022Survivor split by ticket class - Normalized\u0022) +\n    theme(legend.title=element_blank(), plot.title = element_text(size=14))\n\n\nvp \u003c- viewport(width = 0.3, height = 0.3, x = 0.85,\n     y = 0.85)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Pclass,fill=factor(Survived))) + geom_bar(pos  = \u0022fill\u0022) + facet_wrap(~Sex) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by ticket class and gender\u0022)\ng + theme(plot.title = element_text(size=14))\n```\n\nAs expected, higher class of ticket and female gender seem to be good positive predictors of survival.\n\n## Age\n\nI would like to segment by age and create a new feature for age bracket for visualisation, and to see if this improves model performance relative to using individual ages.\n\n```{r}\nqplot(merged$Age,fill=I(\u0022red\u0022),xlab = \u0022Age\u0022)\n\nagebrackets \u003c- c(0,13,18,30,55)\nmerged$Agebracket \u003c- findInterval(merged$Age,agebrackets)\n\nagetable \u003c- data.frame(Agebracket=c(1,2,3,4,5),Age_range=c(\u0022\u003c13\u0022,\u002213-17\u0022,\u002218-29\u0022,\u002230-54\u0022,\u002255+\u0022))\nmerged \u003c- join(merged,agetable,by=\u0022Agebracket\u0022)\nmerged$Agebracket \u003c- as.factor(merged$Agebracket)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos=\u0022dodge\u0022) + labs(fill = \u0022Survived\u0022,title=\u0022Survivor split by age group\u0022) + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\ndftemp \u003c- merged[1:891,] %\u003e%\n    group_by(Age_range) %\u003e%\n    summarise(Survive = sum(Survived == 1) / n(),\n              DidNotSurvive = sum(Survived == 0) / n()) %\u003e%\n    gather(key = Group,value = Surv,Survive:DidNotSurvive)\n\ngn \u003c- ggplot(dftemp, aes(x = Age_range,\n                            y = Surv, \n                            fill = as.factor(Group))) + \n    geom_bar(position = \u0022dodge\u0022,stat = \u0022identity\u0022) + \n    scale_y_continuous(labels = percent_format()) +\n    labs(y = \u0022Proportion Survived\u0022,title=\u0022Survivor split by age group - Normalized\u0022) +\n    theme(legend.title=element_blank(),plot.title = element_text(size=14))\n\nvp \u003c- viewport(width = 0.3, height = 0.3, x = 0.85,\n     y = 0.85)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\ng \u003c- ggplot(merged[1:891,], aes(x=Age_range,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by age and gender - Normalized\u0022) + facet_wrap(~Sex)\ng + theme(plot.title = element_text(size=14))\n```\n\nAge bracket seems to give a lot of information, with youger generally having a better chance\nof survival. Interestingly elderly women has a very good chance of survival whereas elderly men\nhad a very bad chance so it looks like this is a useful division.\n\n\n# Feature Engineering, Cleaning and Completing the Data\n\nI now need to impute the missing data for that analysis, as I already have the pre imputation field \u0022Missing\u0022 I can subset the data based on the what was originally missing. Each new feature is based off a single feature in the original data, so we can map that according to the \u0022Missing\u0022 field.\n\nThe Cabin variable has many missing entries. I\u0027m guessing this isn\u0027t just missing data, but that a lot of people didn\u0027t have a Cabin. So I shall turning this into a 2 factor variable, has / does not have cabin.\n\nIn my previous work I binned some of the variables together for fear of overfitting. However I saw little evidence of overfitting, for example that regularizing the logistic regression model provided very little improvement. As such I will avoid binning variables such as Age and Title, apart from for visualisation purposes.\n\n## Cabin\n\n```{r}\nhead(merged$Cabin,30)\nlength(unique(merged$Cabin))/length(merged$Cabin) ## only 14% are unique so there are a lot shared.\nmerged$Cabin[28] # this looks strange, multiple cabins on one ticket\nsubset(merged,Cabin == \u0022C23 C25 C27\u0022) # it was one family, the Fortunes\n\nmerged$HasCabin \u003c- as.factor(!(merged$Cabin==\u0022\u0022))\n\ng \u003c- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar()\ng \u003c- g +facet_wrap(~Pclass) + labs(title=\u0022Survivor split by class and Cabin\u0022) + theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\ngn \u003c- ggplot(merged[1:891,], aes(x=HasCabin,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ngn \u003c- gn +facet_wrap(~Pclass) +labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Cabin - Normalized\u0022) + theme(plot.title = element_text(size=14))\n\nvp \u003c- viewport(width = 0.35, height = 0.35, x = 0.85,\n     y = 0.8)\n\nprint(gn)\ntheme_set(theme_bw(base_size = 8))\nprint(g,vp=vp)\n\n```\n\nAs expected few people in Class 2 and 3 had cabins, but actually those who did had a good chance of \nsurvival. Helping to capture the smaller number who survived from lower classes should be very additive.\n\n## Fare\n\n```{r}\nqplot(merged$Fare,bins=150,fill=I(\u0022red\u0022),xlab = \u0022Fare\u0022)\n```\n\nThere doesn\u0027t seem to be natural brackets here unlike age, so I will just\nsplit in equal groups. There is one missing entry for Fare, I will impute\nthe average Fare for his Pclass.\n\n```{r}\na \u003c- subset(merged,is.na(merged$Fare))\na\nmerged[a[,1],]$Fare \u003c- mean(subset(merged,Pclass==3)$Fare,na.rm=TRUE)\n\nmerged$Farebracket \u003c- as.factor(cut2(merged$Fare,g=5))\n\ng \u003c- ggplot(merged[1:891,], aes(x=Farebracket,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ng \u003c- g +facet_wrap(~Pclass) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Fare Bracket - Normalized\u0022)\ng \u003c- g + theme(axis.text.x = element_text(angle = 90, hjust = 1),plot.title = element_text(size=14))\ng \n\nsubset(merged,Fare==0)\n```\n\nThis is more useful than expected, it does seem to split out the survivors within\na class quite nicely. There were 17 people who paid 0 fare including some in first\nclass - I don\u0027t think its worth creating a separate category here though.\n\nOne group paid over $500.\n\n```{r}\nhead(order(merged$Fare,decreasing = TRUE))\nmerged[259,]\n\nsubset(merged,Fare==merged$Fare[259])\n```\n\n```{r}\ng \u003c- ggplot(merged[1:891,],aes(x=Fare,y=Age,shape=factor(Survived),color=factor(Survived))) + geom_point() + scale_shape_manual(values=c(1,3)) + xlim(0, 300)\n\ng \u003c- g +facet_wrap(~Pclass) + labs(fill=\u0022Survived\u0022,title=\u0022Survival scatterplot of Fare and Age, Split by Class\u0022) + theme(plot.title = element_text(size=14))\ng\n```\n\nThis is a useful chart and shows some clustering of survivors in Class 2 who have low Age and Fare.\n\n## Title\n\n\n```{r}\nmerged$Title \u003c- gsub(\u0027(.*, )|(\\\\..*)\u0027, \u0027\u0027, merged$Name)\n\ncount(merged,Title)\n\nmerged$Title \u003c- as.factor(merged$Title)\n\na \u003c- count(merged,Title)\n\na \u003c- a[a$n\u003e2,]$Title\ndftemp \u003c- merged[1:891,]\ndftemp \u003c- dftemp[dftemp$Title %in% a,]\n\ng \u003c- ggplot(dftemp, aes(x=Title,fill=factor(Survived))) + geom_bar(pos=\u0022fill\u0022)\ng \u003c- g +facet_wrap(~Pclass) + labs(y = \u0022Proportion Survived\u0022,fill = \u0022Survived\u0022,title=\u0022Survivor split by class and Title - Normalized\u0022) + theme(plot.title = element_text(size=14))\ng\n```\n\nThis does appear to be useful on the normalized scale.\n\n## Name\n\nThis added very little to my prior analysis so I will omit here.\n\n## Ticketsize variable\n\nCreate a variable for number of people on a single tickt to give a count for group size.\n\n```{r}\nmerged \u003c- ddply(merged,.(Ticket),transform,Ticketsize=length(Ticket))\nmerged$Ticketsize \u003c- as.factor(merged$Ticketsize)\nmerged \u003c- merged[order(merged$PassengerId),] # ddply mixes up order\n```\n\n## Embarked\n\nMove the two cases where this is unmarked to the modal case, \u0022S\u0022\n\n```{r}\ncount(merged,Embarked)\nsubset(merged,Embarked == \u0022\u0022)\nmerged[c(62,830),\u0022Embarked\u0022] \u003c- \u0022S\u0022\nmerged$Embarked \u003c- as.factor(merged$Embarked)\n```\n\n## Age\n\nTo begin with, I want to use the mice library to impute the missing ages. Then I want to check if we get improvement by splitting data as explained above. One issue with using other variables to impute missing data is that the variables used in that model are then double counted for those entries.\n\n```{r}\nm1 \u003c- merged[, !names(merged) %in% c(\u0022Agebracket\u0022,\u0022Age_range\u0022)]\nmice_ages \u003c- mice(m1[, !names(m1) %in% c(\u0027PassengerId\u0027,\u0027Name\u0027,\u0027Ticket\u0027,\u0027Cabin\u0027,\u0027Family\u0027,\u0027Surname\u0027,\u0027Survived\u0027,\u0027Missing\u0027)], method=\u0027rf\u0027,seed = 1234)\nmice_out \u003c- mice::complete(mice_ages)\n\nmerged$Age \u003c- mice_out$Age\nmerged$Agebracket \u003c- findInterval(merged$Age,agebrackets)\nmerged \u003c- join(merged,agetable,by=\u0022Agebracket\u0022)\n\ncolSums(is.na(merged))+colSums(merged==\u0022\u0022)\n\n```\n\n# Model Fitting and Comparison\n\nFirst split the data back into training/ CV and set we use for submission,\n\n```{r}\nmergedtrain \u003c- merged[1:891,]\nmergedtest \u003c- merged[892:1309,]\nmergedtrain$Survived \u003c- as.factor(traindata$Survived)\n\nset.seed(414)\ninTrain\u003c- createDataPartition(y=mergedtrain$Survived,p=0.75, list=FALSE)\ntrain \u003c- mergedtrain[inTrain,]\ntest \u003c- mergedtrain[-inTrain,]\n```\n\nFor each of these comparisons I will use random forest models as these were the best performing models in my prior analysis.\n\n## Age Variable and the effect of Grouping\n\n```{r}\nset.seed(414)\n\nrf_agegroups \u003c- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Agebracket + HasCabin + Ticketsize + Embarked + Title,\n                       data = mergedtrain ,na.action = na.pass,nodesize=20)\n\nrf_agegroups\n\nrf_age \u003c- randomForest(factor(Survived) ~ Pclass + Sex + Farebracket + Age + HasCabin + Ticketsize + Embarked + Title,\n                       data = mergedtrain ,na.action = na.pass,nodesize=20)\n\nrf_age\nrf_age$confusion\nvarImpPlot(rf_age)\nimportance(rf_age)\n```\n\nIt appears that grouping ages has a negative effect on performance, but only slightly.\n\n## Generalised Model fit based on which variables are missing.\n\nThis approach references Goodfellow et al. \u0022Deep Learning\u0022, information can be found on page 98 under the section entitled \u0022Classification with missing inputs\u0022.\n\nhttp://www.deeplearningbook.org/contents/ml.html\n\nFor each combination of missing variables, contained in the \u0022Missing\u0022 field, I train a random forest model, and then predict on the test set using the model relevant to each test example\u0027s \u0022Missing\u0022\u0022 combination.\n\n```{r}\n\nunique(merged$Missing)\n\ndftemp \u003c- mergedtrain[,c(\u0022Survived\u0022,\u0022Pclass\u0022,\u0022Sex\u0022,\u0022Fare\u0022,\u0022Age\u0022,\u0022HasCabin\u0022,\u0022Ticketsize\u0022,\u0022Embarked\u0022,\u0022Title\u0022,\u0022Missing\u0022)]\n\nrf110 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022HasCabin\u0022)],dftemp$Missing==\u0022110\u0022))\n\nrf111 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c()],dftemp$Missing==\u0022111\u0022))\n\nrf010 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022Age\u0022,\u0022HasCabin\u0022)],dftemp$Missing==\u0022010\u0022))\n\nrf011 \u003c- randomForest(factor(Survived) ~ .,\n                        data = subset(dftemp[,!names(dftemp) %in% c(\u0022Age\u0022)],dftemp$Missing==\u0022011\u0022))\n\nrf100 \u003c- rf111\n\nrf110$confusion\nrf111$confusion\nrf010$confusion\nrf011$confusion\n```\n\nThere are no training examples for the Missing = 100 example in the test set; as its one example I will just use the imputed value for HasCabin and Fare and treat it the same as the Missing = 111 model.\n\n# Evaluation and submission\n\nI predict each test example depending on which combination of variables were observed.\n\n```{r}\np110 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022110\u0022,])\np111 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022111\u0022,])\np010 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022010\u0022,])\np011 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022011\u0022,])\np100 \u003c- predict(rf110,mergedtest[mergedtest$Missing==\u0022100\u0022,])\n```\n\n# Evaluation and submission\n\nFinally, I prepare the submission file to send to Kaggle.\n\n```{r}\nsubmission \u003c- rbind(data.frame(PassengerId=names(p110),Survived=p110),data.frame(PassengerId=names(p111),Survived=p111),data.frame(PassengerId=names(p010),Survived=p010),data.frame(PassengerId=names(p011),Survived=p011),data.frame(PassengerId=names(p100),Survived=p100))\n\nif(!file.exists(\u0022./predictions.csv\u0022)) {\n        write.csv(submission, file = \u0022./predictions.csv\u0022,row.names = F)}\n```\n\nThis submission obtained 0.79425 accuracy, which is a decent amount worse than the 0.81339 I obtained from imputing variables and running a single random forest model. Lookined at some of the individual confusion matrices for the models, I expect this is because the training data isn\u0027t large enough to split into so many partitions. I would be interested to see how this approach performs on a larger dataset.","dateCreated":"2017-11-27T07:05:43.427Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e941056\u003c/disk_kb_free\u003e\u003cdocker_image_id\u003esha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca\u003c/docker_image_id\u003e\u003cdocker_image_name\u003egcr.io/kaggle-images/rstats\u003c/docker_image_name\u003e\u003cexit_code\u003e0\u003c/exit_code\u003e\u003cfailure_message /\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e32.9021024419926\u003c/run_time_seconds\u003e\u003csucceeded\u003eTrue\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageDigest":null,"dockerImageId":"sha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca","dockerImageName":"kaggle/rstats","diskKbFree":941056,"failureMessage":"","exitCode":0,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":32.9021024419926,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":true,"wasKilled":false},"outputFilesTotalSizeBytes":4265271,"dockerImageVersionId":null,"usedCustomDockerImage":false},"author":{"id":1185558,"displayName":"Harry Emeric","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"harryem","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1185558-kg.png","profileUrl":"/harryem","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/harryem/titanic-comparing-two-approaches-for-missing-data","collaborators":{"owner":{"userId":1185558,"groupId":null,"groupMemberCount":null,"profileUrl":"/harryem","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1185558-kg.png","name":"Harry Emeric","slug":"harryem","userTier":1,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022\\n\\nprocessing file: script.Rmd\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 2.7398730969871394\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |                                                                 |   0%\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.8802079390152358\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..                                                               |   3%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...                                                              |   5%\\nlabel: unnamed-chunk-1 (with options) \\nList of 1\\n $ message: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.9130025929771364\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027dplyr\u0027\\n\\nThe following objects are masked from \u0027package:plyr\u0027:\\n\\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\\n    summarize\\n\\nThe following objects are masked from \u0027package:stats\u0027:\\n\\n    filter, lag\\n\\nThe following objects are masked from \u0027package:base\u0027:\\n\\n    intersect, setdiff, setequal, union\\n\\nLoading required package: lattice\\nLoading required package: survival\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 3.4361382569768466\n},{\n  \u0022data\u0022: \u0022Loading required package: Formula\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.872013062005863\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027Hmisc\u0027\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 5.079955031978898\n},{\n  \u0022data\u0022: \u0022The following objects are masked from \u0027package:dplyr\u0027:\\n\\n    combine, src, summarize\\n\\nThe following objects are masked from \u0027package:plyr\u0027:\\n\\n    is.discrete, summarize\\n\\nThe following objects are masked from \u0027package:base\u0027:\\n\\n    format.pval, round.POSIXt, trunc.POSIXt, units\\n\\nLoading required package: methods\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 5.1141547649749555\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027mice\u0027\\n\\nThe following object is masked from \u0027package:tidyr\u0027:\\n\\n    complete\\n\\nrandomForest 4.6-12\\nType rfNews() to see new features/changes/bug fixes.\\n\\nAttaching package: \u0027randomForest\u0027\\n\\nThe following object is masked from \u0027package:Hmisc\u0027:\\n\\n    combine\\n\\nThe following object is masked from \u0027package:dplyr\u0027:\\n\\n    combine\\n\\nThe following object is masked from \u0027package:ggplot2\u0027:\\n\\n    margin\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 5.441956066992134\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027caret\u0027\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.827864739985671\n},{\n  \u0022data\u0022: \u0022The following object is masked from \u0027package:survival\u0027:\\n\\n    cluster\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.859769561968278\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.....                                                            |   8%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 7.161478422989603\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......                                                          |  10%\\nlabel: unnamed-chunk-2\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 7.448671848978847\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |........                                                         |  13%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 7.80945519998204\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........                                                       |  15%\\nlabel: unnamed-chunk-3\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 7.84266247501364\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............                                                     |  18%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.............                                                    |  21%\\nlabel: unnamed-chunk-4\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 7.874907355988398\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...............                                                  |  23%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 12.259868721012026\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.................                                                |  26%\\nlabel: unnamed-chunk-5\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 12.29346167697804\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..................                                               |  28%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.945083868980873\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |....................                                             |  31%\\nlabel: unnamed-chunk-6\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.978132276970427\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......................                                           |  33%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.91169339301996\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......................                                          |  36%\\nlabel: unnamed-chunk-7\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.9471856559976\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 17.53120906400727\n},{\n  \u0022data\u0022: \u0022\\r  |.........................                                        |  38%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................                                      |  41%\\nlabel: unnamed-chunk-8\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 17.565017236978747\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............................                                     |  44%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 18.476194265997037\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..............................                                   |  46%\\nlabel: unnamed-chunk-9\\n\\r  |                                                                       \\r  |................................                                 |  49%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.................................                                |  51%\\nlabel: unnamed-chunk-10\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 18.5099762629834\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...................................                              |  54%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.....................................                            |  56%\\nlabel: unnamed-chunk-11\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.450697885011323\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......................................                           |  59%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.413702475023456\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |........................................                         |  62%\\nlabel: unnamed-chunk-12\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.447445405006874\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........................................                       |  64%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................................                      |  67%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.560933567001484\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-13\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.595543904986698\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.............................................                    |  69%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.715686690993607\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............................................                  |  72%\\nlabel: unnamed-chunk-14\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.748410333995707\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |................................................                 |  74%\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 30.034734564018436\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..................................................               |  77%\\nlabel: unnamed-chunk-15\\n\\r  |                                                                       \\r  |....................................................             |  79%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.....................................................            |  82%\\nlabel: unnamed-chunk-16\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 30.067622360016685\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......................................................          |  85%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 30.9212808929733\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.........................................................        |  87%\\nlabel: unnamed-chunk-17\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 30.95320842997171\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........................................................       |  90%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |............................................................     |  92%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.068325062980875\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-18\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.102090819971636\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..............................................................   |  95%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............................................................  |  97%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.14818738901522\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-19\\n\\r  |                                                                       \\r  |.................................................................| 100%\\n  ordinary text without R code\\n\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.181886760983616\n},{\n  \u0022data\u0022: \u0022output file: /kaggle/working/script.knit.md\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 32.348173602018505\n},{\n  \u0022data\u0022: \u0022/usr/local/bin/pandoc +RTS -K512m -RTS /kaggle/working/script.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash --output /kaggle/working/__results__.html --smart --email-obfuscation none --standalone --section-divs --table-of-contents --toc-depth 3 --template /usr/local/lib/R/site-library/rmarkdown/rmd/h/default.html --highlight-style tango --number-sections --variable \u0027theme:united\u0027 --include-in-header /tmp/RtmpiIhTb1/rmarkdown-str11172ad05.html --mathjax --variable \u0027mathjax-url:https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0027 \\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.382167702016886\n},{\n  \u0022data\u0022: \u0022\\nOutput created: __results__.html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 32.664055997971445\n},{\n  \u0022data\u0022: \u0022Warning messages:\\n1: In file.rename(from, to) :\\n  cannot rename file \u0027/kaggle/working/__results___files/figure-html\u0027 to \u0027/kaggle/working//kaggle/working/__results___files/figure-html\u0027, reason \u0027No such file or directory\u0027\\n2: In file.rename(from, to) :\\n  cannot rename file \u0027/kaggle/working//kaggle/working/__results___files/figure-html\u0027 to \u0027/kaggle/working/__results___files/figure-html\u0027, reason \u0027No such file or directory\u0027\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 32.69796183600556\n}]","outputFiles":[{"ownerInfo":null,"kernelVersionOutputFileId":8584729,"kernelVersionId":1815671,"kernelId":456649,"size":0,"fullPath":"predictions.csv","previewUrl":"/kernels/preview.json/1815671/c04f2508-3c55-d368-0f17-f9b556fdb392/predictions.csv","downloadUrl":"https://www.kaggleusercontent.com/kf/1815671/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..P0E6ly4s9BaRtdB_xLMdvQ.NYfdqB13aGMrkm4E1_2LcjqbJABKRleRPTFauUsCx7OBBRdYFCxP-h45Qb6C2jVw-peeOk9kwnEqFatfLQuwXn0Mx1gfUniOviNLhyLI91jqyyUT5hZgXy4qZbpiwuoArsMXBKWKbUi_bOmyei4qy6yWgfjy2ouW9U84HWDpcrOxWfUpPLv7lTrtk9ufVtb_.GFv0Sy5mvs4ZcSDUAPw5wQ/predictions.csv","fileType":".csv","contentLength":4515,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"kernelOutputFile","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"predictions.csv","description":null}],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":456649,"kernelVersionId":1815671,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..rZdGRLsTX_biw8-OI4Bd-w.nYWbSug_bS2CWlaeJJ8ptjlaB8f1a7-5oNCabapfhhOI6CheQRUfYzyzdFrC8F7MQarkV6VS3nz_MBwsEgrqz0Hr1TNbE7UqIwbBXuckC36IH2o0sH0hOZ3rUwHZe6E9ohp5UnbnDdPO0kaXHSZqLqzGX3aFFxWBT3vMgnVr6X3oD68Dl3ITX0JphGceszYMRK-_s43s0h66Jnbhv0015j9zPDfb75MmNTDB5GDkPvRqXPyRZyzQssxOQfyBbrpTAUYMeHB1DTH6_vQJy2bgFi2jnMm5TbsjttVrYjep-l3VXen1Q06i3AZwODx7Mzl6JcaxWqHHlTivb4BtWPyUyJY4zos2Xjm32xYXWS4y7aqh13qhljG0RkpKI1cV9VNezlTXOB47oHu0pxEttsnooUXisql1eYEc2bhZh4uWmRLoDLHyxT0lGb6TtnVUgwpsBswUX0jOrkbVAqVr9xAPkzLXXlCuatqG15jdBlPsN3005qNOE_4KZrLjmGgTMef61Z0G_72sJ8krvhf2o7-WbvEjX4XDIztOVhE6PU2FGvWay1O1QyaVtHC0TXUZXfw9.meC8kfubXeGv8oixknpLQA","scope":"harryem/titanic-comparing-two-approaches-for-missing-data"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","sourceUrl":"/c/titanic","slug":"titanic","lastUpdated":"2012-09-28T21:13:33.55Z","overview":"Start here! Predict survival on the Titanic and get familiar with ML basics","sourceType":"competition","sourceVersionType":null,"sourceId":3136,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":"text/html","deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":26502,"dataset":null,"competition":{"competitionId":3136,"dataviewToken":null,"scope":"c/titanic"},"kernel":null,"previewsDisabled":true},"type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"id":63842,"blobFileId":37991,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/gender_submission.csv","creationDate":"2017-02-01T01:49:18Z","isDummy":false,"size":3258,"fullPath":"../input/gender_submission.csv","previewUrl":"kernels/competition-preview/3136?relativePath=gender_submission.csv","downloadUrl":"/c/titanic/download/gender_submission.csv","fileType":".csv","contentLength":3258,"contentType":"text/csv","contentMD5":"MNEHO5ZKXYFUMexgOg3jUw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n"},{"order":1,"originalType":"","type":"boolean","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"gender_submission.csv","description":"892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,0\n901,0\n902,0\n903,0\n904,1\n905,0a\n906,1\n907,0\n908,0\n909,0\n910,0\n911,0\n912,1\n913,0\n914,0\n915,0\n916,1\n917,0\n918,0\n919,0\n920,0\n921,0\n922,0\n923,0\n924,0\n925,0\n926,1\n927,0\n928,0\n929,0\n930,0\n931,1\n932,0\n933,0\n934,0\n935,0\n936,1\n937,0\n938,0\n939,0\n940,1\n941,0\n942,1\n943,0\n944,0\n945,1\n946,0\n947,0\n948,0\n949,0\n950,0\n951,1\n952,0\n953,0\n954,0\n955,0\n956,1\n957,0\n958,0\n959,0\n960,0\n961,1\n962,\n963,0\n964,0\n965,0\n966,1\n967,1\n968,0\n969,0\n970,0\n971,0\n972,0\n973,1\n974,0\n975,0\n976,0\n977,0\n978,0\n979,0\n980,0\n981,0\n982,0\n983,0\n984,0\n985,0\n986,0\n987,0\n988,1\n989,0\n990,0\n991,0\n992,1\n993,0\n994,0\n995,0\n996,0\n997,0\n998,0\n999,0\n1000,0\n1001,0\n1002,0\n1003,0\n1004,0\n1005,0\n1006,1\n1007,0\n1008,0\n1009,0\n1010,1\n1011,0\n1012,0\n1013,0\n1014,1\n1015,0\n1016,0\n1017,0\n1018,0\n1019,0\n1020,0\n1021,0\n1022,0\n1023,0\n1024,0\n1025,0\n1026,0\n1027,0\n1028,0\n1029,0\n1030,0\n1031,0\n1032,0\n1033,1\n1034,1\n1035,0\n1036,0\n1037,0\n1038,1\n1039,0\n1040,0\n1041,0\n1042,1\n1043,0\n1044,0\n1045,0\n1046,0\n1047,0\n1048,1\n1049,0\n1050,0\n1051,0\n1052,0\n1053,0\n1054,0\n1055,0\n1056,0\n1057,0\n1058,1\n1059,0\n1060,0\n1061,0\n1062,0\n1063,0\n1064,0\n1065,0\n1066,0\n1067,0\n1068,0\n1069,1\n1070,0\n1071,1\n1072,0\n1073,1\n1074,1\n1075,0\n1076,1\n1077,0\n1078,0\n1079,0\n1080,1\n1081,0\n1082,0\n1083,0\n1084,0\n1085,0\n1086,0\n1087,0\n1088,1\n1089,0\n1090,0\n1091,0\n1092,0\n1093,0\n1094,1\n1095,0\n1096,0\n1097,0\n1098,0\n1099,0\n1100,0\n1101,0\n1102,0\n1103,0\n1104,1\n1105,0\n1106,0\n1107,0\n1108,0\n1109,1\n1110,1\n1111,0\n1112,0\n1113,0\n1114,0\n1115,0\n1116,0\n1117,0\n1118,0\n1119,0\n1120,0\n1121,0\n1122,1\n1123,0\n1124,0\n1125,0\n1126,1\n1127,0\n1128,1\n1129,0\n1130,0\n1131,1\n1132,0\n1133,0\n1134,1\n1135,0\n1136,0\n1137,1\n1138,0\n1139,0\n1140,0\n1141,0\n1142,0\n1143,0\n1144,1\n1145,0\n1146,0\n1147,0\n1148,0\n1149,0\n1150,0\n1151,0\n1152,0\n1153,0\n1154,0\n1155,0\n1156,0\n1157,0\n1158,0\n1159,0\n1160,0\n1161,0\n1162,1\n1163,0\n1164,1\n1165,0\n1166,0\n1167,0\n1168,0\n1169,0\n1170,0\n1171,0\n1172,0\n1173,0\n1174,0\n1175,0\n1176,0\n1177,0\n1178,0\n1179,1\n1180,0\n1181,0\n1182,0\n1183,0\n1184,0\n1185,1\n1186,0\n1187,0\n1188,0\n1189,0\n1190,1\n1191,0\n1192,0\n1193,0\n1194,0\n1195,0\n1196,0\n1197,0\n1198,1\n1199,0\n1200,1\n1201,0\n1202,0\n1203,0\n1204,0\n1205,0\n1206,1\n1207,0\n1208,1\n1209,0\n1210,0\n1211,0\n1212,0\n1213,0\n1214,0\n1215,0\n1216,1\n1217,0\n1218,0\n1219,1\n1220,0\n1221,0\n1222,0\n1223,0\n1224,0\n1225,0\n1226,0\n1227,0\n1228,0\n1229,0\n1230,0\n1231,0\n1232,0\n1233,0\n1234,1\n1235,1\n1236,0\n1237,0\n1238,0\n1239,0\n1240,0\n1241,0\n1242,1\n1243,0\n1244,1\n1245,1\n1246,0\n1247,0\n1248,1\n1249,0\n1250,0\n1251,0\n1252,1\n1253,0\n1254,0\n1255,0\n1256,1\n1257,1\n1258,0\n1259,0\n1260,0\n1261,0\n1262,0\n1263,1\n1264,0\n1265,0\n1266,1\n1267,1\n1268,0\n1269,0\n1270,1\n1271,0\n1272,0\n1273,0\n1274,0\n1275,0\n1276,0\n1277,1\n1278,0\n1279,0\n1280,0\n1281,0\n1282,1\n1283,0\n1284,0\n1285,0\n1286,0\n1287,1\n1288,0\n1289,1\n1290,0\n1291,0\n1292,1\n1293,0\n1294,0\n1295,1\n1296,0\n1297,0\n1298,0\n1299,1\n1300,0\n1301,0\n1302,0\n1303,1\n1304,0\n1305,0\n1306,1\n1307,0\n1308,0\n1309,0"},{"id":63841,"blobFileId":2613,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/test.csv","creationDate":"2013-06-28T13:40:24.227Z","isDummy":false,"size":28629,"fullPath":"../input/test.csv","previewUrl":"kernels/competition-preview/3136?relativePath=test.csv","downloadUrl":"/c/titanic/download/test.csv","fileType":".csv","contentLength":28629,"contentType":"text/csv","contentMD5":"dTO4Lq5LWCYQy9aKpjawFw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"1"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"1"},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"the name of the passenger"},{"order":3,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":null},{"order":4,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":null},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"of siblings / spouses aboard the Titanic"},{"order":6,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"of parents / children aboard the Titanic"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":"Ticket number"},{"order":8,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":"Passenger fare"},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":"Cabin number"},{"order":10,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"Port of Embarkation"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"test.csv","description":"test data to check the accuracy of the model created\n"},{"id":63840,"blobFileId":2307,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/train.csv","creationDate":"2013-06-28T13:40:25.23Z","isDummy":false,"size":61194,"fullPath":"../input/train.csv","previewUrl":"kernels/competition-preview/3136?relativePath=train.csv","downloadUrl":"/c/titanic/download/train.csv","fileType":".csv","contentLength":61194,"contentType":"text/csv","contentMD5":"IwnMXwR4Ltm7YBbZ9OOBzw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":891},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"type should be integers"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"Survived or Not "},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"Class of Travel"},{"order":3,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"Name of Passenger"},{"order":4,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":"Gender"},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":"Age of Passengers"},{"order":6,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"Number of Sibling/Spouse aboard"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"Number of Parent/Child aboard"},{"order":8,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":null},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":null},{"order":10,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":null},{"order":11,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"train.csv","description":"contains data \n"}],"name":"Titanic: Machine Learning from Disaster","description":"\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe data has been split into two groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etraining set (train.csv)\u003c/li\u003e\n\u003cli\u003etest set (test.csv)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cb\u003e The training set \u003c/b\u003eshould be used to build your machine learning models. For the training set, we provide the outcome (also known as the ground truth) for each passenger. Your model will be based on features like passengers gender and class. You can also use \u003ca href=\u0022https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\u0022 target=\u0022_blank\u0022\u003e feature engineering \u003c/a\u003eto create new features.\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eThe test set \u003c/b\u003eshould be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\u003c/p\u003e\n\u003cp\u003eWe also include \u003cb\u003egender_submission.csv\u003c/b\u003e, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\u003c/p\u003e\n\u003ch3\u003eData Dictionary\u003c/h3\u003e\n\u003ctable style=\u0022width: 100%;\u0022\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003cth\u003e\u003cb\u003eVariable\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eDefinition\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eKey\u003c/b\u003e\u003c/th\u003e\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esurvival\u003c/td\u003e\n\u003ctd\u003eSurvival\u003c/td\u003e\n\u003ctd\u003e0 = No, 1 = Yes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epclass\u003c/td\u003e\n\u003ctd\u003eTicket class\u003c/td\u003e\n\u003ctd\u003e1 = 1st, 2 = 2nd, 3 = 3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esex\u003c/td\u003e\n\u003ctd\u003eSex\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAge\u003c/td\u003e\n\u003ctd\u003eAge in years\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esibsp\u003c/td\u003e\n\u003ctd\u003e# of siblings / spouses aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eparch\u003c/td\u003e\n\u003ctd\u003e# of parents / children aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eticket\u003c/td\u003e\n\u003ctd\u003eTicket number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003efare\u003c/td\u003e\n\u003ctd\u003ePassenger fare\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecabin\u003c/td\u003e\n\u003ctd\u003eCabin number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eembarked\u003c/td\u003e\n\u003ctd\u003ePort of Embarkation\u003c/td\u003e\n\u003ctd\u003eC = Cherbourg, Q = Queenstown, S = Southampton\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eVariable Notes\u003c/h3\u003e\n\u003cp\u003e\u003cb\u003epclass\u003c/b\u003e: A proxy for socio-economic status (SES)\u003cbr /\u003e 1st = Upper\u003cbr /\u003e 2nd = Middle\u003cbr /\u003e 3rd = Lower\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eage\u003c/b\u003e: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003esibsp\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Sibling = brother, sister, stepbrother, stepsister\u003cbr /\u003e Spouse = husband, wife (mistresses and fiancs were ignored)\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eparch\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Parent = mother, father\u003cbr /\u003e Child = daughter, son, stepdaughter, stepson\u003cbr /\u003e Some children travelled only with a nanny, therefore parch=0 for them.\u003c/p\u003e"}],"versions":[{"id":1815671,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2017-11-27T07:05:43.427Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":10,"linesInsertedFromPrevious":10,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":32.9021024419926,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Titanic: Comparing Two Approaches for Missing Data","url":"/harryem/titanic-comparing-two-approaches-for-missing-data?scriptVersionId=1815671","versionNumber":4,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":1815657,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2017-11-27T07:00:49.123Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":6,"linesInsertedFromPrevious":6,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":28.347940479056,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Titanic: Comparing Two Approaches for Missing Data","url":"/harryem/titanic-comparing-two-approaches-for-missing-data?scriptVersionId=1815657","versionNumber":3,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":1815644,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2017-11-27T06:57:11.14Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":40,"linesInsertedFromPrevious":31,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":36.9134984870325,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Titanic: Comparing Two Approaches for Missing Data","url":"/harryem/titanic-comparing-two-approaches-for-missing-data?scriptVersionId=1815644","versionNumber":2,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":1815474,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2017-11-27T06:14:02.91Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":433,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:9ea6ab1a817a1c4f71202acf3ca1f13ed730b1ba200a9514ac3a2f628fd6cbca","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":1,"failureMessage":"The kernel returned an unsuccessful exit code (1).","isValidStatus":true,"runTimeSeconds":6.60171884601004,"succeeded":false,"timeoutExceeded":false,"usedAllSpace":false},"status":"error","title":"Titanic: Comparing Two Approaches for Missing Data","url":"/harryem/titanic-comparing-two-approaches-for-missing-data?scriptVersionId=1815474","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null}],"categories":{"categories":[{"id":13208,"name":"data visualization","displayName":"data visualization","fullPath":"analysis \u003e data visualization","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27data visualization%27","tagUrl":"/tags/data-visualization","fontAwesomeIcon":null,"description":null,"isInherited":false,"datasetCount":131,"competitionCount":0,"scriptCount":6396,"totalCount":6527},{"id":13202,"name":"data cleaning","displayName":"data cleaning","fullPath":"analysis \u003e data cleaning","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27data cleaning%27","tagUrl":"/tags/data-cleaning","fontAwesomeIcon":null,"description":null,"isInherited":false,"datasetCount":54,"competitionCount":0,"scriptCount":1829,"totalCount":1883},{"id":13315,"name":"model comparison","displayName":"model comparison","fullPath":"machine learning \u003e model comparison","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27model comparison%27","tagUrl":"/tags/model-comparison","fontAwesomeIcon":null,"description":null,"isInherited":false,"datasetCount":13,"competitionCount":0,"scriptCount":213,"totalCount":226},{"id":1219,"name":"research","displayName":"research","fullPath":"general reference \u003e research tools and topics \u003e research","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27research%27","tagUrl":"/tags/research","fontAwesomeIcon":null,"description":"Research is our endeavor to systematically increase our knowledge about the world. Whether it\u0027s undertaken by greats like Einstein or underpaid graduate students, you\u0027ll find the fruits of their labor in this tag plus the kernels that make their work reproducible.","isInherited":false,"datasetCount":39,"competitionCount":2,"scriptCount":16,"totalCount":57}],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/1815671","submission":null,"menuLinks":[{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/notebook","text":"Report","title":"Notebook","tab":"report","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/data","text":"Data","title":"Data","tab":"data","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/output","text":"Output","title":"Output","tab":"output","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/comments","text":"Comments","title":"Comments","tab":"comments","count":1,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/versions","text":"Versions","title":"Versions","tab":"versions","count":4,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/harryem/titanic-comparing-two-approaches-for-missing-data/forks","text":"Forks","title":"Forks","tab":"forks","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/1815671","text":"Fork Script","title":"Fork Script","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":"kernels","reportEventType":"anonymousKernelForkCreation"},"voteButton":{"totalVotes":2,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=456649","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"JoshuaFeldman","profileUrl":"/joshuafeldman","tier":"Novice","tierInt":0,"userId":858084,"userName":"joshuafeldman"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1185558-kg.png","displayName":"Harry Emeric","profileUrl":"/harryem","tier":"Contributor","tierInt":1,"userId":1185558,"userName":"harryem"}],"currentUserInfo":null,"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"Titanic: Machine Learning from Disaster","parentUrl":"/c/titanic","thumbnailImageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"canSeeCopyAndEditText":true,"simplifiedViewer":false,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="/harryem/titanic-comparing-two-approaches-for-missing-data" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL_RBXBbKp1Hkkq137HIa00TdJbQrDR91tzOK00RUpQoLYpUKQAhdsJpa_ug8UqtywH6khIwE3fOCaNxNw1slMdgyuwwgXlD2oqrJKGPVgLZ-8dz8dFIq60oRtO9dRNIccs" /></form>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async crossorigin="anonymous" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>&copy; 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="/team">Our Team</a>
            <a href="/terms">Terms</a>
            <a href="/privacy">Privacy</a>
            <a href="/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>




    </main>
</body>
</html>
