
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> 
> ##Loading the required libraries and data sets. 
> library(tidyverse) #visualization and data wrangling
â”€â”€ [1mAttaching packages[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.0 â”€â”€
[32mâœ“[39m [34mggplot2[39m 3.3.2     [32mâœ“[39m [34mpurrr  [39m 0.3.4
[32mâœ“[39m [34mtibble [39m 3.0.1     [32mâœ“[39m [34mdplyr  [39m 1.0.2
[32mâœ“[39m [34mtidyr  [39m 1.1.0     [32mâœ“[39m [34mstringr[39m 1.4.0
[32mâœ“[39m [34mreadr  [39m 1.3.1     [32mâœ“[39m [34mforcats[39m 0.5.0
â”€â”€ [1mConflicts[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
[31mx[39m [34mdplyr[39m::[32mfilter()[39m masks [34mstats[39m::filter()
[31mx[39m [34mdplyr[39m::[32mlag()[39m    masks [34mstats[39m::lag()
Warning messages:
1: package â€˜ggplot2â€™ was built under R version 3.6.2 
2: package â€˜tibbleâ€™ was built under R version 3.6.2 
3: package â€˜tidyrâ€™ was built under R version 3.6.2 
4: package â€˜purrrâ€™ was built under R version 3.6.2 
5: package â€˜dplyrâ€™ was built under R version 3.6.2 
> library(Amelia) #Visualize N/As
Loading required package: Rcpp
## 
## Amelia II: Multiple Imputation
## (Version 1.7.6, built: 2019-11-24)
## Copyright (C) 2005-2020 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 
> library(randomForest) #random forest models
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: â€˜randomForestâ€™

The following object is masked from â€˜package:dplyrâ€™:

    combine

The following object is masked from â€˜package:ggplot2â€™:

    margin

> library(caTools) #train/test spilt
> 
> train <- read.csv("../input/train.csv")
> test <- read.csv("../input/test.csv")
> 
> str(train)
'data.frame':	891 obs. of  12 variables:
 $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
 $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
 $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Name       : Factor w/ 891 levels "Abbing, Mr. Anthony",..: 109 191 358 277 16 559 520 629 417 581 ...
 $ Sex        : Factor w/ 2 levels "female","male": 2 1 1 1 2 2 2 2 1 1 ...
 $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
 $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Ticket     : Factor w/ 681 levels "110152","110413",..: 524 597 670 50 473 276 86 396 345 133 ...
 $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Cabin      : Factor w/ 148 levels "","A10","A14",..: 1 83 1 57 1 1 131 1 1 1 ...
 $ Embarked   : Factor w/ 4 levels "","C","Q","S": 4 2 4 4 4 3 4 4 4 2 ...
> summary(train)
  PassengerId       Survived          Pclass     
 Min.   :  1.0   Min.   :0.0000   Min.   :1.000  
 1st Qu.:223.5   1st Qu.:0.0000   1st Qu.:2.000  
 Median :446.0   Median :0.0000   Median :3.000  
 Mean   :446.0   Mean   :0.3838   Mean   :2.309  
 3rd Qu.:668.5   3rd Qu.:1.0000   3rd Qu.:3.000  
 Max.   :891.0   Max.   :1.0000   Max.   :3.000  
                                                 
                                    Name         Sex           Age       
 Abbing, Mr. Anthony                  :  1   female:314   Min.   : 0.42  
 Abbott, Mr. Rossmore Edward          :  1   male  :577   1st Qu.:20.12  
 Abbott, Mrs. Stanton (Rosa Hunt)     :  1                Median :28.00  
 Abelson, Mr. Samuel                  :  1                Mean   :29.70  
 Abelson, Mrs. Samuel (Hannah Wizosky):  1                3rd Qu.:38.00  
 Adahl, Mr. Mauritz Nils Martin       :  1                Max.   :80.00  
 (Other)                              :885                NA's   :177    
     SibSp           Parch             Ticket         Fare       
 Min.   :0.000   Min.   :0.0000   1601    :  7   Min.   :  0.00  
 1st Qu.:0.000   1st Qu.:0.0000   347082  :  7   1st Qu.:  7.91  
 Median :0.000   Median :0.0000   CA. 2343:  7   Median : 14.45  
 Mean   :0.523   Mean   :0.3816   3101295 :  6   Mean   : 32.20  
 3rd Qu.:1.000   3rd Qu.:0.0000   347088  :  6   3rd Qu.: 31.00  
 Max.   :8.000   Max.   :6.0000   CA 2144 :  6   Max.   :512.33  
                                  (Other) :852                   
         Cabin     Embarked
            :687    :  2   
 B96 B98    :  4   C:168   
 C23 C25 C27:  4   Q: 77   
 G6         :  4   S:644   
 C22 C26    :  3           
 D          :  3           
 (Other)    :186           
> 
> any(is.na(train)) #Are there NA values?
[1] TRUE
> missmap(train, legend = FALSE)
> 
> ggplot(train, aes(x = as.factor(Pclass), y = Age)) + geom_boxplot(aes(fill = as.factor(Pclass))) + 
+                                                     labs(title = "Age According to Ticket Classes",
+                                                            x = "Ticket Classes", y = "Age")
Warning message:
Removed 177 rows containing non-finite values (stat_boxplot). 
> 
> anovamod <- lm(Age ~ as.factor(Pclass), data = train) #model for ANOVA
> anova(anovamod) #presenting the ANOVA table
Analysis of Variance Table

Response: Age
                   Df Sum Sq Mean Sq F value    Pr(>F)    
as.factor(Pclass)   2  20930 10464.8  57.444 < 2.2e-16 ***
Residuals         711 129527   182.2                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
> plot(anovamod) #plotting required graphs such as residuals vs fitted and QQ-plots
> 
> first_class <- filter(train, Pclass == 1)
> floor(mean(first_class[,6], na.rm = T))
[1] 38
> second_class <- filter(train, Pclass == 2)
> floor(mean(second_class[,6], na.rm = T))
[1] 29
> third_class <- filter(train, Pclass == 3)
> floor(mean(third_class[,6], na.rm = T))
[1] 25
> #results came out to be 38, 29 and 25
> 
> for (i in (1:nrow(train))) {
+     if (is.na(train[i,6]) == TRUE){
+         if (train[i,3] == 1){
+             train[i,6] <- 38
+         } else if (train[i,3] == 2){
+             train[i,6] <- 29
+         } else if (train[i,3] == 3){
+             train[i,6] <- 25
+         } 
+     } else {
+         train[i,6] <- train[i,6]
+     }
+ }
> 
> missmap(train, legend = FALSE)
> 
> train <- select(train, -PassengerId, -Name, -Ticket, -Cabin) 
> set.seed(101) 
> split <- sample.split(train$Survived, SplitRatio = 0.7) #this is from the caTools library 
> train_training <- subset(train, split == TRUE)
> train_test <- subset(train, split == FALSE)
> 
> logistic_model <- glm(Survived ~.,family = binomial(link = "logit"), data = train_training)
> summary(logistic_model)

Call:
glm(formula = Survived ~ ., family = binomial(link = "logit"), 
    data = train_training)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7797  -0.5748  -0.4076   0.6468   2.4926  

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  16.056291 535.411464   0.030  0.97608    
Pclass       -1.127286   0.179448  -6.282 3.34e-10 ***
Sexmale      -2.697407   0.239828 -11.247  < 2e-16 ***
Age          -0.041383   0.009553  -4.332 1.48e-05 ***
SibSp        -0.333971   0.128649  -2.596  0.00943 ** 
Parch         0.064668   0.146056   0.443  0.65794    
Fare          0.002620   0.002837   0.924  0.35566    
EmbarkedC   -10.719938 535.411280  -0.020  0.98403    
EmbarkedQ   -10.703089 535.411369  -0.020  0.98405    
EmbarkedS   -11.196651 535.411256  -0.021  0.98332    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 829.60  on 622  degrees of freedom
Residual deviance: 544.44  on 613  degrees of freedom
AIC: 564.44

Number of Fisher Scoring iterations: 12

> step(logistic_model)
Start:  AIC=564.44
Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked

           Df Deviance    AIC
- Embarked  3   548.63 562.63
- Parch     1   544.64 562.64
- Fare      1   545.40 563.40
<none>          544.44 564.44
- SibSp     1   552.34 570.34
- Age       1   565.00 583.00
- Pclass    1   584.38 602.38
- Sex       1   701.60 719.60

Step:  AIC=562.63
Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare

         Df Deviance    AIC
- Parch   1   548.66 560.66
- Fare    1   550.51 562.51
<none>        548.63 562.63
- SibSp   1   557.56 569.56
- Age     1   569.89 581.89
- Pclass  1   589.46 601.46
- Sex     1   714.40 726.40

Step:  AIC=560.66
Survived ~ Pclass + Sex + Age + SibSp + Fare

         Df Deviance    AIC
<none>        548.66 560.66
- Fare    1   550.75 560.75
- SibSp   1   558.28 568.28
- Age     1   569.98 579.98
- Pclass  1   589.89 599.89
- Sex     1   722.74 732.74

Call:  glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Fare, family = binomial(link = "logit"), 
    data = train_training)

Coefficients:
(Intercept)       Pclass      Sexmale          Age        SibSp         Fare  
   5.000833    -1.105354    -2.745318    -0.042031    -0.346229     0.003717  

Degrees of Freedom: 622 Total (i.e. Null);  617 Residual
Null Deviance:	    829.6 
Residual Deviance: 548.7 	AIC: 560.7
> 
> logistic_model_filtered <- glm(Survived~ Pclass + Sex + Age + SibSp + Fare, family = binomial(link = "logit"), data = train_training)
> summary(logistic_model_filtered)

Call:
glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Fare, family = binomial(link = "logit"), 
    data = train_training)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.8447  -0.5721  -0.4168   0.6194   2.4390  

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)  5.000833   0.667422   7.493 6.74e-14 ***
Pclass      -1.105354   0.173289  -6.379 1.79e-10 ***
Sexmale     -2.745318   0.233506 -11.757  < 2e-16 ***
Age         -0.042031   0.009544  -4.404 1.06e-05 ***
SibSp       -0.346229   0.122079  -2.836  0.00457 ** 
Fare         0.003717   0.002789   1.332  0.18275    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 829.60  on 622  degrees of freedom
Residual deviance: 548.66  on 617  degrees of freedom
AIC: 560.66

Number of Fisher Scoring iterations: 5

> 
> test_predictions <- predict(logistic_model_filtered, newdata = train_test, type = 'response')
> table(train_test$Survived, test_predictions > 0.5)
   
    FALSE TRUE
  0   137   28
  1    31   72
> 
> test_predictions_results <- ifelse(test_predictions > 0.5,1,0) #converting true-false values into 1s and 0s
> misClasificError_logit <- mean(test_predictions_results != train_test$Survived)
> print(paste('Accuracy',1-misClasificError_logit)) #0.774
[1] "Accuracy 0.779850746268657"
> 
> rf_model <- randomForest(as.factor(Survived)~.,data = train_training, importance = TRUE)
> print(rf_model)

Call:
 randomForest(formula = as.factor(Survived) ~ ., data = train_training,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 2

        OOB estimate of  error rate: 17.98%
Confusion matrix:
    0   1 class.error
0 341  43   0.1119792
1  69 170   0.2887029
> rf_model$importance
                   0           1 MeanDecreaseAccuracy MeanDecreaseGini
Pclass   0.024983263 0.096145264          0.051948035        19.549862
Sex      0.119282998 0.181338618          0.142620361        71.098894
Age      0.028004850 0.033090844          0.029934686        41.989320
SibSp    0.024856072 0.003056777          0.016622502        12.349033
Parch    0.020268323 0.016684562          0.018831682        10.644283
Fare     0.034131430 0.059663048          0.043938664        49.540480
Embarked 0.004390488 0.016496841          0.008996715         9.275977
> rf_model$confusion
    0   1 class.error
0 341  43   0.1119792
1  69 170   0.2887029
> 
> rf_test_prediction <- predict(rf_model, train_test)
> table(rf_test_prediction,train_test$Survived)
                  
rf_test_prediction   0   1
                 0 150  31
                 1  15  72
> misClasificError_rf <- mean(rf_test_prediction != train_test$Survived)
> print(paste('Accuracy',1-misClasificError_rf)) #~0.828
[1] "Accuracy 0.828358208955224"
> 
> missmap(test, legend = FALSE)
> 
> first_class_test <- filter(test, Pclass == 1)
> floor(mean(first_class_test[,5], na.rm = T))
[1] 40
> second_class_test <- filter(test, Pclass == 2)
> floor(mean(second_class_test[,5], na.rm = T))
[1] 28
> third_class_test <- filter(test, Pclass == 3)
> floor(mean(third_class_test[,5], na.rm = T))
[1] 24
> #results came out to be 40, 28 and 24
> 
> for (i in (1:nrow(test))) {
+   if (is.na(test[i,5]) == TRUE){
+     if (test[i,2] == 1){
+       test[i,5] <- 40
+     } else if (test[i,2] == 2){
+       test[i,5] <- 28
+     } else if (test[i,2] == 3){
+       test[i,5] <- 24
+     } 
+   } else {
+     test[i,5] <- test[i,5]
+   }
+ }
> 
> missmap(test, legend = FALSE)
> 
> PassengerId <- test[,1] #saving the passengerid column for later
> test <- test[,-c(1,10,3,8)] #removing columns
> str(test) #check str of test
'data.frame':	418 obs. of  7 variables:
 $ Pclass  : int  3 3 2 3 3 3 3 2 3 3 ...
 $ Sex     : Factor w/ 2 levels "female","male": 2 1 2 2 1 2 1 2 1 2 ...
 $ Age     : num  34.5 47 62 27 22 14 30 26 18 21 ...
 $ SibSp   : int  0 1 0 0 1 0 0 1 0 2 ...
 $ Parch   : int  0 0 0 0 1 0 0 1 0 0 ...
 $ Fare    : num  7.83 7 9.69 8.66 12.29 ...
 $ Embarked: Factor w/ 3 levels "C","Q","S": 2 3 2 3 3 3 2 3 1 3 ...
> str(train) #check str of train
'data.frame':	891 obs. of  8 variables:
 $ Survived: int  0 1 1 1 0 0 0 0 1 1 ...
 $ Pclass  : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Sex     : Factor w/ 2 levels "female","male": 2 1 1 1 2 2 2 2 1 1 ...
 $ Age     : num  22 38 26 35 35 25 54 2 27 14 ...
 $ SibSp   : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch   : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Fare    : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Embarked: Factor w/ 4 levels "","C","Q","S": 4 2 4 4 4 3 4 4 4 2 ...
> 
> (which(is.na(train$Embarked == ""))) 
integer(0)
> 
> train <- train %>%
+             filter(Embarked != "") %>%
+             droplevels()
> #we check the str of train again
> str(train)
'data.frame':	889 obs. of  8 variables:
 $ Survived: int  0 1 1 1 0 0 0 0 1 1 ...
 $ Pclass  : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Sex     : Factor w/ 2 levels "female","male": 2 1 1 1 2 2 2 2 1 1 ...
 $ Age     : num  22 38 26 35 35 25 54 2 27 14 ...
 $ SibSp   : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch   : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Fare    : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Embarked: Factor w/ 3 levels "C","Q","S": 3 1 3 3 3 2 3 3 3 1 ...
> 
> ## Now we run the entire model on the train data set
> test_model_final <- randomForest(as.factor(Survived)~.,data = train, importance = TRUE)
> 
> ## Run predictions
> test_model_final_predictions <- predict(test_model_final, test, predict.all = TRUE)
> 
> #Exporting predictions into a file 
> results_final <- as.vector(test_model_final_predictions$aggregate)
> results_frame <- data.frame(PassengerId, results_final)
> colnames(results_frame) <- c("PassengerId", "Survived")
> 
> which(is.na(results_frame$Survived == T)) #check for N/A values
[1] 153
> 
> results_frame[153,2] <- 0
> # Exporting to file.
> #write.table(results_frame, file = "Submission.csv", sep = ",", row.names = FALSE)
> #View(results_frame)
> 
> proc.time()
   user  system elapsed 
  2.910   0.202   3.193 
