<!DOCTYPE html>
<html lang="en">
<head>
    <title>A Beginner&#x27;s  Stab At Titanic | Kaggle</title>
    <meta charset="utf-8" />
    <meta name="robots" content="index, follow" />
    <meta name="turbolinks-cache-control" content="no-cache" />
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC" />
    <script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com" /><link rel="dns-prefetch" href="https://stats.g.doubleclick.net" /><link rel="dns-prefetch" href="https://js.intercomcdn.com" /><link rel="dns-prefetch" href="https://storage.googleapis.com/" />
    <link href="/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link rel="manifest" href="/static/json/manifest.json">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic" rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet" type='text/css'/>
        <link rel="canonical" href="/athi94/a-beginner-s-stab-at-titanic" />                    <link rel="stylesheet" type="text/css" href="/static/assets/vendor.css?v=632d145d8598" />
        <link rel="stylesheet" type="text/css" href="/static/assets/app.css?v=9626e4919bfe" />
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => d.deleteRule(x))};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12629138-1"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6"};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@kaggledatasets" />
    <meta name="og:url" content="https://kaggle.com/athi94/a-beginner-s-stab-at-titanic" />
    <meta name="og:title" content="A Beginner&#x27;s  Stab At Titanic" />
    <meta name="og:description" content="Using data from Titanic: Machine Learning from Disaster" />
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/1155483-kg.jpg" />


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL8NVW77BiyiZO1A-S6sqjs6aQpbyyXZ2aLVdmvrFbLgfAJknjo03e7qY0l3JfE5qtGe_zQdim4DAShiogR8MkvsJWXdrkXOvwGajrbrpoIp8--i7bUeGGOY-61wuYmjspg',
        isAnonymous: true,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjAxNzIyNDgsIlVzZXJJZCI6MH0.NOinhEdTlUMNFCDUbIA-Cr4VYnPiEbdqkWVFOVopXmg',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: false,
        
        
        
        
        
        
        
        
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript"
src="//www.googleadservices.com/pagead/conversion_async.js">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="/static/assets/vendor.js?v=4721d2c14786" data-turbolinks-track="reload"></script>
    <script src="/static/assets/app.js?v=1d32f39aa6aa" data-turbolinks-track="reload"></script>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async defer src="https://apis.google.com/js/api.js"
            onload="this.googleApiOnLoad=function(){};handleClientLoad()"
            onreadystatechange="if (this.readyState === 'complete') this.googleApiOnLoad()">
    </script>
</head>
<body data-turbolinks="true">
    






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":327072,"title":"A Beginner\u0027s  Stab At Titanic","forkParent":null,"currentRunId":1408753,"mostRecentRunId":1408753,"url":"/athi94/a-beginner-s-stab-at-titanic","tags":[],"commentCount":0,"upvoteCount":5,"viewCount":359,"forkCount":4,"bestPublicScore":null,"author":{"id":1155483,"displayName":"athi","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"athi94","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1155483-kg.jpg","profileUrl":"/athi94","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2017-08-07T00:22:55.8333333Z","selfLink":"/kernels/327072","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":null,"topicId":null,"readGroupId":null,"writeGroupId":null,"slug":"a-beginner-s-stab-at-titanic"},"kernelBlob":{"id":6420535,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"notebook","language":"r","isGpuEnabled":false,"isInternetEnabled":false},"source":"{\u0022nbformat_minor\u0022: 2, \u0022nbformat\u0022: 4, \u0022cells\u0022: [{\u0022source\u0022: \u0022Introduction\\n=========\\n\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002210efd95221ab0ee97dd2d05e6a869e2ded79627d\u0022, \u0022_cell_guid\u0022: \u0022d481a061-7128-4b58-9581-23a484164252\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Prepping the Data\\n================\\n\\nLoading\\n----------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002275144fa48a87b9355c888edc23ccf504778bb92c\u0022, \u0022_cell_guid\u0022: \u002293907919-ded8-490e-b00e-c9d7fe312533\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = read.csv(\u0027../input/train.csv\u0027, na.strings=\u0027\u0027)\\nfr_test = read.csv(\u0027../input/test.csv\u0027, na.strings=\u0027\u0027)\\n\\nfr_test$Survived = rep(NA, nrow(fr_test))\\nfr_train$Set = rep(\\\u0022train\\\u0022, nrow(fr_train))\\nfr_test$Set = rep(\\\u0022test\\\u0022, nrow(fr_test))\\n\\nfr_titanic = rbind(fr_train, fr_test)\\n\\ndim(fr_train)\\nhead(fr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022310171af41071cea0bc4043098ffd566914aabb2\u0022, \u0022_cell_guid\u0022: \u0022c6b08e12-a94c-4e20-9b29-6d2d157efb2c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Right off the bat we can spot an idiosyncracy in our dataset, namely that we seem to be missing a lot of values in our `Cabin` feature. Dealing with missing data is an important step in any machine learning pipeline, and we\u0027ll spend a bit of time on it a little later on. But first, let\u0027s continue exploring some basic properties of the training portion our dataset.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e556e73603e99eadaa705f5d1042f566232ea1a2\u0022, \u0022_cell_guid\u0022: \u0022dc1d4dbc-68f1-48c2-99a7-24872958651c\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022summary(fr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022c280857be9f9e597da6fb4c303a196f9901447c8\u0022, \u0022_cell_guid\u0022: \u0022653709bd-3ef9-4f98-92db-40e278129d5b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s run through what we see here.\\n\\nFirst of all the mean of `Survived` is 0.38, meaning only 38% of people survived in this dataset. Naturally this means we have more data pertaining to passengers who died, so it wouldn\u0027t be too suprising if our model ends up being better at able to predict who dies than who survives but this is something we\u0027ll have to evaluate later.\\n\\nThere\u0027s also more males than females in this dataset by a fairly significant margin, 577 versus 314. Most interestingly take a look at `Cabin`, there\u0027s a whopping 687 NA\u0027s. That\u0027s a lot of missing data, note that `Age` and `Embarked` are missing values as well but not nearly as much.\\n\\nI like to quickly make helper functions which give me neat, explicit output about what I\u0027m concerned with. Since we\u0027re about to deal with a lot of missing data I\u0027m going to make a short, simple function which summarises the missing data in any generic dataframe.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002263a62f044a4241548e85f05559ceccf058fbb49b\u0022, \u0022_cell_guid\u0022: \u0022d30af6f8-ee7a-452a-b355-ca64285d43bd\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022naSummary = function(df) {\\n    naCount = sapply(df, function(col) {\\n        sum(is.na(col))\\n    })\\n    \\n    return (data.frame(naCount, naPc=naCount/nrow(df)))\\n}\\n\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022e4568784fbf86d523a6f95618f63ff94abf36c98\u0022, \u0022_cell_guid\u0022: \u0022312d0791-1c88-4965-ba8c-f0af6b7556c1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Remember we\u0027re only missing `Survived` data because we made NA\u0027s when merging the test and train sets. Let\u0027s take a look at our data types as the last preliminary check to make sure everything looks good.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002213ff7f2495612d02be0f2824dd0d68f08e12897a\u0022, \u0022_cell_guid\u0022: \u002287296f9d-a740-4b49-9f6f-eb148ec4c892\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022str(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022bb52e73920ea8c9d1af538647ad5573ef447f48a\u0022, \u0022_cell_guid\u0022: \u002224be9c67-24ac-4b47-888f-4ac7df03d71e\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022We should remove passenger ID because it\u0027s a useless feature, let\u0027s also explicitly convert `Survived` to a factor. Remember factors assume no order, categorical features with explicit order should be kept as ints, e.g. `Pclass`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022cfa9b4e9de9e3b5a4369447d2f062de1af288a9c\u0022, \u0022_cell_guid\u0022: \u0022f95d146d-bd64-49bf-8516-be7dbdc5a1f7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Survived = as.factor(fr_titanic$Survived)\\nfr_titanic = subset(fr_titanic, select=-c(PassengerId))\\n\\nstr(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002232d06efaa436efc77cca3fafebe057a3fff35998\u0022, \u0022_cell_guid\u0022: \u0022cfd4cc1d-fbc8-46b0-a2bc-a05819e57e44\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Missing Data Imputation\\n----------------------\\n\\nThere\u0027s essentially two strategies you can employ when you have to deal with missing data. You can throw out the entries with missing variables, or you can replace the missing variables with your best guess. This latter process is called imputation. The downside of throwing data out is simply that you\u0027ll have less data to train your model on, but it\u0027s really simple to do. Strategies for imputation can range from very easy to quite complex, it\u0027s an extensive topic in and of itself and you should spend some time reading up on it.\\n\\n### Embarked\\n\\nLet\u0027s go from easy to hard, and start off with the `Embarked` feature which is only missing two values. This is a totally trivial amount of missing data so we\u0027ll just use a really simple \u0027most frequent\u0027 imputation which is exactly what it sounds like, replace the missing value with the most frequent level for that feature.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022bd16ff2e294f811ccdbd6f1d82bc79735271cde1\u0022, \u0022_cell_guid\u0022: \u0022ab3aca03-4429-4259-952e-44f7b8be8844\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022mcl = fr_titanic$Embarked[which.max(fr_titanic$Embarked)]\\nfr_titanic$Embarked[which(is.na(fr_train$Embarked))] = mcl\\n\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022cc4827c5d553eb3c715e332dcaa333a4b7df7185\u0022, \u0022_cell_guid\u0022: \u00226fa364b2-d30a-4365-b919-b2b4d6e02fb7\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022### Fare\\n\\nWe\u0027ll do the same thing for our one missing value of Fare, except now that it\u0027s a numeric feature we\u0027ll use a mean imputation.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002283b99de43fb2fef0ea5300cc5ccc97f7f861e062\u0022, \u0022_cell_guid\u0022: \u0022b454c439-0588-4f7d-a044-dc366534afe7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Fare[which(is.na(fr_titanic$Fare))] = mean(fr_titanic$Fare, na.rm=TRUE)\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022799b8be488723b4c82f544705f03686245ca6814\u0022, \u0022_cell_guid\u0022: \u0022c02f67c1-199a-47b3-a38b-e826af871739\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022### Age\\n\\n`Age` is a bit harder, we\u0027re missing a non-trivial amount of values. We\u0027re going to attempt a random regression imputation. This involves developing a regression model between `Age` and a set of predictors from the dataset, then adding a residual term to the prediction in order to reintroduce randomosity to the imputed values. Effectively this is another machine learning problem within our bigger Titanic machine learning problem!\\n\\nWe\u0027re going to need features so we can do a bit of feature engineering here. In particular I want to extract the Title of each passenger from the `Name` feature, a look at the data shows that the title \\\u0022Master\\\u0022 seems to be reserved for males under the age of 13. I\u0027d also expect there to be a correlation between the title \\\u0022Miss\\\u0022 and younger females.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022497a3b3a18071c57a3901f493b591eda4946b5fc\u0022, \u0022_cell_guid\u0022: \u00221b4024dd-dbfc-4fcd-9cd3-44d9964fd6e6\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022getTitle = function(name) {\\n    postcom = trimws(strsplit(as.character(name), \u0027,\u0027)[[1]][2])\\n    title = strsplit(postcom, \u0027 \u0027)[[1]][1]\\n    return (substr(title, 1, nchar(title)-1))\\n}\\n\\nfr_titanic$Title = as.factor(sapply(fr_titanic$Name, getTitle))\\nfr_titanic = fr_titanic[c(\\\u0022Survived\\\u0022, \\n                        \\\u0022Pclass\\\u0022,  \\n                        \\\u0022Name\\\u0022,\\n                        \\\u0022Title\\\u0022,\\n                        \\\u0022Sex\\\u0022, \\n                        \\\u0022Age\\\u0022, \\n                        \\\u0022SibSp\\\u0022, \\n                        \\\u0022Parch\\\u0022, \\n                        \\\u0022Ticket\\\u0022, \\n                        \\\u0022Fare\\\u0022, \\n                        \\\u0022Cabin\\\u0022, \\n                        \\\u0022Embarked\\\u0022,\\n                        \\\u0022Set\\\u0022)]\\n\\nhead(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022dd696b1db9766f66df21c322077b933858d9afd1\u0022, \u0022_cell_guid\u0022: \u00222a571552-becc-4a52-828c-291e454b38e1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022So far looks good! Let\u0027s use `table()` to get a better look.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00225f573a9c48184d3849d90cdbf5cc7d53c272bdf1\u0022, \u0022_cell_guid\u0022: \u0022be018dfb-8583-4268-a001-837d485852ca\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022table(fr_titanic$Title)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00221e022cee1f10f10464d2bc2cf9670e7f9c5a3e18\u0022, \u0022_cell_guid\u0022: \u002251a9c26c-84d0-44ab-9769-c39b13898732\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022There\u0027s a lot of special titles being used for a small number of passengers. Let\u0027s coerce them to common values so we only deal with the following subset of titles:\\n\\n* Mr\\n* Mrs\\n* Miss\\n* Master\\n\\nWe\u0027ll use the following mappings.\\n\\n* Dr, Rev, Major, Col, Jonkheer, Don, Sir, Capt -\u003e Mr\\n* Mlle, Ms -\u003e Miss\\n* Dona, Lady, Mme, th -\u003e Mrs\\n\\nI think there would be some amount of predictive power to these title if we had more data, but as it stands these honorifics just don\u0027t have enough entries to act as standalone features so we\u0027re merging them with the most appropriate alternate level.\\n\\nSince we\u0027re removing a lot of levels we have to use the `droplevels()` command to remove them from the feature within R.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022080c0d1fba46edf5fbb2f2328811582ede709ef8\u0022, \u0022_cell_guid\u0022: \u0022b4572c26-530d-4211-9d8c-44941ed3aa77\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022mr_alias = c(\u0027Dr\u0027, \u0027Rev\u0027, \u0027Major\u0027, \u0027Col\u0027, \u0027Jonkheer\u0027, \u0027Don\u0027, \u0027Sir\u0027, \u0027Capt\u0027)\\nmrs_alias = c(\u0027Dona\u0027, \u0027Lady\u0027, \u0027Mme\u0027, \u0027th\u0027)\\nmiss_alias = c(\u0027Mlle\u0027, \u0027Ms\u0027)\\n\\nfr_titanic$Title[which(fr_titanic$Title %in% mr_alias)] = \u0027Mr\u0027\\nfr_titanic$Title[which(fr_titanic$Title %in% mrs_alias)] = \u0027Mrs\u0027\\nfr_titanic$Title[which(fr_titanic$Title %in% miss_alias)] = \u0027Miss\u0027\\n\\nfr_titanic$Title = droplevels(fr_titanic$Title)\\nsummary(fr_titanic$Title)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022083e9f951e8d4cf384514d908de8d8ba9645ff0a\u0022, \u0022_cell_guid\u0022: \u00220dfba0c9-2b0b-4e6b-9f1f-357978fffa95\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Great! Now that\u0027s all done and we have what\u0027s hopefully a useful, additional feature for our Age random regression imputation. We can finally get started with our actual random regression to impute our missing `Age` values.\\n\\nFirst I\u0027m going to define a new dataframe which contains only the features we need to deal with to train our regression model, this means excluding `Name`, `Ticket`, `Cabin` as well as all our test data. We also have to exclude `Survived` because we need to impute missing values in the test set as well.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002205fa7474e0dab7b947c708e7e1f338e802e5c934\u0022, \u0022_cell_guid\u0022: \u00220081f9d9-717c-47bf-9163-eff981695bae\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022rr_train = subset(fr_titanic, select=-c(Survived, Name, Ticket, Cabin, Set))\\nrr_train = na.omit(rr_train) # Omits test data as Survived values are all NA\u0027s\\n\\nhead(rr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002250db118563e8bd4bafde3c726f1d12bf947b534a\u0022, \u0022_cell_guid\u0022: \u00229eb7e2ea-aa5f-42ca-9024-44e7f3fe8582\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022lm.fit = lm(Age ~ ., data=rr_train)\\nsummary(lm.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225017dd181175aaf667a75f8207013dc356b52823\u0022, \u0022_cell_guid\u0022: \u00224bede0b2-fa0e-467e-ae5a-0fb2571fbd2d\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s take a quick look at these p-values. `Pclass` is a statistically significant feauture in predicting `Age`, boxplots are useful in investigate the nature of the relationship further.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022c1450515257bee063df352f8651ce0655857592d\u0022, \u0022_cell_guid\u0022: \u0022f28d249a-bd38-4ec8-81ef-4e98c4096f29\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022plot(as.factor(rr_train$Pclass), rr_train$Age, xlab=\\\u0022Passenger Class\\\u0022, ylab=\\\u0022Age\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00227f5559c1661380a9797ff7b57c4ad6503e6a52d2\u0022, \u0022_cell_guid\u0022: \u0022d990579c-2441-42a1-88d8-15a558666c67\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like first class passengers skew older which isn\u0027t suprising. `Title` is a significant feature too so our little bit of feature engineering has paid off! `Sex` has no significance in predicting `Age` which isn\u0027t particularly surprising. The number of siblings/spouses in `SibSp` is significant as well, my guess is that younger people tend to have a higher count as they likely have siblings on board. Another boxplot should help us determine this.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022bcbe4ea431b45c2ed1201a74d4316f322d0c4f16\u0022, \u0022_cell_guid\u0022: \u00222615dff2-2476-41aa-b93b-97328949944d\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022plot(as.factor(rr_train$SibSp), rr_train$Age, xlab=\\\u0022# siblings + spouses\\\u0022, ylab=\\\u0022Age\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f95c872c25fd9aee88dd98a29c27b3da75e9a6cf\u0022, \u0022_cell_guid\u0022: \u0022f43336f5-9d98-4069-8136-ff10d8f5f5b4\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Bingo, looks like that\u0027s exactly the trend. The last significant feature is `Embarked`, in particular if you embarked from location Q. To be honest I have no idea why, if you do know leave a comment because I\u0027m curious!\\n\\nLet\u0027s create a simpler regression model which excludes the insignificant features: `Sex`, `Parch` and `Fare`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002272d0b677a5b1934231f35d8f45430589c03e82d8\u0022, \u0022_cell_guid\u0022: \u002242f7b28b-a0e3-4367-808a-e603d258997f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022lm.fit = lm(Age ~ Pclass + Title + SibSp + Embarked, data=rr_train)\\n\\nsummary(lm.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00224783d9e9da2ebfdc5573b7d41771fb58fa29c88a\u0022, \u0022_cell_guid\u0022: \u0022a441fa69-ca32-48f5-85de-dd7e4e68dc5b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Now looking at our $R^2$ this definitely isn\u0027t the best `Age` predictor but remember this is just for imputation, effectively we\u0027re trying to maintain the relationships between `Age` and other variables which exist so as not to diffuse the strength of any patterns in the data when we build our actual Survival predictor. Other strategies like estimating a distribution then sampling from that randomly to fill missing values maintains the state of information we have about `Age`, but potentially weakens the patterns between `Age` and other features.\\n\\nFinally, let\u0027s do our imputation. But first I\u0027m going to see if there\u0027s any people with the title \\\u0022Master\\\u0022 that have missing ages, remember that title appears to be reserved for males under the age of 13. It\u0027ll be an interesting test to see if our imputed ages maintain that criteria.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022a5cbf9d15856ddfe373d9ddcb3699c7086c08e99\u0022, \u0022_cell_guid\u0022: \u00227d76e060-6b1f-4824-a308-36cfae54727b\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022missing_age_masters = which(fr_titanic$Title == \u0027Master\u0027 \u0026 is.na(fr_titanic$Age))\\nfr_titanic[missing_age_masters, ]\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002219186872062e278f531934e31fafc17377c841be\u0022, \u0022_cell_guid\u0022: \u0022c1f5822c-05a2-4092-8a7a-4b6aa3917fe8\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022set.seed(10) # this makes the kernel results reproducible\\n\\ndet_imputed = predict(lm.fit, fr_titanic[which(is.na(fr_titanic$Age)), ])\\nrandom_imputed = rnorm(length(det_imputed), det_imputed, abs(residuals(lm.fit)))\\n\\n# We need to round the values to integers and floor them at a value of 1\\ndet_imputed[which(det_imputed \u003c 0)] = 1\\ndet_imputed = round(det_imputed)\\n\\nrandom_imputed[which(random_imputed \u003c 0)] = 1\\nrandom_imputed = round(random_imputed)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022a79567bbf026e92746d66aacc909663b974bc235\u0022, \u0022_cell_guid\u0022: \u0022dd703cee-4383-4018-bd48-a0bfa141881b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s take a look at the original values vs the imputed values.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00222c1b227ae35a64c94203df044c79d4f3bb33f3a8\u0022, \u0022_cell_guid\u0022: \u002203de8754-2439-4b9f-ae18-62d4f6e90004\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022par(mfrow=c(3,1))\\nhist(rr_train$Age, breaks=10, freq=F)\\nhist(det_imputed, breaks=10, freq=F)\\nhist(random_imputed, breaks=10, freq=F)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002268a50c966ee27af627e2939ffeda4792f974b6fb\u0022, \u0022_cell_guid\u0022: \u0022bd4ed940-327b-4c5f-b7c8-6384b8b7257c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Under the assumption that the missing values are missing completely at random and with sufficient missing values, we would expect our histograms of the imputed values to be very similar to the original values. This seems to be what we\u0027re seeing here. It\u0027s also good to compare the deterministic imputations vs the random imputations, the deterministic imputations lie on the regression line by definition. This means that it assumes there\u0027s a deterministic relationship between the predictors and the target which is clearly not likely to be accurate. The random imputations take the deterministic imputations and adds an error term proportional to the residuals in the regression fit. Effectively we try and reintroduce appropriate variance in the imputed values.\\n\\nViolin plots really help us see this effect.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e1b4e6f76beed2cc4dca7d1d6870f0c5e2d9fec1\u0022, \u0022_cell_guid\u0022: \u0022c48c09b2-e39b-49a6-88a6-4e917ea9b68b\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(ggplot2)\\n\\nkde_mat = rbind(cbind(rr_train$Age, rep(\\\u0022Original\\\u0022, length(rr_train$Age))),\\n        cbind(det_imputed, rep(\\\u0022Deterministic Imputation\\\u0022, length(det_imputed))),\\n        cbind(random_imputed, rep(\\\u0022Randomised Imputation\\\u0022, length(random_imputed))))\\n\\nkde_df = data.frame(Age=as.numeric(kde_mat[,1]), Source=as.factor(kde_mat[,2]))\\n\\nggplot(kde_df, aes(x=Source, y=Age, fill=Source)) + geom_violin()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002259930c25aa670c4029729112c5a5181a2f1dc53e\u0022, \u0022_cell_guid\u0022: \u0022202491b7-176f-4c23-830c-ded2b4ae87aa\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s merge the imputed values back into our dataframe now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022a8d705a5fc654b1dc1bf109bba434a7d5144232a\u0022, \u0022_cell_guid\u0022: \u0022d8e90a16-2e94-4be4-92b2-beb1e0e869b0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Age[which(is.na(fr_titanic$Age))] = random_imputed\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00229a1e1115b74ce253c707d3898dabf91c951a023d\u0022, \u0022_cell_guid\u0022: \u00220d87f31f-b8af-4e44-a062-36a824dcfa2c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s go back to the 4 passengers with the \\\u0022Master\\\u0022 title and missing ages now and see what the randomised imputations they received were.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00220dd0087b4ef49d9ccef2eee2592c1ce6cad18802\u0022, \u0022_cell_guid\u0022: \u00220c1fe54d-69fb-48f8-8bc0-ebe8b86938a2\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic[missing_age_masters,]\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00227cfcec17a7a86e3ddf700bcc65c4649d16c6aa46\u0022, \u0022_cell_guid\u0022: \u0022bee2e198-294a-45de-87dc-3844de00684e\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Remember we expected them to have an `Age` of less than 13 and we do see that, this is a good indication that our random regression imputation has succeeded in preserving relationships between Age and the other features in the dataset.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002253e16d6b178bfa893ff375459221b6f99114174d\u0022, \u0022_cell_guid\u0022: \u00228a5a9808-1ceb-4158-9193-c1a7578292d5\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022### Cabin\\n\\nLet\u0027s be practical, it\u0027s not really possible to impute values for `Cabin` given the nature of the data. Instead let\u0027s focus on transforming it into a useful feature in the feature engineering phase.\\n\\nFeature Engineering\\n===========\\n\\nCabin\\n-----\\n\\nSince we\u0027re missing most of our Cabin values the simplest strategy to see if this could be a useful feature would be to encode it as a simple binary variable, whether a Cabin is listed or not.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002217fa76f77ec08c5b6f1f304af0621d6fe01032f0\u0022, \u0022_cell_guid\u0022: \u00223c925e13-a0a7-4d9c-aafe-61e90bf1bd71\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(reshape2)\\n\\nfr_titanic$hasCabin = as.factor(!is.na(fr_titanic$Cabin))\\n\\n# Make a convenience feature which is directly descriptive\\nSurvived_Desc = ifelse(fr_titanic$Survived == 1, \\\u0022Survived\\\u0022, \\\u0022Died\\\u0022)\\n\\nfreq = table(fr_titanic$hasCabin, Survived_Desc)\\nfreq_df = as.data.frame.matrix(freq)\\n\\nfreq_df = data.frame(Cabin=row.names(freq_df), freq_df)\\nfreq_df = melt(freq_df, id.vars=\\\u0022Cabin\\\u0022)\\n\\nggplot(freq_df, aes(x=Cabin, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225cb47ff7809ef5ae9ceb9674baa177f666946e9f\u0022, \u0022_cell_guid\u0022: \u00229e9ff83e-f952-4911-8b64-3fbef5a6f09a\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Luckily for us `hasCabin` may actually has some decent predictive power, we can see that those with a listed cabin are far more likely to survive than those without. The next step I think here is to extract the deck out of the `cabin` for each passenger with a `cabin` value and see if there\u0027s predictive power associated with that.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022collapsed\u0022: true, \u0022_uuid\u0022: \u002285f28e92774e8fbc546fe900382fcce44e82767e\u0022, \u0022_cell_guid\u0022: \u0022d9fff799-8e42-4ea5-94e7-d949de7b76b7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Deck = sapply(fr_titanic$Cabin, function(cabin) {\\n    substr(as.character(cabin), 1, 1)\\n})\\n\\nfr_titanic$Deck[which(is.na(fr_titanic$Deck))] = \\\u0022None\\\u0022\\nfr_titanic$Deck = as.factor(fr_titanic$Deck)\\n\\nsummary(fr_titanic$Deck)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00223d58862db59b360216feb04787db266a65debf3c\u0022, \u0022_cell_guid\u0022: \u0022ae5fc19a-7d85-4d04-99f1-01f5a3827612\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Since there\u0027s only one value for `T` we\u0027ll just coerce it into factor `None`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002297ef46e2c180b2b8dc480c52511c49b7d50c4102\u0022, \u0022_cell_guid\u0022: \u002292522a0d-c0a3-4ccb-a85a-942dd50ed916\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Deck[which(fr_titanic$Deck == \u0027T\u0027)] = as.factor(\u0027None\u0027)\\nfr_titanic$Deck = droplevels(fr_titanic$Deck)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022140eefd90d16846f225dfbe819de8a91db190784\u0022, \u0022_cell_guid\u0022: \u00228bea4135-68b5-43fa-b665-3505be73c768\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022freq = table(fr_titanic$Deck, Survived_Desc)\\nfreq_df = as.data.frame.matrix(freq)\\nfreq_df = data.frame(Deck=row.names(freq_df), freq_df)\\n\\nfreq_df = melt(freq_df, id.vars=\\\u0022Deck\\\u0022)\\n\\nggplot(freq_df, aes(x=Deck, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002250d6c42b3a53f3fa05386a58b626e3464c1c2ee7\u0022, \u0022_cell_guid\u0022: \u0022eac6f99d-35d6-4b25-9aec-f9178a8e1662\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022## Tickets\\n\\nSince group tickets were available, we can introduce a new feature which guesses whether a person travelled in a group and then see if that has a relationship with survival rate.\\n\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00220a4e52bc3231b765f42dce517862aaf80be596a7\u0022, \u0022_cell_guid\u0022: \u0022f3ce3a14-22d2-4f0b-9a77-cdeb00359bd0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022inGroup = as.factor(duplicated(fr_titanic$Ticket))\\n\\nfreq_df = as.data.frame.matrix(table(inGroup, Survived_Desc))\\nfreq_df = data.frame(inGroup=row.names(freq_df), freq_df)\\n\\nfreq_df = melt(freq_df, id.vars=\\\u0022inGroup\\\u0022)\\n\\nggplot(freq_df, aes(x=inGroup, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002257ff854cc8b5504babd71a45239ef11d648d486e\u0022, \u0022_cell_guid\u0022: \u0022d60bd2a1-a9b1-4036-b25e-563baf956a0d\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like if you\u0027re not in a group you are more likely to die than those who are not, so we can add this as a proper feature in our dataframe now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022937fa653a5463cf411d4e1ff0c63e03131632d15\u0022, \u0022_cell_guid\u0022: \u00227d4c840b-bca5-4211-a9e0-e6eef23b7b7f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$inGroup = inGroup\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022987f032835fb1204043fe5ad4896fc655179b3d3\u0022, \u0022_cell_guid\u0022: \u0022c9cef19b-5469-4bfe-833c-8019643b91e2\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022## Women and Children First!\\n\\nWe don\u0027t really have to worry about the \u0027woman\u0027 part seeing as that\u0027s already handled by the `Sex` feature. What we can investigate is whether there\u0027s any merit to introducing a new `Child` feature rather than just relying on ages. Or more generally binning the ages into a set of wider levels.\\n\\nFirst off let\u0027s plot the distribution of `Survival` vs `Age`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00228e2d3fd84fc973daca1466414573620923264e81\u0022, \u0022_cell_guid\u0022: \u002202dc7fd9-bf8b-41bf-bae0-840bb6583a33\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = fr_titanic[which(fr_titanic$Set == \u0027train\u0027), ]\\n\\nuniq_ages = sort(unique(fr_train$Age))\\n\\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\\n    mean(fr_train[which(fr_train$Age == age), ]$Survived == 1)\\n})\\n\\nuniq_ages\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022ef83a47449d9c73978adb5f17fb39b76cdc4ffc5\u0022, \u0022_cell_guid\u0022: \u0022000be72f-43b4-4ca8-86ff-cd002845922b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like in the original data there was some fractional ages. Let\u0027s round these for simplicity, redo our survival rate calculation, and plot the results.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002287d66137832c1ac4e537cf6ff0bf8077e7315639\u0022, \u0022_cell_guid\u0022: \u0022cce2eb61-b72f-42a3-b419-2cbf540bf7e9\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train$Age = round(fr_train$Age)\\nuniq_ages = sort(unique(fr_train$Age))\\n\\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\\n    selection = fr_train[which(fr_train$Age == age), ]$Survived\\n    mean(selection == 1)\\n})\\n\\nage_surv_rate_df = data.frame(Age=uniq_ages, SurvivalRate=survival_rates_by_age)\\nggplot(age_surv_rate_df, aes(x=Age, y=SurvivalRate)) + geom_col()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022c1ddc9c4286db8b75f887ce8c0a07673ab53016b\u0022, \u0022_cell_guid\u0022: \u00220d0ee261-af6b-4411-a70b-ae87c8ad5a1c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022There\u0027s actually a lot of noise in this plot and it\u0027s difficult to make out a clear trend because there\u0027s not many samples for each individual age. Instead let\u0027s bin the ages into groups of 5 and plot the average survival rate for each bin.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022929d1be0d49019c125f35e32799373d7283520e0\u0022, \u0022_cell_guid\u0022: \u0022642aec8d-54fa-4c2c-9592-cfbda5f37ec0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022age_bins = split(uniq_ages, ceiling(seq_along(uniq_ages)/5))\\nbinned_surv_rate = sapply(age_bins, function(bin) {\\n    mean(age_surv_rate_df[which(age_surv_rate_df$Age %in% bin), ]$SurvivalRate)\\n})\\n\\nbinned_age_surv_df = data.frame(AgeBin=factor(names(age_bins), levels=names(age_bins)), SurvivalRate=binned_surv_rate)\\nggplot(binned_age_surv_df, aes(x=AgeBin, y=SurvivalRate)) + geom_col()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f92e2f3b4d926d0a946fce77ac650e6cf9abf03c\u0022, \u0022_cell_guid\u0022: \u0022a53465d3-9e8d-42df-8631-354f1a3d3242\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022This gives us a much clearer picture of what\u0027s going on. First off we see that the first bin has the highest survival rate by far, this would correspond to passengers in the age range of 0 to 4. Children typically have a higher survival rate as we can see in bins 2, 3, and 4 which corresponds to ages 5-19. The last bin only contains one measurement of survival and should be effectively considered noise. After that there\u0027s no major differences in survival rate outside of an outlier in bin 11, but there\u0027s no logical explanation for this I can think of. Based on this info let\u0027s engineer a new three level categorical feature based on Age, the levels will be `Toddler` for ages 0-4, `Child` for ages 5-18, and Adult for ages 18+.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00222b3a532c5c8e95b1e3e3f6fc534dbf3306d04922\u0022, \u0022_cell_guid\u0022: \u0022dfebd5ae-6bac-4c2b-a156-b73947fdf403\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$AgeGroup = sapply(fr_titanic$Age, function(age) {\\n    if (age \u003c 5) {\\n        return (1)\\n    } else if (age \u003e= 5 \u0026\u0026 age \u003c 18) {\\n        return (2)\\n    } else {\\n        return (3)\\n    }\\n})\\n\\ntable(as.factor(fr_titanic$AgeGroup))\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022bfe231b5670f8e1b841561df60ae1b2590805848\u0022, \u0022_cell_guid\u0022: \u002200fbf301-2e75-4500-a47a-78a13c82157a\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022I think this should do in terms of feature engineering for now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002227b3a624101d6e067e3a8f96ac8b196789cb76ae\u0022, \u0022_cell_guid\u0022: \u002210698e72-ebab-461c-92fc-eead14154424\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Predictions\\n======\\n\\nWe\u0027ll build both a `Support Vector Classifier` and a `Random Forest` model in this section, compare them, and choose the one that works best.\\n\\nSplit Train and Test Set\\n-----------------------\\n\\nFirst we split our dataframe back into the original train and test sets. Also clean up the data and remove the now unnecessary `Name`, `Ticket`, `Cabin` and `Set` variables as well as the `Survived` variable for the test set.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002258d3f9cc5cab327e45490090e7d1b175f5a7f697\u0022, \u0022_cell_guid\u0022: \u002219771177-fc49-4d48-b039-e823a2a85c91\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = fr_titanic[which(fr_titanic$Set == \u0027train\u0027),]\\nfr_test = fr_titanic[which(fr_titanic$Set == \u0027test\u0027),]\\n\\nfr_train = subset(fr_train, select=-c(Name, Ticket, Set, Cabin))\\nfr_test = subset(fr_test, select=-c(Name, Ticket, Set, Cabin, Survived))\\n\\nhead(fr_train)\\nstr(fr_train)\\nstr(fr_test)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022053350cbe42d34f2b900a5ec01348d6ea45292b0\u0022, \u0022_cell_guid\u0022: \u0022807af696-562c-41ce-b9ce-3d7d7c0200d5\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Support Vector Classifier\\n-------------------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022dfa1f4d9f98d51e20213da3d1b981d16c940ad40\u0022, \u0022_cell_guid\u0022: \u0022cdee7eb7-234e-439c-aa32-8cc671143533\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(e1071)\\n\\nset.seed(7)\\n\\ntuned = tune(svm, Survived ~ ., data=fr_train, kernel=\\\u0022linear\\\u0022, scale=TRUE, \\n             ranges=list(cost=seq(0.3, 0.6, length=20)))\\n\\nsummary(tuned)\\nsvm.fit = tuned$best.model\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225abed0ecc88a87b6013d6f7f112254ef6d57e3d6\u0022, \u0022_cell_guid\u0022: \u00225abd26b2-aacd-473a-bd3b-6b5aeab92cad\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Random Forest\\n------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022dd923f4d2c45a69c4e48b6e7a5dd2a365028ae43\u0022, \u0022_cell_guid\u0022: \u002221729e54-9d00-4453-9a3e-c73085856280\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(randomForest)\\n\\nset.seed(7)\\nrf.fit = randomForest(Survived ~ ., data=fr_train)\\nsummary(rf.fit$err.rate)\\n\\n# Thanks to Megan Risdal\u0027s excellent Titanic kernel for this little error rate graph\\nplot(rf.fit, ylim=c(0,0.36))\\nlegend(\u0027top\u0027, colnames(rf.fit$err.rate), col=1:3, fill=1:3, bty=\\\u0022n\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002267688780d9440b6648be1896c71b554ff336e10b\u0022, \u0022_cell_guid\u0022: \u0022fa8b1560-f7a5-4255-a3ed-d577d75171c1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022The first thing to notice here is how much better we are at predicting death than survival. Remember the start of our dataset where we guessed we\u0027d be better at predicting who died than who survived, this seems to have taken effect but in reality this is also simply a consequence of how the Random Forest model works. It\u0027ll always perform much better on the bigger class.\\n\\nThe random forest model also slightly outperforms our support vector classifier, which had an error rate of 17.6% as estimated by the 10-fold cross validation. A convenient feature present in the randomForest object is the ability to plot importance measures. Handy as we can see if our feature engineering actually helped us.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022c6d9f4be868d40055998402309d22ab11faa701b\u0022, \u0022_cell_guid\u0022: \u0022af4a34a8-a042-4cf4-85e1-dc6d1f5ce0ea\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022varImpPlot(rf.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f4f512a2c5cee41cfda063c56570bbd8aa5f45d2\u0022, \u0022_cell_guid\u0022: \u00229c4fe071-d725-4799-aa47-fe246f6195e8\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Unfortunately it looks like our inGroup and AgeGroup weren\u0027t very successful features, Title on the other hand did extremely well!\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e8fa2aae9e9cb4507a3135f983ff7f4ae8fd6b25\u0022, \u0022_cell_guid\u0022: \u00220ecc7514-6e79-4cbb-b822-6aa03a03a7bc\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Making our Prediction File\\n------------------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00224e2e4dfac6de4b5f533229a6a4e5b89d30c2c135\u0022, \u0022_cell_guid\u0022: \u0022d5fb5ceb-c629-4ec1-827d-109286e3813f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022rf.preds = predict(rf.fit, fr_test)\\nrf.submission = data.frame(PassengerId=names(rf.preds), Survived=rf.preds)\\nwrite.csv(rf.submission, file=\\\u0022rf_submission.csv\\\u0022, row.names=FALSE)\\n\\nsvm.preds = predict(svm.fit, fr_test)\\nsvm.submission = data.frame(PassengerId=names(svm.preds), Survived=svm.preds)\\nwrite.csv(svm.submission, file=\\\u0022svm_submission.csv\\\u0022, row.names=FALSE)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002291dcb41bdfa2fea5f98e0ebf25954dcf619b8b70\u0022, \u0022_cell_guid\u0022: \u0022feb15285-8483-43b0-86ee-5838311c25cb\u0022}, \u0022execution_count\u0022: 1}], \u0022metadata\u0022: {\u0022language_info\u0022: {\u0022pygments_lexer\u0022: \u0022r\u0022, \u0022version\u0022: \u00223.4.1\u0022, \u0022codemirror_mode\u0022: \u0022r\u0022, \u0022file_extension\u0022: \u0022.r\u0022, \u0022mimetype\u0022: \u0022text/x-r-source\u0022, \u0022name\u0022: \u0022R\u0022}, \u0022kernelspec\u0022: {\u0022display_name\u0022: \u0022R\u0022, \u0022language\u0022: \u0022R\u0022, \u0022name\u0022: \u0022ir\u0022}}}","dateCreated":"2017-08-07T00:22:54.897Z"},"kernelRun":{"id":1408753,"kernelId":327072,"status":"complete","type":"batch","sourceType":"notebook","language":"r","title":"A Beginner\u0027s  Stab At Titanic","dateCreated":"2017-08-07T00:22:54.897Z","dateEvaluated":"2017-08-07T00:22:55.833Z","workerContainerPort":null,"workerUptimeSeconds":8880229,"workerIPAddress":"10.3.0.100     ","scriptLanguageId":12,"scriptLanguageName":"R Notebook HTML","renderedOutputUrl":"https://www.kaggleusercontent.com/kf/1408753/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..1J_pY784ni9XSEqs391-0w.9xDQXGI6q0AfW3d2mKqB5svVrXGusgwrmKNamWpJXfpzjlu2FkZNS9Aw0k9L8-07Fy7VrkPnuo5KCFwYi2aD3s_ynYUS-hSy69TdNTUBcndjU_e6WijangZ2jmChUvbeU7YkvTFnVYv1GkxtSJqaFg.j5tDdw3csyAg4eKcqjUbow/__results__.html","commit":{"id":6420535,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"notebook","language":"r","isGpuEnabled":false,"isInternetEnabled":false},"source":"{\u0022nbformat_minor\u0022: 2, \u0022nbformat\u0022: 4, \u0022cells\u0022: [{\u0022source\u0022: \u0022Introduction\\n=========\\n\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002210efd95221ab0ee97dd2d05e6a869e2ded79627d\u0022, \u0022_cell_guid\u0022: \u0022d481a061-7128-4b58-9581-23a484164252\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Prepping the Data\\n================\\n\\nLoading\\n----------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002275144fa48a87b9355c888edc23ccf504778bb92c\u0022, \u0022_cell_guid\u0022: \u002293907919-ded8-490e-b00e-c9d7fe312533\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = read.csv(\u0027../input/train.csv\u0027, na.strings=\u0027\u0027)\\nfr_test = read.csv(\u0027../input/test.csv\u0027, na.strings=\u0027\u0027)\\n\\nfr_test$Survived = rep(NA, nrow(fr_test))\\nfr_train$Set = rep(\\\u0022train\\\u0022, nrow(fr_train))\\nfr_test$Set = rep(\\\u0022test\\\u0022, nrow(fr_test))\\n\\nfr_titanic = rbind(fr_train, fr_test)\\n\\ndim(fr_train)\\nhead(fr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022310171af41071cea0bc4043098ffd566914aabb2\u0022, \u0022_cell_guid\u0022: \u0022c6b08e12-a94c-4e20-9b29-6d2d157efb2c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Right off the bat we can spot an idiosyncracy in our dataset, namely that we seem to be missing a lot of values in our `Cabin` feature. Dealing with missing data is an important step in any machine learning pipeline, and we\u0027ll spend a bit of time on it a little later on. But first, let\u0027s continue exploring some basic properties of the training portion our dataset.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e556e73603e99eadaa705f5d1042f566232ea1a2\u0022, \u0022_cell_guid\u0022: \u0022dc1d4dbc-68f1-48c2-99a7-24872958651c\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022summary(fr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022c280857be9f9e597da6fb4c303a196f9901447c8\u0022, \u0022_cell_guid\u0022: \u0022653709bd-3ef9-4f98-92db-40e278129d5b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s run through what we see here.\\n\\nFirst of all the mean of `Survived` is 0.38, meaning only 38% of people survived in this dataset. Naturally this means we have more data pertaining to passengers who died, so it wouldn\u0027t be too suprising if our model ends up being better at able to predict who dies than who survives but this is something we\u0027ll have to evaluate later.\\n\\nThere\u0027s also more males than females in this dataset by a fairly significant margin, 577 versus 314. Most interestingly take a look at `Cabin`, there\u0027s a whopping 687 NA\u0027s. That\u0027s a lot of missing data, note that `Age` and `Embarked` are missing values as well but not nearly as much.\\n\\nI like to quickly make helper functions which give me neat, explicit output about what I\u0027m concerned with. Since we\u0027re about to deal with a lot of missing data I\u0027m going to make a short, simple function which summarises the missing data in any generic dataframe.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002263a62f044a4241548e85f05559ceccf058fbb49b\u0022, \u0022_cell_guid\u0022: \u0022d30af6f8-ee7a-452a-b355-ca64285d43bd\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022naSummary = function(df) {\\n    naCount = sapply(df, function(col) {\\n        sum(is.na(col))\\n    })\\n    \\n    return (data.frame(naCount, naPc=naCount/nrow(df)))\\n}\\n\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022e4568784fbf86d523a6f95618f63ff94abf36c98\u0022, \u0022_cell_guid\u0022: \u0022312d0791-1c88-4965-ba8c-f0af6b7556c1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Remember we\u0027re only missing `Survived` data because we made NA\u0027s when merging the test and train sets. Let\u0027s take a look at our data types as the last preliminary check to make sure everything looks good.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002213ff7f2495612d02be0f2824dd0d68f08e12897a\u0022, \u0022_cell_guid\u0022: \u002287296f9d-a740-4b49-9f6f-eb148ec4c892\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022str(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022bb52e73920ea8c9d1af538647ad5573ef447f48a\u0022, \u0022_cell_guid\u0022: \u002224be9c67-24ac-4b47-888f-4ac7df03d71e\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022We should remove passenger ID because it\u0027s a useless feature, let\u0027s also explicitly convert `Survived` to a factor. Remember factors assume no order, categorical features with explicit order should be kept as ints, e.g. `Pclass`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022cfa9b4e9de9e3b5a4369447d2f062de1af288a9c\u0022, \u0022_cell_guid\u0022: \u0022f95d146d-bd64-49bf-8516-be7dbdc5a1f7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Survived = as.factor(fr_titanic$Survived)\\nfr_titanic = subset(fr_titanic, select=-c(PassengerId))\\n\\nstr(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002232d06efaa436efc77cca3fafebe057a3fff35998\u0022, \u0022_cell_guid\u0022: \u0022cfd4cc1d-fbc8-46b0-a2bc-a05819e57e44\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Missing Data Imputation\\n----------------------\\n\\nThere\u0027s essentially two strategies you can employ when you have to deal with missing data. You can throw out the entries with missing variables, or you can replace the missing variables with your best guess. This latter process is called imputation. The downside of throwing data out is simply that you\u0027ll have less data to train your model on, but it\u0027s really simple to do. Strategies for imputation can range from very easy to quite complex, it\u0027s an extensive topic in and of itself and you should spend some time reading up on it.\\n\\n### Embarked\\n\\nLet\u0027s go from easy to hard, and start off with the `Embarked` feature which is only missing two values. This is a totally trivial amount of missing data so we\u0027ll just use a really simple \u0027most frequent\u0027 imputation which is exactly what it sounds like, replace the missing value with the most frequent level for that feature.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022bd16ff2e294f811ccdbd6f1d82bc79735271cde1\u0022, \u0022_cell_guid\u0022: \u0022ab3aca03-4429-4259-952e-44f7b8be8844\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022mcl = fr_titanic$Embarked[which.max(fr_titanic$Embarked)]\\nfr_titanic$Embarked[which(is.na(fr_train$Embarked))] = mcl\\n\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022cc4827c5d553eb3c715e332dcaa333a4b7df7185\u0022, \u0022_cell_guid\u0022: \u00226fa364b2-d30a-4365-b919-b2b4d6e02fb7\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022### Fare\\n\\nWe\u0027ll do the same thing for our one missing value of Fare, except now that it\u0027s a numeric feature we\u0027ll use a mean imputation.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002283b99de43fb2fef0ea5300cc5ccc97f7f861e062\u0022, \u0022_cell_guid\u0022: \u0022b454c439-0588-4f7d-a044-dc366534afe7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Fare[which(is.na(fr_titanic$Fare))] = mean(fr_titanic$Fare, na.rm=TRUE)\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022799b8be488723b4c82f544705f03686245ca6814\u0022, \u0022_cell_guid\u0022: \u0022c02f67c1-199a-47b3-a38b-e826af871739\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022### Age\\n\\n`Age` is a bit harder, we\u0027re missing a non-trivial amount of values. We\u0027re going to attempt a random regression imputation. This involves developing a regression model between `Age` and a set of predictors from the dataset, then adding a residual term to the prediction in order to reintroduce randomosity to the imputed values. Effectively this is another machine learning problem within our bigger Titanic machine learning problem!\\n\\nWe\u0027re going to need features so we can do a bit of feature engineering here. In particular I want to extract the Title of each passenger from the `Name` feature, a look at the data shows that the title \\\u0022Master\\\u0022 seems to be reserved for males under the age of 13. I\u0027d also expect there to be a correlation between the title \\\u0022Miss\\\u0022 and younger females.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022497a3b3a18071c57a3901f493b591eda4946b5fc\u0022, \u0022_cell_guid\u0022: \u00221b4024dd-dbfc-4fcd-9cd3-44d9964fd6e6\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022getTitle = function(name) {\\n    postcom = trimws(strsplit(as.character(name), \u0027,\u0027)[[1]][2])\\n    title = strsplit(postcom, \u0027 \u0027)[[1]][1]\\n    return (substr(title, 1, nchar(title)-1))\\n}\\n\\nfr_titanic$Title = as.factor(sapply(fr_titanic$Name, getTitle))\\nfr_titanic = fr_titanic[c(\\\u0022Survived\\\u0022, \\n                        \\\u0022Pclass\\\u0022,  \\n                        \\\u0022Name\\\u0022,\\n                        \\\u0022Title\\\u0022,\\n                        \\\u0022Sex\\\u0022, \\n                        \\\u0022Age\\\u0022, \\n                        \\\u0022SibSp\\\u0022, \\n                        \\\u0022Parch\\\u0022, \\n                        \\\u0022Ticket\\\u0022, \\n                        \\\u0022Fare\\\u0022, \\n                        \\\u0022Cabin\\\u0022, \\n                        \\\u0022Embarked\\\u0022,\\n                        \\\u0022Set\\\u0022)]\\n\\nhead(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022dd696b1db9766f66df21c322077b933858d9afd1\u0022, \u0022_cell_guid\u0022: \u00222a571552-becc-4a52-828c-291e454b38e1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022So far looks good! Let\u0027s use `table()` to get a better look.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00225f573a9c48184d3849d90cdbf5cc7d53c272bdf1\u0022, \u0022_cell_guid\u0022: \u0022be018dfb-8583-4268-a001-837d485852ca\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022table(fr_titanic$Title)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00221e022cee1f10f10464d2bc2cf9670e7f9c5a3e18\u0022, \u0022_cell_guid\u0022: \u002251a9c26c-84d0-44ab-9769-c39b13898732\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022There\u0027s a lot of special titles being used for a small number of passengers. Let\u0027s coerce them to common values so we only deal with the following subset of titles:\\n\\n* Mr\\n* Mrs\\n* Miss\\n* Master\\n\\nWe\u0027ll use the following mappings.\\n\\n* Dr, Rev, Major, Col, Jonkheer, Don, Sir, Capt -\u003e Mr\\n* Mlle, Ms -\u003e Miss\\n* Dona, Lady, Mme, th -\u003e Mrs\\n\\nI think there would be some amount of predictive power to these title if we had more data, but as it stands these honorifics just don\u0027t have enough entries to act as standalone features so we\u0027re merging them with the most appropriate alternate level.\\n\\nSince we\u0027re removing a lot of levels we have to use the `droplevels()` command to remove them from the feature within R.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022080c0d1fba46edf5fbb2f2328811582ede709ef8\u0022, \u0022_cell_guid\u0022: \u0022b4572c26-530d-4211-9d8c-44941ed3aa77\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022mr_alias = c(\u0027Dr\u0027, \u0027Rev\u0027, \u0027Major\u0027, \u0027Col\u0027, \u0027Jonkheer\u0027, \u0027Don\u0027, \u0027Sir\u0027, \u0027Capt\u0027)\\nmrs_alias = c(\u0027Dona\u0027, \u0027Lady\u0027, \u0027Mme\u0027, \u0027th\u0027)\\nmiss_alias = c(\u0027Mlle\u0027, \u0027Ms\u0027)\\n\\nfr_titanic$Title[which(fr_titanic$Title %in% mr_alias)] = \u0027Mr\u0027\\nfr_titanic$Title[which(fr_titanic$Title %in% mrs_alias)] = \u0027Mrs\u0027\\nfr_titanic$Title[which(fr_titanic$Title %in% miss_alias)] = \u0027Miss\u0027\\n\\nfr_titanic$Title = droplevels(fr_titanic$Title)\\nsummary(fr_titanic$Title)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022083e9f951e8d4cf384514d908de8d8ba9645ff0a\u0022, \u0022_cell_guid\u0022: \u00220dfba0c9-2b0b-4e6b-9f1f-357978fffa95\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Great! Now that\u0027s all done and we have what\u0027s hopefully a useful, additional feature for our Age random regression imputation. We can finally get started with our actual random regression to impute our missing `Age` values.\\n\\nFirst I\u0027m going to define a new dataframe which contains only the features we need to deal with to train our regression model, this means excluding `Name`, `Ticket`, `Cabin` as well as all our test data. We also have to exclude `Survived` because we need to impute missing values in the test set as well.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002205fa7474e0dab7b947c708e7e1f338e802e5c934\u0022, \u0022_cell_guid\u0022: \u00220081f9d9-717c-47bf-9163-eff981695bae\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022rr_train = subset(fr_titanic, select=-c(Survived, Name, Ticket, Cabin, Set))\\nrr_train = na.omit(rr_train) # Omits test data as Survived values are all NA\u0027s\\n\\nhead(rr_train)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002250db118563e8bd4bafde3c726f1d12bf947b534a\u0022, \u0022_cell_guid\u0022: \u00229eb7e2ea-aa5f-42ca-9024-44e7f3fe8582\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022lm.fit = lm(Age ~ ., data=rr_train)\\nsummary(lm.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225017dd181175aaf667a75f8207013dc356b52823\u0022, \u0022_cell_guid\u0022: \u00224bede0b2-fa0e-467e-ae5a-0fb2571fbd2d\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s take a quick look at these p-values. `Pclass` is a statistically significant feauture in predicting `Age`, boxplots are useful in investigate the nature of the relationship further.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022c1450515257bee063df352f8651ce0655857592d\u0022, \u0022_cell_guid\u0022: \u0022f28d249a-bd38-4ec8-81ef-4e98c4096f29\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022plot(as.factor(rr_train$Pclass), rr_train$Age, xlab=\\\u0022Passenger Class\\\u0022, ylab=\\\u0022Age\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00227f5559c1661380a9797ff7b57c4ad6503e6a52d2\u0022, \u0022_cell_guid\u0022: \u0022d990579c-2441-42a1-88d8-15a558666c67\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like first class passengers skew older which isn\u0027t suprising. `Title` is a significant feature too so our little bit of feature engineering has paid off! `Sex` has no significance in predicting `Age` which isn\u0027t particularly surprising. The number of siblings/spouses in `SibSp` is significant as well, my guess is that younger people tend to have a higher count as they likely have siblings on board. Another boxplot should help us determine this.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022bcbe4ea431b45c2ed1201a74d4316f322d0c4f16\u0022, \u0022_cell_guid\u0022: \u00222615dff2-2476-41aa-b93b-97328949944d\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022plot(as.factor(rr_train$SibSp), rr_train$Age, xlab=\\\u0022# siblings + spouses\\\u0022, ylab=\\\u0022Age\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f95c872c25fd9aee88dd98a29c27b3da75e9a6cf\u0022, \u0022_cell_guid\u0022: \u0022f43336f5-9d98-4069-8136-ff10d8f5f5b4\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Bingo, looks like that\u0027s exactly the trend. The last significant feature is `Embarked`, in particular if you embarked from location Q. To be honest I have no idea why, if you do know leave a comment because I\u0027m curious!\\n\\nLet\u0027s create a simpler regression model which excludes the insignificant features: `Sex`, `Parch` and `Fare`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002272d0b677a5b1934231f35d8f45430589c03e82d8\u0022, \u0022_cell_guid\u0022: \u002242f7b28b-a0e3-4367-808a-e603d258997f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022lm.fit = lm(Age ~ Pclass + Title + SibSp + Embarked, data=rr_train)\\n\\nsummary(lm.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00224783d9e9da2ebfdc5573b7d41771fb58fa29c88a\u0022, \u0022_cell_guid\u0022: \u0022a441fa69-ca32-48f5-85de-dd7e4e68dc5b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Now looking at our $R^2$ this definitely isn\u0027t the best `Age` predictor but remember this is just for imputation, effectively we\u0027re trying to maintain the relationships between `Age` and other variables which exist so as not to diffuse the strength of any patterns in the data when we build our actual Survival predictor. Other strategies like estimating a distribution then sampling from that randomly to fill missing values maintains the state of information we have about `Age`, but potentially weakens the patterns between `Age` and other features.\\n\\nFinally, let\u0027s do our imputation. But first I\u0027m going to see if there\u0027s any people with the title \\\u0022Master\\\u0022 that have missing ages, remember that title appears to be reserved for males under the age of 13. It\u0027ll be an interesting test to see if our imputed ages maintain that criteria.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022a5cbf9d15856ddfe373d9ddcb3699c7086c08e99\u0022, \u0022_cell_guid\u0022: \u00227d76e060-6b1f-4824-a308-36cfae54727b\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022missing_age_masters = which(fr_titanic$Title == \u0027Master\u0027 \u0026 is.na(fr_titanic$Age))\\nfr_titanic[missing_age_masters, ]\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002219186872062e278f531934e31fafc17377c841be\u0022, \u0022_cell_guid\u0022: \u0022c1f5822c-05a2-4092-8a7a-4b6aa3917fe8\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022set.seed(10) # this makes the kernel results reproducible\\n\\ndet_imputed = predict(lm.fit, fr_titanic[which(is.na(fr_titanic$Age)), ])\\nrandom_imputed = rnorm(length(det_imputed), det_imputed, abs(residuals(lm.fit)))\\n\\n# We need to round the values to integers and floor them at a value of 1\\ndet_imputed[which(det_imputed \u003c 0)] = 1\\ndet_imputed = round(det_imputed)\\n\\nrandom_imputed[which(random_imputed \u003c 0)] = 1\\nrandom_imputed = round(random_imputed)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022a79567bbf026e92746d66aacc909663b974bc235\u0022, \u0022_cell_guid\u0022: \u0022dd703cee-4383-4018-bd48-a0bfa141881b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s take a look at the original values vs the imputed values.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00222c1b227ae35a64c94203df044c79d4f3bb33f3a8\u0022, \u0022_cell_guid\u0022: \u002203de8754-2439-4b9f-ae18-62d4f6e90004\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022par(mfrow=c(3,1))\\nhist(rr_train$Age, breaks=10, freq=F)\\nhist(det_imputed, breaks=10, freq=F)\\nhist(random_imputed, breaks=10, freq=F)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002268a50c966ee27af627e2939ffeda4792f974b6fb\u0022, \u0022_cell_guid\u0022: \u0022bd4ed940-327b-4c5f-b7c8-6384b8b7257c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Under the assumption that the missing values are missing completely at random and with sufficient missing values, we would expect our histograms of the imputed values to be very similar to the original values. This seems to be what we\u0027re seeing here. It\u0027s also good to compare the deterministic imputations vs the random imputations, the deterministic imputations lie on the regression line by definition. This means that it assumes there\u0027s a deterministic relationship between the predictors and the target which is clearly not likely to be accurate. The random imputations take the deterministic imputations and adds an error term proportional to the residuals in the regression fit. Effectively we try and reintroduce appropriate variance in the imputed values.\\n\\nViolin plots really help us see this effect.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e1b4e6f76beed2cc4dca7d1d6870f0c5e2d9fec1\u0022, \u0022_cell_guid\u0022: \u0022c48c09b2-e39b-49a6-88a6-4e917ea9b68b\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(ggplot2)\\n\\nkde_mat = rbind(cbind(rr_train$Age, rep(\\\u0022Original\\\u0022, length(rr_train$Age))),\\n        cbind(det_imputed, rep(\\\u0022Deterministic Imputation\\\u0022, length(det_imputed))),\\n        cbind(random_imputed, rep(\\\u0022Randomised Imputation\\\u0022, length(random_imputed))))\\n\\nkde_df = data.frame(Age=as.numeric(kde_mat[,1]), Source=as.factor(kde_mat[,2]))\\n\\nggplot(kde_df, aes(x=Source, y=Age, fill=Source)) + geom_violin()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002259930c25aa670c4029729112c5a5181a2f1dc53e\u0022, \u0022_cell_guid\u0022: \u0022202491b7-176f-4c23-830c-ded2b4ae87aa\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s merge the imputed values back into our dataframe now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022a8d705a5fc654b1dc1bf109bba434a7d5144232a\u0022, \u0022_cell_guid\u0022: \u0022d8e90a16-2e94-4be4-92b2-beb1e0e869b0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Age[which(is.na(fr_titanic$Age))] = random_imputed\\nnaSummary(fr_titanic)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00229a1e1115b74ce253c707d3898dabf91c951a023d\u0022, \u0022_cell_guid\u0022: \u00220d87f31f-b8af-4e44-a062-36a824dcfa2c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Let\u0027s go back to the 4 passengers with the \\\u0022Master\\\u0022 title and missing ages now and see what the randomised imputations they received were.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00220dd0087b4ef49d9ccef2eee2592c1ce6cad18802\u0022, \u0022_cell_guid\u0022: \u00220c1fe54d-69fb-48f8-8bc0-ebe8b86938a2\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic[missing_age_masters,]\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00227cfcec17a7a86e3ddf700bcc65c4649d16c6aa46\u0022, \u0022_cell_guid\u0022: \u0022bee2e198-294a-45de-87dc-3844de00684e\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Remember we expected them to have an `Age` of less than 13 and we do see that, this is a good indication that our random regression imputation has succeeded in preserving relationships between Age and the other features in the dataset.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002253e16d6b178bfa893ff375459221b6f99114174d\u0022, \u0022_cell_guid\u0022: \u00228a5a9808-1ceb-4158-9193-c1a7578292d5\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022### Cabin\\n\\nLet\u0027s be practical, it\u0027s not really possible to impute values for `Cabin` given the nature of the data. Instead let\u0027s focus on transforming it into a useful feature in the feature engineering phase.\\n\\nFeature Engineering\\n===========\\n\\nCabin\\n-----\\n\\nSince we\u0027re missing most of our Cabin values the simplest strategy to see if this could be a useful feature would be to encode it as a simple binary variable, whether a Cabin is listed or not.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002217fa76f77ec08c5b6f1f304af0621d6fe01032f0\u0022, \u0022_cell_guid\u0022: \u00223c925e13-a0a7-4d9c-aafe-61e90bf1bd71\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(reshape2)\\n\\nfr_titanic$hasCabin = as.factor(!is.na(fr_titanic$Cabin))\\n\\n# Make a convenience feature which is directly descriptive\\nSurvived_Desc = ifelse(fr_titanic$Survived == 1, \\\u0022Survived\\\u0022, \\\u0022Died\\\u0022)\\n\\nfreq = table(fr_titanic$hasCabin, Survived_Desc)\\nfreq_df = as.data.frame.matrix(freq)\\n\\nfreq_df = data.frame(Cabin=row.names(freq_df), freq_df)\\nfreq_df = melt(freq_df, id.vars=\\\u0022Cabin\\\u0022)\\n\\nggplot(freq_df, aes(x=Cabin, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225cb47ff7809ef5ae9ceb9674baa177f666946e9f\u0022, \u0022_cell_guid\u0022: \u00229e9ff83e-f952-4911-8b64-3fbef5a6f09a\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Luckily for us `hasCabin` may actually has some decent predictive power, we can see that those with a listed cabin are far more likely to survive than those without. The next step I think here is to extract the deck out of the `cabin` for each passenger with a `cabin` value and see if there\u0027s predictive power associated with that.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022collapsed\u0022: true, \u0022_uuid\u0022: \u002285f28e92774e8fbc546fe900382fcce44e82767e\u0022, \u0022_cell_guid\u0022: \u0022d9fff799-8e42-4ea5-94e7-d949de7b76b7\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Deck = sapply(fr_titanic$Cabin, function(cabin) {\\n    substr(as.character(cabin), 1, 1)\\n})\\n\\nfr_titanic$Deck[which(is.na(fr_titanic$Deck))] = \\\u0022None\\\u0022\\nfr_titanic$Deck = as.factor(fr_titanic$Deck)\\n\\nsummary(fr_titanic$Deck)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00223d58862db59b360216feb04787db266a65debf3c\u0022, \u0022_cell_guid\u0022: \u0022ae5fc19a-7d85-4d04-99f1-01f5a3827612\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Since there\u0027s only one value for `T` we\u0027ll just coerce it into factor `None`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002297ef46e2c180b2b8dc480c52511c49b7d50c4102\u0022, \u0022_cell_guid\u0022: \u002292522a0d-c0a3-4ccb-a85a-942dd50ed916\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$Deck[which(fr_titanic$Deck == \u0027T\u0027)] = as.factor(\u0027None\u0027)\\nfr_titanic$Deck = droplevels(fr_titanic$Deck)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022140eefd90d16846f225dfbe819de8a91db190784\u0022, \u0022_cell_guid\u0022: \u00228bea4135-68b5-43fa-b665-3505be73c768\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022freq = table(fr_titanic$Deck, Survived_Desc)\\nfreq_df = as.data.frame.matrix(freq)\\nfreq_df = data.frame(Deck=row.names(freq_df), freq_df)\\n\\nfreq_df = melt(freq_df, id.vars=\\\u0022Deck\\\u0022)\\n\\nggplot(freq_df, aes(x=Deck, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002250d6c42b3a53f3fa05386a58b626e3464c1c2ee7\u0022, \u0022_cell_guid\u0022: \u0022eac6f99d-35d6-4b25-9aec-f9178a8e1662\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022## Tickets\\n\\nSince group tickets were available, we can introduce a new feature which guesses whether a person travelled in a group and then see if that has a relationship with survival rate.\\n\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00220a4e52bc3231b765f42dce517862aaf80be596a7\u0022, \u0022_cell_guid\u0022: \u0022f3ce3a14-22d2-4f0b-9a77-cdeb00359bd0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022inGroup = as.factor(duplicated(fr_titanic$Ticket))\\n\\nfreq_df = as.data.frame.matrix(table(inGroup, Survived_Desc))\\nfreq_df = data.frame(inGroup=row.names(freq_df), freq_df)\\n\\nfreq_df = melt(freq_df, id.vars=\\\u0022inGroup\\\u0022)\\n\\nggplot(freq_df, aes(x=inGroup, y=value)) + geom_bar(aes(fill = variable), position = \\\u0022dodge\\\u0022, stat=\\\u0022identity\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002257ff854cc8b5504babd71a45239ef11d648d486e\u0022, \u0022_cell_guid\u0022: \u0022d60bd2a1-a9b1-4036-b25e-563baf956a0d\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like if you\u0027re not in a group you are more likely to die than those who are not, so we can add this as a proper feature in our dataframe now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022937fa653a5463cf411d4e1ff0c63e03131632d15\u0022, \u0022_cell_guid\u0022: \u00227d4c840b-bca5-4211-a9e0-e6eef23b7b7f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$inGroup = inGroup\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022987f032835fb1204043fe5ad4896fc655179b3d3\u0022, \u0022_cell_guid\u0022: \u0022c9cef19b-5469-4bfe-833c-8019643b91e2\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022## Women and Children First!\\n\\nWe don\u0027t really have to worry about the \u0027woman\u0027 part seeing as that\u0027s already handled by the `Sex` feature. What we can investigate is whether there\u0027s any merit to introducing a new `Child` feature rather than just relying on ages. Or more generally binning the ages into a set of wider levels.\\n\\nFirst off let\u0027s plot the distribution of `Survival` vs `Age`.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00228e2d3fd84fc973daca1466414573620923264e81\u0022, \u0022_cell_guid\u0022: \u002202dc7fd9-bf8b-41bf-bae0-840bb6583a33\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = fr_titanic[which(fr_titanic$Set == \u0027train\u0027), ]\\n\\nuniq_ages = sort(unique(fr_train$Age))\\n\\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\\n    mean(fr_train[which(fr_train$Age == age), ]$Survived == 1)\\n})\\n\\nuniq_ages\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022ef83a47449d9c73978adb5f17fb39b76cdc4ffc5\u0022, \u0022_cell_guid\u0022: \u0022000be72f-43b4-4ca8-86ff-cd002845922b\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Looks like in the original data there was some fractional ages. Let\u0027s round these for simplicity, redo our survival rate calculation, and plot the results.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002287d66137832c1ac4e537cf6ff0bf8077e7315639\u0022, \u0022_cell_guid\u0022: \u0022cce2eb61-b72f-42a3-b419-2cbf540bf7e9\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train$Age = round(fr_train$Age)\\nuniq_ages = sort(unique(fr_train$Age))\\n\\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\\n    selection = fr_train[which(fr_train$Age == age), ]$Survived\\n    mean(selection == 1)\\n})\\n\\nage_surv_rate_df = data.frame(Age=uniq_ages, SurvivalRate=survival_rates_by_age)\\nggplot(age_surv_rate_df, aes(x=Age, y=SurvivalRate)) + geom_col()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022c1ddc9c4286db8b75f887ce8c0a07673ab53016b\u0022, \u0022_cell_guid\u0022: \u00220d0ee261-af6b-4411-a70b-ae87c8ad5a1c\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022There\u0027s actually a lot of noise in this plot and it\u0027s difficult to make out a clear trend because there\u0027s not many samples for each individual age. Instead let\u0027s bin the ages into groups of 5 and plot the average survival rate for each bin.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022929d1be0d49019c125f35e32799373d7283520e0\u0022, \u0022_cell_guid\u0022: \u0022642aec8d-54fa-4c2c-9592-cfbda5f37ec0\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022age_bins = split(uniq_ages, ceiling(seq_along(uniq_ages)/5))\\nbinned_surv_rate = sapply(age_bins, function(bin) {\\n    mean(age_surv_rate_df[which(age_surv_rate_df$Age %in% bin), ]$SurvivalRate)\\n})\\n\\nbinned_age_surv_df = data.frame(AgeBin=factor(names(age_bins), levels=names(age_bins)), SurvivalRate=binned_surv_rate)\\nggplot(binned_age_surv_df, aes(x=AgeBin, y=SurvivalRate)) + geom_col()\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f92e2f3b4d926d0a946fce77ac650e6cf9abf03c\u0022, \u0022_cell_guid\u0022: \u0022a53465d3-9e8d-42df-8631-354f1a3d3242\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022This gives us a much clearer picture of what\u0027s going on. First off we see that the first bin has the highest survival rate by far, this would correspond to passengers in the age range of 0 to 4. Children typically have a higher survival rate as we can see in bins 2, 3, and 4 which corresponds to ages 5-19. The last bin only contains one measurement of survival and should be effectively considered noise. After that there\u0027s no major differences in survival rate outside of an outlier in bin 11, but there\u0027s no logical explanation for this I can think of. Based on this info let\u0027s engineer a new three level categorical feature based on Age, the levels will be `Toddler` for ages 0-4, `Child` for ages 5-18, and Adult for ages 18+.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00222b3a532c5c8e95b1e3e3f6fc534dbf3306d04922\u0022, \u0022_cell_guid\u0022: \u0022dfebd5ae-6bac-4c2b-a156-b73947fdf403\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_titanic$AgeGroup = sapply(fr_titanic$Age, function(age) {\\n    if (age \u003c 5) {\\n        return (1)\\n    } else if (age \u003e= 5 \u0026\u0026 age \u003c 18) {\\n        return (2)\\n    } else {\\n        return (3)\\n    }\\n})\\n\\ntable(as.factor(fr_titanic$AgeGroup))\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022bfe231b5670f8e1b841561df60ae1b2590805848\u0022, \u0022_cell_guid\u0022: \u002200fbf301-2e75-4500-a47a-78a13c82157a\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022I think this should do in terms of feature engineering for now.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002227b3a624101d6e067e3a8f96ac8b196789cb76ae\u0022, \u0022_cell_guid\u0022: \u002210698e72-ebab-461c-92fc-eead14154424\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Predictions\\n======\\n\\nWe\u0027ll build both a `Support Vector Classifier` and a `Random Forest` model in this section, compare them, and choose the one that works best.\\n\\nSplit Train and Test Set\\n-----------------------\\n\\nFirst we split our dataframe back into the original train and test sets. Also clean up the data and remove the now unnecessary `Name`, `Ticket`, `Cabin` and `Set` variables as well as the `Survived` variable for the test set.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u002258d3f9cc5cab327e45490090e7d1b175f5a7f697\u0022, \u0022_cell_guid\u0022: \u002219771177-fc49-4d48-b039-e823a2a85c91\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022fr_train = fr_titanic[which(fr_titanic$Set == \u0027train\u0027),]\\nfr_test = fr_titanic[which(fr_titanic$Set == \u0027test\u0027),]\\n\\nfr_train = subset(fr_train, select=-c(Name, Ticket, Set, Cabin))\\nfr_test = subset(fr_test, select=-c(Name, Ticket, Set, Cabin, Survived))\\n\\nhead(fr_train)\\nstr(fr_train)\\nstr(fr_test)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022053350cbe42d34f2b900a5ec01348d6ea45292b0\u0022, \u0022_cell_guid\u0022: \u0022807af696-562c-41ce-b9ce-3d7d7c0200d5\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Support Vector Classifier\\n-------------------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022dfa1f4d9f98d51e20213da3d1b981d16c940ad40\u0022, \u0022_cell_guid\u0022: \u0022cdee7eb7-234e-439c-aa32-8cc671143533\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(e1071)\\n\\nset.seed(7)\\n\\ntuned = tune(svm, Survived ~ ., data=fr_train, kernel=\\\u0022linear\\\u0022, scale=TRUE, \\n             ranges=list(cost=seq(0.3, 0.6, length=20)))\\n\\nsummary(tuned)\\nsvm.fit = tuned$best.model\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u00225abed0ecc88a87b6013d6f7f112254ef6d57e3d6\u0022, \u0022_cell_guid\u0022: \u00225abd26b2-aacd-473a-bd3b-6b5aeab92cad\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Random Forest\\n------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022dd923f4d2c45a69c4e48b6e7a5dd2a365028ae43\u0022, \u0022_cell_guid\u0022: \u002221729e54-9d00-4453-9a3e-c73085856280\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022library(randomForest)\\n\\nset.seed(7)\\nrf.fit = randomForest(Survived ~ ., data=fr_train)\\nsummary(rf.fit$err.rate)\\n\\n# Thanks to Megan Risdal\u0027s excellent Titanic kernel for this little error rate graph\\nplot(rf.fit, ylim=c(0,0.36))\\nlegend(\u0027top\u0027, colnames(rf.fit$err.rate), col=1:3, fill=1:3, bty=\\\u0022n\\\u0022)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002267688780d9440b6648be1896c71b554ff336e10b\u0022, \u0022_cell_guid\u0022: \u0022fa8b1560-f7a5-4255-a3ed-d577d75171c1\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022The first thing to notice here is how much better we are at predicting death than survival. Remember the start of our dataset where we guessed we\u0027d be better at predicting who died than who survived, this seems to have taken effect but in reality this is also simply a consequence of how the Random Forest model works. It\u0027ll always perform much better on the bigger class.\\n\\nThe random forest model also slightly outperforms our support vector classifier, which had an error rate of 17.6% as estimated by the 10-fold cross validation. A convenient feature present in the randomForest object is the ability to plot importance measures. Handy as we can see if our feature engineering actually helped us.\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022c6d9f4be868d40055998402309d22ab11faa701b\u0022, \u0022_cell_guid\u0022: \u0022af4a34a8-a042-4cf4-85e1-dc6d1f5ce0ea\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022varImpPlot(rf.fit)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u0022f4f512a2c5cee41cfda063c56570bbd8aa5f45d2\u0022, \u0022_cell_guid\u0022: \u00229c4fe071-d725-4799-aa47-fe246f6195e8\u0022}, \u0022execution_count\u0022: 1}, {\u0022source\u0022: \u0022Unfortunately it looks like our inGroup and AgeGroup weren\u0027t very successful features, Title on the other hand did extremely well!\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u0022e8fa2aae9e9cb4507a3135f983ff7f4ae8fd6b25\u0022, \u0022_cell_guid\u0022: \u00220ecc7514-6e79-4cbb-b822-6aa03a03a7bc\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022Making our Prediction File\\n------------------------\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022markdown\u0022, \u0022metadata\u0022: {\u0022_uuid\u0022: \u00224e2e4dfac6de4b5f533229a6a4e5b89d30c2c135\u0022, \u0022_cell_guid\u0022: \u0022d5fb5ceb-c629-4ec1-827d-109286e3813f\u0022}, \u0022execution_count\u0022: null}, {\u0022source\u0022: \u0022rf.preds = predict(rf.fit, fr_test)\\nrf.submission = data.frame(PassengerId=names(rf.preds), Survived=rf.preds)\\nwrite.csv(rf.submission, file=\\\u0022rf_submission.csv\\\u0022, row.names=FALSE)\\n\\nsvm.preds = predict(svm.fit, fr_test)\\nsvm.submission = data.frame(PassengerId=names(svm.preds), Survived=svm.preds)\\nwrite.csv(svm.submission, file=\\\u0022svm_submission.csv\\\u0022, row.names=FALSE)\u0022, \u0022outputs\u0022: [], \u0022cell_type\u0022: \u0022code\u0022, \u0022metadata\u0022: {\u0022_execution_state\u0022: \u0022idle\u0022, \u0022collapsed\u0022: true, \u0022trusted\u0022: false, \u0022_uuid\u0022: \u002291dcb41bdfa2fea5f98e0ebf25954dcf619b8b70\u0022, \u0022_cell_guid\u0022: \u0022feb15285-8483-43b0-86ee-5838311c25cb\u0022}, \u0022execution_count\u0022: 1}], \u0022metadata\u0022: {\u0022language_info\u0022: {\u0022pygments_lexer\u0022: \u0022r\u0022, \u0022version\u0022: \u00223.4.1\u0022, \u0022codemirror_mode\u0022: \u0022r\u0022, \u0022file_extension\u0022: \u0022.r\u0022, \u0022mimetype\u0022: \u0022text/x-r-source\u0022, \u0022name\u0022: \u0022R\u0022}, \u0022kernelspec\u0022: {\u0022display_name\u0022: \u0022R\u0022, \u0022language\u0022: \u0022R\u0022, \u0022name\u0022: \u0022ir\u0022}}}","dateCreated":"2017-08-07T00:22:54.897Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e472896\u003c/disk_kb_free\u003e\u003cdocker_image_id\u003esha256:bef25c7a033d4d9b63f7c55773351f0ae5cd3f427554a5a8bfd47a8b85f9344e\u003c/docker_image_id\u003e\u003cdocker_image_name\u003ekaggle/rstats\u003c/docker_image_name\u003e\u003cexit_code\u003e0\u003c/exit_code\u003e\u003cfailure_message /\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e57.4539694972336\u003c/run_time_seconds\u003e\u003csucceeded\u003eTrue\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageDigest":null,"dockerImageId":"sha256:bef25c7a033d4d9b63f7c55773351f0ae5cd3f427554a5a8bfd47a8b85f9344e","dockerImageName":"kaggle/rstats","diskKbFree":472896,"failureMessage":"","exitCode":0,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":57.4539694972336,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":true,"wasKilled":false},"outputFilesTotalSizeBytes":684631,"dockerImageVersionId":null,"usedCustomDockerImage":false},"author":{"id":1155483,"displayName":"athi","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"athi94","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1155483-kg.jpg","profileUrl":"/athi94","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/athi94/a-beginner-s-stab-at-titanic","collaborators":{"owner":{"userId":1155483,"groupId":null,"groupMemberCount":null,"profileUrl":"/athi94","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1155483-kg.jpg","name":"athi","slug":"athi94","userTier":1,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022[NbConvertApp] Converting notebook __notebook_source__.ipynb to html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.6949263326823711\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed (u\u0027execution_count\u0027, u\u0027outputs\u0027 were unexpected)\\n\\nFailed validating u\u0027additionalProperties\u0027 in markdown_cell:\\n\\nOn instance[u\u0027cells\u0027][0]:\\n{u\u0027cell_type\u0027: u\u0027markdown\u0027,\\n u\u0027execution_count\u0027: None,\\n u\u0027metadata\u0027: {u\u0027_cell_guid\u0027: u\u0027d481a061-7128-4b58-9581-23a484164252\u0027,\\n               u\u0027_uuid\u0027: u\u002710efd95221ab0ee97dd2d05e6a869e2ded79627d\u0027},\\n u\u0027outputs\u0027: [\u0027...0 outputs...\u0027],\\n u\u0027source\u0027: u\\\u0022Introduction\\\\n=========\\\\n\\\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\\\u0022}\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.699592214077711\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Writing 315587 bytes to __results__.html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.8989274557679892\n}{\n  \u0022data\u0022: \u0022[NbConvertApp] Converting notebook __notebook_source__.ipynb to notebook\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.5689013376832008\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed (u\u0027outputs\u0027, u\u0027execution_count\u0027 were unexpected)\\n\\nFailed validating u\u0027additionalProperties\u0027 in markdown_cell:\\n\\nOn instance[u\u0027cells\u0027][0]:\\n{u\u0027cell_type\u0027: u\u0027markdown\u0027,\\n u\u0027execution_count\u0027: None,\\n u\u0027metadata\u0027: {u\u0027_cell_guid\u0027: u\u0027d481a061-7128-4b58-9581-23a484164252\u0027,\\n               u\u0027_uuid\u0027: u\u002710efd95221ab0ee97dd2d05e6a869e2ded79627d\u0027},\\n u\u0027outputs\u0027: [\u0027...0 outputs...\u0027],\\n u\u0027source\u0027: u\\\u0022Introduction\\\\n=========\\\\n\\\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\\\u0022}\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.5725664794445038\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Executing notebook with kernel: ir\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.5819856449961662\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed (u\u0027outputs\u0027, u\u0027execution_count\u0027 were unexpected)\\n\\nFailed validating u\u0027additionalProperties\u0027 in markdown_cell:\\n\\nOn instance[u\u0027cells\u0027][0]:\\n{u\u0027cell_type\u0027: u\u0027markdown\u0027,\\n u\u0027execution_count\u0027: None,\\n u\u0027metadata\u0027: {u\u0027_cell_guid\u0027: u\u0027d481a061-7128-4b58-9581-23a484164252\u0027,\\n               u\u0027_uuid\u0027: u\u002710efd95221ab0ee97dd2d05e6a869e2ded79627d\u0027},\\n u\u0027outputs\u0027: [\u0027...0 outputs...\u0027],\\n u\u0027source\u0027: u\\\u0022Introduction\\\\n=========\\\\n\\\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\\\u0022}\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 28.659395905211568\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Writing 576453 bytes to __notebook__.ipynb\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 28.873741829767823\n}{\n  \u0022data\u0022: \u0022[NbConvertApp] Converting notebook __notebook__.ipynb to html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.6503103952854872\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed (u\u0027execution_count\u0027, u\u0027outputs\u0027 were unexpected)\\n\\nFailed validating u\u0027additionalProperties\u0027 in markdown_cell:\\n\\nOn instance[u\u0027cells\u0027][0]:\\n{u\u0027cell_type\u0027: u\u0027markdown\u0027,\\n u\u0027execution_count\u0027: None,\\n u\u0027metadata\u0027: {u\u0027_cell_guid\u0027: u\u0027d481a061-7128-4b58-9581-23a484164252\u0027,\\n               u\u0027_uuid\u0027: u\u002710efd95221ab0ee97dd2d05e6a869e2ded79627d\u0027},\\n u\u0027outputs\u0027: [\u0027...0 outputs...\u0027],\\n u\u0027source\u0027: u\\\u0022Introduction\\\\n=========\\\\n\\\\nHi all, this is my first Kaggle kernel and the first data science problem I\u0027ve tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I\u0027m sure there are a few!\\\u0022}\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.6628963835537434\n},{\n  \u0022data\u0022: \u0022/usr/local/lib/python2.7/dist-packages/nbconvert/filters/datatypefilter.py:41: UserWarning: Your element with mimetype(s) [] is not able to be represented.\\n  mimetypes=output.keys())\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.8369093425571918\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Support files will be in __results___files/\\n[NbConvertApp] Making directory __results___files\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.8713474795222282\n},{\n  \u0022data\u0022: \u0022[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Making directory __results___files\\n[NbConvertApp] Writing 365167 bytes to __results__.html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 1.8749254178255796\n}","outputFiles":[{"ownerInfo":null,"kernelVersionOutputFileId":5195006,"kernelVersionId":1408753,"kernelId":327072,"size":0,"fullPath":"Rplot001.png","previewUrl":"/kernels/preview.json/1408753/1b408102-22b9-a578-02f7-7a0a74ea6b54/Rplot001.png","downloadUrl":"https://www.kaggleusercontent.com/kf/1408753/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..JyVTUkI7n2FC4LE0eHwbgQ.-KpV5H9M7F9sY_GN8ySa-YqCGYGcP2Bp90iiWR0Ff3duzqZ_w53w6MWeyFuDdaLoTmnIiQoLH0coQWyxhXdrMsWPCKogC1c8WmrjFxEFPjgaU0hmOPO8XqzHIa__IakVHGCbL4B2jr-6vnCcmeng6g.t6nenf_QX4FX-Hkqd7U77g/Rplot001.png","fileType":".png","contentLength":7578,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"kernelOutputFile","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"Rplot001.png","description":null},{"ownerInfo":null,"kernelVersionOutputFileId":5195018,"kernelVersionId":1408753,"kernelId":327072,"size":0,"fullPath":"rf_submission.csv","previewUrl":"/kernels/preview.json/1408753/1b408102-22b9-a578-02f7-7a0a74ea6b54/rf_submission.csv","downloadUrl":"https://www.kaggleusercontent.com/kf/1408753/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..xSXnoFizCCXYOY7Ve0-NSA.eIDUb3LEz4lh8l3WGfeRV7QDJgbgoHRjQi8ByphPO5fWUwLpKBlu96GtmOVbUUngxputrincccGbqhEyusJU1UJSuNcf4TBRf44V4mv6BPLgo0YE5SzFftjHTHmyViFEz72WcR6qNzDa4WThfycFmA.nHqfzMCDtW0JfCSRza3M-g/rf_submission.csv","fileType":".csv","contentLength":4515,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"kernelOutputFile","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"rf_submission.csv","description":null},{"ownerInfo":null,"kernelVersionOutputFileId":5195019,"kernelVersionId":1408753,"kernelId":327072,"size":0,"fullPath":"svm_submission.csv","previewUrl":"/kernels/preview.json/1408753/1b408102-22b9-a578-02f7-7a0a74ea6b54/svm_submission.csv","downloadUrl":"https://www.kaggleusercontent.com/kf/1408753/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..XvCv7OlapQNw8DjmJH2M8Q.Nc2NeUsjC1dMaHpAmuDQfYe14BQkXCVaIfE_fSXECr5irmOZSE2oDQ3uElyWvngUh-p4MiVzTY4lBt0k0MBp_ELVbPZML7fZOqB9LCrjL7l4CWT69jYl3ZfOlDgesm5j0zq593faCmpocDr7EfA-ow.E8j6YrOWdisfvPnkSQ7GYQ/svm_submission.csv","fileType":".csv","contentLength":4515,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"kernelOutputFile","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"svm_submission.csv","description":null}],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":327072,"kernelVersionId":1408753,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.._uhWO7fvk6U6gP25iM9dUA.q1c1BDwl2v_OVhr5ISyyYKd9ZhAG23OP7I4eGlAEFhWi8tqEpmZISWKGvlKMcO9YaeYIaokCrtiHw957MC_xFty0NIpW3dDwe6QyoVeL3rcWAfJslP6_Mx1fa4ciI8I9P1gw8aaoGz7KfjXFW_QaRErnowUG5y09dibFKGMWbGzpT08uDepWhZmvTsQO9pbSR050AeuEuX1B5_n47LY8keZwtDZrZi1lzrVX5JyHOjy9-H8gZ2oZebzC7g_ZEk9Ju5vL-KZLrXej1oRMvsS_kFa98NIjZlmT0Ys8WIr-t2Dlyet9TE_6l2jqfRkEuTFedhWbffpNSdxgqwCx5keopaZtNaqoVNXnykOlC0YFPixReoLVMlEBeo3ZRzRCERqx6WRMQn4yggBATUKeeyZkF5nxLACQrU8MW7hpq_oGo_z__6Zgoz1y_J6gNAZmzvvfSRnixKpYH_T1Moh0VNLEinpoYggqrtbhJU4DidqomxPmibXEUujjlpiNGnbXNj-Xl6HZ5JZHHNNo5GfUc0Et5uREUp_9cXXbVxP7qLNTMjItCcf5vNSBGGnVjoaE7tlZeNLsKzDcB8eFSfe8SXd1xAGOnbA52YCZdRliWLvBBFc.NSZi7ZImn8ssJCmoWPaZtQ","scope":"athi94/a-beginner-s-stab-at-titanic"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","sourceUrl":"/c/titanic","slug":"titanic","lastUpdated":"2012-09-28T21:13:33.55Z","overview":"Start here! Predict survival on the Titanic and get familiar with ML basics","sourceType":"competition","sourceVersionType":null,"sourceId":3136,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":"text/html","deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":26502,"dataset":null,"competition":{"competitionId":3136,"dataviewToken":null,"scope":"c/titanic"},"kernel":null,"previewsDisabled":true},"type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"id":63842,"blobFileId":37991,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/gender_submission.csv","creationDate":"2017-02-01T01:49:18Z","isDummy":false,"size":3258,"fullPath":"../input/gender_submission.csv","previewUrl":"kernels/competition-preview/3136?relativePath=gender_submission.csv","downloadUrl":"/c/titanic/download/gender_submission.csv","fileType":".csv","contentLength":3258,"contentType":"text/csv","contentMD5":"MNEHO5ZKXYFUMexgOg3jUw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n"},{"order":1,"originalType":"","type":"boolean","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"gender_submission.csv","description":"892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,0\n901,0\n902,0\n903,0\n904,1\n905,0a\n906,1\n907,0\n908,0\n909,0\n910,0\n911,0\n912,1\n913,0\n914,0\n915,0\n916,1\n917,0\n918,0\n919,0\n920,0\n921,0\n922,0\n923,0\n924,0\n925,0\n926,1\n927,0\n928,0\n929,0\n930,0\n931,1\n932,0\n933,0\n934,0\n935,0\n936,1\n937,0\n938,0\n939,0\n940,1\n941,0\n942,1\n943,0\n944,0\n945,1\n946,0\n947,0\n948,0\n949,0\n950,0\n951,1\n952,0\n953,0\n954,0\n955,0\n956,1\n957,0\n958,0\n959,0\n960,0\n961,1\n962,\n963,0\n964,0\n965,0\n966,1\n967,1\n968,0\n969,0\n970,0\n971,0\n972,0\n973,1\n974,0\n975,0\n976,0\n977,0\n978,0\n979,0\n980,0\n981,0\n982,0\n983,0\n984,0\n985,0\n986,0\n987,0\n988,1\n989,0\n990,0\n991,0\n992,1\n993,0\n994,0\n995,0\n996,0\n997,0\n998,0\n999,0\n1000,0\n1001,0\n1002,0\n1003,0\n1004,0\n1005,0\n1006,1\n1007,0\n1008,0\n1009,0\n1010,1\n1011,0\n1012,0\n1013,0\n1014,1\n1015,0\n1016,0\n1017,0\n1018,0\n1019,0\n1020,0\n1021,0\n1022,0\n1023,0\n1024,0\n1025,0\n1026,0\n1027,0\n1028,0\n1029,0\n1030,0\n1031,0\n1032,0\n1033,1\n1034,1\n1035,0\n1036,0\n1037,0\n1038,1\n1039,0\n1040,0\n1041,0\n1042,1\n1043,0\n1044,0\n1045,0\n1046,0\n1047,0\n1048,1\n1049,0\n1050,0\n1051,0\n1052,0\n1053,0\n1054,0\n1055,0\n1056,0\n1057,0\n1058,1\n1059,0\n1060,0\n1061,0\n1062,0\n1063,0\n1064,0\n1065,0\n1066,0\n1067,0\n1068,0\n1069,1\n1070,0\n1071,1\n1072,0\n1073,1\n1074,1\n1075,0\n1076,1\n1077,0\n1078,0\n1079,0\n1080,1\n1081,0\n1082,0\n1083,0\n1084,0\n1085,0\n1086,0\n1087,0\n1088,1\n1089,0\n1090,0\n1091,0\n1092,0\n1093,0\n1094,1\n1095,0\n1096,0\n1097,0\n1098,0\n1099,0\n1100,0\n1101,0\n1102,0\n1103,0\n1104,1\n1105,0\n1106,0\n1107,0\n1108,0\n1109,1\n1110,1\n1111,0\n1112,0\n1113,0\n1114,0\n1115,0\n1116,0\n1117,0\n1118,0\n1119,0\n1120,0\n1121,0\n1122,1\n1123,0\n1124,0\n1125,0\n1126,1\n1127,0\n1128,1\n1129,0\n1130,0\n1131,1\n1132,0\n1133,0\n1134,1\n1135,0\n1136,0\n1137,1\n1138,0\n1139,0\n1140,0\n1141,0\n1142,0\n1143,0\n1144,1\n1145,0\n1146,0\n1147,0\n1148,0\n1149,0\n1150,0\n1151,0\n1152,0\n1153,0\n1154,0\n1155,0\n1156,0\n1157,0\n1158,0\n1159,0\n1160,0\n1161,0\n1162,1\n1163,0\n1164,1\n1165,0\n1166,0\n1167,0\n1168,0\n1169,0\n1170,0\n1171,0\n1172,0\n1173,0\n1174,0\n1175,0\n1176,0\n1177,0\n1178,0\n1179,1\n1180,0\n1181,0\n1182,0\n1183,0\n1184,0\n1185,1\n1186,0\n1187,0\n1188,0\n1189,0\n1190,1\n1191,0\n1192,0\n1193,0\n1194,0\n1195,0\n1196,0\n1197,0\n1198,1\n1199,0\n1200,1\n1201,0\n1202,0\n1203,0\n1204,0\n1205,0\n1206,1\n1207,0\n1208,1\n1209,0\n1210,0\n1211,0\n1212,0\n1213,0\n1214,0\n1215,0\n1216,1\n1217,0\n1218,0\n1219,1\n1220,0\n1221,0\n1222,0\n1223,0\n1224,0\n1225,0\n1226,0\n1227,0\n1228,0\n1229,0\n1230,0\n1231,0\n1232,0\n1233,0\n1234,1\n1235,1\n1236,0\n1237,0\n1238,0\n1239,0\n1240,0\n1241,0\n1242,1\n1243,0\n1244,1\n1245,1\n1246,0\n1247,0\n1248,1\n1249,0\n1250,0\n1251,0\n1252,1\n1253,0\n1254,0\n1255,0\n1256,1\n1257,1\n1258,0\n1259,0\n1260,0\n1261,0\n1262,0\n1263,1\n1264,0\n1265,0\n1266,1\n1267,1\n1268,0\n1269,0\n1270,1\n1271,0\n1272,0\n1273,0\n1274,0\n1275,0\n1276,0\n1277,1\n1278,0\n1279,0\n1280,0\n1281,0\n1282,1\n1283,0\n1284,0\n1285,0\n1286,0\n1287,1\n1288,0\n1289,1\n1290,0\n1291,0\n1292,1\n1293,0\n1294,0\n1295,1\n1296,0\n1297,0\n1298,0\n1299,1\n1300,0\n1301,0\n1302,0\n1303,1\n1304,0\n1305,0\n1306,1\n1307,0\n1308,0\n1309,0"},{"id":63841,"blobFileId":2613,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/test.csv","creationDate":"2013-06-28T13:40:24.227Z","isDummy":false,"size":28629,"fullPath":"../input/test.csv","previewUrl":"kernels/competition-preview/3136?relativePath=test.csv","downloadUrl":"/c/titanic/download/test.csv","fileType":".csv","contentLength":28629,"contentType":"text/csv","contentMD5":"dTO4Lq5LWCYQy9aKpjawFw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"1"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"1"},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"the name of the passenger"},{"order":3,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":null},{"order":4,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":null},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"of siblings / spouses aboard the Titanic"},{"order":6,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"of parents / children aboard the Titanic"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":"Ticket number"},{"order":8,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":"Passenger fare"},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":"Cabin number"},{"order":10,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"Port of Embarkation"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"test.csv","description":"test data to check the accuracy of the model created\n"},{"id":63840,"blobFileId":2307,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/train.csv","creationDate":"2013-06-28T13:40:25.23Z","isDummy":false,"size":61194,"fullPath":"../input/train.csv","previewUrl":"kernels/competition-preview/3136?relativePath=train.csv","downloadUrl":"/c/titanic/download/train.csv","fileType":".csv","contentLength":61194,"contentType":"text/csv","contentMD5":"IwnMXwR4Ltm7YBbZ9OOBzw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":891},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"type should be integers"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"Survived or Not "},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"Class of Travel"},{"order":3,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"Name of Passenger"},{"order":4,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":"Gender"},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":"Age of Passengers"},{"order":6,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"Number of Sibling/Spouse aboard"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"Number of Parent/Child aboard"},{"order":8,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":null},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":null},{"order":10,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":null},{"order":11,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"train.csv","description":"contains data \n"}],"name":"Titanic: Machine Learning from Disaster","description":"\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe data has been split into two groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etraining set (train.csv)\u003c/li\u003e\n\u003cli\u003etest set (test.csv)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cb\u003e The training set \u003c/b\u003eshould be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use \u003ca href=\u0022https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\u0022 target=\u0022_blank\u0022\u003e feature engineering \u003c/a\u003eto create new features.\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eThe test set \u003c/b\u003eshould be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\u003c/p\u003e\n\u003cp\u003eWe also include \u003cb\u003egender_submission.csv\u003c/b\u003e, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\u003c/p\u003e\n\u003ch3\u003eData Dictionary\u003c/h3\u003e\n\u003ctable style=\u0022width: 100%;\u0022\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003cth\u003e\u003cb\u003eVariable\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eDefinition\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eKey\u003c/b\u003e\u003c/th\u003e\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esurvival\u003c/td\u003e\n\u003ctd\u003eSurvival\u003c/td\u003e\n\u003ctd\u003e0 = No, 1 = Yes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epclass\u003c/td\u003e\n\u003ctd\u003eTicket class\u003c/td\u003e\n\u003ctd\u003e1 = 1st, 2 = 2nd, 3 = 3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esex\u003c/td\u003e\n\u003ctd\u003eSex\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAge\u003c/td\u003e\n\u003ctd\u003eAge in years\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esibsp\u003c/td\u003e\n\u003ctd\u003e# of siblings / spouses aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eparch\u003c/td\u003e\n\u003ctd\u003e# of parents / children aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eticket\u003c/td\u003e\n\u003ctd\u003eTicket number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003efare\u003c/td\u003e\n\u003ctd\u003ePassenger fare\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecabin\u003c/td\u003e\n\u003ctd\u003eCabin number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eembarked\u003c/td\u003e\n\u003ctd\u003ePort of Embarkation\u003c/td\u003e\n\u003ctd\u003eC = Cherbourg, Q = Queenstown, S = Southampton\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eVariable Notes\u003c/h3\u003e\n\u003cp\u003e\u003cb\u003epclass\u003c/b\u003e: A proxy for socio-economic status (SES)\u003cbr /\u003e 1st = Upper\u003cbr /\u003e 2nd = Middle\u003cbr /\u003e 3rd = Lower\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eage\u003c/b\u003e: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003esibsp\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Sibling = brother, sister, stepbrother, stepsister\u003cbr /\u003e Spouse = husband, wife (mistresses and fiancés were ignored)\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eparch\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Parent = mother, father\u003cbr /\u003e Child = daughter, son, stepdaughter, stepson\u003cbr /\u003e Some children travelled only with a nanny, therefore parch=0 for them.\u003c/p\u003e"}],"versions":[{"id":1408753,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"R","lastRunTime":"2017-08-07T00:22:54.897Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":2,"linesInsertedFromPrevious":2,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:bef25c7a033d4d9b63f7c55773351f0ae5cd3f427554a5a8bfd47a8b85f9344e","dockerImageName":"kaggle/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":57.4539694972336,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"A Beginner\u0027s  Stab At Titanic","url":"/athi94/a-beginner-s-stab-at-titanic?scriptVersionId=1408753","versionNumber":2,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":1396170,"kernelVersionId":null,"isForkParent":false,"isNotebook":true,"languageName":"R","lastRunTime":"2017-08-02T07:41:47.307Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":405,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:bef25c7a033d4d9b63f7c55773351f0ae5cd3f427554a5a8bfd47a8b85f9344e","dockerImageName":"kaggle/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":1111.44836071704,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"A Beginner\u0027s  Stab At Titanic","url":"/athi94/a-beginner-s-stab-at-titanic?scriptVersionId=1396170","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null}],"categories":{"categories":[],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/1408753","submission":null,"menuLinks":[{"href":"/athi94/a-beginner-s-stab-at-titanic/notebook","text":"Notebook","title":"Notebook","tab":"notebook","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/data","text":"Data","title":"Data","tab":"data","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/output","text":"Output","title":"Output","tab":"output","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/comments","text":"Comments","title":"Comments","tab":"comments","count":0,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/versions","text":"Versions","title":"Versions","tab":"versions","count":2,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/athi94/a-beginner-s-stab-at-titanic/forks","text":"Forks","title":"Forks","tab":"forks","count":4,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/1408753","text":"Fork Notebook","title":"Fork Notebook","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":"kernels","reportEventType":"anonymousKernelForkCreation"},"voteButton":{"totalVotes":5,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=327072","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/948516-gr.jpg","displayName":"Lucian Maly","profileUrl":"/luckylittle","tier":"Novice","tierInt":0,"userId":948516,"userName":"luckylittle"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1020983-kg.png","displayName":"Oscar Takeshita","profileUrl":"/pliptor","tier":"Expert","tierInt":2,"userId":1020983,"userName":"pliptor"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"Kevin Tham","profileUrl":"/kevintham","tier":"Novice","tierInt":0,"userId":1121088,"userName":"kevintham"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1155483-kg.jpg","displayName":"athi","profileUrl":"/athi94","tier":"Contributor","tierInt":1,"userId":1155483,"userName":"athi94"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1203952-kg.jpg","displayName":"Cole Hickerson","profileUrl":"/colehickerson","tier":"Novice","tierInt":0,"userId":1203952,"userName":"colehickerson"}],"currentUserInfo":null,"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"Titanic: Machine Learning from Disaster","parentUrl":"/c/titanic","thumbnailImageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"simplifiedViewer":false,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="/athi94/a-beginner-s-stab-at-titanic" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL8NVW77BiyiZO1A-S6sqjs6aQpbyyXZ2aLVdmvrFbLgfAJknjo03e7qY0l3JfE5qtGe_zQdim4DAShiogR8MkvsJWXdrkXOvwGajrbrpoIp8--i7bUeGGOY-61wuYmjspg" /></form>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async crossorigin="anonymous" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>&copy; 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="/team">Our Team</a>
            <a href="/terms">Terms</a>
            <a href="/privacy">Privacy</a>
            <a href="/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>




</body>
</html>
