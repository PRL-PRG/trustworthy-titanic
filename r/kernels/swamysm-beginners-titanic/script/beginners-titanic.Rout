
R version 3.6.1 (2019-07-05) -- "Action of the Toes"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> ## ---- message = FALSE------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ## Load all the library required one by one
> 
> library('ggplot2') 
Warning message:
package ‘ggplot2’ was built under R version 3.6.2 
> library('caret') 
Loading required package: lattice
> library('dplyr') 

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

Warning message:
package ‘dplyr’ was built under R version 3.6.2 
> library('randomForest') 
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:dplyr’:

    combine

The following object is masked from ‘package:ggplot2’:

    margin

> library(rpart)
> library(rpart.plot)
> library(car)
Loading required package: carData

Attaching package: ‘car’

The following object is masked from ‘package:dplyr’:

    recode

Warning messages:
1: package ‘car’ was built under R version 3.6.2 
2: package ‘carData’ was built under R version 3.6.2 
> library(e1071)
> 
> 
> ##Lets Load raw data in the orginal form by setting stringsAsFactors = F
> 
> train.tit <- read.csv('../input/train.csv', stringsAsFactors = F)
> test.tit  <- read.csv('../input/test.csv', stringsAsFactors = F)
> test.tit$Survived <- NA
> 
> ##Combine both test and train
> full_titanic <- rbind(train.tit, test.tit)
> 
> ##Check the structure
> str(full_titanic)
'data.frame':	1309 obs. of  12 variables:
 $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...
 $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...
 $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...
 $ Name       : chr  "Braund, Mr. Owen Harris" "Cumings, Mrs. John Bradley (Florence Briggs Thayer)" "Heikkinen, Miss. Laina" "Futrelle, Mrs. Jacques Heath (Lily May Peel)" ...
 $ Sex        : chr  "male" "female" "female" "female" ...
 $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...
 $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...
 $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...
 $ Ticket     : chr  "A/5 21171" "PC 17599" "STON/O2. 3101282" "113803" ...
 $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...
 $ Cabin      : chr  "" "C85" "" "C123" ...
 $ Embarked   : chr  "S" "C" "S" "S" ...
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###is there any Missing obesrvation
> colSums(is.na(full_titanic))
PassengerId    Survived      Pclass        Name         Sex         Age 
          0         418           0           0           0         263 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          0           0           0           1           0           0 
> 
> ####Empty data
> colSums(full_titanic=='')
PassengerId    Survived      Pclass        Name         Sex         Age 
          0          NA           0           0           0          NA 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          0           0           0          NA        1014           2 
> 
> ##Summary shows, Age missing 263 value, Cabin too having lots of missing value..will look into them later in exploratory analysis nd Embarked missing 2
> 
> ###Lets replace Embarked by blank
> 
> table(full_titanic$Embarked)

      C   Q   S 
  2 270 123 914 
> full_titanic$Embarked[full_titanic$Embarked==""]="S"
> table(full_titanic$Embarked)

  C   Q   S 
270 123 916 
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ###Check the length and see how many varibles of then we can move to factor for our analysis
> 
> apply(full_titanic,2, function(x) length(unique(x)))
PassengerId    Survived      Pclass        Name         Sex         Age 
       1309           3           3        1307           2          99 
      SibSp       Parch      Ticket        Fare       Cabin    Embarked 
          7           8         929         282         187           3 
> 
> 
> ###will convert the below varible into factor for ananlysis
> 
> cols=c("Survived","Pclass","Sex","Embarked")
> for (i in cols){
+   full_titanic[,i]=as.factor(full_titanic[,i])
+ }
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> ## Hypothesis is that,  Rich folks survival much better than poor folks, Does any diffrence in Titanic?  
> 
> ###Take a look into Visualization with P class which is the best proxy for Rich and Poor  
> 
> ggplot(full_titanic[1:891,],aes(x = Pclass,fill=factor(Survived))) +
+ geom_bar() +
+ ggtitle("Pclass v/s Survival Rate")+
+ xlab("Pclass") +
+ ylab("Total Count") +
+ labs(fill = "Survived")  
> 
> ##No diffrences in a the Titanic too, First class Survival rate is far more better than the 3rd class  
> ##No doubt Rich peope have better Survival rate than the poor
> 
> # Visualize the 3-way relationship of sex, pclass, and survival
> ggplot(full_titanic[1:891,], aes(x = Sex, fill = Survived)) +
+ geom_bar() +
+ facet_wrap(~Pclass) + 
+ ggtitle("3D View of sex, pclass, and survival") +
+ xlab("Sex") +
+ ylab("Total Count") +
+ labs(fill = "Survived")
> 
> ##In the all the class Female Survival rate is better than Men
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> head(full_titanic$Name)
[1] "Braund, Mr. Owen Harris"                            
[2] "Cumings, Mrs. John Bradley (Florence Briggs Thayer)"
[3] "Heikkinen, Miss. Laina"                             
[4] "Futrelle, Mrs. Jacques Heath (Lily May Peel)"       
[5] "Allen, Mr. William Henry"                           
[6] "Moran, Mr. James"                                   
> ##Lets extract the title and check if we have predictive power in that
> names <- full_titanic$Name
> title <-  gsub("^.*, (.*?)\\..*$", "\\1", names)
> 
> full_titanic$title <- title
> 
> table(title)
title
        Capt          Col          Don         Dona           Dr     Jonkheer 
           1            4            1            1            8            1 
        Lady        Major       Master         Miss         Mlle          Mme 
           1            2           61          260            2            1 
          Mr          Mrs           Ms          Rev          Sir the Countess 
         757          197            2            8            1            1 
> 
> ###MISS, Mrs Master, Mr are takimg more numbers
> 
> ###Better to group Other titles into bigger basket by checking gender and survival rate to aviod any overfitting
> 
> 
> full_titanic$title[full_titanic$title == 'Mlle']        <- 'Miss' 
> full_titanic$title[full_titanic$title == 'Ms']          <- 'Miss'
> full_titanic$title[full_titanic$title == 'Mme']         <- 'Mrs' 
> full_titanic$title[full_titanic$title == 'Lady']          <- 'Miss'
> full_titanic$title[full_titanic$title == 'Dona']          <- 'Miss'
> 
> ## Iam afraid creating a new varible with small data can causes a overfit
> ## However, My thinking is that combining below feauter into orginl variable may loss some predictive power as they are all army folks, doctor and nobel peoples 
> 
> full_titanic$title[full_titanic$title == 'Capt']        <- 'Officer' 
> full_titanic$title[full_titanic$title == 'Col']        <- 'Officer' 
> full_titanic$title[full_titanic$title == 'Major']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Dr']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Rev']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Don']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Sir']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'the Countess']   <- 'Officer'
> full_titanic$title[full_titanic$title == 'Jonkheer']   <- 'Officer'
> 
> 
> # Lets check who among Mr, Master, Miss hving a better survival rate
>  ggplot(full_titanic[1:891,],aes(x = title,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Title V/S Survival rate")+
+   xlab("Title") +
+   ylab("Total Count") +
+   labs(fill = "Survived") 
> 
> ##In the titanic you are a Mr then there is less chance of survival, Miss and Mrs having beteer survival rate then Master and Officer 
> 
> 
> ### Visualize the 3-way of relationship of Title, Pclass, and Survival
> 
> ggplot(full_titanic[1:891,], aes(x = title, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~Pclass) + 
+   ggtitle("3-way of relationship of Title, Pclass, and Survival") +
+   xlab("Title") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ##Master in 1st and 2nd class has 100% Survival where has Mrs and Miss having 90% chance of Survival in 1st and 2nd class 
> ##Note that Title is alwayes relating with Age except few cases, So I will use title in place of instted of missing vlaue age which is very critcil variable
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> # Lets create a Family size using Sibsp and Parch, becuase Some time if the kids are more then it would be difficult for parents to take care all   
> 
> full_titanic$FamilySize <-full_titanic$SibSp + full_titanic$Parch + 1
> table(full_titanic[1:891,15])
< table of extent 0 >
> 
> full_titanic$FamilySized[full_titanic$FamilySize == 1]   <- 'Single'
> full_titanic$FamilySized[full_titanic$FamilySize < 5 & full_titanic$FamilySize >= 2]   <- 'Small'
> full_titanic$FamilySized[full_titanic$FamilySize >= 5]   <- 'Big'
> 
> full_titanic$FamilySized=as.factor(full_titanic$FamilySized)
> 
> 
> ###Lets Visualize the Survival rate by Family size 
> ggplot(full_titanic[1:891,],aes(x = FamilySized,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Family Size V/S Survival Rate") +
+   xlab("FamilySized") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ###Big Family in Titnic having worst survival rate then Small and Alone
> 
> ####Why Big Family has a probelm?, Check in the below visualization
> 
> ggplot(full_titanic[1:891,], aes(x = FamilySized, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~title) + 
+   ggtitle("3D View of Fmily Size, Title and Survival rate") +
+   xlab("family.size") +
+   ylab("Total Count") +
+   ylim(0,300) +
+   labs(fill = "Survived")
Warning message:
Removed 1 rows containing missing values (geom_bar). 
> 
> ####You are a Master and Mr in the Big Family then your Survival rate is absolutely nill 
>   
> ###I am very surprised to see Single coming out to be bulk, however 
> ##there is chance that, they could come with friends or survents
> ##I though to get extract those number using same ticket number distributed
> 
> 
> # Engineer features based on all the passengers with the same ticket
> ticket.unique <- rep(0, nrow(full_titanic))
> tickets <- unique(full_titanic$Ticket)
> 
> for (i in 1:length(tickets)) {
+   current.ticket <- tickets[i]
+   party.indexes <- which(full_titanic$Ticket == current.ticket)
+   
+   
+   for (k in 1:length(party.indexes)) {
+     ticket.unique[party.indexes[k]] <- length(party.indexes)
+   }
+ }
> 
> full_titanic$ticket.unique <- ticket.unique
> 
> 
> full_titanic$ticket.size[full_titanic$ticket.unique == 1]   <- 'Single'
> full_titanic$ticket.size[full_titanic$ticket.unique < 5 & full_titanic$ticket.unique>= 2]   <- 'Small'
> full_titanic$ticket.size[full_titanic$ticket.unique >= 5]   <- 'Big'
> 
> ###Lets check the Ticket size through grpah
> ggplot(full_titanic[1:891,],aes(x = ticket.size,fill=factor(Survived))) +
+   geom_bar() +
+   xlab("ticket.Size VS Survival") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ###Lets check the Ticket and title size through grpah
> ggplot(full_titanic[1:891,], aes(x = ticket.size, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~title) + 
+   ggtitle("3D View of Ticket, Title and Survival rate") +
+   xlab("ticket.size") +
+   ylab("Total Count") +
+   ylim(0,300) +
+   labs(fill = "Survived")
Warning message:
Removed 1 rows containing missing values (geom_bar). 
>   
> ##We can't see huge diffrence b/w ticket size and Family Size, May be we will use any one of them which is contributing more
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###is there any association between Survial rate and where he get in   
>  ggplot(full_titanic[1:891,],aes(x = Embarked,fill=factor(Survived))) +
+   geom_bar() +
+   ggtitle("Embarked vs Survival") +
+   xlab("Title") +
+   ylab("Total Count") +
+   labs(fill = "Survived") 
> 
> ##Lets further divide the grpah by Pclass
> ggplot(full_titanic[1:891,], aes(x = Embarked, fill = Survived)) +
+   geom_bar() +
+   facet_wrap(~Pclass) + 
+   ggtitle("Pclass vs Embarked") +
+   xlab("Pclass") +
+   ylab("Total Count") +
+   labs(fill = "Survived")
> 
> ##Haha..I don't think there is a link between Survival rate and Embarked 
> 
> ##There is a lot of Missing value in Cabin, i dont think its good idea to use that
> ##As mentioned earlier will use Title inplace of Age 
> 
> full_titanic$ticket.size <- as.factor(full_titanic$ticket.size)
> full_titanic$title <- as.factor(full_titanic$title)
> 
> ##From the Explortory anlysis part we have decided to use below variables for our model building 
> 
> ##"Pclass", "title","Sex","Embarked","FamilySized","ticket.size"
> 
> ##Any redaundnt varible among above will drop in the course of analysis
> 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###lets prepare the and keep it in proper format before modeling
> 
> feauter1<-full_titanic[1:891, c("Pclass", "title","Sex","Embarked","FamilySized","ticket.size")]
> response <- as.factor(train.tit$Survived)
> feauter1$Survived=as.factor(train.tit$Survived)
> 
> 
> ###For Cross validation purpose will keep 20% of data aside from my orginal train set
> ##This is just to check how well my data works for unseen data
> set.seed(500)
> ind=createDataPartition(feauter1$Survived,times=1,p=0.8,list=FALSE)
> train_val=feauter1[ind,]
> test_val=feauter1[-ind,]
> 
> ####check the proprtion of Survival rate in orginal training data, current traing and testing data
> round(prop.table(table(train.tit$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> round(prop.table(table(train_val$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> round(prop.table(table(test_val$Survived)*100),digits = 1)

  0   1 
0.6 0.4 
> 
> 
> ###Divided the data with same proportion of survival rate, lets start model building
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ##Even Random forest for more better than Single tree, Single tree is very easy to use and illustrate
> set.seed(1234)
> Model_DT=rpart(Survived~.,data=train_val,method="class")
> 
> 
> rpart.plot(Model_DT,extra =  3,fallen.leaves = T)
> 
> ###Surprise, Visualize data our Single tree model is using only Title, Pclass and Ticket.size and vomited rest
> ###Lets Predict train data and check the accuracy of single tree
> 
> PRE_TDT=predict(Model_DT,data=train_val,type="class")
> confusionMatrix(PRE_TDT,train_val$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 412  86
         1  28 188
                                          
               Accuracy : 0.8403          
                 95% CI : (0.8114, 0.8665)
    No Information Rate : 0.6162          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6484          
                                          
 Mcnemar's Test P-Value : 9.37e-08        
                                          
            Sensitivity : 0.9364          
            Specificity : 0.6861          
         Pos Pred Value : 0.8273          
         Neg Pred Value : 0.8704          
             Prevalence : 0.6162          
         Detection Rate : 0.5770          
   Detection Prevalence : 0.6975          
      Balanced Accuracy : 0.8112          
                                          
       'Positive' Class : 0               
                                          
> 
> #####There is the Accurcay using single tree, Accuracy is 0.8375
> ####Not at all bad using Single tree and just 3 feauters
> 
> ##There is chance of overfitting in Single tree, So I will go for cross validation using '10 fold techinque'
> set.seed(1234)
> cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10)
> 
> # Set up caret's trainControl object per above.
> ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
+                        index = cv.10)
> 
> ##Train the data
> Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
+                    trControl = ctrl)
> 
> 
> ##Check the accurcay
>  ##Accurcay using 10 fold cross validation of Single tree is 0.8139 
> ##Overfitting earlier using Single tree there our accurcay rate is 0.83
> 
> # Plot now and check the variable imporatnce, is the same as in Single tree
> rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)
> 
> ##Yes, there is no chane in the imporatnce of varible
> 
> 
> ###Lets cross validate the accurcay using data that kept aside for testing purpose
> PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
> confusionMatrix(PRE_VDTS,test_val$Survived)
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 94 20
         1 15 48
                                          
               Accuracy : 0.8023          
                 95% CI : (0.7359, 0.8582)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 7.432e-08       
                                          
                  Kappa : 0.5762          
                                          
 Mcnemar's Test P-Value : 0.499           
                                          
            Sensitivity : 0.8624          
            Specificity : 0.7059          
         Pos Pred Value : 0.8246          
         Neg Pred Value : 0.7619          
             Prevalence : 0.6158          
         Detection Rate : 0.5311          
   Detection Prevalence : 0.6441          
      Balanced Accuracy : 0.7841          
                                          
       'Positive' Class : 0               
                                          
> 
> ###There it is how exactly our train data and test data matches in accuracy (0.8192) 
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> set.seed(1234)
> rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
> rf.1

Call:
 randomForest(x = train_val[, -7], y = train_val[, 7], ntree = 1000,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 1000
No. of variables tried at each split: 2

        OOB estimate of  error rate: 16.11%
Confusion matrix:
    0   1 class.error
0 407  33   0.0750000
1  82 192   0.2992701
> varImpPlot(rf.1)
> 
> ####Random Forest accurcay rate is 82.91 which is 1% better than the decison  tree
> ####Lets remove 2 redaundant varibles and do the modeling again
> train_val1=train_val[,-4:-5]
> test_val1=test_val[,-4:-5]
> 
> set.seed(1234)
> rf.2 <- randomForest(x = train_val1[,-5],y=train_val1[,5], importance = TRUE, ntree = 1000)
> rf.2

Call:
 randomForest(x = train_val1[, -5], y = train_val1[, 5], ntree = 1000,      importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 1000
No. of variables tried at each split: 2

        OOB estimate of  error rate: 17.09%
Confusion matrix:
    0   1 class.error
0 389  51   0.1159091
1  71 203   0.2591241
> varImpPlot(rf.2)
> 
> ###Can see the Magic now, increease in accuracy by just removing 2 varibles, its 84.03 
> 
> ##Even though ranom forest is so power full we accept the model only after cross vlaidation
> 
> 
> set.seed(2348)
> cv10_1 <- createMultiFolds(train_val1[,5], k = 10, times = 10)
> 
> # Set up caret's trainControl object per above.
> ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
+                       index = cv10_1)
> 
> 
> 
> # Set seed for reproducibility and train
> set.seed(1234)
> rf.5<- train(x = train_val1[,-5], y = train_val1[,5], method = "rf", tuneLength = 3,
+               ntree = 1000, trControl =ctrl_1)
> 
> rf.5
Random Forest 

714 samples
  4 predictor
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 10 times) 
Summary of sample sizes: 643, 643, 642, 643, 642, 642, ... 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
  2     0.8267195  0.6282674
  3     0.8256025  0.6259203
  4     0.8211228  0.6155793

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 2.
> 
> ##So the Cross validation model give us the accurcay rate of .8393#
> 
> ###Lets Predict the test data 
> 
> pr.rf=predict(rf.5,newdata = test_val1)
> 
> confusionMatrix(pr.rf,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 100  17
         1   9  51
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 3.506e-12       
                                          
                  Kappa : 0.6825          
                                          
 Mcnemar's Test P-Value : 0.1698          
                                          
            Sensitivity : 0.9174          
            Specificity : 0.7500          
         Pos Pred Value : 0.8547          
         Neg Pred Value : 0.8500          
             Prevalence : 0.6158          
         Detection Rate : 0.5650          
   Detection Prevalence : 0.6610          
      Balanced Accuracy : 0.8337          
                                          
       'Positive' Class : 0               
                                          
> 
> ####accuracy rate is 0.8192, low compare to trained data
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> ###Before going to model lets tune the cost Parameter
> 
> set.seed(1274)
> liner.tune=tune.svm(Survived~.,data=train_val1,kernel="linear",cost=c(0.01,0.1,0.2,0.5,0.7,1,2,3,5,10,15,20,50,100))
> 
> liner.tune

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
 cost
  0.5

- best performance: 0.1863263 

> 
> ###best perforamnce is when cost=3 and accuracy rate is 82.7
> 
> 
> ####Lets get a best.liner model  
> best.linear=liner.tune$best.model
> 
> ##Predict Survival rate using test data
> 
> best.test=predict(best.linear,newdata=test_val1,type="class")
> confusionMatrix(best.test,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 102  19
         1   7  49
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 3.506e-12       
                                          
                  Kappa : 0.6789          
                                          
 Mcnemar's Test P-Value : 0.03098         
                                          
            Sensitivity : 0.9358          
            Specificity : 0.7206          
         Pos Pred Value : 0.8430          
         Neg Pred Value : 0.8750          
             Prevalence : 0.6158          
         Detection Rate : 0.5763          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8282          
                                          
       'Positive' Class : 0               
                                          
> 
> ##############Linear model accuracy is 0.8136
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> 
> ######Lets go to non liner SVM, Radial Kerenl
> set.seed(1274)
> 
> rd.poly=tune.svm(Survived~.,data=train_val1,kernel="radial",gamma=seq(0.1,5))
> 
> summary(rd.poly)

Parameter tuning of ‘svm’:

- sampling method: 10-fold cross validation 

- best parameters:
 gamma
   2.1

- best performance: 0.1723787 

- Detailed performance results:
  gamma     error dispersion
1   0.1 0.1793818 0.07488403
2   1.1 0.1766041 0.07504011
3   2.1 0.1723787 0.06347706
4   3.1 0.1751956 0.06111433
5   4.1 0.1751956 0.06111433

> best.rd=rd.poly$best.model
> 
> ###Non Linear Kerenel giving better accuray 
> 
> ##Lets Predict test data
> pre.rd=predict(best.rd,newdata = test_val1)
> 
> confusionMatrix(pre.rd,test_val1$Survived)
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 98 17
         1 11 51
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc > NIR] : 4.229e-11       
                                          
                  Kappa : 0.66            
                                          
 Mcnemar's Test P-Value : 0.3447          
                                          
            Sensitivity : 0.8991          
            Specificity : 0.7500          
         Pos Pred Value : 0.8522          
         Neg Pred Value : 0.8226          
             Prevalence : 0.6158          
         Detection Rate : 0.5537          
   Detection Prevalence : 0.6497          
      Balanced Accuracy : 0.8245          
                                          
       'Positive' Class : 0               
                                          
> 
> ####Accurcay of test data using Non Liner model is 0.81..still there is diffrence train and test accurcay
> ####it could be due we are using smaller set of sample for testing data
> 
> 
> ## ---- message=FALSE, warning=FALSE-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
> contrasts(train_val1$Sex)
       male
female    0
male      1
> contrasts(train_val1$Pclass)
  2 3
1 0 0
2 1 0
3 0 1
> 
> ##The above shows how the varible coded among  
> 
> ##Lets run Logistic regression model
> log.mod <- glm(Survived ~ ., family = binomial(link=logit), 
+                data = train_val1)
> ###Check the P value
> summary(log.mod)

Call:
glm(formula = Survived ~ ., family = binomial(link = logit), 
    data = train_val1)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.3057  -0.6037  -0.4163   0.5910   2.9010  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
(Intercept)        15.2687   535.4118   0.029    0.977    
Pclass2            -1.2513     0.3035  -4.123 3.73e-05 ***
Pclass3            -2.0792     0.2632  -7.900 2.79e-15 ***
titleMiss         -14.4739   535.4118  -0.027    0.978    
titleMr            -3.3519     0.5297  -6.328 2.48e-10 ***
titleMrs          -14.1159   535.4118  -0.026    0.979    
titleOfficer       -3.4576     0.8180  -4.227 2.37e-05 ***
Sexmale           -14.0305   535.4116  -0.026    0.979    
ticket.sizeSingle   1.7907     0.3956   4.526 6.00e-06 ***
ticket.sizeSmall    1.7550     0.3790   4.630 3.66e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 612.70  on 704  degrees of freedom
AIC: 632.7

Number of Fisher Scoring iterations: 12

> confint(log.mod)
Waiting for profiling to be done...
                       2.5 %     97.5 %
(Intercept)       -93.577086         NA
Pclass2            -1.856074 -0.6645044
Pclass3            -2.604921 -1.5714594
titleMiss                 NA 94.3697051
titleMr            -4.426245 -2.3405610
titleMrs                  NA 94.7241620
titleOfficer       -5.149130 -1.9119238
Sexmale                   NA 94.9285419
ticket.sizeSingle   1.035252  2.5896481
ticket.sizeSmall    1.026807  2.5167892
There were 45 warnings (use warnings() to see them)
> 
> ###You will first have to create a vector of the predicted probabilities, as follows:
> train.probs <- predict(log.mod, data=train_val1,type =  "response")
> table(train_val1$Survived,train.probs>0.5)
   
    FALSE TRUE
  0   390   50
  1    73  201
> 
> (395+204)/(395+204+70+45)
[1] 0.8389356
> 
> ###Logistic regression predict train data with accuracy rate of 0.83 
> 
> test.probs <- predict(log.mod, newdata=test_val1,type =  "response")
> table(test_val1$Survived,test.probs>0.5)
   
    FALSE TRUE
  0   102    7
  1    18   50
> 
> (97+47)/(97+12+21+47)
[1] 0.8135593
> 
> ###Accuracy rate of teat data is 0.8135..again there is gap b/w both prediction
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
 81.406   2.355  83.881 
