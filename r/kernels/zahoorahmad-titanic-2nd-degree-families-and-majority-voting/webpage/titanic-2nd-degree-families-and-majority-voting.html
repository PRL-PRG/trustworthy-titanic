<!DOCTYPE html>
<html lang="en">
<head>
    <title>Titanic: 2nd degree families and majority voting | Kaggle</title>
    <meta charset="utf-8" />
    <meta name="robots" content="index, follow" />
    <meta name="turbolinks-cache-control" content="no-cache" />
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC" />
    <script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com" /><link rel="dns-prefetch" href="https://stats.g.doubleclick.net" /><link rel="dns-prefetch" href="https://js.intercomcdn.com" /><link rel="dns-prefetch" href="https://storage.googleapis.com/" />
    <link href="/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link rel="manifest" href="/static/json/manifest.json">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic" rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet" type='text/css'/>
        <link rel="canonical" href="/zahoorahmad/titanic-2nd-degree-families-and-majority-voting" />                    <link rel="stylesheet" type="text/css" href="/static/assets/vendor.css?v=632d145d8598" />
        <link rel="stylesheet" type="text/css" href="/static/assets/app.css?v=1d00932a7505" />
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => d.deleteRule(x))};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12629138-1"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6"};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@kaggledatasets" />
    <meta name="og:url" content="https://kaggle.com/zahoorahmad/titanic-2nd-degree-families-and-majority-voting" />
    <meta name="og:title" content="Titanic: 2nd degree families and majority voting" />
    <meta name="og:description" content="Using data from Titanic: Machine Learning from Disaster" />
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/1364657-kg.JPG" />


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL-F2AGb4mZj-AVDm0gsc4jZAXpGkgoaJ8vGlzvL4bnwuVVki9BhPjcolWqsiRWxAPm7e4-J2bL2B8xTeBZKa6EfX5IfvhfM_gtmmoifq7MonYe5XsBWnr17jtL6o6fqGr0',
        isAnonymous: true,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjAzNDQ3ODEsIlVzZXJJZCI6MH0.aye3mvl7tYMtmjmMgEWb8fLSa2Mb0ZZr6HMuW-_6JNg',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: false,
        
        
        
        
        
        
        
        
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript"
src="//www.googleadservices.com/pagead/conversion_async.js">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="/static/assets/vendor.js?v=4721d2c14786" data-turbolinks-track="reload"></script>
    <script src="/static/assets/app.js?v=1a3cd8c35fe7" data-turbolinks-track="reload"></script>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async defer src="https://apis.google.com/js/api.js"
            onload="this.googleApiOnLoad=function(){};handleClientLoad()"
            onreadystatechange="if (this.readyState === 'complete') this.googleApiOnLoad()">
    </script>
</head>
<body data-turbolinks="true">
    <main>
        






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":786539,"title":"Titanic: 2nd degree families and majority voting","forkParent":{"kernelId":487546,"runId":2951774,"url":"/erikbruin/titanic-2nd-degree-families-and-majority-voting","title":"Titanic: 2nd degree families and majority voting","author":{"id":1443335,"displayName":"Erik Bruin","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"erikbruin","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1443335-kg.jpg","profileUrl":"/erikbruin","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"diff":{"linesInserted":0,"linesDeleted":0,"linesChanged":0,"linesUnchanged":0,"newTotalLines":0,"url":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/versions#base=2951774\u0026new=2972542"},"isRedacted":false,"dateCreated":"2018-03-27T08:45:22.207Z","outputFilesTotalSizeBytes":105748,"workerStatus":"complete","isolatorResults":null,"languageId":5},"currentRunId":2972542,"mostRecentRunId":5591907,"url":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting","tags":[{"name":"data visualization","slug":"data-visualization","url":"/tags/data-visualization"},{"name":"feature engineering","slug":"feature-engineering","url":"/tags/feature-engineering"}],"commentCount":0,"upvoteCount":3,"viewCount":202,"forkCount":0,"bestPublicScore":0.81339,"author":{"id":1364657,"displayName":"ZahoorAhmad","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"zahoorahmad","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1364657-kg.JPG","profileUrl":"/zahoorahmad","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2018-03-28T10:58:58.1766667Z","selfLink":"/kernels/786539","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":null,"topicId":null,"readGroupId":null,"writeGroupId":null,"slug":"titanic-2nd-degree-families-and-majority-voting"},"kernelBlob":{"id":5402226,"settings":{"dockerImageVersionId":47,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Finding the \u0027real\u0027 families on the Titanic, and majority vote ensemble\u0022\nauthor: \u0022Erik Bruin\u0022\noutput:\n  html_document:\n    number_sections: true\n    toc: true\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n#Executive Summary\nThis project is my first attempt to compete in a Kaggle Machine Learning competition in which we have to predict who survived the Titanic disaster. I enjoyed it very much and learned a lot. Key findings were:\n\n* My key to success was to dive deep into groups of people that traveled together. My grouping variable is different when compared to other kernels that I have looked at.\n* The main things that I have done that I have not seen in any other kernels yet is the grouping of \u0027second degree\u0027 family members. Uncles, grandparents, cousins, and brothers/sisters-in-law can actually be found in the data.\n* My public score on Kaggle is 0.81818. As this is a top4% score, I am pretty pleased with the result.\n* I am just using 5 predictors. A significant difference with most kernels is that I eventually got rid of the Title variable. I believe that the models are much cleaner model now as the Title variance double counts the Sex/Gender variance (and also male children (called Masters)).\n* My analysis includes three models: a Random Forest model, a Support Vector Machine (SVM) model, and a Gradient Boosting Machine (GBM) model.\n* I included three frameworks that combine models.\n    * The first one is a simple voting ensemble that takes the majority vote of 3 models.\n    * The second framework is similar. It takes the predictions from one model (the best model), and only changes the prediction if both other models disagree with that best model.\n    * The third thing that I tried is selectively using models for specific categories.\n* The best results were achieved by using the SVM model for 1st and 2nd class passengers, and use the GBM model for 3rd class passengers. \n\n#Introduction\n\nKaggle describes this competition as [follows](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n\u003ccenter\u003e\u003cimg src=\u0022https://vignette.wikia.nocookie.net/jamescameronstitanic/images/5/55/Titanic_sinking.jpg/revision/latest?cb=20130918052255\u0022 style=\u0022width: 600px;\u0022/\u003e\u003c/center\u003e\n\n# Loading and Exploring Data\n\n##Loading libraries required and reading the data into R\n\nLoading R packages used besides base R.\n\n```{r, message=FALSE, warning=FALSE}\nlibrary(Hmisc)\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(randomForest)\nlibrary(gridExtra)\nlibrary(ROCR)\nlibrary(corrplot)\n```\n\nBelow, I am reading the csv\u0027s as dataframes into R.\n\n```{r}\ntrain \u003c- read.csv(\u0022../input/train.csv\u0022, stringsAsFactors = F, na.strings = c(\u0022NA\u0022, \u0022\u0022))\ntest \u003c- read.csv(\u0022../input/test.csv\u0022, stringsAsFactors = F, na.strings = c(\u0022NA\u0022, \u0022\u0022))\n```\n\n##Data size and structure\n\nThe training set consist of 891 observations and 12 variables. I have read all the \u0022factors\u0022 (for instance male/female) into R as character strings, as some of them require processing first.\n\n```{r}\nstr(train)\n```\n\nA description of each variable, including description of some key values, is given below.\n\nVariable Name | Description                       |Key\n--------------|-----------------------------------|----------------------------------------------\nSurvived      | Survival                          |0 = No, 1 = Yes\nPclass        | Passenger\u0027s class                 |1 = 1st, 2 = 2nd, 3 = 3rd\nName          | Passenger\u0027s name                  |\nSex           | Passenger\u0027s sex                   |\nAge           | Passenger\u0027s age                   |\nSibSp         | Number of siblings/spouses aboard |\nParch         | Number of parents/children aboard |\nTicket        | Ticket number                     |\nFare          | Fare                              |\nCabin         | Cabin                             |\nEmbarked      | Port of embarkation               |C = Cherbourg, Q = Queenstown, S = Southampton\n--------------------------------------------------------------------------------------------------\n\nThe test set consists of 418 observations, with the variable \u0022Survived\u0022 missing compared to the training set. \u0022Creating\u0022 this variable is eventually the purpose of this project.\n\nBelow I am merging test and train, as this is required for data cleaning and feature engineering.\n\n```{r}\ntest$Survived \u003c- NA\nall \u003c- rbind(train, test)\n```\n\n\n##Completeness of the data\n\nFirst of all, I would like to see which variables contain missing values (blanks are also imported as NA (=Not Available)).\n\n```{r}\nsapply(all, function(x) {sum(is.na(x))})\n```\n\nOf course, the 418 NAs in Survived is the total number is observations in the test set. So this variable is what it should be (No NAs in train). Of the other variables, Cabin is sparsely populated. Age is also missing a substantial number of values. In addition, Embarked is missing two values and one Fare value is missing.\n\n##Exploring some of the most important variables\n\nOur response variable in the training set is complete, as well as Sex and Pclass, which seem two of the most important predictors. Since they are complete and tidy, I am converting them into factors.\n\n```{r}\nall$Sex \u003c- as.factor(all$Sex)\nall$Survived \u003c- as.factor(all$Survived)\nall$Pclass \u003c- as.ordered(all$Pclass) #because Pclass is ordinal\n```\n\n###The response variable; Survived\nOf course, the very first thing that I want to do is explore the response variable. How many people survived, and how many died? You can see this below. Altogether, of the people in the training set (891 observations) 61.6% died. For the remaining 418 observations (test set), this is what we have to predict.\n\n```{r, out.width=\u002250%\u0022}\nggplot(all[!is.na(all$Survived),], aes(x = Survived, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) +\n  labs(x = \u0027How many people died and survived on the Titanic?\u0027) +\n        geom_label(stat=\u0027count\u0027,aes(label=..count..), size=7) +\n        theme_grey(base_size = 18)\n```\n\n\n###Sex/gender\n\nOf the 1309 people on the Titanic, a majority of 64.4% was male. This percentage was almost the same in the training data (64.7%). Within the training data 81.1% of the men died, and 25.8% of the women died. Due to this large difference, Sex/gender seems a very important predictor.\n\n```{r}\np1 \u003c- ggplot(all, aes(x = Sex, fill = Sex)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + theme_grey() +\n  labs(x = \u0027All data\u0027) +\n        geom_label(stat=\u0027count\u0027, aes(label=..count..)) +\n        scale_fill_manual(\u0022legend\u0022, values = c(\u0022female\u0022 = \u0022pink\u0022, \u0022male\u0022 = \u0022green\u0022))\np2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Sex, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + theme_grey() +\n  labs(x = \u0027Training data only\u0027) +\n        geom_label(stat=\u0027count\u0027, aes(label=..count..))\n\ngrid.arrange(p1,p2, nrow=1)\n```\n\n###Passenger Class\n\nAs you can see below, most people traveled in 3rd class. Also, as expected, survival is strongly correlated with the passenger class. A majority of first class passengers survived, and most people in 3rd class died. It is also noticable that almost all women in 1st and 2nd class survived. For men, 2nd class was almost as bad as 3rd class.\n\n```{r, out.width=\u0022100%\u0022}\np3 \u003c- ggplot(all, aes(x = Pclass, fill = Pclass)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  labs(x = \u0027Pclass, All data\u0027) + geom_label(stat=\u0027count\u0027, aes(label=..count..)) +\n   theme(legend.position=\u0022none\u0022) + theme_grey()     \np4 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + labs(x = \u0027Training data only\u0027) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\np5 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027stack\u0027) +\n  labs(x = \u0027Training data only\u0027, y= \u0022Count\u0022) + facet_grid(.~Sex) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\np6 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027fill\u0027) +\n  labs(x = \u0027Training data only\u0027, y= \u0022Percent\u0022) + facet_grid(.~Sex) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\n\ngrid.arrange(p3, p4, p5, p6, ncol=2)\n```\n\nIn early version, I have been working with Pclass and Sex as separate predictors. However, I realized that the \u0027headline\u0027 of the model should actually be a combination of the two (also thanks to Oscar Takeshita, who also uses this idea in his excellent analysis. See: [Divide and Conquer [0.82296]](https://www.kaggle.com/pliptor/divide-and-conquer-0-82296)). Details that are lost when using the predictors separately were actually already mentioned in the beginning of this section (Pclass 1 and 2 are almost guaranteed survival for women, and Pclass 2 is almost as bad as Pclass 3 for men).\n\n```{r}\nall$PclassSex[all$Pclass==\u00271\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P1Male\u0027\nall$PclassSex[all$Pclass==\u00272\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P2Male\u0027\nall$PclassSex[all$Pclass==\u00273\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P3Male\u0027\nall$PclassSex[all$Pclass==\u00271\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P1Female\u0027\nall$PclassSex[all$Pclass==\u00272\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P2Female\u0027\nall$PclassSex[all$Pclass==\u00273\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P3Female\u0027\nall$PclassSex \u003c- as.factor(all$PclassSex)\n```\n\n#Feature engineering\n\nWhile I also started by using the Title as a variable, I am not using it anymore. Although most kernals use it, I believe it double counts variance to much (overfitting). While I am not using the Title directly anymore in my prediction models, it needs to stay in the analysis as it is used to predict missing Ages in section 4.4.\n\n##Creating the Title variable\n\nThe name variable is complete (no NAs), but actually contains more than just a first name and surname. It also contains a Title for each person, which must be separated from the name to obtain tidy data. I am also saving the Surname (first part of the name variable, before the title), as I want to investigate the effects of families traveling together later on (matching with #siblings/spouses and #parents/children).\n\n```{r}\n#Extracting Title and Surname from Name\nall$Surname \u003c- sapply(all$Name, function(x) {strsplit(x, split=\u0027[,.]\u0027)[[1]][1]})\n #correcting some surnames that also include a maiden name\nall$Surname \u003c- sapply(all$Surname, function(x) {strsplit(x, split=\u0027[-]\u0027)[[1]][1]})\nall$Title \u003c- sapply(all$Name, function(x) {strsplit(x, split=\u0027[,.]\u0027)[[1]][2]})\nall$Title \u003c- sub(\u0027 \u0027, \u0027\u0027, all$Title) #removing spaces before title\nkable(table(all$Sex, all$Title))\n```\n\nAfter seeing this, I want to reducing the number of titles to create better and more substantial Titles that can be used for prediction. Ms. is usually used for younger married women. I will therefore join this one with Miss. I assume that Mlle stands for Mademoiselle in French. I will also join this category with Miss. I also assume that Mme stands for Madame, and I will join Madame with Mrs. For the titles with low frequecies, I will create one new category.\n\n```{r}\nall$Title[all$Title %in% c(\u0022Mlle\u0022, \u0022Ms\u0022)] \u003c- \u0022Miss\u0022\nall$Title[all$Title== \u0022Mme\u0022] \u003c- \u0022Mrs\u0022\nall$Title[!(all$Title %in% c(\u0027Master\u0027, \u0027Miss\u0027, \u0027Mr\u0027, \u0027Mrs\u0027))] \u003c- \u0022Rare Title\u0022\nall$Title \u003c- as.factor(all$Title)\nkable(table(all$Sex, all$Title))\n```\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Title, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027stack\u0027) +\n  labs(x = \u0027Title\u0027) +theme_grey()\n```\n\n##Finding groups of people traveling together\n\n###Families; siblings, spouses, parents and children\n\nIn order to create the family size for each person on the boat, I will add up his/her number of parents/children, his/her number of siblings/spouses, and of course add one (the person himself).\n\n```{r, message=FALSE}\n#creating family size variable (Fsize)\nall$Fsize \u003c- all$SibSp+all$Parch +1\n```\n\nBelow, you can easily see that solo travelers had a much higher chance to die than to survive. In addition, people traveling in families of 2-4 people actually had a relatively high chance to survive. This chance is significantly lower among 5+ families.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Fsize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Family Size\u0027) + theme_grey()\n```\n\nWhat I now could do is convert these family sizes into categories (solo, small family, large family), but I first want to check if there are any inconsistencies in the data.\n\n###Family Size inconsistencies, and correcting the effects of a cancellation\n\nTo check the family size data for inconsistencies, I am creating a variable that combines the surname and the Fsize. After that, I am going to check where these combinations lead to strange numbers of families.\n\n```{r}\n#composing variable that combines total Fsize and Surname\nall$FsizeName \u003c- paste(as.character(all$Fsize), all$Surname, sep=\u0022\u0022)\n\nSizeCheck \u003c- all %\u003e%\n        group_by(FsizeName, Fsize) %\u003e%\n        summarise(NumObs=n())\nSizeCheck$NumFam \u003c- SizeCheck$NumObs/SizeCheck$Fsize\nSizeCheck$modulo \u003c- SizeCheck$NumObs %% SizeCheck$Fsize\nSizeCheck \u003c- SizeCheck[SizeCheck$modulo !=0,]\nsum(SizeCheck$NumObs) #total number of Observations with inconsistencies\nkable(SizeCheck[SizeCheck$FsizeName %in% c(\u00273Davies\u0027, \u00275Hocking\u0027, \u00276Richards\u0027, \u00272Wilkes\u0027, \u00273Richards\u0027, \u00274Hocking\u0027),]) #only display some inconsistencies that are discussed in the text\n\n```\n\nAs you can see, this check does not always add up to a round number of families (for a total of 93 passengers). A quick internet search learns us that the passenger list seems complete as there were around 1300 passengers on board indeed (the rest of the people on the boat were crew). Some inconsistencies can likely be explained by cancellations (SibSp and Parch info not updated after a cancellation). For instance: there must have been two Davies families on board, while the SizeCheck only shows five obervations for FsizeName \u00273Davies\u0027. \n\n```{r}\nkable(all[all$FsizeName==\u00273Davies\u0027,c(2,3,14,5,6,7,8,17,9,15)])\n```\n\nThe Davies\u0027 on Tickets A/4 48871 and A/4 48873 are very likely a complete group. The error seems to be that Mrs Davies [1222] was supposed to travel with 2 children, but eventually only traveled with one son (Master Davies [550]). A quick internet search told me that a person with the name Davies cancelled his trip indeed due to illness. Let\u0027s correct this info.\n\n```{r}\nall$FsizeName[c(550, 1222)] \u003c- \u00272Davies\u0027\nall$SibSp[550] \u003c- 0\nall$Parch[1222] \u003c- 1\nall$Fsize[c(550, 1222)] \u003c- 2\nkable(all[all$FsizeName==\u00272Davies\u0027,c(2,3,14,5,6,7,8,17,9,15)])\n```\n\nI believe that there could be more cancellations that were not administered fully correctly, but I also think that the effects on the final models is likely to be very minor. So let\u0027s move on to the next section quickly.\n\n###Families; what about uncles, aunts, cousins, nieces, grandparents, brothers/sisters-in law?\n\nI found out that there is something \u0027hidden\u0027 in this information that seems more interesting than a few cancellations. For instance, it turns out that the Hockings and the Richards\u0027 are related. The connection here is that passenger 438 travels with 2 children, 1 parent, a brother and a sister. For her, all these people count are direct family. However, other people are linked indirectly. For the 2 children for instance, only the brother and mother count as direct family. This leads to Fsizes that cannot be compared to most families as \u0027apples to apples\u0027. Their Fsizes are generally too high, as it is likely that those people have split up into smaller groups. The mother may have stayed with her children, while the brother and sister probably have stayed with the grandmother.\n\nNote: this family is actually even more complex, as the grandmother also travels with a sister with the same maiden name. However, as this really seems an exception and the other Mrs Needs already has the very reasonable Fsize of 2 (it\u0027s  Mrs Wilkes Needs), I am not taking her into consideration.\n\n```{r}\nkable(all[all$Ticket %in% c(\u002729104\u0027, \u002729105\u0027, \u002729106\u0027),c(2,3,4,5,6,7,8,9,15)])\n```\n\nIn order to fix this, I first have to \u0027glue\u0027 those families together using maiden names.\n\n```{r}\nNC \u003c- all[all$FsizeName %in% SizeCheck$FsizeName,] #create data frame with only relevant Fsizenames\n\n#extracting maiden names\nNC$Name \u003c- sub(\u0022\\\\s$\u0022, \u0022\u0022, NC$Name) #removing spaces at end Name\nNC$Maiden \u003c- sub(\u0022.*[^\\\\)]$\u0022, \u0022\u0022, NC$Name) #remove when not ending with \u0027)\u0027\nNC$Maiden \u003c- sub(\u0022.*\\\\s(.*)\\\\)$\u0022, \u0022\\\\1\u0022, NC$Maiden)\nNC$Maiden[NC$Title!=\u0027Mrs\u0027] \u003c- \u0022\u0022 #cleaning up other stuff between brackets (including Nickname of a Mr)\nNC$Maiden \u003c- sub(\u0022^\\\\(\u0022, \u0027\u0027, NC$Maiden) #removing opening brackets (sometimes single name, no spaces between brackets)\n#making an exceptions match\nNC$Maiden[NC$Name==\u0027Andersen-Jensen, Miss. Carla Christine Nielsine\u0027] \u003c- \u0027Jensen\u0027\n\n#take only Maiden names that also exist as surname in other Observations\nNC$Maiden2[NC$Maiden %in% NC$Surname] \u003c- NC$Maiden[NC$Maiden %in% NC$Surname] \n#create surname+maiden name combinations\nNC$Combi[!is.na(NC$Maiden2)] \u003c- paste(NC$Surname[!is.na(NC$Maiden2)], NC$Maiden[!is.na(NC$Maiden2)])\n\n#create labels dataframe with surname and maiden merged into one column\nlabels1 \u003c- NC[!is.na(NC$Combi), c(\u0027Surname\u0027,\u0027Combi\u0027)]\nlabels2 \u003c- NC[!is.na(NC$Combi), c(\u0027Maiden\u0027,\u0027Combi\u0027)]\ncolnames(labels2) \u003c- c(\u0027Surname\u0027, \u0027Combi\u0027)\nlabels1 \u003c- rbind(labels1, labels2)\n\nNC$Combi \u003c- NULL\nNC \u003c- left_join(NC, labels1, by=\u0027Surname\u0027)\n\n#Find the maximum Fsize within each newly found \u0027second degree\u0027 family\nCombiMaxF \u003c- NC[!is.na(NC$Combi),] %\u003e%\n        group_by(Combi) %\u003e%\n        summarise(MaxF=max(Fsize)) #summarise(MaxF=n())\nNC \u003c- left_join(NC, CombiMaxF, by = \u0022Combi\u0022)\n\n#create family names for those larger families\nNC$FsizeCombi[!is.na(NC$Combi)] \u003c- paste(as.character(NC$Fsize[!is.na(NC$Combi)]), NC$Combi[!is.na(NC$Combi)], sep=\u0022\u0022)\n\n#find the ones in which not all Fsizes are the same\nFamMaid \u003c- NC[!is.na(NC$FsizeCombi),] %\u003e%\n        group_by(FsizeCombi, MaxF, Fsize) %\u003e%\n        summarise(NumObs=n())\nFamMaidWrong \u003c- FamMaid[FamMaid$MaxF!=FamMaid$NumObs,]\n\nkable(unique(NC[!is.na(NC$Combi) \u0026 NC$FsizeCombi %in% FamMaidWrong$FsizeCombi, c(\u0027Combi\u0027, \u0027MaxF\u0027)]))\n```\n\nAs you can see, 7 combinations (total of 28 passengers) are found as families with not all members having the same Fsize, which means that they are broader families with non-direct family links included. Before I decided what to do with these, I first have to find the families who are similarly linked on the \u0027male\u0027 side.\n\n```{r}\nNC$MaxF \u003c- NULL #erasing MaxF column maiden combi\u0027s\n\n#Find the maximum Fsize within remaining families (no maiden combi\u0027s)\nFamMale \u003c- NC[is.na(NC$Combi),] %\u003e%\n        group_by(Surname) %\u003e%\n        summarise(MaxF=max(Fsize))\nNC \u003c- left_join(NC, FamMale, by = \u0022Surname\u0022)\n\nNCMale \u003c- NC[is.na(NC$Combi),] %\u003e%\n        group_by(Surname, FsizeName, MaxF) %\u003e%\n        summarise(count=n()) %\u003e%\n        group_by(Surname, MaxF) %\u003e%\n        filter(n()\u003e1) %\u003e%\n        summarise(NumFsizes=n())\n\nNC$Combi[NC$Surname %in% NCMale$Surname] \u003c- NC$Surname[NC$Surname %in% NCMale$Surname]\n\nkable(NCMale[, c(1,2)])\n```\n\nExample. Mr Julius Vander Planke is traveling with a spouse and 2 siblings. His spouse and siblings (brothers/sisters-in-law) are \u0027indirectly\u0027 related to each other.\n\n```{r}\nkable(all[all$Surname==\u0027Vander Planke\u0027, c(2,3,4,5,6,7,8,9,15)])\n```\n\nThis means that altogether, there are 9 families (37 passengers) that include \u0027second degree\u0027 family members. What I want to do is give each member in such family the same Fsize (which gives everybody in these families the same survival chances with regards to the group variable). I have chosen to make this the average of the Fsize (which are based on siblings/spouse/parents/children only).\n\n```{r}\n#selecting those 37 passengers In Not Correct dataframe\nNC \u003c- NC[(NC$FsizeCombi %in% FamMaidWrong$FsizeCombi)|(NC$Surname %in% NCMale$Surname),]\n\n#calculating the average Fsize for those 9 families\nNC1 \u003c- NC %\u003e%\n        group_by(Combi) %\u003e%\n        summarise(Favg=mean(Fsize))\nkable(NC1)\n```\n\nA result is that for instance the Fsize is 4 for all 6 people in the Richards-Hockings family. This exactly what I wanted, as I wanted to combine those people into a group with all members having the same Fsize (to give equal survival chances to all members within the group) but also not the maximum size as they are less likely to stay together than first degree families.\n\n```{r}\nNC \u003c- left_join(NC, NC1, by = \u0022Combi\u0022) #adding Favg to NC dataframe \nNC$Favg \u003c- round(NC$Favg) #rounding those averages to integers\nNC \u003c- NC[, c(\u0027PassengerId\u0027, \u0027Favg\u0027)]\nall \u003c- left_join(all, NC, by=\u0027PassengerId\u0027)\n\n#replacing Fsize by Favg\nall$Fsize[!is.na(all$Favg)] \u003c- all$Favg[!is.na(all$Favg)]\n```\n\n###Can we still find more second degree families?\n\nAm I still missing some second degree families? Yes, at it appears that some people traveling solo with the same surname have tickets with almost the same number!\n\n```{r}\n#creating a variable with almost the same ticket numbers (only last 2 digits varying)\nall$Ticket2 \u003c- sub(\u0022..$\u0022, \u0022xx\u0022, all$Ticket)\n```\n\nAs they have no sibling/spouses and no parents/children, these people are likely cousins/uncles. If you look deeper into the data, you will see that these groups of cousins/uncles sometimes also travel with (first degree) families. However, I think the key to this exercise is not to find the absolute largest groups that people may have stayed together with. I think it should be to detect smaller groups that actually stayed together. It sounds reasonable to assume that first degree families stayed together, and that uncles/cousins also took care of each other (this is consistent with the averaging of the Fsizes in the previous section). Altogether, I have found another 56 passengers that I can assign a group size to.\n\n```{r}\nrest \u003c- all %\u003e%\n        select(PassengerId, Title, Age, Ticket, Ticket2, Surname, Fsize) %\u003e%\n        filter(Fsize==\u00271\u0027) %\u003e%\n        group_by(Ticket2, Surname) %\u003e%\n        summarise(count=n())\nrest \u003c- rest[rest$count\u003e1,]\nrest1 \u003c- all[(all$Ticket2 %in% rest$Ticket2 \u0026 all$Surname %in% rest$Surname \u0026 all$Fsize==\u00271\u0027), c(\u0027PassengerId\u0027, \u0027Surname\u0027, \u0027Title\u0027, \u0027Age\u0027, \u0027Ticket\u0027, \u0027Ticket2\u0027, \u0027Fsize\u0027, \u0027SibSp\u0027, \u0027Parch\u0027)]\nrest1 \u003c- left_join(rest1, rest, by = c(\u0022Surname\u0022, \u0022Ticket2\u0022))\nrest1 \u003c- rest1[!is.na(rest1$count),]\nrest1 \u003c- rest1 %\u003e%\n        arrange(Surname, Ticket2)\nkable(rest1[1:12,])\n```\n\n```{r}\n#replacing Fsize size in my overall dataframe with the count numbers in the table above\nall \u003c- left_join(all, rest1)\nfor (i in 1:nrow(all)){\n        if (!is.na(all$count[i])){\n                all$Fsize[i] \u003c- all$count[i]\n        }\n}\n```\n\n###Did people book together?\n\nBesides families, groups of friends can off course also travel together. A nice example of this is the ticket below.\n\n```{r}\nkable(all[all$Ticket==\u00271601\u0027, c(\u0027Survived\u0027, \u0027Pclass\u0027, \u0027Title\u0027, \u0027Surname\u0027, \u0027Age\u0027, \u0027Ticket\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Fsize\u0027)])\n```\n\nBelow, I am adding the number of people on each ticket as variable.\n\n```{r}\n#composing data frame with group size for each Ticket\nTicketGroup \u003c- all %\u003e%\n        select(Ticket) %\u003e%\n        group_by(Ticket) %\u003e%\n        summarise(Tsize=n())\nall \u003c- left_join(all, TicketGroup, by = \u0022Ticket\u0022)\n```\n\nVery similarly to the family group sizes, small groups of 2-4 people traveling together on the same ticket have a higher chance of survival.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Tsize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Ticket Size\u0027) + theme_grey()\n```\n\nAs there is so much overlap between family size and ticket size, I am consolidating these two variables into one group variable. Now I can finally created my factorized variable for the group sizes.\n\n```{r}\n#taking the max of family and ticket size as the group size\nall$Group \u003c- all$Fsize\nfor (i in 1:nrow(all)){\n           all$Group[i] \u003c- max(all$Group[i], all$Tsize[i])\n}\n\n#Creating final group categories\nall$GroupSize[all$Group==1] \u003c- \u0027solo\u0027\nall$GroupSize[all$Group==2] \u003c- \u0027duo\u0027\nall$GroupSize[all$Group\u003e=3 \u0026 all$Group\u003c=4] \u003c- \u0027group\u0027\nall$GroupSize[all$Group\u003e=5] \u003c- \u0027large group\u0027\nall$GroupSize \u003c- as.factor(all$GroupSize)\n```\n\nAs \u00271\u0027 and \u00272\u0027 are large groups with their own typical survival rates, I am keeping them as separate groups. Sizes \u00273\u0027 and \u00274\u0027 clearly have the best survival chances, and the groups of 5 and more clearly have worse chances.\n\n```{r}\ng1 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Group, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Final Group Sizes\u0027) + theme_grey()\n\ng2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = GroupSize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  labs(x = \u0027Final Group Categories\u0027) + theme_grey() +\n        scale_x_discrete (limits = c(\u0027solo\u0027, \u0027duo\u0027, \u0027group\u0027, \u0027large group\u0027))\ngrid.arrange(g2, g1)\n```\n\n```{r, echo=FALSE}\n#clean up\nall$count \u003c- NULL\nall$Name \u003c- NULL\nrm(CombiMaxF)\nrm(FamMaid)\nrm(FamMaidWrong)\nrm(FamMale)\nrm(labels1)\nrm(labels2)\nrm(NC)\nrm(NC1)\nrm(NCMale)\nrm(rest)\n#rm(rest1)\nrm(SizeCheck)\nrm(TicketGroup)\nrm(p1); rm(p2); rm(p3); rm(p4); rm(p5); rm(p6)\n```\n\n\n##Dealing with the Fare variable\n\n###Which data relevant to fare are missing?\nThere are two missing values in Embarked, and one in Fare. Embarked could be important to Fare, as different Embarkement cities mean longer or shorter journeys.\n\n```{r}\n#display passengers with missing Embarked\nkable(all[which(is.na(all$Embarked)),c(\u0027Surname\u0027, \u0027Title\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Age\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Ticket\u0027, \u0027Fare\u0027, \u0027Cabin\u0027, \u0027Embarked\u0027, \u0027Group\u0027) ])\n```\n\nBoth women are traveling solo from a family perspective (Fsize=1), but must be friends as they are both are traveling on ticket 113572 (nobody else was traveling on this ticket, so Group=2). Both also have the same fare, but this fare might still have been per person. I came to the conclusion that prices are indeed per ticket. As the explanation was getting lengthy, I will now just continue under the assumption that fares are per person. \n\nI want to impute the missing embarkement city with the median Fare Per Person for each Embarkement city, and per Pclass.\n\n```{r}\nall$FarePP \u003c- all$Fare/all$Tsize #creating the Fare Per Person variable\n\ntab2 \u003c- all[(!is.na(all$Embarked) \u0026 !is.na(all$Fare)),] %\u003e%\n        group_by(Embarked, Pclass) %\u003e%\n        summarise(FarePP=median(FarePP))\nkable(tab2)\n```\n\nAs the FarePP of those two women is 40, they most likely embarked at Cherbourgh.\n\n```{r}\n#imputing missing Embarked values\nall$Embarked[all$Ticket==\u0027113572\u0027] \u003c- \u0027C\u0027\n#converting Embarked into a factor\nall$Embarked \u003c- as.factor(all$Embarked)\n```\n\nI can actually use the same table to find a sensible fare for Mr Story. As you can see below, he traveled 3rd class and embarked at Southampton. \n\n```{r}\n#display passengers with missing Fare\nkable(all[which(is.na(all$Fare)), c(\u0027Surname\u0027, \u0027Title\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Age\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Ticket\u0027, \u0027Fare\u0027, \u0027Cabin\u0027, \u0027Embarked\u0027, \u0027Group\u0027)])\n```\n\n```{r}\n#imputing FarePP (as the Fare will be dropped later on anyway)\nall$FarePP[1044] \u003c- 7.8\n```\n\n###The Fare Per Person Variable\n\nAlthough there now are no missing FarePP\u0027s anymore, I also noticed that 17 Fares actually have the value 0. These people are not children that might have traveled for free. I think the information might actually be correct (have people won free tickets?), but I also think that the zero-Fares might confuse the algorithm. For instance, there are zero-Fares within the 1st class passengers. To avoid this possible confusion, I am replacing these values by the median FarePP\u0027s for each Pclass.\n\n```{r}\ntab3 \u003c- all[(!is.na(all$FarePP)),] %\u003e%\n        group_by(Pclass) %\u003e%\n        summarise(MedianFarePP=median(FarePP))\nall \u003c- left_join(all, tab3, by = \u0022Pclass\u0022)\nall$FarePP[which(all$FarePP==0)] \u003c- all$MedianFarePP[which(all$FarePP==0)]\n```\n\nBelow you can see that the FarePP is very skewed. I know that this is not desirable for some algorithms, and can be solved by taking the logarithm or normalisation (preprocessing with centering and scaling). \n\n```{r}\nggplot(all, aes(x=FarePP)) +\n        geom_histogram(binwidth = 5, fill=\u0027blue\u0027) + theme_grey() +\n        scale_x_continuous(breaks= seq(0, 150, by=10))\n```\n\nAnother option is to use Fare Bins instead of keeping the FarePP as a numeric variable. I am using Fare Bin in the GBM model. As there are more FareBins than Pclasses, there is of course some overlap between FareBins and Pclasses.\n\n```{r}\n#Note Hmisc needs to be loaded before dplyr, as the other way around errors occured due to the kernel using the Hmisc summarize function instead of the dplyr summarize function\nall$FareBins \u003c- cut2(all$FarePP, g=5)\n\nggplot(all[!is.na(all$Survived),], aes(x=FareBins, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027) + theme_grey() + facet_grid(.~Pclass)+\n        theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n##Predicting missing Age values\n\nThe density plot below shows that survival chances of children are relatively high. Survival chances of ages 20-30 are below average, and I see less significant differences in the 30+ region. I think there may be a lot of solo travelers in the 20-30 category, which could explain the below averages survival chances. A possible use case of Age could be to use it to identify children. Therefore, I will focus on good looking Age imputations in the region 0-18 years old.\n\n```{r}\nggplot(all[(!is.na(all$Survived) \u0026 !is.na(all$Age)),], aes(x = Age, fill = Survived)) +\ngeom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\u0022Survival density and Age\u0022) +\nscale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()\n```\n\nI first want to visualize the relation between the Age. Title and Pclass seem the most important predictors for Age to me. As you can see below, there are significant differences in Age across the Titles (By the way, this graph tells me that \u0022Masters\u0022 are all very young. I did not know what a master was, but googling it tells me that a master was used as a title for the eldest son only.). Similarly, there differences in Age when looking at the Title/Passenger Class combinations.\n\n```{r}\nggplot(all[!is.na(all$Age),], aes(x = Title, y = Age, fill=Pclass )) +\n  geom_boxplot() + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()\n```\n\nThe title Master seems to be a good predictor for male children. However, female children are included in the Miss title, and of the 263 missing age values, 51 are Misses. If I would just take the median Age of the Titles (possibly also by Pclass), I would at least not predict the missing ages of female children well. I tried both Mice imputation and Linear Regression, and focused on how good the imputations for children looked. The Mice imputations looked reasonable, but I preferred Linear Regression.\n\n```{r}\n#predicting Age with Linear Regression\nset.seed(12000)\nAgeLM \u003c- lm(Age ~ Pclass + Sex + SibSp + Parch + Embarked + Title + GroupSize, data=all[!is.na(all$Age),])\nsummary(AgeLM)\nall$AgeLM \u003c- predict(AgeLM, all)\n```\n\nAs expected, the most significant predictors according to Linear Regression were Passenger Class and Title. Below you can see that the histogram of the predicted values versus the shape of the known ages. The Mice histogram actually looked nicer, but I was wondering how it could predict high ages well given the sparseness of these ages in the original data?\n\n```{r}\npar(mfrow=c(1,2))\nhist(all$Age[!is.na(all$Age)], main=\u0027Original data, non-missing\u0027, xlab=\u0027Age\u0027, col=\u0027green\u0027)\nhist(all$AgeLM[is.na(all$Age)], main= \u0027LM NA predictions\u0027, xlab=\u0027Age\u0027, col=\u0027orange\u0027, xlim=range(0:80))\n```\n\nAs mentioned before, I especially looked at young predicted ages. Both mice and Linear Regression predicted all Masters with missing ages to be children indeed (the one in Linear Regression with a negative age did not bother me that much, as it is categorized as a child anyway). Mice predicted some Mr.\u0027s to be 14 years old, which is too young. As Linear Regression also predicted a reasonable number of Misses to be children, I eventually chose Linear Regression.\n\n```{r}\n#display which passengers are predicted to be children (age\u003c18) with Linear Regression.\nall[(is.na(all$Age) \u0026 all$AgeLM \u003c18), c(\u0027Sex\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Title\u0027, \u0027Pclass\u0027, \u0027Survived\u0027, \u0027AgeLM\u0027)]\n```\n\n```{r}\n#imputing Linear Regression predictions for missing Ages\nindexMissingAge \u003c- which(is.na(all$Age))\nindexAgeSurvivedNotNA\u003c- which(!is.na(all$Age) \u0026 (!is.na(all$Survived))) #needed in sections 4.6 and 4.7\nall$Age[indexMissingAge] \u003c- all$AgeLM[indexMissingAge]\n```\n\nSo now all missing data have been imputed. Am I going to use Age as a predictor in my model? I am not sure yet, as the substantial number of imputations will also add noise. I wil look at using it to create a Child predictor later on.\n\n##What to do with Cabin?\n\nCabin is very sparsely populated. So I either have to ignore it, or use it somehow without making it too specific. On the internet, you can find that that the first letter corresponds to the Deck. Decks A-E are the topdecks and cabins on those decks are mostly first class.\n\n```{r}\n#replacing NAs with imaginary Deck U, and keeping only the first letter of ech Cabin (=Deck)\nall$Cabin[is.na(all$Cabin)] \u003c- \u0022U\u0022\nall$Cabin \u003c- substring(all$Cabin, 1, 1)\nall$Cabin \u003c- as.factor(all$Cabin)\n\nggplot(all[(!is.na(all$Survived)\u0026 all$Cabin!=\u0027U\u0027),], aes(x=Cabin, fill=Survived)) +\n        geom_bar(stat=\u0027count\u0027) + theme_grey() + facet_grid(.~Pclass) + labs(title=\u0022Survivor split by class and Cabin\u0022)\n```\n\nBelow, you can see that there are interesting difference among Decks. For instance, the top Deck (A) was not best place to be. Even Deck F had better survival rates.\n\n```{r}\nc1 \u003c- round(prop.table(table(all$Survived[(!is.na(all$Survived)\u0026all$Cabin!=\u0027U\u0027)], all$Cabin[(!is.na(all$Survived)\u0026all$Cabin!=\u0027U\u0027)]),2)*100)\nkable(c1)\n```\n\nAlthough I feel that Deck and Deck sections (front/back of boat, sections close to stairs et cetera) would be great predictors, I am not using Cabin due to the the sparseness of the data.\n\n##How to deal with Children in the model?\n\nThe survival density plot in the Age section shows that Children below roughly 14.5 (which is also the maximum Age of Masters in the data) have a better survival rate than then other Ages. However, if you look at the imputed Ages below 14.5, you will also see that all these age imputation are for Pclass 3 and most of these children actually died (10 out of 13).\n\nThis makes me wonder if I should add a survival \u0027bonus\u0027 for all Pclasses. Below you can see that most children in P3 actually die. As these children in P3 also include age imputations which may add noise, I decided to exclude P3 from the Child predictor.\n\n```{r, out.width=\u002250%\u0022}\nggplot(all[all$Age\u003c14.5 \u0026 !is.na(all$Survived),], aes(x=Pclass, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027) + theme_grey(base_size = 18)\n```\n\n\n\n```{r}\nall$IsChildP12 \u003c- \u0027No\u0027\nall$IsChildP12[all$Age\u003c=14.5 \u0026 all$Pclass %in% c(\u00271\u0027, \u00272\u0027)] \u003c- \u0027Yes\u0027\nall$IsChildP12 \u003c- as.factor(all$IsChildP12)\n```\n\n\n##What does Embarked tell us?\n\nAlthough I feel that the city of Embarked should not be related to survival rates, I still wanted to check it. As you can see below, there somehow are significant differences between the three ports of embarkment.\n\n```{r}\nd1 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) + theme_grey() + labs(x = \u0027Embarked\u0027, y= \u0027Count\u0027)\nd2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position= \u0027fill\u0027) + theme_grey() + labs(x = \u0027Embarked\u0027, y= \u0027Percent\u0027)\n\ngrid.arrange(d1, d2, nrow=1)\n```\n\nTo get a feel for where this differences may come from, I plotted them against Sex and Pclass. Roughly, differences were:\n\n* Southampton survival rates are worse than Cherbourg in all Pclass/Sex combinations\n* Cherbourg survival rates are better than Queenstown as many 1st class passengers boarded at Cherbourgh, while almost all Queenstown passengers boarded 3rd class (but within 3rd class, female survival rate is better than Cherbourg and male survival rate is worse than Cherbourgh).\n\nMy conclusion is that at least the lower survival rate of Southampton compared to Cherbourg cannot be explained by Pclass or Sex. One thing that I want to look at is the relation between Embarked, Age and Survived, because Linear Regression surprisingly enough also labeled Embarked at Queenstown as a significant predictor for Age. Below I am only using the known Ages of the training data (714 observation = training set - 177 observations with missing Age).\n\n```{r, message=FALSE}\nggplot(all[indexAgeSurvivedNotNA,], aes(x = Age, fill = Survived)) +\ngeom_histogram(aes(fill=factor(Survived))) + labs(title=\u0022Survival density, known-ages, and Embarked\u0022) +\nscale_x_continuous(breaks = scales::pretty_breaks(n = 5)) + theme_grey() + facet_grid(.~Embarked)\n```\n\nThis shows that is very little data for especially Queenstown when looking at known Ages. Below you can see that the total number of people who embarked at Queenstown is low indeed, but especially the high percentage of missing ages in Queenstown is really high. Using imputed ages will therefore add too much noise, and combining Age and Embarked as a predictor is a bad idea.\n\n```{r}\ntab1 \u003c- rbind(table(all$Embarked[!is.na(all$Survived)]),table(all$Embarked[indexAgeSurvivedNotNA]))\ntab1 \u003c- cbind(tab1, (rowSums(tab1)))\ntab1 \u003c- rbind(tab1, tab1[1,]-tab1[2,])\ntab1 \u003c- rbind(tab1, round((tab1[3,]/tab1[1,])*100))\nrownames(tab1) \u003c- c(\u0022All\u0022, \u0022With Age\u0022, \u0022Missing Age\u0022, \u0022Percent Missing\u0022)\ncolnames(tab1) \u003c- c(\u0022C\u0022, \u0022Q\u0022, \u0022S\u0022, \u0022Total\u0022)\nkable(tab1)\n```\n\nThe only other thing that I can think of that might explain the differences is that probably people from the different embarkement cities are somehow grouped on certain sections of the decks. \n\nI kept Embarked in my model in early versions. However, it gradually became clear that Embarked does not add anything and I am not using it anymore.\n\n##Ticket survivors\n\nThis variable checks if any people in a group survived. The idea is that if anyone in a certain group survived, chances of others also surviving are higher. I did this using the Ticket information, and it improved the scores.\n\n```{r}\nTicketSurvivors \u003c- all %\u003e%\n        group_by(Ticket) %\u003e%\n        summarize(Tsize = length(Survived),\n                  NumNA = sum(is.na(Survived)),\n                  SumSurvived = sum(as.numeric(Survived)-1, na.rm=T))\n```\n\n```{r}\nall \u003c- left_join(all, TicketSurvivors)\nall$AnySurvivors[all$Tsize==1] \u003c- \u0027other\u0027\nall$AnySurvivors[all$Tsize\u003e=2] \u003c- ifelse(all$SumSurvived[all$Tsize\u003e=2]\u003e=1, \u0027survivors in group\u0027, \u0027other\u0027)\nall$AnySurvivors \u003c- as.factor(all$AnySurvivors)\n\nkable(x=table(all$AnySurvivors), col.names= c(\u0027AnySurvivors\u0027, \u0027Frequency\u0027))\n```\n\n##Adding an \u0022Is Solo\u0022 variable\u0022 based on Siblings and Spouse (SibSp) only\n\nIn an earlier version, I experimented with an \u0022IsSolo\u0022 predictor that was based on the Group size. However, this double counted the Group categories too much and did not work. Eventually, I added an IsSolo predictor that is only based on the SibSp information. Using this predictor in the SVM model leads to slightly better results.\n\n```{r, out.width=\u002250%\u0022}\nall$IsSolo[all$SibSp==0] \u003c- \u0027Yes\u0027\nall$IsSolo[all$SibSp!=0] \u003c- \u0027No\u0027\nall$IsSolo \u003c- as.factor(all$IsSolo)\n\nggplot(all[!is.na(all$Survived),], aes(x = IsSolo, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) + theme_grey(base_size = 18)\n```\n\n#Predictions (with caret cross validation)\n\n```{r, echo=FALSE}\n#cleaning up\nall$PassengerId \u003c- NULL\nall$SibSp \u003c- NULL\nall$Parch \u003c- NULL\nall$Ticket \u003c- NULL\nall$Fare \u003c- NULL\nall$Cabin \u003c- NULL\nall$Surname \u003c- NULL\nall$Fsize \u003c- NULL\nall$FsizeName \u003c- NULL\nall$Favg \u003c- NULL\nall$Tsize \u003c- NULL\n#all$Group \u003c- NULL\nall$Ticket2 \u003c- NULL\nall$AgeLM \u003c- NULL\nall$Child \u003c- NULL\nall$HasParch \u003c- NULL\nall$MedianFarePP \u003c- NULL\nrm(tab1); rm(tab2); rm(tab3); rm(AgeLM); rm(c1); rm(d1); rm(d2);\n```\n\nAltogether, I created predictions with 3 different algorithms. In addition, I tried to combine (ensemble) the models in 3 different ways. This ensemble further improved the scores.\n\n```{r}\n#splitting data into train and test set again\ntrainClean \u003c- all[!is.na(all$Survived),]\ntestClean \u003c- all[is.na(all$Survived),]\n```\n\n##Random Forest model\nI started this analysis with just a Random Forest model, as it is known for high accuracy and limiting overfitting.\n\nAlthough the formula function must be used with many algorithms, it is better to not use it with Random Forest as this causes issues with weights of predictors. I am just using 5 predictors.\n\n```{r}\nset.seed(2017)\ncaret_matrix \u003c- train(x=trainClean[,c(\u0027PclassSex\u0027, \u0027GroupSize\u0027, \u0027FarePP\u0027, \u0027AnySurvivors\u0027, \u0027IsChildP12\u0027)], y=trainClean$Survived, data=trainClean, method=\u0027rf\u0027, trControl=trainControl(method=\u0022cv\u0022, number=5))\ncaret_matrix\ncaret_matrix$results\n```\n\n```{r}\nvarImpPlot(caret_matrix$finalModel, main=\u0022 Variable importance\u0022)\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_rf \u003c- predict(caret_matrix, testClean)\n```\n\n##Support Vector Machine (SVM) model\n\nThe second algorithm that I want to use is SVM, as it is known to work well with small datasets. As I am only having a few predictors and relatively many observation, I am choosing svmRadial (Gaussian) over svmLinear.\n\n```{r}\nset.seed(2017)\ncaret_svm \u003c- train(Survived~ PclassSex + FarePP + AnySurvivors + IsChildP12 + IsSolo, data=trainClean, method=\u0027svmRadial\u0027, preProcess= c(\u0027center\u0027, \u0027scale\u0027), trControl=trainControl(method=\u0022cv\u0022, number=5))\ncaret_svm\ncaret_svm$results\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_svm \u003c- predict(caret_svm, testClean)\n```\n\n##Gradient Boosting Machine (GBM) model\n\nAs I am already having a model that uses Bagging, I want the 3rd model to be a boosting model. Of the possible boosting algorithms, I am choosing GBM.\n\n```{r}\nset.seed(2017)\ncaret_boost \u003c- train(Survived~ PclassSex + GroupSize + FareBins + AnySurvivors + IsChildP12, data=trainClean, method=\u0027gbm\u0027, preProcess= c(\u0027center\u0027, \u0027scale\u0027), trControl=trainControl(method=\u0022cv\u0022, number=7), verbose=FALSE)\nprint(caret_boost)\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_boost \u003c- predict(caret_boost, testClean)\n```\n\n##Combining models\n\n### Majority vote ensemble of the three models\n\nA simple majority vote a multiple good models can help to increase accuracy. This idea is really well explained in [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/). It works best with multiple good models that are as uncorrelated as possible.\n\n```{r}\n#adding model predictions to test dataframe\ntestClean$RF \u003c- as.numeric(solution_rf)-1\ntestClean$SVM \u003c- as.numeric(solution_svm)-1\ntestClean$Boost \u003c- as.numeric(solution_boost)-1\n\n#compose correlations plot\ncorrplot.mixed(cor(testClean[, c(\u0027RF\u0027, \u0027SVM\u0027, \u0027Boost\u0027)]), order=\u0022hclust\u0022, tl.col=\u0022black\u0022)\n```\n\nGiven the fact that all three models have decent public scores, especially the correlation between SVM and the GBM model is surprisingly low. The most likely explanation is that SVM really is a different algorithm (both other models are tree-based).\n\nThe idea is very simple:\n\n* If 0 or 1 model predicts \u0027Survived\u0027, the overall prediction will be \u0027Died\u0027\n* If 2 or 3 models predict \u0027Survived\u0027, the overall prediction will be \u0027Survived\u0027\n\n```{r}\n\ntestClean$Sum \u003c- testClean$RF + testClean$SVM + testClean$Boost\ntestClean$Majority \u003c- ifelse(testClean$Sum\u003c=1, 0, 1)\n```\n\n###Taking predictions from one model, unless the others both disagree\n\nAlthough I have done my best to avoid over fitting as much as possible (by for instance not using the Titles), the high cross validation scores of both RF and GBM are an indication that these 2 models still overfit somewhat.\n\nThe best kernels on Kaggle show that a public score of around 0.82 - 0.83 is likely to be the maximum achievable test accuracy. The cross validation score of the SVM model is exactely in this range. Probably even more importantly, a low AccuracySD seems more important than the Accuracy itself regarding Public Scores. As the SVM also has a really low AccuracySD, I am going to use SVM as my best model. In this second framework, I am taking the SVM predictions unless both RF and GBM disagree with the SVM prediction.\n\n```{r}\ntestClean$DisagreeSVM \u003c- ifelse(testClean$RF==testClean$Boost \u0026 testClean$SVM != testClean$RF, testClean$RF, testClean$SVM)\n```\n\n###Selectively combining models for PclassSex combinations\nAnother idea is to select the model that seems best for each PclassSex combination. When looking at predictions on the training set, issues seem similar in all models. All produce tend to produce False Negatives for men (men predicted to die, but survived), and False Positives for women (predicted to survive, but died). \n\n```{r}\n#predictions of the models on the training set\ntrainClean$RF \u003c- predict(caret_matrix, trainClean)\ntrainClean$SVM \u003c- predict(caret_svm, trainClean)\ntrainClean$Boost \u003c- predict(caret_boost, trainClean)\n\n\n#plot differences between actual survived and predictions\nf1 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$RF,], aes(x=PclassSex, fill=RF)) +\n        geom_bar(stat=\u0027count\u0027) + labs(title=\u0022FP and FN, RF model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\nf2 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$SVM,], aes(x=PclassSex, fill=SVM)) +\n        geom_bar(stat=\u0027count\u0027)+ labs(title=\u0022FP and FN, SVM model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\nf3 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$Boost,], aes(x=PclassSex, fill=Boost)) +\n        geom_bar(stat=\u0027count\u0027)+ labs(title=\u0022FP and FN, GBM model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\ngrid.arrange(f1, f2, f3, nrow = 1)\n```\n\nA noticable difference however is that the SVM model also produced a significant amount of False Positives in P3Male (the blue part). As the survival rate of men in P3 was really low, this large amount of False Positives seems a bad sign.\n\nWhat I now could do is take SVM as the base model, but take GBM for the P3 predictions.\n\n```{r}\n#selecting SVM prediction, and GMB predictions for P3\ntestClean$Select \u003c- ifelse(testClean$Pclass != 3, testClean$SVM, testClean$Boost)\n```\n\nThe best framework turned out to be the combination of SVM for P1 and P2, and GBM for P3. The majority voting and \u0027take SVM unless both RF and GBM disagree\u0027 did not improve my score. However, chances are that these methods will also improve the scores if I add a few more good models. This should decrease of 2 (alternative) models both getting a prediction wrong.\n\n```{r}\n#writing final submission file\nsubmission_select \u003c- data.frame(PassengerId = test$PassengerId, Survived = testClean$Select)\nwrite.csv(submission_select, file = \u0027Titanic_select.csv\u0027, row.names = F)\n```\n\n##Where is room for improvement?\n\n###How to fix Male in 1st class issues?\nThis class is hard to predict, as 37% of men in P1 survived while men overall have a much lower survival rate. As shown in the previous section, predictions include many False Negatives. Many False Negatives means that the predicted number of survivors on the test set is likely to be too low. As you can see below, all models predict the survival rate of this group to be significantly lower than 37% indeed (.37*57=21 survivors).\n\n```{r}\ncat(\u0027Total number of Male passengers in P1 in the test set is\u0027, length(testClean$Survived[testClean$PclassSex==\u0027P1Male\u0027]))\n\np1m_surv \u003c- as.data.frame(sapply(testClean[testClean$PclassSex==\u0027P1Male\u0027, c(\u0027RF\u0027, \u0027SVM\u0027, \u0027Boost\u0027)], function(x) {sum(x)}))\nkable(x=p1m_surv, col.names = c(\u0027Predicted number of survivors\u0027))\n```\n\nAlthough SVM only predicts 2 survivors, these 2 are in fact the 2 children in this class. This might actually be the best bet, if survival is hard to predict (predicting dead is better when unclear as the majority died).\n\nI do not know if the survival rate of P1Male in the test set is also 37%, but it seems likely that the predicted survival rate for this group is too low in all models. Therefore, I have looked for angles to \u0027reliably\u0027 increase this number. As you can see below, there is a significant difference in survival density of men below and above appromimately 40. So the survival \u0027bonus\u0027 that children have in general, is for P1Male \u0027extended\u0027 to 40.\n\nI have actually tried to include this exception in the models, but It did not improve the scores. I assume this is because the survival rate in P1Male under 40 now really gets close to 50/50, which makes it very hard to predict with some degree of certainty.\n\n```{r}\np1m1 \u003c- ggplot(all[indexAgeSurvivedNotNA,] %\u003e% filter(PclassSex==\u0027P1Male\u0027), aes(x = Age, fill = Survived)) + geom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\u0022Survival density and Age P1 Male\u0022) + theme_grey()\n\nall$P1AgeMale[indexAgeSurvivedNotNA=T \u0026 all$PclassSex==\u0027P1Male\u0027 \u0026 all$Age\u003c40] \u003c- \u0027Under40\u0027\nall$P1AgeMale[indexAgeSurvivedNotNA=T \u0026 all$PclassSex==\u0027P1Male\u0027 \u0026 all$Age\u003e=40] \u003c- \u0027Over40\u0027\n\np1m2 \u003c- ggplot(all[!is.na(all$Survived) \u0026 !is.na(all$P1AgeMale),], aes(x=P1AgeMale, fill=Survived))+\n        geom_bar(stat = \u0027count\u0027, position = \u0027fill\u0027) + theme(legend.position=\u0022none\u0022)\n\n\ngrid.arrange(p1m1, p1m2, widths=c(2,1))\n```\n\n###How to fix Female in 3rd class issues?\nFemales in 3rd class have an overall 50/50 survival chance, which is hard to predict. In the previous section, P3Female showed many False Positives. This was expected, as women generally survived. Similar to the males in P1, I found something that is specific to this group.\n\nAs you can see below, solo women (based on SibSp) had better chances of survival in all Pclasses. This is especially relevant to the women in P3, as differences in P2Female and P1Female are small while they mostly survived anyway. In previous versions, I tried a different IsSolo predictor (based on Fsize), and did not manage to model this exception succesfully. However, it may be worth trying a Male/Female split with the IsSolo predictor based on SibSp only.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x=IsSolo, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027, position=\u0027fill\u0027) + facet_grid(.~Pclass+Sex)\n```\n\n\n","dateCreated":"2018-03-28T10:58:56.927Z"},"kernelRun":{"id":2972542,"kernelId":786539,"status":"complete","type":"batch","sourceType":"script","language":"rmarkdown","title":"Titanic: 2nd degree families and majority voting","dateCreated":"2018-03-28T10:58:56.927Z","dateEvaluated":"2018-03-28T10:58:58.177Z","workerContainerPort":null,"workerUptimeSeconds":300203,"workerIPAddress":"172.16.8.3     ","scriptLanguageId":5,"scriptLanguageName":"RMarkdown","renderedOutputUrl":"https://www.kaggleusercontent.com/kf/2972542/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0.._xzhn2WYmC8qwSNLRXa0Ag.sTTpbaaRjhOepYhV5-yAMMvLCxDejPd8QXvrdG1SSQ55CbkMVHBsqSDkrASn7tIvfZvDn85k5tvIYbtHdLzN8IJJy3NZtdCG-ran1RFOPBzNVBqRLXqKUHtPv7FJmeOHjArevbYAJG_8P-CZKz8LqBYka6k3kk7a5Y3BwCegOqoqxH20HfoV_bTozQDnhnUM.yXupOsRzfkk4A2zbU_n3NQ/__results__.html","commit":{"id":5402226,"settings":{"dockerImageVersionId":47,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"rmarkdown","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Finding the \u0027real\u0027 families on the Titanic, and majority vote ensemble\u0022\nauthor: \u0022Erik Bruin\u0022\noutput:\n  html_document:\n    number_sections: true\n    toc: true\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n#Executive Summary\nThis project is my first attempt to compete in a Kaggle Machine Learning competition in which we have to predict who survived the Titanic disaster. I enjoyed it very much and learned a lot. Key findings were:\n\n* My key to success was to dive deep into groups of people that traveled together. My grouping variable is different when compared to other kernels that I have looked at.\n* The main things that I have done that I have not seen in any other kernels yet is the grouping of \u0027second degree\u0027 family members. Uncles, grandparents, cousins, and brothers/sisters-in-law can actually be found in the data.\n* My public score on Kaggle is 0.81818. As this is a top4% score, I am pretty pleased with the result.\n* I am just using 5 predictors. A significant difference with most kernels is that I eventually got rid of the Title variable. I believe that the models are much cleaner model now as the Title variance double counts the Sex/Gender variance (and also male children (called Masters)).\n* My analysis includes three models: a Random Forest model, a Support Vector Machine (SVM) model, and a Gradient Boosting Machine (GBM) model.\n* I included three frameworks that combine models.\n    * The first one is a simple voting ensemble that takes the majority vote of 3 models.\n    * The second framework is similar. It takes the predictions from one model (the best model), and only changes the prediction if both other models disagree with that best model.\n    * The third thing that I tried is selectively using models for specific categories.\n* The best results were achieved by using the SVM model for 1st and 2nd class passengers, and use the GBM model for 3rd class passengers. \n\n#Introduction\n\nKaggle describes this competition as [follows](https://www.kaggle.com/c/titanic):\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n\u003ccenter\u003e\u003cimg src=\u0022https://vignette.wikia.nocookie.net/jamescameronstitanic/images/5/55/Titanic_sinking.jpg/revision/latest?cb=20130918052255\u0022 style=\u0022width: 600px;\u0022/\u003e\u003c/center\u003e\n\n# Loading and Exploring Data\n\n##Loading libraries required and reading the data into R\n\nLoading R packages used besides base R.\n\n```{r, message=FALSE, warning=FALSE}\nlibrary(Hmisc)\nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(caret)\nlibrary(randomForest)\nlibrary(gridExtra)\nlibrary(ROCR)\nlibrary(corrplot)\n```\n\nBelow, I am reading the csv\u0027s as dataframes into R.\n\n```{r}\ntrain \u003c- read.csv(\u0022../input/train.csv\u0022, stringsAsFactors = F, na.strings = c(\u0022NA\u0022, \u0022\u0022))\ntest \u003c- read.csv(\u0022../input/test.csv\u0022, stringsAsFactors = F, na.strings = c(\u0022NA\u0022, \u0022\u0022))\n```\n\n##Data size and structure\n\nThe training set consist of 891 observations and 12 variables. I have read all the \u0022factors\u0022 (for instance male/female) into R as character strings, as some of them require processing first.\n\n```{r}\nstr(train)\n```\n\nA description of each variable, including description of some key values, is given below.\n\nVariable Name | Description                       |Key\n--------------|-----------------------------------|----------------------------------------------\nSurvived      | Survival                          |0 = No, 1 = Yes\nPclass        | Passenger\u0027s class                 |1 = 1st, 2 = 2nd, 3 = 3rd\nName          | Passenger\u0027s name                  |\nSex           | Passenger\u0027s sex                   |\nAge           | Passenger\u0027s age                   |\nSibSp         | Number of siblings/spouses aboard |\nParch         | Number of parents/children aboard |\nTicket        | Ticket number                     |\nFare          | Fare                              |\nCabin         | Cabin                             |\nEmbarked      | Port of embarkation               |C = Cherbourg, Q = Queenstown, S = Southampton\n--------------------------------------------------------------------------------------------------\n\nThe test set consists of 418 observations, with the variable \u0022Survived\u0022 missing compared to the training set. \u0022Creating\u0022 this variable is eventually the purpose of this project.\n\nBelow I am merging test and train, as this is required for data cleaning and feature engineering.\n\n```{r}\ntest$Survived \u003c- NA\nall \u003c- rbind(train, test)\n```\n\n\n##Completeness of the data\n\nFirst of all, I would like to see which variables contain missing values (blanks are also imported as NA (=Not Available)).\n\n```{r}\nsapply(all, function(x) {sum(is.na(x))})\n```\n\nOf course, the 418 NAs in Survived is the total number is observations in the test set. So this variable is what it should be (No NAs in train). Of the other variables, Cabin is sparsely populated. Age is also missing a substantial number of values. In addition, Embarked is missing two values and one Fare value is missing.\n\n##Exploring some of the most important variables\n\nOur response variable in the training set is complete, as well as Sex and Pclass, which seem two of the most important predictors. Since they are complete and tidy, I am converting them into factors.\n\n```{r}\nall$Sex \u003c- as.factor(all$Sex)\nall$Survived \u003c- as.factor(all$Survived)\nall$Pclass \u003c- as.ordered(all$Pclass) #because Pclass is ordinal\n```\n\n###The response variable; Survived\nOf course, the very first thing that I want to do is explore the response variable. How many people survived, and how many died? You can see this below. Altogether, of the people in the training set (891 observations) 61.6% died. For the remaining 418 observations (test set), this is what we have to predict.\n\n```{r, out.width=\u002250%\u0022}\nggplot(all[!is.na(all$Survived),], aes(x = Survived, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) +\n  labs(x = \u0027How many people died and survived on the Titanic?\u0027) +\n        geom_label(stat=\u0027count\u0027,aes(label=..count..), size=7) +\n        theme_grey(base_size = 18)\n```\n\n\n###Sex/gender\n\nOf the 1309 people on the Titanic, a majority of 64.4% was male. This percentage was almost the same in the training data (64.7%). Within the training data 81.1% of the men died, and 25.8% of the women died. Due to this large difference, Sex/gender seems a very important predictor.\n\n```{r}\np1 \u003c- ggplot(all, aes(x = Sex, fill = Sex)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + theme_grey() +\n  labs(x = \u0027All data\u0027) +\n        geom_label(stat=\u0027count\u0027, aes(label=..count..)) +\n        scale_fill_manual(\u0022legend\u0022, values = c(\u0022female\u0022 = \u0022pink\u0022, \u0022male\u0022 = \u0022green\u0022))\np2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Sex, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + theme_grey() +\n  labs(x = \u0027Training data only\u0027) +\n        geom_label(stat=\u0027count\u0027, aes(label=..count..))\n\ngrid.arrange(p1,p2, nrow=1)\n```\n\n###Passenger Class\n\nAs you can see below, most people traveled in 3rd class. Also, as expected, survival is strongly correlated with the passenger class. A majority of first class passengers survived, and most people in 3rd class died. It is also noticable that almost all women in 1st and 2nd class survived. For men, 2nd class was almost as bad as 3rd class.\n\n```{r, out.width=\u0022100%\u0022}\np3 \u003c- ggplot(all, aes(x = Pclass, fill = Pclass)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  labs(x = \u0027Pclass, All data\u0027) + geom_label(stat=\u0027count\u0027, aes(label=..count..)) +\n   theme(legend.position=\u0022none\u0022) + theme_grey()     \np4 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) + labs(x = \u0027Training data only\u0027) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\np5 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027stack\u0027) +\n  labs(x = \u0027Training data only\u0027, y= \u0022Count\u0022) + facet_grid(.~Sex) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\np6 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027fill\u0027) +\n  labs(x = \u0027Training data only\u0027, y= \u0022Percent\u0022) + facet_grid(.~Sex) +\n        theme(legend.position=\u0022none\u0022) + theme_grey()\n\ngrid.arrange(p3, p4, p5, p6, ncol=2)\n```\n\nIn early version, I have been working with Pclass and Sex as separate predictors. However, I realized that the \u0027headline\u0027 of the model should actually be a combination of the two (also thanks to Oscar Takeshita, who also uses this idea in his excellent analysis. See: [Divide and Conquer [0.82296]](https://www.kaggle.com/pliptor/divide-and-conquer-0-82296)). Details that are lost when using the predictors separately were actually already mentioned in the beginning of this section (Pclass 1 and 2 are almost guaranteed survival for women, and Pclass 2 is almost as bad as Pclass 3 for men).\n\n```{r}\nall$PclassSex[all$Pclass==\u00271\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P1Male\u0027\nall$PclassSex[all$Pclass==\u00272\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P2Male\u0027\nall$PclassSex[all$Pclass==\u00273\u0027 \u0026 all$Sex==\u0027male\u0027] \u003c- \u0027P3Male\u0027\nall$PclassSex[all$Pclass==\u00271\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P1Female\u0027\nall$PclassSex[all$Pclass==\u00272\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P2Female\u0027\nall$PclassSex[all$Pclass==\u00273\u0027 \u0026 all$Sex==\u0027female\u0027] \u003c- \u0027P3Female\u0027\nall$PclassSex \u003c- as.factor(all$PclassSex)\n```\n\n#Feature engineering\n\nWhile I also started by using the Title as a variable, I am not using it anymore. Although most kernals use it, I believe it double counts variance to much (overfitting). While I am not using the Title directly anymore in my prediction models, it needs to stay in the analysis as it is used to predict missing Ages in section 4.4.\n\n##Creating the Title variable\n\nThe name variable is complete (no NAs), but actually contains more than just a first name and surname. It also contains a Title for each person, which must be separated from the name to obtain tidy data. I am also saving the Surname (first part of the name variable, before the title), as I want to investigate the effects of families traveling together later on (matching with #siblings/spouses and #parents/children).\n\n```{r}\n#Extracting Title and Surname from Name\nall$Surname \u003c- sapply(all$Name, function(x) {strsplit(x, split=\u0027[,.]\u0027)[[1]][1]})\n #correcting some surnames that also include a maiden name\nall$Surname \u003c- sapply(all$Surname, function(x) {strsplit(x, split=\u0027[-]\u0027)[[1]][1]})\nall$Title \u003c- sapply(all$Name, function(x) {strsplit(x, split=\u0027[,.]\u0027)[[1]][2]})\nall$Title \u003c- sub(\u0027 \u0027, \u0027\u0027, all$Title) #removing spaces before title\nkable(table(all$Sex, all$Title))\n```\n\nAfter seeing this, I want to reducing the number of titles to create better and more substantial Titles that can be used for prediction. Ms. is usually used for younger married women. I will therefore join this one with Miss. I assume that Mlle stands for Mademoiselle in French. I will also join this category with Miss. I also assume that Mme stands for Madame, and I will join Madame with Mrs. For the titles with low frequecies, I will create one new category.\n\n```{r}\nall$Title[all$Title %in% c(\u0022Mlle\u0022, \u0022Ms\u0022)] \u003c- \u0022Miss\u0022\nall$Title[all$Title== \u0022Mme\u0022] \u003c- \u0022Mrs\u0022\nall$Title[!(all$Title %in% c(\u0027Master\u0027, \u0027Miss\u0027, \u0027Mr\u0027, \u0027Mrs\u0027))] \u003c- \u0022Rare Title\u0022\nall$Title \u003c- as.factor(all$Title)\nkable(table(all$Sex, all$Title))\n```\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Title, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027stack\u0027) +\n  labs(x = \u0027Title\u0027) +theme_grey()\n```\n\n##Finding groups of people traveling together\n\n###Families; siblings, spouses, parents and children\n\nIn order to create the family size for each person on the boat, I will add up his/her number of parents/children, his/her number of siblings/spouses, and of course add one (the person himself).\n\n```{r, message=FALSE}\n#creating family size variable (Fsize)\nall$Fsize \u003c- all$SibSp+all$Parch +1\n```\n\nBelow, you can easily see that solo travelers had a much higher chance to die than to survive. In addition, people traveling in families of 2-4 people actually had a relatively high chance to survive. This chance is significantly lower among 5+ families.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Fsize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Family Size\u0027) + theme_grey()\n```\n\nWhat I now could do is convert these family sizes into categories (solo, small family, large family), but I first want to check if there are any inconsistencies in the data.\n\n###Family Size inconsistencies, and correcting the effects of a cancellation\n\nTo check the family size data for inconsistencies, I am creating a variable that combines the surname and the Fsize. After that, I am going to check where these combinations lead to strange numbers of families.\n\n```{r}\n#composing variable that combines total Fsize and Surname\nall$FsizeName \u003c- paste(as.character(all$Fsize), all$Surname, sep=\u0022\u0022)\n\nSizeCheck \u003c- all %\u003e%\n        group_by(FsizeName, Fsize) %\u003e%\n        summarise(NumObs=n())\nSizeCheck$NumFam \u003c- SizeCheck$NumObs/SizeCheck$Fsize\nSizeCheck$modulo \u003c- SizeCheck$NumObs %% SizeCheck$Fsize\nSizeCheck \u003c- SizeCheck[SizeCheck$modulo !=0,]\nsum(SizeCheck$NumObs) #total number of Observations with inconsistencies\nkable(SizeCheck[SizeCheck$FsizeName %in% c(\u00273Davies\u0027, \u00275Hocking\u0027, \u00276Richards\u0027, \u00272Wilkes\u0027, \u00273Richards\u0027, \u00274Hocking\u0027),]) #only display some inconsistencies that are discussed in the text\n\n```\n\nAs you can see, this check does not always add up to a round number of families (for a total of 93 passengers). A quick internet search learns us that the passenger list seems complete as there were around 1300 passengers on board indeed (the rest of the people on the boat were crew). Some inconsistencies can likely be explained by cancellations (SibSp and Parch info not updated after a cancellation). For instance: there must have been two Davies families on board, while the SizeCheck only shows five obervations for FsizeName \u00273Davies\u0027. \n\n```{r}\nkable(all[all$FsizeName==\u00273Davies\u0027,c(2,3,14,5,6,7,8,17,9,15)])\n```\n\nThe Davies\u0027 on Tickets A/4 48871 and A/4 48873 are very likely a complete group. The error seems to be that Mrs Davies [1222] was supposed to travel with 2 children, but eventually only traveled with one son (Master Davies [550]). A quick internet search told me that a person with the name Davies cancelled his trip indeed due to illness. Let\u0027s correct this info.\n\n```{r}\nall$FsizeName[c(550, 1222)] \u003c- \u00272Davies\u0027\nall$SibSp[550] \u003c- 0\nall$Parch[1222] \u003c- 1\nall$Fsize[c(550, 1222)] \u003c- 2\nkable(all[all$FsizeName==\u00272Davies\u0027,c(2,3,14,5,6,7,8,17,9,15)])\n```\n\nI believe that there could be more cancellations that were not administered fully correctly, but I also think that the effects on the final models is likely to be very minor. So let\u0027s move on to the next section quickly.\n\n###Families; what about uncles, aunts, cousins, nieces, grandparents, brothers/sisters-in law?\n\nI found out that there is something \u0027hidden\u0027 in this information that seems more interesting than a few cancellations. For instance, it turns out that the Hockings and the Richards\u0027 are related. The connection here is that passenger 438 travels with 2 children, 1 parent, a brother and a sister. For her, all these people count are direct family. However, other people are linked indirectly. For the 2 children for instance, only the brother and mother count as direct family. This leads to Fsizes that cannot be compared to most families as \u0027apples to apples\u0027. Their Fsizes are generally too high, as it is likely that those people have split up into smaller groups. The mother may have stayed with her children, while the brother and sister probably have stayed with the grandmother.\n\nNote: this family is actually even more complex, as the grandmother also travels with a sister with the same maiden name. However, as this really seems an exception and the other Mrs Needs already has the very reasonable Fsize of 2 (it\u0027s  Mrs Wilkes Needs), I am not taking her into consideration.\n\n```{r}\nkable(all[all$Ticket %in% c(\u002729104\u0027, \u002729105\u0027, \u002729106\u0027),c(2,3,4,5,6,7,8,9,15)])\n```\n\nIn order to fix this, I first have to \u0027glue\u0027 those families together using maiden names.\n\n```{r}\nNC \u003c- all[all$FsizeName %in% SizeCheck$FsizeName,] #create data frame with only relevant Fsizenames\n\n#extracting maiden names\nNC$Name \u003c- sub(\u0022\\\\s$\u0022, \u0022\u0022, NC$Name) #removing spaces at end Name\nNC$Maiden \u003c- sub(\u0022.*[^\\\\)]$\u0022, \u0022\u0022, NC$Name) #remove when not ending with \u0027)\u0027\nNC$Maiden \u003c- sub(\u0022.*\\\\s(.*)\\\\)$\u0022, \u0022\\\\1\u0022, NC$Maiden)\nNC$Maiden[NC$Title!=\u0027Mrs\u0027] \u003c- \u0022\u0022 #cleaning up other stuff between brackets (including Nickname of a Mr)\nNC$Maiden \u003c- sub(\u0022^\\\\(\u0022, \u0027\u0027, NC$Maiden) #removing opening brackets (sometimes single name, no spaces between brackets)\n#making an exceptions match\nNC$Maiden[NC$Name==\u0027Andersen-Jensen, Miss. Carla Christine Nielsine\u0027] \u003c- \u0027Jensen\u0027\n\n#take only Maiden names that also exist as surname in other Observations\nNC$Maiden2[NC$Maiden %in% NC$Surname] \u003c- NC$Maiden[NC$Maiden %in% NC$Surname] \n#create surname+maiden name combinations\nNC$Combi[!is.na(NC$Maiden2)] \u003c- paste(NC$Surname[!is.na(NC$Maiden2)], NC$Maiden[!is.na(NC$Maiden2)])\n\n#create labels dataframe with surname and maiden merged into one column\nlabels1 \u003c- NC[!is.na(NC$Combi), c(\u0027Surname\u0027,\u0027Combi\u0027)]\nlabels2 \u003c- NC[!is.na(NC$Combi), c(\u0027Maiden\u0027,\u0027Combi\u0027)]\ncolnames(labels2) \u003c- c(\u0027Surname\u0027, \u0027Combi\u0027)\nlabels1 \u003c- rbind(labels1, labels2)\n\nNC$Combi \u003c- NULL\nNC \u003c- left_join(NC, labels1, by=\u0027Surname\u0027)\n\n#Find the maximum Fsize within each newly found \u0027second degree\u0027 family\nCombiMaxF \u003c- NC[!is.na(NC$Combi),] %\u003e%\n        group_by(Combi) %\u003e%\n        summarise(MaxF=max(Fsize)) #summarise(MaxF=n())\nNC \u003c- left_join(NC, CombiMaxF, by = \u0022Combi\u0022)\n\n#create family names for those larger families\nNC$FsizeCombi[!is.na(NC$Combi)] \u003c- paste(as.character(NC$Fsize[!is.na(NC$Combi)]), NC$Combi[!is.na(NC$Combi)], sep=\u0022\u0022)\n\n#find the ones in which not all Fsizes are the same\nFamMaid \u003c- NC[!is.na(NC$FsizeCombi),] %\u003e%\n        group_by(FsizeCombi, MaxF, Fsize) %\u003e%\n        summarise(NumObs=n())\nFamMaidWrong \u003c- FamMaid[FamMaid$MaxF!=FamMaid$NumObs,]\n\nkable(unique(NC[!is.na(NC$Combi) \u0026 NC$FsizeCombi %in% FamMaidWrong$FsizeCombi, c(\u0027Combi\u0027, \u0027MaxF\u0027)]))\n```\n\nAs you can see, 7 combinations (total of 28 passengers) are found as families with not all members having the same Fsize, which means that they are broader families with non-direct family links included. Before I decided what to do with these, I first have to find the families who are similarly linked on the \u0027male\u0027 side.\n\n```{r}\nNC$MaxF \u003c- NULL #erasing MaxF column maiden combi\u0027s\n\n#Find the maximum Fsize within remaining families (no maiden combi\u0027s)\nFamMale \u003c- NC[is.na(NC$Combi),] %\u003e%\n        group_by(Surname) %\u003e%\n        summarise(MaxF=max(Fsize))\nNC \u003c- left_join(NC, FamMale, by = \u0022Surname\u0022)\n\nNCMale \u003c- NC[is.na(NC$Combi),] %\u003e%\n        group_by(Surname, FsizeName, MaxF) %\u003e%\n        summarise(count=n()) %\u003e%\n        group_by(Surname, MaxF) %\u003e%\n        filter(n()\u003e1) %\u003e%\n        summarise(NumFsizes=n())\n\nNC$Combi[NC$Surname %in% NCMale$Surname] \u003c- NC$Surname[NC$Surname %in% NCMale$Surname]\n\nkable(NCMale[, c(1,2)])\n```\n\nExample. Mr Julius Vander Planke is traveling with a spouse and 2 siblings. His spouse and siblings (brothers/sisters-in-law) are \u0027indirectly\u0027 related to each other.\n\n```{r}\nkable(all[all$Surname==\u0027Vander Planke\u0027, c(2,3,4,5,6,7,8,9,15)])\n```\n\nThis means that altogether, there are 9 families (37 passengers) that include \u0027second degree\u0027 family members. What I want to do is give each member in such family the same Fsize (which gives everybody in these families the same survival chances with regards to the group variable). I have chosen to make this the average of the Fsize (which are based on siblings/spouse/parents/children only).\n\n```{r}\n#selecting those 37 passengers In Not Correct dataframe\nNC \u003c- NC[(NC$FsizeCombi %in% FamMaidWrong$FsizeCombi)|(NC$Surname %in% NCMale$Surname),]\n\n#calculating the average Fsize for those 9 families\nNC1 \u003c- NC %\u003e%\n        group_by(Combi) %\u003e%\n        summarise(Favg=mean(Fsize))\nkable(NC1)\n```\n\nA result is that for instance the Fsize is 4 for all 6 people in the Richards-Hockings family. This exactly what I wanted, as I wanted to combine those people into a group with all members having the same Fsize (to give equal survival chances to all members within the group) but also not the maximum size as they are less likely to stay together than first degree families.\n\n```{r}\nNC \u003c- left_join(NC, NC1, by = \u0022Combi\u0022) #adding Favg to NC dataframe \nNC$Favg \u003c- round(NC$Favg) #rounding those averages to integers\nNC \u003c- NC[, c(\u0027PassengerId\u0027, \u0027Favg\u0027)]\nall \u003c- left_join(all, NC, by=\u0027PassengerId\u0027)\n\n#replacing Fsize by Favg\nall$Fsize[!is.na(all$Favg)] \u003c- all$Favg[!is.na(all$Favg)]\n```\n\n###Can we still find more second degree families?\n\nAm I still missing some second degree families? Yes, at it appears that some people traveling solo with the same surname have tickets with almost the same number!\n\n```{r}\n#creating a variable with almost the same ticket numbers (only last 2 digits varying)\nall$Ticket2 \u003c- sub(\u0022..$\u0022, \u0022xx\u0022, all$Ticket)\n```\n\nAs they have no sibling/spouses and no parents/children, these people are likely cousins/uncles. If you look deeper into the data, you will see that these groups of cousins/uncles sometimes also travel with (first degree) families. However, I think the key to this exercise is not to find the absolute largest groups that people may have stayed together with. I think it should be to detect smaller groups that actually stayed together. It sounds reasonable to assume that first degree families stayed together, and that uncles/cousins also took care of each other (this is consistent with the averaging of the Fsizes in the previous section). Altogether, I have found another 56 passengers that I can assign a group size to.\n\n```{r}\nrest \u003c- all %\u003e%\n        select(PassengerId, Title, Age, Ticket, Ticket2, Surname, Fsize) %\u003e%\n        filter(Fsize==\u00271\u0027) %\u003e%\n        group_by(Ticket2, Surname) %\u003e%\n        summarise(count=n())\nrest \u003c- rest[rest$count\u003e1,]\nrest1 \u003c- all[(all$Ticket2 %in% rest$Ticket2 \u0026 all$Surname %in% rest$Surname \u0026 all$Fsize==\u00271\u0027), c(\u0027PassengerId\u0027, \u0027Surname\u0027, \u0027Title\u0027, \u0027Age\u0027, \u0027Ticket\u0027, \u0027Ticket2\u0027, \u0027Fsize\u0027, \u0027SibSp\u0027, \u0027Parch\u0027)]\nrest1 \u003c- left_join(rest1, rest, by = c(\u0022Surname\u0022, \u0022Ticket2\u0022))\nrest1 \u003c- rest1[!is.na(rest1$count),]\nrest1 \u003c- rest1 %\u003e%\n        arrange(Surname, Ticket2)\nkable(rest1[1:12,])\n```\n\n```{r}\n#replacing Fsize size in my overall dataframe with the count numbers in the table above\nall \u003c- left_join(all, rest1)\nfor (i in 1:nrow(all)){\n        if (!is.na(all$count[i])){\n                all$Fsize[i] \u003c- all$count[i]\n        }\n}\n```\n\n###Did people book together?\n\nBesides families, groups of friends can off course also travel together. A nice example of this is the ticket below.\n\n```{r}\nkable(all[all$Ticket==\u00271601\u0027, c(\u0027Survived\u0027, \u0027Pclass\u0027, \u0027Title\u0027, \u0027Surname\u0027, \u0027Age\u0027, \u0027Ticket\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Fsize\u0027)])\n```\n\nBelow, I am adding the number of people on each ticket as variable.\n\n```{r}\n#composing data frame with group size for each Ticket\nTicketGroup \u003c- all %\u003e%\n        select(Ticket) %\u003e%\n        group_by(Ticket) %\u003e%\n        summarise(Tsize=n())\nall \u003c- left_join(all, TicketGroup, by = \u0022Ticket\u0022)\n```\n\nVery similarly to the family group sizes, small groups of 2-4 people traveling together on the same ticket have a higher chance of survival.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x = Tsize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Ticket Size\u0027) + theme_grey()\n```\n\nAs there is so much overlap between family size and ticket size, I am consolidating these two variables into one group variable. Now I can finally created my factorized variable for the group sizes.\n\n```{r}\n#taking the max of family and ticket size as the group size\nall$Group \u003c- all$Fsize\nfor (i in 1:nrow(all)){\n           all$Group[i] \u003c- max(all$Group[i], all$Tsize[i])\n}\n\n#Creating final group categories\nall$GroupSize[all$Group==1] \u003c- \u0027solo\u0027\nall$GroupSize[all$Group==2] \u003c- \u0027duo\u0027\nall$GroupSize[all$Group\u003e=3 \u0026 all$Group\u003c=4] \u003c- \u0027group\u0027\nall$GroupSize[all$Group\u003e=5] \u003c- \u0027large group\u0027\nall$GroupSize \u003c- as.factor(all$GroupSize)\n```\n\nAs \u00271\u0027 and \u00272\u0027 are large groups with their own typical survival rates, I am keeping them as separate groups. Sizes \u00273\u0027 and \u00274\u0027 clearly have the best survival chances, and the groups of 5 and more clearly have worse chances.\n\n```{r}\ng1 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Group, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  scale_x_continuous(breaks=c(1:11)) +\n  labs(x = \u0027Final Group Sizes\u0027) + theme_grey()\n\ng2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = GroupSize, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position=\u0027dodge\u0027) +\n  labs(x = \u0027Final Group Categories\u0027) + theme_grey() +\n        scale_x_discrete (limits = c(\u0027solo\u0027, \u0027duo\u0027, \u0027group\u0027, \u0027large group\u0027))\ngrid.arrange(g2, g1)\n```\n\n```{r, echo=FALSE}\n#clean up\nall$count \u003c- NULL\nall$Name \u003c- NULL\nrm(CombiMaxF)\nrm(FamMaid)\nrm(FamMaidWrong)\nrm(FamMale)\nrm(labels1)\nrm(labels2)\nrm(NC)\nrm(NC1)\nrm(NCMale)\nrm(rest)\n#rm(rest1)\nrm(SizeCheck)\nrm(TicketGroup)\nrm(p1); rm(p2); rm(p3); rm(p4); rm(p5); rm(p6)\n```\n\n\n##Dealing with the Fare variable\n\n###Which data relevant to fare are missing?\nThere are two missing values in Embarked, and one in Fare. Embarked could be important to Fare, as different Embarkement cities mean longer or shorter journeys.\n\n```{r}\n#display passengers with missing Embarked\nkable(all[which(is.na(all$Embarked)),c(\u0027Surname\u0027, \u0027Title\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Age\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Ticket\u0027, \u0027Fare\u0027, \u0027Cabin\u0027, \u0027Embarked\u0027, \u0027Group\u0027) ])\n```\n\nBoth women are traveling solo from a family perspective (Fsize=1), but must be friends as they are both are traveling on ticket 113572 (nobody else was traveling on this ticket, so Group=2). Both also have the same fare, but this fare might still have been per person. I came to the conclusion that prices are indeed per ticket. As the explanation was getting lengthy, I will now just continue under the assumption that fares are per person. \n\nI want to impute the missing embarkement city with the median Fare Per Person for each Embarkement city, and per Pclass.\n\n```{r}\nall$FarePP \u003c- all$Fare/all$Tsize #creating the Fare Per Person variable\n\ntab2 \u003c- all[(!is.na(all$Embarked) \u0026 !is.na(all$Fare)),] %\u003e%\n        group_by(Embarked, Pclass) %\u003e%\n        summarise(FarePP=median(FarePP))\nkable(tab2)\n```\n\nAs the FarePP of those two women is 40, they most likely embarked at Cherbourgh.\n\n```{r}\n#imputing missing Embarked values\nall$Embarked[all$Ticket==\u0027113572\u0027] \u003c- \u0027C\u0027\n#converting Embarked into a factor\nall$Embarked \u003c- as.factor(all$Embarked)\n```\n\nI can actually use the same table to find a sensible fare for Mr Story. As you can see below, he traveled 3rd class and embarked at Southampton. \n\n```{r}\n#display passengers with missing Fare\nkable(all[which(is.na(all$Fare)), c(\u0027Surname\u0027, \u0027Title\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Age\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Ticket\u0027, \u0027Fare\u0027, \u0027Cabin\u0027, \u0027Embarked\u0027, \u0027Group\u0027)])\n```\n\n```{r}\n#imputing FarePP (as the Fare will be dropped later on anyway)\nall$FarePP[1044] \u003c- 7.8\n```\n\n###The Fare Per Person Variable\n\nAlthough there now are no missing FarePP\u0027s anymore, I also noticed that 17 Fares actually have the value 0. These people are not children that might have traveled for free. I think the information might actually be correct (have people won free tickets?), but I also think that the zero-Fares might confuse the algorithm. For instance, there are zero-Fares within the 1st class passengers. To avoid this possible confusion, I am replacing these values by the median FarePP\u0027s for each Pclass.\n\n```{r}\ntab3 \u003c- all[(!is.na(all$FarePP)),] %\u003e%\n        group_by(Pclass) %\u003e%\n        summarise(MedianFarePP=median(FarePP))\nall \u003c- left_join(all, tab3, by = \u0022Pclass\u0022)\nall$FarePP[which(all$FarePP==0)] \u003c- all$MedianFarePP[which(all$FarePP==0)]\n```\n\nBelow you can see that the FarePP is very skewed. I know that this is not desirable for some algorithms, and can be solved by taking the logarithm or normalisation (preprocessing with centering and scaling). \n\n```{r}\nggplot(all, aes(x=FarePP)) +\n        geom_histogram(binwidth = 5, fill=\u0027blue\u0027) + theme_grey() +\n        scale_x_continuous(breaks= seq(0, 150, by=10))\n```\n\nAnother option is to use Fare Bins instead of keeping the FarePP as a numeric variable. I am using Fare Bin in the GBM model. As there are more FareBins than Pclasses, there is of course some overlap between FareBins and Pclasses.\n\n```{r}\n#Note Hmisc needs to be loaded before dplyr, as the other way around errors occured due to the kernel using the Hmisc summarize function instead of the dplyr summarize function\nall$FareBins \u003c- cut2(all$FarePP, g=5)\n\nggplot(all[!is.na(all$Survived),], aes(x=FareBins, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027) + theme_grey() + facet_grid(.~Pclass)+\n        theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n##Predicting missing Age values\n\nThe density plot below shows that survival chances of children are relatively high. Survival chances of ages 20-30 are below average, and I see less significant differences in the 30+ region. I think there may be a lot of solo travelers in the 20-30 category, which could explain the below averages survival chances. A possible use case of Age could be to use it to identify children. Therefore, I will focus on good looking Age imputations in the region 0-18 years old.\n\n```{r}\nggplot(all[(!is.na(all$Survived) \u0026 !is.na(all$Age)),], aes(x = Age, fill = Survived)) +\ngeom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\u0022Survival density and Age\u0022) +\nscale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()\n```\n\nI first want to visualize the relation between the Age. Title and Pclass seem the most important predictors for Age to me. As you can see below, there are significant differences in Age across the Titles (By the way, this graph tells me that \u0022Masters\u0022 are all very young. I did not know what a master was, but googling it tells me that a master was used as a title for the eldest son only.). Similarly, there differences in Age when looking at the Title/Passenger Class combinations.\n\n```{r}\nggplot(all[!is.na(all$Age),], aes(x = Title, y = Age, fill=Pclass )) +\n  geom_boxplot() + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()\n```\n\nThe title Master seems to be a good predictor for male children. However, female children are included in the Miss title, and of the 263 missing age values, 51 are Misses. If I would just take the median Age of the Titles (possibly also by Pclass), I would at least not predict the missing ages of female children well. I tried both Mice imputation and Linear Regression, and focused on how good the imputations for children looked. The Mice imputations looked reasonable, but I preferred Linear Regression.\n\n```{r}\n#predicting Age with Linear Regression\nset.seed(12000)\nAgeLM \u003c- lm(Age ~ Pclass + Sex + SibSp + Parch + Embarked + Title + GroupSize, data=all[!is.na(all$Age),])\nsummary(AgeLM)\nall$AgeLM \u003c- predict(AgeLM, all)\n```\n\nAs expected, the most significant predictors according to Linear Regression were Passenger Class and Title. Below you can see that the histogram of the predicted values versus the shape of the known ages. The Mice histogram actually looked nicer, but I was wondering how it could predict high ages well given the sparseness of these ages in the original data?\n\n```{r}\npar(mfrow=c(1,2))\nhist(all$Age[!is.na(all$Age)], main=\u0027Original data, non-missing\u0027, xlab=\u0027Age\u0027, col=\u0027green\u0027)\nhist(all$AgeLM[is.na(all$Age)], main= \u0027LM NA predictions\u0027, xlab=\u0027Age\u0027, col=\u0027orange\u0027, xlim=range(0:80))\n```\n\nAs mentioned before, I especially looked at young predicted ages. Both mice and Linear Regression predicted all Masters with missing ages to be children indeed (the one in Linear Regression with a negative age did not bother me that much, as it is categorized as a child anyway). Mice predicted some Mr.\u0027s to be 14 years old, which is too young. As Linear Regression also predicted a reasonable number of Misses to be children, I eventually chose Linear Regression.\n\n```{r}\n#display which passengers are predicted to be children (age\u003c18) with Linear Regression.\nall[(is.na(all$Age) \u0026 all$AgeLM \u003c18), c(\u0027Sex\u0027, \u0027SibSp\u0027, \u0027Parch\u0027, \u0027Title\u0027, \u0027Pclass\u0027, \u0027Survived\u0027, \u0027AgeLM\u0027)]\n```\n\n```{r}\n#imputing Linear Regression predictions for missing Ages\nindexMissingAge \u003c- which(is.na(all$Age))\nindexAgeSurvivedNotNA\u003c- which(!is.na(all$Age) \u0026 (!is.na(all$Survived))) #needed in sections 4.6 and 4.7\nall$Age[indexMissingAge] \u003c- all$AgeLM[indexMissingAge]\n```\n\nSo now all missing data have been imputed. Am I going to use Age as a predictor in my model? I am not sure yet, as the substantial number of imputations will also add noise. I wil look at using it to create a Child predictor later on.\n\n##What to do with Cabin?\n\nCabin is very sparsely populated. So I either have to ignore it, or use it somehow without making it too specific. On the internet, you can find that that the first letter corresponds to the Deck. Decks A-E are the topdecks and cabins on those decks are mostly first class.\n\n```{r}\n#replacing NAs with imaginary Deck U, and keeping only the first letter of ech Cabin (=Deck)\nall$Cabin[is.na(all$Cabin)] \u003c- \u0022U\u0022\nall$Cabin \u003c- substring(all$Cabin, 1, 1)\nall$Cabin \u003c- as.factor(all$Cabin)\n\nggplot(all[(!is.na(all$Survived)\u0026 all$Cabin!=\u0027U\u0027),], aes(x=Cabin, fill=Survived)) +\n        geom_bar(stat=\u0027count\u0027) + theme_grey() + facet_grid(.~Pclass) + labs(title=\u0022Survivor split by class and Cabin\u0022)\n```\n\nBelow, you can see that there are interesting difference among Decks. For instance, the top Deck (A) was not best place to be. Even Deck F had better survival rates.\n\n```{r}\nc1 \u003c- round(prop.table(table(all$Survived[(!is.na(all$Survived)\u0026all$Cabin!=\u0027U\u0027)], all$Cabin[(!is.na(all$Survived)\u0026all$Cabin!=\u0027U\u0027)]),2)*100)\nkable(c1)\n```\n\nAlthough I feel that Deck and Deck sections (front/back of boat, sections close to stairs et cetera) would be great predictors, I am not using Cabin due to the the sparseness of the data.\n\n##How to deal with Children in the model?\n\nThe survival density plot in the Age section shows that Children below roughly 14.5 (which is also the maximum Age of Masters in the data) have a better survival rate than then other Ages. However, if you look at the imputed Ages below 14.5, you will also see that all these age imputation are for Pclass 3 and most of these children actually died (10 out of 13).\n\nThis makes me wonder if I should add a survival \u0027bonus\u0027 for all Pclasses. Below you can see that most children in P3 actually die. As these children in P3 also include age imputations which may add noise, I decided to exclude P3 from the Child predictor.\n\n```{r, out.width=\u002250%\u0022}\nggplot(all[all$Age\u003c14.5 \u0026 !is.na(all$Survived),], aes(x=Pclass, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027) + theme_grey(base_size = 18)\n```\n\n\n\n```{r}\nall$IsChildP12 \u003c- \u0027No\u0027\nall$IsChildP12[all$Age\u003c=14.5 \u0026 all$Pclass %in% c(\u00271\u0027, \u00272\u0027)] \u003c- \u0027Yes\u0027\nall$IsChildP12 \u003c- as.factor(all$IsChildP12)\n```\n\n\n##What does Embarked tell us?\n\nAlthough I feel that the city of Embarked should not be related to survival rates, I still wanted to check it. As you can see below, there somehow are significant differences between the three ports of embarkment.\n\n```{r}\nd1 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) + theme_grey() + labs(x = \u0027Embarked\u0027, y= \u0027Count\u0027)\nd2 \u003c- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027, position= \u0027fill\u0027) + theme_grey() + labs(x = \u0027Embarked\u0027, y= \u0027Percent\u0027)\n\ngrid.arrange(d1, d2, nrow=1)\n```\n\nTo get a feel for where this differences may come from, I plotted them against Sex and Pclass. Roughly, differences were:\n\n* Southampton survival rates are worse than Cherbourg in all Pclass/Sex combinations\n* Cherbourg survival rates are better than Queenstown as many 1st class passengers boarded at Cherbourgh, while almost all Queenstown passengers boarded 3rd class (but within 3rd class, female survival rate is better than Cherbourg and male survival rate is worse than Cherbourgh).\n\nMy conclusion is that at least the lower survival rate of Southampton compared to Cherbourg cannot be explained by Pclass or Sex. One thing that I want to look at is the relation between Embarked, Age and Survived, because Linear Regression surprisingly enough also labeled Embarked at Queenstown as a significant predictor for Age. Below I am only using the known Ages of the training data (714 observation = training set - 177 observations with missing Age).\n\n```{r, message=FALSE}\nggplot(all[indexAgeSurvivedNotNA,], aes(x = Age, fill = Survived)) +\ngeom_histogram(aes(fill=factor(Survived))) + labs(title=\u0022Survival density, known-ages, and Embarked\u0022) +\nscale_x_continuous(breaks = scales::pretty_breaks(n = 5)) + theme_grey() + facet_grid(.~Embarked)\n```\n\nThis shows that is very little data for especially Queenstown when looking at known Ages. Below you can see that the total number of people who embarked at Queenstown is low indeed, but especially the high percentage of missing ages in Queenstown is really high. Using imputed ages will therefore add too much noise, and combining Age and Embarked as a predictor is a bad idea.\n\n```{r}\ntab1 \u003c- rbind(table(all$Embarked[!is.na(all$Survived)]),table(all$Embarked[indexAgeSurvivedNotNA]))\ntab1 \u003c- cbind(tab1, (rowSums(tab1)))\ntab1 \u003c- rbind(tab1, tab1[1,]-tab1[2,])\ntab1 \u003c- rbind(tab1, round((tab1[3,]/tab1[1,])*100))\nrownames(tab1) \u003c- c(\u0022All\u0022, \u0022With Age\u0022, \u0022Missing Age\u0022, \u0022Percent Missing\u0022)\ncolnames(tab1) \u003c- c(\u0022C\u0022, \u0022Q\u0022, \u0022S\u0022, \u0022Total\u0022)\nkable(tab1)\n```\n\nThe only other thing that I can think of that might explain the differences is that probably people from the different embarkement cities are somehow grouped on certain sections of the decks. \n\nI kept Embarked in my model in early versions. However, it gradually became clear that Embarked does not add anything and I am not using it anymore.\n\n##Ticket survivors\n\nThis variable checks if any people in a group survived. The idea is that if anyone in a certain group survived, chances of others also surviving are higher. I did this using the Ticket information, and it improved the scores.\n\n```{r}\nTicketSurvivors \u003c- all %\u003e%\n        group_by(Ticket) %\u003e%\n        summarize(Tsize = length(Survived),\n                  NumNA = sum(is.na(Survived)),\n                  SumSurvived = sum(as.numeric(Survived)-1, na.rm=T))\n```\n\n```{r}\nall \u003c- left_join(all, TicketSurvivors)\nall$AnySurvivors[all$Tsize==1] \u003c- \u0027other\u0027\nall$AnySurvivors[all$Tsize\u003e=2] \u003c- ifelse(all$SumSurvived[all$Tsize\u003e=2]\u003e=1, \u0027survivors in group\u0027, \u0027other\u0027)\nall$AnySurvivors \u003c- as.factor(all$AnySurvivors)\n\nkable(x=table(all$AnySurvivors), col.names= c(\u0027AnySurvivors\u0027, \u0027Frequency\u0027))\n```\n\n##Adding an \u0022Is Solo\u0022 variable\u0022 based on Siblings and Spouse (SibSp) only\n\nIn an earlier version, I experimented with an \u0022IsSolo\u0022 predictor that was based on the Group size. However, this double counted the Group categories too much and did not work. Eventually, I added an IsSolo predictor that is only based on the SibSp information. Using this predictor in the SVM model leads to slightly better results.\n\n```{r, out.width=\u002250%\u0022}\nall$IsSolo[all$SibSp==0] \u003c- \u0027Yes\u0027\nall$IsSolo[all$SibSp!=0] \u003c- \u0027No\u0027\nall$IsSolo \u003c- as.factor(all$IsSolo)\n\nggplot(all[!is.na(all$Survived),], aes(x = IsSolo, fill = Survived)) +\n  geom_bar(stat=\u0027count\u0027) + theme_grey(base_size = 18)\n```\n\n#Predictions (with caret cross validation)\n\n```{r, echo=FALSE}\n#cleaning up\nall$PassengerId \u003c- NULL\nall$SibSp \u003c- NULL\nall$Parch \u003c- NULL\nall$Ticket \u003c- NULL\nall$Fare \u003c- NULL\nall$Cabin \u003c- NULL\nall$Surname \u003c- NULL\nall$Fsize \u003c- NULL\nall$FsizeName \u003c- NULL\nall$Favg \u003c- NULL\nall$Tsize \u003c- NULL\n#all$Group \u003c- NULL\nall$Ticket2 \u003c- NULL\nall$AgeLM \u003c- NULL\nall$Child \u003c- NULL\nall$HasParch \u003c- NULL\nall$MedianFarePP \u003c- NULL\nrm(tab1); rm(tab2); rm(tab3); rm(AgeLM); rm(c1); rm(d1); rm(d2);\n```\n\nAltogether, I created predictions with 3 different algorithms. In addition, I tried to combine (ensemble) the models in 3 different ways. This ensemble further improved the scores.\n\n```{r}\n#splitting data into train and test set again\ntrainClean \u003c- all[!is.na(all$Survived),]\ntestClean \u003c- all[is.na(all$Survived),]\n```\n\n##Random Forest model\nI started this analysis with just a Random Forest model, as it is known for high accuracy and limiting overfitting.\n\nAlthough the formula function must be used with many algorithms, it is better to not use it with Random Forest as this causes issues with weights of predictors. I am just using 5 predictors.\n\n```{r}\nset.seed(2017)\ncaret_matrix \u003c- train(x=trainClean[,c(\u0027PclassSex\u0027, \u0027GroupSize\u0027, \u0027FarePP\u0027, \u0027AnySurvivors\u0027, \u0027IsChildP12\u0027)], y=trainClean$Survived, data=trainClean, method=\u0027rf\u0027, trControl=trainControl(method=\u0022cv\u0022, number=5))\ncaret_matrix\ncaret_matrix$results\n```\n\n```{r}\nvarImpPlot(caret_matrix$finalModel, main=\u0022 Variable importance\u0022)\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_rf \u003c- predict(caret_matrix, testClean)\n```\n\n##Support Vector Machine (SVM) model\n\nThe second algorithm that I want to use is SVM, as it is known to work well with small datasets. As I am only having a few predictors and relatively many observation, I am choosing svmRadial (Gaussian) over svmLinear.\n\n```{r}\nset.seed(2017)\ncaret_svm \u003c- train(Survived~ PclassSex + FarePP + AnySurvivors + IsChildP12 + IsSolo, data=trainClean, method=\u0027svmRadial\u0027, preProcess= c(\u0027center\u0027, \u0027scale\u0027), trControl=trainControl(method=\u0022cv\u0022, number=5))\ncaret_svm\ncaret_svm$results\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_svm \u003c- predict(caret_svm, testClean)\n```\n\n##Gradient Boosting Machine (GBM) model\n\nAs I am already having a model that uses Bagging, I want the 3rd model to be a boosting model. Of the possible boosting algorithms, I am choosing GBM.\n\n```{r}\nset.seed(2017)\ncaret_boost \u003c- train(Survived~ PclassSex + GroupSize + FareBins + AnySurvivors + IsChildP12, data=trainClean, method=\u0027gbm\u0027, preProcess= c(\u0027center\u0027, \u0027scale\u0027), trControl=trainControl(method=\u0022cv\u0022, number=7), verbose=FALSE)\nprint(caret_boost)\n```\n\n```{r}\n#using the model to make Survival predictions on the test set\nsolution_boost \u003c- predict(caret_boost, testClean)\n```\n\n##Combining models\n\n### Majority vote ensemble of the three models\n\nA simple majority vote a multiple good models can help to increase accuracy. This idea is really well explained in [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/). It works best with multiple good models that are as uncorrelated as possible.\n\n```{r}\n#adding model predictions to test dataframe\ntestClean$RF \u003c- as.numeric(solution_rf)-1\ntestClean$SVM \u003c- as.numeric(solution_svm)-1\ntestClean$Boost \u003c- as.numeric(solution_boost)-1\n\n#compose correlations plot\ncorrplot.mixed(cor(testClean[, c(\u0027RF\u0027, \u0027SVM\u0027, \u0027Boost\u0027)]), order=\u0022hclust\u0022, tl.col=\u0022black\u0022)\n```\n\nGiven the fact that all three models have decent public scores, especially the correlation between SVM and the GBM model is surprisingly low. The most likely explanation is that SVM really is a different algorithm (both other models are tree-based).\n\nThe idea is very simple:\n\n* If 0 or 1 model predicts \u0027Survived\u0027, the overall prediction will be \u0027Died\u0027\n* If 2 or 3 models predict \u0027Survived\u0027, the overall prediction will be \u0027Survived\u0027\n\n```{r}\n\ntestClean$Sum \u003c- testClean$RF + testClean$SVM + testClean$Boost\ntestClean$Majority \u003c- ifelse(testClean$Sum\u003c=1, 0, 1)\n```\n\n###Taking predictions from one model, unless the others both disagree\n\nAlthough I have done my best to avoid over fitting as much as possible (by for instance not using the Titles), the high cross validation scores of both RF and GBM are an indication that these 2 models still overfit somewhat.\n\nThe best kernels on Kaggle show that a public score of around 0.82 - 0.83 is likely to be the maximum achievable test accuracy. The cross validation score of the SVM model is exactely in this range. Probably even more importantly, a low AccuracySD seems more important than the Accuracy itself regarding Public Scores. As the SVM also has a really low AccuracySD, I am going to use SVM as my best model. In this second framework, I am taking the SVM predictions unless both RF and GBM disagree with the SVM prediction.\n\n```{r}\ntestClean$DisagreeSVM \u003c- ifelse(testClean$RF==testClean$Boost \u0026 testClean$SVM != testClean$RF, testClean$RF, testClean$SVM)\n```\n\n###Selectively combining models for PclassSex combinations\nAnother idea is to select the model that seems best for each PclassSex combination. When looking at predictions on the training set, issues seem similar in all models. All produce tend to produce False Negatives for men (men predicted to die, but survived), and False Positives for women (predicted to survive, but died). \n\n```{r}\n#predictions of the models on the training set\ntrainClean$RF \u003c- predict(caret_matrix, trainClean)\ntrainClean$SVM \u003c- predict(caret_svm, trainClean)\ntrainClean$Boost \u003c- predict(caret_boost, trainClean)\n\n\n#plot differences between actual survived and predictions\nf1 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$RF,], aes(x=PclassSex, fill=RF)) +\n        geom_bar(stat=\u0027count\u0027) + labs(title=\u0022FP and FN, RF model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\nf2 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$SVM,], aes(x=PclassSex, fill=SVM)) +\n        geom_bar(stat=\u0027count\u0027)+ labs(title=\u0022FP and FN, SVM model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\nf3 \u003c- ggplot(trainClean[trainClean$Survived != trainClean$Boost,], aes(x=PclassSex, fill=Boost)) +\n        geom_bar(stat=\u0027count\u0027)+ labs(title=\u0022FP and FN, GBM model\u0022) + theme_grey() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n        theme(legend.position=\u0022none\u0022) + xlab(\u0022\u0022)\n\ngrid.arrange(f1, f2, f3, nrow = 1)\n```\n\nA noticable difference however is that the SVM model also produced a significant amount of False Positives in P3Male (the blue part). As the survival rate of men in P3 was really low, this large amount of False Positives seems a bad sign.\n\nWhat I now could do is take SVM as the base model, but take GBM for the P3 predictions.\n\n```{r}\n#selecting SVM prediction, and GMB predictions for P3\ntestClean$Select \u003c- ifelse(testClean$Pclass != 3, testClean$SVM, testClean$Boost)\n```\n\nThe best framework turned out to be the combination of SVM for P1 and P2, and GBM for P3. The majority voting and \u0027take SVM unless both RF and GBM disagree\u0027 did not improve my score. However, chances are that these methods will also improve the scores if I add a few more good models. This should decrease of 2 (alternative) models both getting a prediction wrong.\n\n```{r}\n#writing final submission file\nsubmission_select \u003c- data.frame(PassengerId = test$PassengerId, Survived = testClean$Select)\nwrite.csv(submission_select, file = \u0027Titanic_select.csv\u0027, row.names = F)\n```\n\n##Where is room for improvement?\n\n###How to fix Male in 1st class issues?\nThis class is hard to predict, as 37% of men in P1 survived while men overall have a much lower survival rate. As shown in the previous section, predictions include many False Negatives. Many False Negatives means that the predicted number of survivors on the test set is likely to be too low. As you can see below, all models predict the survival rate of this group to be significantly lower than 37% indeed (.37*57=21 survivors).\n\n```{r}\ncat(\u0027Total number of Male passengers in P1 in the test set is\u0027, length(testClean$Survived[testClean$PclassSex==\u0027P1Male\u0027]))\n\np1m_surv \u003c- as.data.frame(sapply(testClean[testClean$PclassSex==\u0027P1Male\u0027, c(\u0027RF\u0027, \u0027SVM\u0027, \u0027Boost\u0027)], function(x) {sum(x)}))\nkable(x=p1m_surv, col.names = c(\u0027Predicted number of survivors\u0027))\n```\n\nAlthough SVM only predicts 2 survivors, these 2 are in fact the 2 children in this class. This might actually be the best bet, if survival is hard to predict (predicting dead is better when unclear as the majority died).\n\nI do not know if the survival rate of P1Male in the test set is also 37%, but it seems likely that the predicted survival rate for this group is too low in all models. Therefore, I have looked for angles to \u0027reliably\u0027 increase this number. As you can see below, there is a significant difference in survival density of men below and above appromimately 40. So the survival \u0027bonus\u0027 that children have in general, is for P1Male \u0027extended\u0027 to 40.\n\nI have actually tried to include this exception in the models, but It did not improve the scores. I assume this is because the survival rate in P1Male under 40 now really gets close to 50/50, which makes it very hard to predict with some degree of certainty.\n\n```{r}\np1m1 \u003c- ggplot(all[indexAgeSurvivedNotNA,] %\u003e% filter(PclassSex==\u0027P1Male\u0027), aes(x = Age, fill = Survived)) + geom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\u0022Survival density and Age P1 Male\u0022) + theme_grey()\n\nall$P1AgeMale[indexAgeSurvivedNotNA=T \u0026 all$PclassSex==\u0027P1Male\u0027 \u0026 all$Age\u003c40] \u003c- \u0027Under40\u0027\nall$P1AgeMale[indexAgeSurvivedNotNA=T \u0026 all$PclassSex==\u0027P1Male\u0027 \u0026 all$Age\u003e=40] \u003c- \u0027Over40\u0027\n\np1m2 \u003c- ggplot(all[!is.na(all$Survived) \u0026 !is.na(all$P1AgeMale),], aes(x=P1AgeMale, fill=Survived))+\n        geom_bar(stat = \u0027count\u0027, position = \u0027fill\u0027) + theme(legend.position=\u0022none\u0022)\n\n\ngrid.arrange(p1m1, p1m2, widths=c(2,1))\n```\n\n###How to fix Female in 3rd class issues?\nFemales in 3rd class have an overall 50/50 survival chance, which is hard to predict. In the previous section, P3Female showed many False Positives. This was expected, as women generally survived. Similar to the males in P1, I found something that is specific to this group.\n\nAs you can see below, solo women (based on SibSp) had better chances of survival in all Pclasses. This is especially relevant to the women in P3, as differences in P2Female and P1Female are small while they mostly survived anyway. In previous versions, I tried a different IsSolo predictor (based on Fsize), and did not manage to model this exception succesfully. However, it may be worth trying a Male/Female split with the IsSolo predictor based on SibSp only.\n\n```{r}\nggplot(all[!is.na(all$Survived),], aes(x=IsSolo, fill=Survived))+\n        geom_bar(stat=\u0027count\u0027, position=\u0027fill\u0027) + facet_grid(.~Pclass+Sex)\n```\n\n\n","dateCreated":"2018-03-28T10:58:56.927Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e940516\u003c/disk_kb_free\u003e\u003cdocker_image_digest\u003e52937f97db1d60cc30110f82402aec2d3dec26569f3ae4239adbe334f10492ad\u003c/docker_image_digest\u003e\u003cdocker_image_id\u003esha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a\u003c/docker_image_id\u003e\u003cdocker_image_name\u003egcr.io/kaggle-images/rstats\u003c/docker_image_name\u003e\u003cexit_code\u003e0\u003c/exit_code\u003e\u003cfailure_message /\u003e\u003cinvalid_path_errors\u003eFalse\u003c/invalid_path_errors\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e49.6756983119994\u003c/run_time_seconds\u003e\u003csucceeded\u003eTrue\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageDigest":"52937f97db1d60cc30110f82402aec2d3dec26569f3ae4239adbe334f10492ad","dockerImageId":"sha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a","dockerImageName":"kaggle/rstats","diskKbFree":940516,"failureMessage":"","exitCode":0,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":49.6756983119994,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":true,"wasKilled":false},"outputFilesTotalSizeBytes":105748,"dockerImageVersionId":47,"usedCustomDockerImage":false},"author":{"id":1364657,"displayName":"ZahoorAhmad","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"zahoorahmad","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1364657-kg.JPG","profileUrl":"/zahoorahmad","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":1,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting","collaborators":{"owner":{"userId":1364657,"groupId":null,"groupMemberCount":null,"profileUrl":"/zahoorahmad","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1364657-kg.JPG","name":"ZahoorAhmad","slug":"zahoorahmad","userTier":1,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022\\n\\nprocessing file: script.Rmd\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 2.6125611889874563\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |                                                                 |   0%\\r  |                                                                       \\r  |                                                                 |   1%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.8161492079962045\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.                                                                |   1%\\nlabel: setup (with options) \\nList of 1\\n $ include: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.84898687095847\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.                                                                |   2%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.9099150389665738\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..                                                               |   3%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 2.94189389096573\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-1 (with options) \\nList of 2\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 3.053966879961081\n},{\n  \u0022data\u0022: \u0022 $ message: logi FALSE\\n $ warning: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 3.0859720039879903\n},{\n  \u0022data\u0022: \u0022Loading required package: lattice\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 3.365530395996757\n},{\n  \u0022data\u0022: \u0022Loading required package: survival\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 3.420593890012242\n},{\n  \u0022data\u0022: \u0022Loading required package: Formula\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.289072621962987\n},{\n  \u0022data\u0022: \u0022Loading required package: ggplot2\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.322128663014155\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027Hmisc\u0027\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.754997826996259\n},{\n  \u0022data\u0022: \u0022The following objects are masked from \u0027package:base\u0027:\\n\\n    format.pval, units\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.787950453988742\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027dplyr\u0027\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.826543456991203\n},{\n  \u0022data\u0022: \u0022The following objects are masked from \u0027package:Hmisc\u0027:\\n\\n    src, summarize\\n\\nThe following objects are masked from \u0027package:stats\u0027:\\n\\n    filter, lag\\n\\nThe following objects are masked from \u0027package:base\u0027:\\n\\n    intersect, setdiff, setequal, union\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 4.857953283004463\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027caret\u0027\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.370267716003582\n},{\n  \u0022data\u0022: \u0022The following object is masked from \u0027package:survival\u0027:\\n\\n    cluster\\n\\nrandomForest 4.6-12\\nType rfNews() to see new features/changes/bug fixes.\\n\\nAttaching package: \u0027randomForest\u0027\\n\\nThe following object is masked from \u0027package:dplyr\u0027:\\n\\n    combine\\n\\nThe following object is masked from \u0027package:ggplot2\u0027:\\n\\n    margin\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.403427166980691\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027gridExtra\u0027\\n\\nThe following object is masked from \u0027package:randomForest\u0027:\\n\\n    combine\\n\\nThe following object is masked from \u0027package:dplyr\u0027:\\n\\n    combine\\n\\nLoading required package: gplots\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.4345486119855195\n},{\n  \u0022data\u0022: \u0022\\nAttaching package: \u0027gplots\u0027\\n\\nThe following object is masked from \u0027package:stats\u0027:\\n\\n    lowess\\n\\nLoading required package: methods\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.465534424001817\n},{\n  \u0022data\u0022: \u0022corrplot 0.84 loaded\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 6.510314156010281\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...                                                              |   4%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 6.526897698990069\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-2\\n\\r  |                                                                       \\r  |...                                                              |   5%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-3\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 6.570458456990309\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |....                                                             |   6%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |....                                                             |   7%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 6.744945687998552\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-4\\n\\r  |                                                                       \\r  |.....                                                            |   7%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.....                                                            |   8%\\nlabel: unnamed-chunk-5\\n\\r  |                                                                       \\r  |......                                                           |   8%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |......                                                           |   9%\\nlabel: unnamed-chunk-6\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 6.776663249009289\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......                                                           |  10%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.......                                                          |  10%\\nlabel: unnamed-chunk-7 (with options) \\nList of 1\\n $ out.width: chr \\\u002250%\\\u0022\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 6.807998327014502\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......                                                          |  11%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |........                                                         |  12%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.377271612000186\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-8\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 8.416340997966472\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |........                                                         |  13%\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 10.446815537987277\n},{\n  \u0022data\u0022: \u0022\\nlabel: unnamed-chunk-9 (with options) \\nList of 1\\n $ out.width: chr \\\u0022100%\\\u0022\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 10.479892177972943\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.........                                                        |  14%\\n  ordinary text without R code\\n\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.23857984796632\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-10\\n\\r  |                                                                       \\r  |..........                                                       |  15%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..........                                                       |  16%\\nlabel: unnamed-chunk-11\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.272131750010885\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...........                                                      |  16%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........                                                      |  17%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.342144608963281\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-12\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.373790944984648\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...........                                                      |  18%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |............                                                     |  18%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.51431075995788\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-13\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.54733083100291\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............                                                     |  19%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.............                                                    |  20%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.94671066099545\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-14 (with options) \\nList of 1\\n $ message: logi FALSE\\n\\n\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..............                                                   |  21%\\nlabel: unnamed-chunk-15\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 13.979801439971197\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..............                                                   |  22%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.43835594697157\n},{\n  \u0022data\u0022: \u0022\\nlabel: unnamed-chunk-16\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.469808658002876\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...............                                                  |  23%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............                                                  |  24%\\nlabel: unnamed-chunk-17\\n\\r  |                                                                       \\r  |................                                                 |  24%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |................                                                 |  25%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.501090986013878\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-18\\n\\r  |                                                                       \\r  |.................                                                |  25%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.................                                                |  26%\\nlabel: unnamed-chunk-19\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.532169774000067\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.................                                                |  27%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..................                                               |  27%\\nlabel: unnamed-chunk-20\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.563664676970802\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..................                                               |  28%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...................                                              |  29%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.648464916972443\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-21\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.679712729994208\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |....................                                             |  30%\\nlabel: unnamed-chunk-22\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.710947312996723\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |....................                                             |  31%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-23\\n\\r  |                                                                       \\r  |.....................                                            |  32%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.....................                                            |  33%\\nlabel: unnamed-chunk-24\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.742822306987364\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......................                                           |  33%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |......................                                           |  34%\\nlabel: unnamed-chunk-25\\n\\r  |                                                                       \\r  |.......................                                          |  35%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-26\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.77423889900092\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......................                                          |  36%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |........................                                         |  37%\\nlabel: unnamed-chunk-27\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.80561687698355\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.........................                                        |  38%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.841630506969523\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-28\\n\\r  |                                                                       \\r  |.........................                                        |  39%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-29\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.872925049974583\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........................                                       |  40%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..........................                                       |  41%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.90698741900269\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-30\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 14.938120979990344\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...........................                                      |  41%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................                                      |  42%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 15.356268632982392\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-31\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 15.387938088970259\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............................                                     |  42%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |............................                                     |  43%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 15.453674548014533\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-32\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 15.485124900005758\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............................                                     |  44%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.............................                                    |  44%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.297032270987984\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-33 (with options) \\nList of 1\\n $ echo: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.329794581979513\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.............................                                    |  45%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..............................                                   |  46%\\nlabel: unnamed-chunk-34\\n\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............................                                  |  47%\\nlabel: unnamed-chunk-35\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.361094312975183\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...............................                                  |  48%\\n  ordinary text without R code\\n\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.39409032301046\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-36\\n\\r  |                                                                       \\r  |................................                                 |  49%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |................................                                 |  50%\\nlabel: unnamed-chunk-37\\n\\r  |                                                                       \\r  |.................................                                |  50%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.................................                                |  51%\\nlabel: unnamed-chunk-38\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.427092794969212\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..................................                               |  52%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-39\\n\\r  |                                                                       \\r  |..................................                               |  53%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...................................                              |  54%\\nlabel: unnamed-chunk-40\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.458762064983603\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |....................................                             |  55%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.815851207007654\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-41\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 16.849536082998384\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |....................................                             |  56%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.....................................                            |  56%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 17.81367979897186\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-42\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 17.84663729299791\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.....................................                            |  57%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 18.367041805002373\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.....................................                            |  58%\\nlabel: unnamed-chunk-43\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 18.400611713004764\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......................................                           |  58%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |......................................                           |  59%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.242767239979003\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-44\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.2777368290117\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......................................                          |  59%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.......................................                          |  60%\\nlabel: unnamed-chunk-45\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.309769571002107\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |........................................                         |  61%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.56179050297942\n},{\n  \u0022data\u0022: \u0022\\nlabel: unnamed-chunk-46\\n\\r  |                                                                       \\r  |........................................                         |  62%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.........................................                        |  63%\\nlabel: unnamed-chunk-47\\n\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..........................................                       |  64%\\nlabel: unnamed-chunk-48\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 19.592464431014378\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........................................                       |  65%\\n  ordinary text without R code\\n\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.282695489004254\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-49\\n\\r  |                                                                       \\r  |...........................................                      |  66%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................................                      |  67%\\nlabel: unnamed-chunk-50 (with options) \\nList of 1\\n $ out.width: chr \\\u002250%\\\u0022\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.3164598759613\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............................................                     |  67%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.77424737199908\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |............................................                     |  68%\\nlabel: unnamed-chunk-51\\n\\r  |                                                                       \\r  |.............................................                    |  69%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-52\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 20.80743313196581\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.............................................                    |  70%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.62979609001195\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..............................................                   |  71%\\nlabel: unnamed-chunk-53 (with options) \\nList of 1\\n $ message: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 21.66288960899692\n},{\n  \u0022data\u0022: \u0022`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 21.686400077014696\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............................................                  |  72%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 22.495486648986116\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-54\\n\\r  |                                                                       \\r  |...............................................                  |  73%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |................................................                 |  73%\\nlabel: unnamed-chunk-55\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 22.526597603980917\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |................................................                 |  74%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |................................................                 |  75%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 22.62590792600531\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-56\\n\\r  |                                                                       \\r  |.................................................                |  75%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.................................................                |  76%\\nlabel: unnamed-chunk-57 (with options) \\nList of 1\\n $ out.width: chr \\\u002250%\\\u0022\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 22.65724405599758\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..................................................               |  76%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..................................................               |  77%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 23.132354249013588\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-58 (with options) \\nList of 1\\n $ echo: logi FALSE\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 23.16555116296513\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |...................................................              |  78%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-59\\n\\r  |                                                                       \\r  |...................................................              |  79%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |....................................................             |  80%\\nlabel: unnamed-chunk-60\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 23.196835967013612\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.52186354598962\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.....................................................            |  81%\\nlabel: unnamed-chunk-61\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.55355090997182\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.....................................................            |  82%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.65020896401256\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |......................................................           |  82%\\nlabel: unnamed-chunk-62\\n\\r  |                                                                       \\r  |......................................................           |  83%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |......................................................           |  84%\\nlabel: unnamed-chunk-63\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 32.68149531300878\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.......................................................          |  84%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.......................................................          |  85%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 41.218283289985266\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-64\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 41.251325068005826\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |........................................................         |  86%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 41.337588236958254\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-65\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 41.37032257899409\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.........................................................        |  87%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |.........................................................        |  88%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 44.69783297798131\n},{\n  \u0022data\u0022: \u0022label: unnamed-chunk-66\\n\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |..........................................................       |  89%\\nlabel: unnamed-chunk-67\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 44.731233679980505\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |..........................................................       |  90%\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 45.500224962015636\n},{\n  \u0022data\u0022: \u0022  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................................................      |  90%\\nlabel: unnamed-chunk-68\\n\\r  |                                                                       \\r  |...........................................................      |  91%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...........................................................      |  92%\\nlabel: unnamed-chunk-69\\n\\r  |                                                                       \\r  |............................................................     |  92%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |............................................................     |  93%\\nlabel: unnamed-chunk-70\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 45.53186360996915\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.............................................................    |  93%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 46.82797865400789\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.............................................................    |  94%\\nlabel: unnamed-chunk-71\\n\\r  |                                                                       \\r  |..............................................................   |  95%\\n  ordinary text without R code\\n\\n\\nlabel: unnamed-chunk-72\\n\\r  |                                                                       \\r  |..............................................................   |  96%\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |...............................................................  |  97%\\nlabel: unnamed-chunk-73\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 46.85941020998871\n},{\n  \u0022data\u0022: \u0022\\n  ordinary text without R code\\n\\n\\r  |                                                                       \\r  |................................................................ |  98%\\nlabel: unnamed-chunk-74\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 46.89040122798178\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |................................................................ |  99%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 47.655889551970176\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.................................................................|  99%\\nlabel: unnamed-chunk-75\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 47.687344683974516\n},{\n  \u0022data\u0022: \u0022\\r  |                                                                       \\r  |.................................................................| 100%\\n  ordinary text without R code\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 48.71857148397248\n},{\n  \u0022data\u0022: \u0022\\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 48.75095740600955\n},{\n  \u0022data\u0022: \u0022output file: /kaggle/working/script.knit.md\\n\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 48.753130576980766\n},{\n  \u0022data\u0022: \u0022/usr/local/bin/pandoc +RTS -K512m -RTS /kaggle/working/script.utf8.md --to html --from markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash --output /kaggle/working/__results__.html --smart --email-obfuscation none --standalone --section-divs --table-of-contents --toc-depth 3 --template /usr/local/lib/R/site-library/rmarkdown/rmd/h/default.html --no-highlight --variable highlightjs=1 --number-sections --variable \u0027theme:bootstrap\u0027 --include-in-header /tmp/Rtmpq4aJ6k/rmarkdown-str16d919024.html --mathjax --variable \u0027mathjax-url:https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\u0027 \\n\u0022,\n  \u0022stream_name\u0022: \u0022stdout\u0022,\n  \u0022time\u0022: 48.92950754496269\n},{\n  \u0022data\u0022: \u0022\\nOutput created: __results__.html\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 49.284036196011584\n},{\n  \u0022data\u0022: \u0022Warning messages:\\n1: In file.rename(from, to) :\\n  cannot rename file \u0027/kaggle/working/__results___files/figure-html\u0027 to \u0027/kaggle/working//kaggle/working/__results___files/figure-html\u0027, reason \u0027No such file or directory\u0027\\n2: In file.rename(from, to) :\\n  cannot rename file \u0027/kaggle/working//kaggle/working/__results___files/figure-html\u0027 to \u0027/kaggle/working/__results___files/figure-html\u0027, reason \u0027No such file or directory\u0027\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 49.31761646497762\n}]","outputFiles":[{"ownerInfo":null,"kernelVersionOutputFileId":11163942,"kernelVersionId":2972542,"kernelId":786539,"size":0,"fullPath":"Titanic_select.csv","previewUrl":"/kernels/preview.json/2972542/8c8aa985-6b22-be04-8574-66242f8e67f7/Titanic_select.csv","downloadUrl":"https://www.kaggleusercontent.com/kf/2972542/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..k_gE39t9bXr1AJT0koTnFw._gCNWa0Rd3YlpJGHppAw_QCRMOdetirq6r8I8zBWeTfssKx1eAlpLnB3Bg2YOpIRuNRrdWX77M-T7pP-RtIbFD0CbrIUFR-zgKjBEodOr50b7BLZid26-rJwfjOrNeUZDfB2hn7IMAb4zcu6dtZwGMOopmy86Ih3wvkjgsH-ITWeUcx-uIsMpmbK-PHhcWji.SDJ-mcLZaXxXUmDGAmftyw/Titanic_select.csv","fileType":".csv","contentLength":2843,"contentType":null,"contentMD5":null,"validationErrors":null,"type":"kernelOutputFile","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"Titanic_select.csv","description":null}],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":786539,"kernelVersionId":2972542,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..IJPZrwc1JVrMzVKVnYOCSw.9GSBrulp0OSTZ1DJPwYCzZiuYRGN90k77E7xoRiMy-6eNy4rmcDk7Gmb98-UQT952nFW6cdQIbBbo8OYL0WZL0MPkPtlWvtwhJcXu7_QN7x-54V4f4W9aTrpxgMgHioiKYAhQs9LZ4tcmmJQOPpOe3Q-XjB6DqCFCiOfDGSjbZ0WhQC_7t_joeXVp1ijJbpfjQFLiVCaaI7Tr8zSNksVWv_i8oXVp2p01B1hqbRzBz2V2Q6sPP4aeKbfMo8JdG8XzdWMCGj30qDHLD61-RsVWnyo2rC_sDj606WatBSpcMlcWGYH8xxw1nciBQAToGUIRtpkMPw9GkcTqA0tITKshXud3qns919Oddu_cksCkluiwzc1ngauvHf0ccoI5z61aC-QJc5s6RB2yyeKprKfyBcfkG8Z5v2z5FYurMvFWb6U1FDTQCl_zoRFT43eEL9zrRiiWCLOu3xX4uDjgiEmiqxpAmQ9RUssyS_tmK1kEAGkItyu6wJ3GCWKQu34lcU_sTP-7yWJkhhje5H2v3lSvKErYc7iqSVhqRa5gL3--ygm0bnOQOpxNvUmK42Qrmqa12z7XXymxhwKHU4UFpf6Pw.5y29BEkxpFaNDfxSSUlAhQ","scope":"zahoorahmad/titanic-2nd-degree-families-and-majority-voting"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","sourceUrl":"/c/titanic","slug":"titanic","lastUpdated":"2012-09-28T21:13:33.55Z","overview":"Start here! Predict survival on the Titanic and get familiar with ML basics","sourceType":"competition","sourceVersionType":null,"sourceId":3136,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":"text/html","deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":26502,"dataset":null,"competition":{"competitionId":3136,"dataviewToken":null,"scope":"c/titanic"},"kernel":null,"previewsDisabled":true},"type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"id":63842,"blobFileId":37991,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/gender_submission.csv","creationDate":"2017-02-01T01:49:18Z","isDummy":false,"size":3258,"fullPath":"../input/gender_submission.csv","previewUrl":"kernels/competition-preview/3136?relativePath=gender_submission.csv","downloadUrl":"/c/titanic/download/gender_submission.csv","fileType":".csv","contentLength":3258,"contentType":"text/csv","contentMD5":"MNEHO5ZKXYFUMexgOg3jUw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n"},{"order":1,"originalType":"","type":"boolean","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"gender_submission.csv","description":"892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,0\n901,0\n902,0\n903,0\n904,1\n905,0a\n906,1\n907,0\n908,0\n909,0\n910,0\n911,0\n912,1\n913,0\n914,0\n915,0\n916,1\n917,0\n918,0\n919,0\n920,0\n921,0\n922,0\n923,0\n924,0\n925,0\n926,1\n927,0\n928,0\n929,0\n930,0\n931,1\n932,0\n933,0\n934,0\n935,0\n936,1\n937,0\n938,0\n939,0\n940,1\n941,0\n942,1\n943,0\n944,0\n945,1\n946,0\n947,0\n948,0\n949,0\n950,0\n951,1\n952,0\n953,0\n954,0\n955,0\n956,1\n957,0\n958,0\n959,0\n960,0\n961,1\n962,\n963,0\n964,0\n965,0\n966,1\n967,1\n968,0\n969,0\n970,0\n971,0\n972,0\n973,1\n974,0\n975,0\n976,0\n977,0\n978,0\n979,0\n980,0\n981,0\n982,0\n983,0\n984,0\n985,0\n986,0\n987,0\n988,1\n989,0\n990,0\n991,0\n992,1\n993,0\n994,0\n995,0\n996,0\n997,0\n998,0\n999,0\n1000,0\n1001,0\n1002,0\n1003,0\n1004,0\n1005,0\n1006,1\n1007,0\n1008,0\n1009,0\n1010,1\n1011,0\n1012,0\n1013,0\n1014,1\n1015,0\n1016,0\n1017,0\n1018,0\n1019,0\n1020,0\n1021,0\n1022,0\n1023,0\n1024,0\n1025,0\n1026,0\n1027,0\n1028,0\n1029,0\n1030,0\n1031,0\n1032,0\n1033,1\n1034,1\n1035,0\n1036,0\n1037,0\n1038,1\n1039,0\n1040,0\n1041,0\n1042,1\n1043,0\n1044,0\n1045,0\n1046,0\n1047,0\n1048,1\n1049,0\n1050,0\n1051,0\n1052,0\n1053,0\n1054,0\n1055,0\n1056,0\n1057,0\n1058,1\n1059,0\n1060,0\n1061,0\n1062,0\n1063,0\n1064,0\n1065,0\n1066,0\n1067,0\n1068,0\n1069,1\n1070,0\n1071,1\n1072,0\n1073,1\n1074,1\n1075,0\n1076,1\n1077,0\n1078,0\n1079,0\n1080,1\n1081,0\n1082,0\n1083,0\n1084,0\n1085,0\n1086,0\n1087,0\n1088,1\n1089,0\n1090,0\n1091,0\n1092,0\n1093,0\n1094,1\n1095,0\n1096,0\n1097,0\n1098,0\n1099,0\n1100,0\n1101,0\n1102,0\n1103,0\n1104,1\n1105,0\n1106,0\n1107,0\n1108,0\n1109,1\n1110,1\n1111,0\n1112,0\n1113,0\n1114,0\n1115,0\n1116,0\n1117,0\n1118,0\n1119,0\n1120,0\n1121,0\n1122,1\n1123,0\n1124,0\n1125,0\n1126,1\n1127,0\n1128,1\n1129,0\n1130,0\n1131,1\n1132,0\n1133,0\n1134,1\n1135,0\n1136,0\n1137,1\n1138,0\n1139,0\n1140,0\n1141,0\n1142,0\n1143,0\n1144,1\n1145,0\n1146,0\n1147,0\n1148,0\n1149,0\n1150,0\n1151,0\n1152,0\n1153,0\n1154,0\n1155,0\n1156,0\n1157,0\n1158,0\n1159,0\n1160,0\n1161,0\n1162,1\n1163,0\n1164,1\n1165,0\n1166,0\n1167,0\n1168,0\n1169,0\n1170,0\n1171,0\n1172,0\n1173,0\n1174,0\n1175,0\n1176,0\n1177,0\n1178,0\n1179,1\n1180,0\n1181,0\n1182,0\n1183,0\n1184,0\n1185,1\n1186,0\n1187,0\n1188,0\n1189,0\n1190,1\n1191,0\n1192,0\n1193,0\n1194,0\n1195,0\n1196,0\n1197,0\n1198,1\n1199,0\n1200,1\n1201,0\n1202,0\n1203,0\n1204,0\n1205,0\n1206,1\n1207,0\n1208,1\n1209,0\n1210,0\n1211,0\n1212,0\n1213,0\n1214,0\n1215,0\n1216,1\n1217,0\n1218,0\n1219,1\n1220,0\n1221,0\n1222,0\n1223,0\n1224,0\n1225,0\n1226,0\n1227,0\n1228,0\n1229,0\n1230,0\n1231,0\n1232,0\n1233,0\n1234,1\n1235,1\n1236,0\n1237,0\n1238,0\n1239,0\n1240,0\n1241,0\n1242,1\n1243,0\n1244,1\n1245,1\n1246,0\n1247,0\n1248,1\n1249,0\n1250,0\n1251,0\n1252,1\n1253,0\n1254,0\n1255,0\n1256,1\n1257,1\n1258,0\n1259,0\n1260,0\n1261,0\n1262,0\n1263,1\n1264,0\n1265,0\n1266,1\n1267,1\n1268,0\n1269,0\n1270,1\n1271,0\n1272,0\n1273,0\n1274,0\n1275,0\n1276,0\n1277,1\n1278,0\n1279,0\n1280,0\n1281,0\n1282,1\n1283,0\n1284,0\n1285,0\n1286,0\n1287,1\n1288,0\n1289,1\n1290,0\n1291,0\n1292,1\n1293,0\n1294,0\n1295,1\n1296,0\n1297,0\n1298,0\n1299,1\n1300,0\n1301,0\n1302,0\n1303,1\n1304,0\n1305,0\n1306,1\n1307,0\n1308,0\n1309,0"},{"id":63841,"blobFileId":2613,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/test.csv","creationDate":"2013-06-28T13:40:24.227Z","isDummy":false,"size":28629,"fullPath":"../input/test.csv","previewUrl":"kernels/competition-preview/3136?relativePath=test.csv","downloadUrl":"/c/titanic/download/test.csv","fileType":".csv","contentLength":28629,"contentType":"text/csv","contentMD5":"dTO4Lq5LWCYQy9aKpjawFw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"1"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"1"},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"the name of the passenger"},{"order":3,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":null},{"order":4,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":null},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"of siblings / spouses aboard the Titanic"},{"order":6,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"of parents / children aboard the Titanic"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":"Ticket number"},{"order":8,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":"Passenger fare"},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":"Cabin number"},{"order":10,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"Port of Embarkation"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"test.csv","description":"test data to check the accuracy of the model created\n"},{"id":63840,"blobFileId":2307,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/train.csv","creationDate":"2013-06-28T13:40:25.23Z","isDummy":false,"size":61194,"fullPath":"../input/train.csv","previewUrl":"kernels/competition-preview/3136?relativePath=train.csv","downloadUrl":"/c/titanic/download/train.csv","fileType":".csv","contentLength":61194,"contentType":"text/csv","contentMD5":"IwnMXwR4Ltm7YBbZ9OOBzw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":891},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"type should be integers"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"Survived or Not "},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"Class of Travel"},{"order":3,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"Name of Passenger"},{"order":4,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":"Gender"},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":"Age of Passengers"},{"order":6,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"Number of Sibling/Spouse aboard"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"Number of Parent/Child aboard"},{"order":8,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":null},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":null},{"order":10,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":null},{"order":11,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"train.csv","description":"contains data \n"}],"name":"Titanic: Machine Learning from Disaster","description":"\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe data has been split into two groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etraining set (train.csv)\u003c/li\u003e\n\u003cli\u003etest set (test.csv)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cb\u003e The training set \u003c/b\u003eshould be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use \u003ca href=\u0022https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\u0022 target=\u0022_blank\u0022\u003e feature engineering \u003c/a\u003eto create new features.\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eThe test set \u003c/b\u003eshould be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\u003c/p\u003e\n\u003cp\u003eWe also include \u003cb\u003egender_submission.csv\u003c/b\u003e, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\u003c/p\u003e\n\u003ch3\u003eData Dictionary\u003c/h3\u003e\n\u003ctable style=\u0022width: 100%;\u0022\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003cth\u003e\u003cb\u003eVariable\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eDefinition\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eKey\u003c/b\u003e\u003c/th\u003e\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esurvival\u003c/td\u003e\n\u003ctd\u003eSurvival\u003c/td\u003e\n\u003ctd\u003e0 = No, 1 = Yes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epclass\u003c/td\u003e\n\u003ctd\u003eTicket class\u003c/td\u003e\n\u003ctd\u003e1 = 1st, 2 = 2nd, 3 = 3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esex\u003c/td\u003e\n\u003ctd\u003eSex\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAge\u003c/td\u003e\n\u003ctd\u003eAge in years\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esibsp\u003c/td\u003e\n\u003ctd\u003e# of siblings / spouses aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eparch\u003c/td\u003e\n\u003ctd\u003e# of parents / children aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eticket\u003c/td\u003e\n\u003ctd\u003eTicket number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003efare\u003c/td\u003e\n\u003ctd\u003ePassenger fare\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecabin\u003c/td\u003e\n\u003ctd\u003eCabin number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eembarked\u003c/td\u003e\n\u003ctd\u003ePort of Embarkation\u003c/td\u003e\n\u003ctd\u003eC = Cherbourg, Q = Queenstown, S = Southampton\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eVariable Notes\u003c/h3\u003e\n\u003cp\u003e\u003cb\u003epclass\u003c/b\u003e: A proxy for socio-economic status (SES)\u003cbr /\u003e 1st = Upper\u003cbr /\u003e 2nd = Middle\u003cbr /\u003e 3rd = Lower\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eage\u003c/b\u003e: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003esibsp\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Sibling = brother, sister, stepbrother, stepsister\u003cbr /\u003e Spouse = husband, wife (mistresses and fiancés were ignored)\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eparch\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Parent = mother, father\u003cbr /\u003e Child = daughter, son, stepdaughter, stepson\u003cbr /\u003e Some children travelled only with a nanny, therefore parch=0 for them.\u003c/p\u003e"}],"versions":[{"id":2972542,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2018-03-28T10:58:56.927Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":49.6756983119994,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Titanic: 2nd degree families and majority voting","url":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting?scriptVersionId=2972542","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":2951774,"kernelVersionId":null,"isForkParent":true,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2018-03-27T08:45:22.207Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":105748,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:0b7b0f4ac1cf07839ba6945c2874afc761b5fb9cbbab6acdc631a1b6c7c7180a","dockerImageName":"gcr.io/kaggle-images/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":45.341836706968,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Titanic: 2nd degree families and majority voting","url":"/erikbruin/titanic-2nd-degree-families-and-majority-voting","versionNumber":0,"hasVersionNumber":false,"isRedacted":false,"versionAuthor":null}],"categories":{"categories":[{"id":13208,"name":"data visualization","displayName":"data visualization","fullPath":"analysis \u003e data visualization","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27data visualization%27","tagUrl":"/tags/data-visualization","fontAwesomeIcon":null,"description":null,"isInherited":false,"datasetCount":131,"competitionCount":0,"scriptCount":6393,"totalCount":6524},{"id":13306,"name":"feature engineering","displayName":"feature engineering","fullPath":"machine learning \u003e feature engineering","listingUrl":"/kernels?sortBy=relevance\u0026group=all\u0026search=tag%3A%27feature engineering%27","tagUrl":"/tags/feature-engineering","fontAwesomeIcon":null,"description":null,"isInherited":false,"datasetCount":44,"competitionCount":0,"scriptCount":1973,"totalCount":2017}],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/2972542","submission":{"date":"2018-03-28T11:02:19.053Z","privateScore":null,"publicScore":"0.81339","submissionId":7036320,"teamName":"ZahoorAhmad"},"menuLinks":[{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/notebook","text":"Report","title":"Notebook","tab":"report","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/data","text":"Data","title":"Data","tab":"data","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/output","text":"Output","title":"Output","tab":"output","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/comments","text":"Comments","title":"Comments","tab":"comments","count":0,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/versions","text":"Versions","title":"Versions","tab":"versions","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/zahoorahmad/titanic-2nd-degree-families-and-majority-voting/forks","text":"Forks","title":"Forks","tab":"forks","count":0,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/2972542","text":"Fork Script","title":"Fork Script","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":"kernels","reportEventType":"anonymousKernelForkCreation"},"voteButton":{"totalVotes":3,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=786539","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/732709-kg.jpg","displayName":"LydiaChege","profileUrl":"/wabbiy","tier":"Novice","tierInt":0,"userId":732709,"userName":"wabbiy"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1330380-gp.jpg","displayName":"Ömer Yalçın","profileUrl":"/omeryalcin","tier":"Novice","tierInt":0,"userId":1330380,"userName":"omeryalcin"},{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/1364657-kg.JPG","displayName":"ZahoorAhmad","profileUrl":"/zahoorahmad","tier":"Contributor","tierInt":1,"userId":1364657,"userName":"zahoorahmad"}],"currentUserInfo":null,"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"Titanic: Machine Learning from Disaster","parentUrl":"/c/titanic","thumbnailImageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"canSeeCopyAndEditText":true,"simplifiedViewer":false,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="/zahoorahmad/titanic-2nd-degree-families-and-majority-voting" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL-F2AGb4mZj-AVDm0gsc4jZAXpGkgoaJ8vGlzvL4bnwuVVki9BhPjcolWqsiRWxAPm7e4-J2bL2B8xTeBZKa6EfX5IfvhfM_gtmmoifq7MonYe5XsBWnr17jtL6o6fqGr0" /></form>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async crossorigin="anonymous" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>&copy; 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="/team">Our Team</a>
            <a href="/terms">Terms</a>
            <a href="/privacy">Privacy</a>
            <a href="/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>




    </main>
</body>
</html>
