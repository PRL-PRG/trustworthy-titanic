{"cells":[{"metadata":{"_uuid":"007bf6a70936c7370199013dbc60537cf86b2f0a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"## Importing packages\n\n# This R environment comes with all of CRAN and many other helpful packages preinstalled.\n# You can see which packages are installed by checking out the kaggle/rstats docker image: \n# https://github.com/kaggle/docker-rstats\n\nlibrary(tidyverse) # metapackage with lots of helpful functions\n\ndados = read.csv('../input/train.csv', sep = ',', header = T)\n\n# Convertendo sexo para numérica (1 = male)\ndados$Sexo = 0\ndados[which(dados$Sex == 'Male'), 'Sexo'] = 1\n\ndados = dados %>% select(c('Survived', 'Age', 'Sexo', 'Fare', 'SibSp', 'Parch', 'Pclass'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cdece3e2fa70d03f3dd306af826d0f8b50a261c"},"cell_type":"code","source":"# XGBoost\nlibrary(xgboost)\n\n# Caret para fazer o split da amostra (treino e teste)\nlibrary(caret)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12c1bff3e592d939c16680ba63437768b9c3ac7a"},"cell_type":"code","source":"# Número de linhas no data frame\nnrow(dados)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4d3ed752b4016a3ee65df222d33b70895e424bb"},"cell_type":"code","source":"# Dividindo a amostra em treino e teste\n\np_treino = .9 # proporção de casos para amostra de treino\n\n# Usando o caret, podemos dividir a amostra preservando a proporção entre sobreviventes e não-sobreviventes\nindice_treino = createDataPartition(dados$Survived, times = 1, p = p_treino)\n\n# Testando\ntable(dados[indice_treino$Resample1, 'Survived']) / sum(table(dados[indice_treino$Resample1, 'Survived']))\ntable(dados[-indice_treino$Resample1, 'Survived']) / sum(table(dados[-indice_treino$Resample1, 'Survived']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4589cedc1015495d23166ff1c88bde7f98b96c46"},"cell_type":"code","source":"# Criando amostra de treino e teste\ntrain = dados[indice_treino$Resample1,]\ntest = dados[-indice_treino$Resample1, ]\n\nX_train = as.matrix(train %>% select(c(Sexo, Fare, Age, Parch, SibSp, Pclass)))\ny_train = as.matrix(train$Survived)\n\nX_test = as.matrix(test %>% select(c(Sexo, Fare, Age, Parch, SibSp, Pclass)))\ny_test = as.matrix(test$Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8112f2a80e26b6f46f4ec8513796201ec2e0d767"},"cell_type":"code","source":"# Treinando um modelo na amostra de treino\nlista_n = c(3, 10, 100, 200, 500, 1000)\nres = data.frame(nrounds = NA, erro_treino = NA, erro_teste = NA)\nfor(i in 1:length(lista_n)) {\n    print(paste0(\"Rodando xgboost com \", lista_n[i], \" rounds.\"))\n    mod1 = xgboost(data = X_train, label = y_train, nrounds = lista_n[i], verbose = 0, objective = 'binary:logistic')\n    erro_treino = mod1$evaluation_log$train_error[length(mod1$evaluation_log$train_error)]\n    y_pred = predict(mod1, X_test)    \n    y_pred = ifelse(y_pred > 0, 1, 0)\n    tmp = data.frame(previsto = y_pred, real = y_test)\n    erro_teste = 1 - sum(tmp$previsto == tmp$real) / nrow(tmp)\n    res = rbind(res, data.frame(nrounds = lista_n[i], erro_treino = erro_treino, erro_teste = erro_teste))\n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff8c943af4c5e8b48dea1e927d22e2ec382da964","scrolled":true},"cell_type":"code","source":"dt.plot = data.frame(x = mod1$evaluation_log$iter, y = mod1$evaluation_log$train_error)\ng = ggplot(data = dt.plot, aes(x = x, y = y))\ng + geom_line() + geom_point() + annotate('text', label = 'Note como o erro de treino não para de cair', x = 500, y = 0.15, color = 'black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9d7e25864d1a2b6c365b448847a994d75169eaf"},"cell_type":"code","source":"# Fazendo cross-validation \n\n# Construindo as matrizes para o xgboost\nX = as.matrix(dados %>% select(c(Sexo, Fare, Age, Parch, SibSp, Pclass)))\ny = as.matrix(dados$Survived)\n\n# Teste: executando o cross-validation uma vez\n# nfold = 5 significa que a função vai dividir a base de dados em 5 fatias e vai treinar o modelo 5 vezes (cada vez deixando uma fatia de fora\n# para fazer o papel de amostra de teste)\ncv.res = xgb.cv(data = X, label = y, nfold = 5, nrounds = 100, max_depth = 6, objective = 'binary:logistic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df3987d150d978913928f047066b99cf55f8d2b"},"cell_type":"code","source":"# Fazendo o gráfico do erro de treino x erro de teste\ndt.plot = data.frame(iter = cv.res$evaluation_log$iter, test = cv.res$evaluation_log$test_error_mean, train = cv.res$evaluation_log$train_error_mean)\n\n# Preciso dessa biblioteca para usar a função melt\nlibrary(reshape)\n\n# Essa função tem o efeito de transformar duas colunas (test e train) em uma coluna \"valor\" e uma coluna \"variável\"\n# Por exemplo, em vez de ter uma linha\n#\n#   id  |  test  |  train\n#   1   |   0.5  |   0.3\n#\n# Passamos a ter duas linhas\n#\n#   id  |  variable  |  value\n#    1  |   test     | 0.5\n#    1  |   train    | 0.3\n#\n# Essa operação é útil para fazermos o gráfico das duas linhas com cores diferentes, conforme ggplot abaixo\ndt.plot = melt(data = dt.plot, measure.vars = c('test', 'train'), id.vars = 'iter')\n\ng = ggplot(data = dt.plot, aes(x = iter, y = value, color = variable))\ng + geom_line() + geom_point() + labs(color = 'Erro') + xlab(\"Número de modelos\") + ylab(\"Erro\") + \nannotate(\"text\", label = \"Note como o erro de teste para de cair, \\nenquanto o erro de treino continua caindo...\", x = 25, y = 0.25, color = \"black\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ab59eb3be277e3e922e8fcc9dd059f1ea37b017"},"cell_type":"code","source":"# Fazendo cross-validation para um parâmetro (max_depth)\n\n# Lista de valores possíveis\nlista_max_depth = c(1, 2, 3, 6, 10, 20)\n\ndf.erro = data.frame(max_depth = NA, erro_medio = NA)\nfor(l in lista_max_depth) {\n    print(paste0(\"Testando max_depth = \", l))\n    # Rodo o cross-validation com o valor atual de lista_max_depth\n    cv.res = xgb.cv(data = X, label = y, nfold = 5, nrounds = 50, max_depth = l, verbose = F, objective='binary:logistic')\n    \n    # Guardo o erro de teste médio\n    erro = mean(cv.res$evaluation_log$test_error_mean)\n    df.erro = rbind(df.erro, data.frame(max_depth = l, erro_medio = erro))\n}\ndf.erro = df.erro[2:nrow(df.erro),]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f087cfbe48876af19f49898cef39f0a662cdcbd"},"cell_type":"code","source":"# Visualizando resultados\n# Valor ótimo foi max_depth = 3\ndf.erro","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8164e844d835223af5c1d484fd56ae5ae053d63"},"cell_type":"code","source":"# Rodando cross-validation para dois parâmetros\n# Existem vários outros parâmetros que podem ser otimizados\n# Ver a lista em https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster\nlista_max_depth = c(2, 3, 10)\nlista_colsample_bytree = c(2/6,3/6,4/6,5/6)\n\ndf.res = data.frame(max_depth = NA, colsample_bytree = NA, erro_medio = NA)\nfor(max_depth in lista_max_depth) {\n    for(colsample_bytree in lista_colsample_bytree){\n        print(paste0(\"Testando max_depth = \", max_depth, \" e colsample_bytree = \", colsample_bytree))\n        # Rodo o cross-validation com o valor atual dos parâmetros\n        cv.res = xgb.cv(data = X, label = y, nfold = 5, nrounds = 50, max_depth = max_depth, colsample_bytree = colsample_bytree, verbose = F, objective='binary:logistic')\n\n        # Guardo o erro de teste médio\n        erro = mean(cv.res$evaluation_log$test_error_mean)\n        df.res = rbind(df.res, data.frame(max_depth = max_depth, colsample_bytree = colsample_bytree, erro_medio = erro))\n    }\n}\n\ndf.res = df.res[2:nrow(df.res), ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e739c9ea33aac833f89dbf8ad61941580a1f5c04"},"cell_type":"code","source":"# Avaliando resultados\n# Ordeno o data frame em ordem crescente do erro_medio\ndf.res[order(df.res$erro_medio),]\n# O melhor resultado foi com max_depth = 3 e colsample_bytree = 0.333 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fb85bb0bd243c91866f54847c1733dc1384d73d"},"cell_type":"code","source":"# Treinando o modelo com os melhores parâmetros\nmax_depth = 3\ncolsample_bytree = 1 / 3\nmod.opt = xgboost(data = X, label = y, nrounds = 50, verbose = 0, max_depth = max_depth, colsample_bytree = colsample_bytree, objective = 'binary:logistic')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98133ab081be00cc85a9a2bcba84455d1e601a9d"},"cell_type":"code","source":"# Amostra de teste Kaggle\ntest = read.csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fe19b4eb44dbb74d313f9da763d8d65c201df2a"},"cell_type":"code","source":"# Preenchendo missing de Age e Fare\ntest[which(is.na(test$Age)), 'Age'] = mean(test$Age, na.rm = T)\ntest[which(is.na(test$Fare)), 'Fare'] = mean(test$Fare, na.rm = T)\ntest$Sexo = 0\ntest[which(dados$Sex == 'Male'), 'Sexo'] = 1\n\nX_test = as.matrix(test %>% select(c(Sexo, Fare, Age, Parch, SibSp, Pclass)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2356aa867c4ef09ee5e89aef42686c9e62e482c8"},"cell_type":"code","source":"# Calculando previsões para submeter à competição\nres = predict(mod.opt, X_test)\n\n# Aplicando o threshold: se a probabilidade prevista for maior que t, considero que a previsão é \"sobrevivente\"\nt = 0.5\npres = ifelse(res > t, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13ab0433f603381e0346604231021ff6aabcc21d"},"cell_type":"code","source":"submit = data.frame(PassengerId = test$PassengerId, Survived = pres)\nwrite.csv(submit, \"submit_XG.csv\", row.names = F)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0f9433610552f62b9e8ba53e4dad409ec342ded"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}