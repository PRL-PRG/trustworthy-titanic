
---
title: "Modeling the Titanic Dataset"
author: "Mauricio Anderson Ricci"
date: 'Jul 2016'
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 1 
    fig_width: 7
    fig_height: 4.5
    theme: readable
    highlight: tango
---

<style type = "text/css">
  body{   font-size: 14px;}
  h1{     font-size: 24px;}
  h2{     font-size: 18px;}
  h3{     font-size: 14px;}
  code.r{ font-size: 12px;}
  pre{    font-size: 12px;}
</style>

```{r, include=FALSE}
# Multiple plot function 
# from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
# 
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifing the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

# Introduction

This is a brief summary of my first script at Kaggle at which I'm going to perform a model to predict the survivors on the Titanic dataset. In order to this, I'm going to follow the [crisp-dm](https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining) methodology so this report continues with the next sections: 

 * Exploratory Data Analysis
 * Data Preparation: Cleaning Data and Feature Engeniering
 * Modeling and Evaluation
 * Making the Predictions
 
Finally, before start, I want to mention that everyone is welcome leave your comments and feedback. Thanks.

Here we go.


# Exploratory Data Analysis

First of all, we need to load the libraries we are going to use:

```{r, message = FALSE, warning = FALSE}
library(data.table)
library(ggplot2)
library(plyr)
library(dplyr)
library(caret)
library(caretEnsemble)
```

And the data:

```{r, message = FALSE, warning=FALSE}
test             <- read.csv("../input/test.csv",  stringsAsFactors = F, header = T, na.strings = c('NA',''))
train_valid_data <- read.csv("../input/train.csv", stringsAsFactors = F, header = T, na.strings = c('NA',''))
```

We won't touch again the test data for now. Respect to this point, We've seen other works in which the exploratory analysis includes it. Perhaps that's the most apropiated way in this case, but I prefer don't include it because it reduces generality of the model we will to perform.

Now, a first look at the training set:

```{r}
str(train_valid_data)
```

We can see there are 11 varables (plus the ID) and 891 observations. The meaning of each variable and the codification is found at information section of the competition.


# Data Preparation
## PassengerId

This column really doesn't contain information about the passengers. Its finality is identify the passengers, so we will treat the column as character type:

```{r, message = FALSE}
train_valid_data$PassengerId <- as.character(train_valid_data$PassengerId)
```

## Survival

This varible represent the final state of each passenger in the titanic. According to the documentation: 0 = 'Perished'; 1 = 'Survived'. We will make a little change during this section, only for clarity purposes, and then  convert it to factor type.

```{r, message = FALSE}
train_valid_data$Survived <- as.factor(ifelse(train_valid_data$Survived == 1, 'Survived', 'Perished'))
```

The distribution of the passengers is:

```{r}
round(prop.table(table(train_valid_data$Survived)),2)
```

We see that the natural rate of the dataset is 62/38, so our floor to measure the performance of the model respect to the randomness is 62%.

## Ticket

The ticket variable, at first glance, doesn't contribute with anything relevant so we'll remove it.

```{r}
head(train_valid_data$Ticket, 15)
train_valid_data$Ticket <- NULL
```

## Pclass

This variable represents the Passengers' Class so we're going to treat it as factor type:

```{r}
train_valid_data$Pclass <- as.factor(train_valid_data$Pclass)
```

The distribution of this variable respect the survivors is:

```{r}
round(prop.table(table(train_valid_data$Survived, train_valid_data$Pclass), margin = 2),2)
```

We see that the class is a stronge variable: the higher the class, the higher the chances of surviving... and we can suppose the higher the fare. 

Perhaps this varible could be useful if we decided tp create a model to Passengers of Pclass 1, and another to 2 and 3. So, we'll keep it for now.

## Fare

To check the last sentence let's to visualize the relationship between the class and the fare: 

```{r, message=FALSE, warning=FALSE}
ggplot(train_valid_data, aes(x = Fare, fill = Pclass)) +
  geom_density(alpha = 0.5) +
  lims(x = c(0, 100))
```

To my surprise, it's true that the class is in some manner is correlate with the class, but I was expecting something more strongly. So, based on this fact, we will generate fare intervals because it could be helpful at the moment of training models.

```{r, message=FALSE, warning=FALSE, fig.height=10}
p1 = ggplot(train_valid_data, aes(x = Fare, fill = Survived)) + 
      geom_density(alpha = 0.5) +
      geom_vline(xintercept = c(15, 25, 50), size = 1.2, col = 'blue') +
      ggtitle("Distribution of survivors respect to the fare") +
      lims(x = c(0, 100))

p2 = ggplot(train_valid_data, aes(x = Fare, fill = Survived)) + 
      geom_density(alpha = 0.5, position = 'fill') +
      geom_vline(xintercept = c(15, 25, 50), size = 1.2, col = 'blue') +
      ggtitle("Proportion of survivors respect to the age") +
      lims(x = c(0, 100))

multiplot(p1, p2, cols=1)
```

Let's to creat intervals of this variable.

```{r}
if(anyNA(train_valid_data$Fare)) train_valid_data[is.na(train_valid_data$Fare),]$Fare <- mean(train_valid_data$Fare, na.rm = T)

train_valid_data$Fare_type <- as.factor(ifelse(train_valid_data$Fare <= 15, "Low", 
                                        ifelse(train_valid_data$Fare >  15 & train_valid_data$Fare <= 25, "Medium", 
                                        ifelse(train_valid_data$Fare >  25 & train_valid_data$Fare <= 50, "High", "Very_High"))))
```

And the final relation with the survivors is:

```{r}
round(prop.table(table(train_valid_data$Survived, train_valid_data$Fare_type), margin = 2),2)
```

Again, we see a strong relation between the fare and the target.


## Cabin

In the cabin variable we find a lot of missing values, near 77% of the registers, most of these NA belong to Pclass 2 and 3. To deal with these we will to replace with _X_ and then analize the distribution.

```{r}
train_valid_data$Cabin <- substr(train_valid_data$Cabin,0,1)
train_valid_data$Cabin <- ifelse(is.na(train_valid_data$Cabin), 'X', train_valid_data$Cabin)
train_valid_data$Cabin <- ifelse(train_valid_data$Cabin %in% c('A', 'B', 'C', 'D', 'E'), train_valid_data$Cabin, 'X')
train_valid_data$Cabin <- as.factor(train_valid_data$Cabin)

table(train_valid_data$Cabin, train_valid_data$Pclass)

table(train_valid_data[train_valid_data$Pclass=='1',]$Cabin, train_valid_data[train_valid_data$Pclass=='1',]$Survived)
```

This variable could be very usefull if we creat a model for first class and other for the other.


## Sex

Let's see what can find between gender and survivors:

```{r}
train_valid_data$Sex <- as.factor(train_valid_data$Sex)
round(prop.table(table(train_valid_data$Survived, train_valid_data$Sex), margin = 2),2)
```

Interesting, while the 74% of women survived, only 19% of men survived. This is another good variable to generate multiple models.

## Name

Respect to the names of the passengers there are a lot of thing which could be fun to play, but I'll stay only with the essential. If at the end of the work I don't get good results we can come back and try extract more information from the names.

```{r}
head(train_valid_data$Name, 15)
```

All passengers' names have a _title_ which contain some information about each one, so we're going to put this title into a variable and remove the original variable. After some glance at the names we can identify the next titles: 

```{r}
train_valid_data$Name_title <- as.factor(ifelse(grepl(pattern = " miss.", x = train_valid_data$Name, ignore.case = T), "miss",
                                ifelse(grepl(pattern = " mrs.", x = train_valid_data$Name, ignore.case = T), "mrs", 
                                ifelse(grepl(pattern = " mr.", x = train_valid_data$Name, ignore.case = T), "mr", 
                                ifelse(grepl(pattern = " master.", x = train_valid_data$Name, ignore.case = T), "master", 
                                ifelse((as.character.factor(train_valid_data$Sex)=='male') & (train_valid_data$Age>=13), "mr", 
                                ifelse((as.character.factor(train_valid_data$Sex)=='male') & (train_valid_data$Age<13), "master", "mrs")))))))

train_valid_data$Name_title[is.na(train_valid_data$Name_title)] <- ifelse((is.na(train_valid_data$Name_title)) & (as.character.factor(train_valid_data$Sex) == 'male'), 'mr', 'mrs')

train_valid_data$Name <- NULL

round(prop.table(table(train_valid_data$Name_title)),2)
```

## SibSp & Parch

These variable tell us about the family composition. We're going to create two new variables, `family_size`, which indicate the size of the family and `SibSp_Parch_mult` which is the product of the two original varibles.

```{r, warning=FALSE}
train_valid_data$family_size      <- train_valid_data$Parch + train_valid_data$SibSp + 1
train_valid_data$SibSp_Parch_mult <- train_valid_data$SibSp * train_valid_data$Parch
```

## Age

Let's inspect the ages:

```{r, warning=FALSE}
summary(train_valid_data$Age)
```

In first place, we find 177 NA's values, which represents ~20% of the total passengers. This is a huge amount of cases so the most convenient is impute them is some way but, before impute these value let's see if it is conveniente split the variable in groups:

```{r, warning=FALSE, fig.height=10}
p1 <- ggplot(train_valid_data, aes(x = Age, fill = Survived)) + 
        geom_density(alpha = 0.5) +
        geom_vline(xintercept = c(13, 30, 50), size = 1.2, col = 'blue') +
        ggtitle("Distribution of survivors respect to the age") +
        lims(x = c(0, 80)) 

p2 <- ggplot(train_valid_data, aes(x = Age, fill = Survived)) + 
        geom_density(alpha = 0.5, position = "fill") +
        geom_vline(xintercept = c(13, 30, 50), size = 1.2, col = 'blue') +
        ggtitle("Proportion of survivors respect to the age") +
        lims(x = c(0, 80))

multiplot(p1, p2, cols=1)
```

Now let's go to impute each missing value. The way I've choosen is by a random forest model trained with the completed cases and then using it to impute the missing cases:

```{r age_model, warning=FALSE, message=FALSE}
Age_model <- train(Age ~ Sex + Pclass + SibSp + Parch + SibSp_Parch_mult + Fare + Name_title,
                 data = train_valid_data[complete.cases(train_valid_data),], 
                 method = "rf")

train_valid_data[is.na(train_valid_data$Age),]$Age <- predict(object = Age_model, 
                                                              newdata = train_valid_data[is.na(train_valid_data$Age),])
```

Again, we're going to split the variable into groups related with the proportions of survivors in each one:

```{r, warning=FALSE}
train_valid_data$Age_group <- as.factor(ifelse(train_valid_data$Age > 0  & train_valid_data$Age <= 13,  "g0_13", 
                                        ifelse(train_valid_data$Age > 13 & train_valid_data$Age <= 30,  "g13_30", 
                                        ifelse(train_valid_data$Age > 30 & train_valid_data$Age <= 50,  "g30_50", 
                                        ifelse(train_valid_data$Age > 50, "g50_inf", NA)))))
```

The final distribution of this variable respect the survaviors is:

```{r}
round(prop.table(table(train_valid_data$Survived, train_valid_data$Age_group), margin = 2),2)
```

## Embarked

Finally, the place where people have embarked doesn't seem to be relevant. There are two missing values, so we'll impute them in the majority class:

```{r, warning=FALSE}
round(prop.table(table(train_valid_data$Embarked)), 2)
if(anyNA(train_valid_data$Embarked)) train_valid_data[is.na(train_valid_data$Embarked),]$Embarked <- "S" 
train_valid_data$Embarked <- as.factor(train_valid_data$Embarked)
```

## Extra features

Some additional variables I've seen in other works but I'm not sure about their usefulness.

```{r, warning=FALSE}
train_valid_data$Fare_family_div <- train_valid_data$Fare / train_valid_data$family_size
train_valid_data$Age_Fare_mult <- train_valid_data$Age * train_valid_data$Fare
```

## Final View

Once we have explored each variable in the dataset, let's return the Survived variable to its original form and look at the final structure:

```{r}
train_valid_data$Survived <- as.factor(ifelse(as.character.factor(train_valid_data$Survived) == 'Survived', '1', '0'))
str(train_valid_data)
```

We've conserved the `r length(train_valid_data$Survived)` observations and prepared `r length(names(train_valid_data))-2` variables to train the models. 

Now, before continue with next step we're going to apply the same transformation to the test set.

```{r, warning = FALSE, message=FALSE, results="hide", echo=FALSE}

test$PassengerId <- as.character(test$PassengerId)

test$Pclass      <- as.factor(test$Pclass)

test$Sex         <- as.factor(test$Sex)

if(anyNA(test$Fare)) test[is.na(test$Fare),]$Fare <- mean(train_valid_data$Fare, na.rm = T)

test$Fare_type   <- as.factor(ifelse(test$Fare <= 15, "Low", 
                              ifelse(test$Fare >  15 & test$Fare <= 25, "Medium", 
                              ifelse(test$Fare >  25 & test$Fare <= 50, "High", "Very_High"))))

test$Cabin <- substr(test$Cabin,0,1)
test$Cabin <- ifelse(is.na(test$Cabin), 'X', test$Cabin)
test$Cabin <- ifelse(test$Cabin %in% c('A', 'B', 'C', 'D', 'E'), test$Cabin, 'X')
test$Cabin <- as.factor(test$Cabin)

test$Name_title <- as.factor(ifelse(grepl(pattern = " miss.", x = test$Name, ignore.case = T), "miss",
                                ifelse(grepl(pattern = " mrs.", x = test$Name, ignore.case = T), "mrs", 
                                ifelse(grepl(pattern = " mr.", x = test$Name, ignore.case = T), "mr", 
                                ifelse(grepl(pattern = " master.", x = test$Name, ignore.case = T), "master", 
                                ifelse((as.character.factor(test$Sex)=='male') & (test$Age>=13), "mr", 
                                ifelse((as.character.factor(test$Sex)=='male') & (test$Age<13), "master", "mrs")))))))

test$Name_title[is.na(test$Name_title)] <- ifelse((is.na(test$Name_title)) & (as.character.factor(test$Sex) == 'male'), 'mr', 'mrs')

test$family_size <- test$Parch + test$SibSp + 1

test$SibSp_Parch_mult <- test$SibSp * test$Parch

if(anyNA(test$Embarked)) test[is.na(test$Embarked),]$Embarked <- "S" 

test$Embarked <- as.factor(test$Embarked)
                          
test[is.na(test$Age),]$Age <- predict(object = Age_model, newdata = test[is.na(test$Age),])

test$Age_group <- as.factor(ifelse(test$Age > 0  & test$Age <= 13,  "g0_13", 
                            ifelse(test$Age > 13 & test$Age <= 30,  "g13_30", 
                            ifelse(test$Age > 30 & test$Age <= 50,  "g30_50", 
                            ifelse(test$Age > 50, "g50_inf", NA)))))
                            
test$Fare_family_div <- test$Fare / test$family_size
test$Age_Fare_mult <- test$Age * test$Fare

```

# Models

We're going to perform three models in differents ways and lastly select the best one to upload.

## Modeling, version 1

The first thing to do is split the data into two datasets, the training set which will be used to train the model and the validation set to select the model to generate the predictions.

```{r, message = FALSE, warning = FALSE}
set.seed(88)
trainIndex  <- createDataPartition(train_valid_data$Survived, p = .6, list = FALSE, times = 1)
training    <- train_valid_data[ trainIndex,]
validation  <- train_valid_data[-trainIndex,]
```

Now we have the to analize the distribution of the target:

```{r, warning=FALSE}
round(prop.table(table(training$Survived)),2)  
```

We can see the target is not balanced. To deal with this, there are some techniques which can be implemented. These techniques consist in make distinct types of sampling the data so we're going to create a list of distinct training sets applying them. 

```{r, warning=FALSE}
training_list <- list(training_original   = training,
                      training_upSample   = upSample(x = training[, -1], y = training$Survived, yname = "Survived"),
                      training_downSample = downSample(x = training[, -1], y = training$Survived, yname = "Survived"))
```

Now it's time to select the algorithm and the set configuration to train the model.

```{r}
algorithms <- c("plr", "lda", "glm", "rpart", "C5.0", "rf")
```

And finnaly we begin to train models and measure.

```{r model_1, message=FALSE, warning = FALSE, results="hide"}

results <- list()

modelFit_final <- NULL
best_accuracy  <- 0

for(i in seq(algorithms)){ 
  for(j in seq(training_list)){
    
    dataset <- training_list[[j]]
    
    set.seed(88)
    modelFit    <- train(Survived ~ Sex + Pclass + Name_title + Parch + SibSp + SibSp_Parch_mult + Age + Fare + Embarked,
                         #Survived ~ Sex + Pclass + Cabin + Name_title + family_size + SibSp + Parch + Age + Age_group + 
                         #           Fare + Fare_type + Embarked + Fare_family_div + Age_Fare_mult + SibSp_Parch_mult,
                         data = dataset,
                         preProcess = c("center", "scale"),
                         trControl = trainControl(method = "cv", number = 10),
                         tuneLength = 3,
                         method = algorithms[i])
    
    validation$my_prediction <- predict(object = modelFit, newdata = validation, type = "raw")
    validation$result        <- ifelse(validation$my_prediction == validation$Survived, 1, 0)
    accuracy                  <- round(mean(validation$result),3)
    dataname                  <- names(training_list)[j]
    results                   <- c(results, list(c(modelFit$modelInfo$label, algorithms[i], dataname, accuracy)))
  
    if(accuracy >= best_accuracy){
      modelFit_final <- modelFit
      best_accuracy <- accuracy
    }
  }
}

results <- data.frame(t(data.frame(results)))
names(results) <- c("model", "name", "data", "accuracy")
rownames(results) <- NULL
results$model <- as.character.factor(results$model)
results$name <- as.character.factor(results$name)
results$accuracy <- as.numeric(as.character.factor(results$accuracy))
results$data <- substr(x = results$data, start = 10, stop = 20)
```

```{r, message=FALSE, warning=FALSE}
ggplot(data = results) + 
  geom_point(mapping = aes(y = model, x = accuracy, col = data, shape = data), size = 3) + 
  lims(x = c(0.7, 0.9))
```

Some points to mention. Given that the relation of the classes in the target is not so unbalanced, the balancing doesn't seem to affect the accuracy in a good way. On the other hand, we have tested only a few algorithms. In the next table we can see the best of these based on the accuracies. In the next table we can see the best accuracies we got. We're going to pick the best of them and using it to predict the test set.

```{r,message=FALSE, warning = FALSE, echo=FALSE, results='asis'}
knitr::kable(arrange(results, desc(accuracy)) %>% top_n(n = 5))
```

Our final model is:

```{r}
modelFit_final
```

## Modeling, version 2

Given that the passengers gender seems to be a good discriminant we're going to create two models, one for males passengers, and the other for famale passengers.

```{r model_2, warning = FALSE, message=FALSE, results="hide"}
## model 1
set.seed(88)
model_M <-  train(Survived ~ Pclass + Name_title + Parch + SibSp + SibSp_Parch_mult + Age + Fare,
                  data        = train_valid_data[as.character.factor(train_valid_data$Sex)=='male',],
                  trControl   = trainControl(),
                  preProcess = c("center", "scale"),
                  tuneGrid    = expand.grid(.mtry=c(1:10)),
                  method      = "rf")
 
## model 2
set.seed(88)
model_F <- train(Survived ~ Pclass + Name_title + Parch + SibSp + SibSp_Parch_mult + Age + Fare,
                 data        = train_valid_data[as.character.factor(train_valid_data$Sex)!='male',],
                 trControl   = trainControl(),
                 preProcess = c("center", "scale"),
                 tuneGrid    = expand.grid(.mtry=c(1:10)),
                 method      = "rf")
```

The final models are:

```{r}
model_M
model_F
```

## Modeling, version 3

Another version I want to probe is a combined model. To generate this new model I will use the _caretEnsemble_ package:

```{r model_3, warning = FALSE, message=FALSE, results="hide"}

train_valid_data$Survived   <- as.factor(ifelse(as.character.factor(train_valid_data$Survived) == '1', 'Survived', 'Perished'))

## CREATING MODELOS
set.seed(88)
models <- caretList(Survived ~ Sex + Cabin + Pclass + Name_title + Parch + SibSp + SibSp_Parch_mult + Age + Fare + Embarked,
                    data       = train_valid_data,
                    preProcess = c("center", "scale"),
                    trControl  = trainControl(method = "cv", number = 10, classProbs=TRUE),
                    methodList = c("rf", "lda", "pls"))

                    
## GREEDY ENSEMBLE
set.seed(88)
greedy.model <- caretEnsemble(models, trControl = trainControl(classProbs=TRUE))

```

The final model is:

```{r}
summary(greedy.model)
```

# Predictions

What's is the best choice one to upload? Well, the three ones seems to perform similar, but the second one has a little better results so I'll go to select it.

```{r, warning = FALSE, message=FALSE, results="hide"}
my_prediction <- predict(modelFit_final, newdata = test, type = "raw")
solution <- data.frame(PassengerID = test$PassengerId, Survived = my_prediction)
write.csv(solution, file = 'my_solution1.csv', row.names = F, quote = F)
```

```{r, warning = FALSE, message=FALSE, results="hide"}
test_M  <- test[as.character.factor(test$Sex)=='male',]
test_M$my_prediction <- predict(object = model_M, newdata = test_M, type = "raw")
solution1 <- data.frame(PassengerID = test_M$PassengerId, Survived = test_M$my_prediction)

test_F <- test[as.character.factor(test$Sex)!='male',]
test_F$my_prediction <- predict(object = model_F, newdata = test_F, type = "raw")
solution2 <- data.frame(PassengerID = test_F$PassengerId, Survived = test_F$my_prediction)

write.csv(arrange(rbind(solution1, solution2), PassengerID), file = 'my_solution2.csv', row.names = F, quote = F)
```

```{r, warning = FALSE, message=FALSE, results="hide"}
test$my_prediction <- predict(object = greedy.model, newdata = test, type = "raw")
test$my_prediction <- ifelse(as.character.factor(test$my_prediction) == 'Survived', 1, 0)
solution <- data.frame(PassengerID = test$PassengerId, Survived = test$my_prediction)
write.csv(solution, file = 'my_solution3.csv', row.names = F, quote = F)
```













