{"cells":[{"metadata":{"_uuid":"0e1944dc51cfcecb43bc16716abde042fc2d1da6"},"cell_type":"markdown","source":"# Predicting Survival from Titanic Dataset\n\n***\n# Problem statement\n\n### First, I am new to this!\n\nI am interested in machine learning and doing this in my down time.  I don't work in data science or statistics or ML.\n\n### Competition Description\n\n\nFrom kaggle:\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n### Disclaimer\n\nI did this project borrowing ideas from other kernels.  I make no claim that the ideas in my project are my original ideas. I am _not_ submitting this kernel for competition - only to figure out how to do it on Kaggle and learn from the process, in case I do want to enter competitions down the road.\n\n"},{"metadata":{"_uuid":"a5642ecf53222c7f30221a658b7115426f7107ce","_execution_state":"idle","trusted":false},"cell_type":"markdown","source":"***\n# Exploratory Data Analysis\n\n"},{"metadata":{"_uuid":"c80ef3e0f035c21e25e8cc85b6d923b3c35e2289","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"library(elasticnet)\nlibrary(caret)\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(skimr)\nlibrary(RANN)\nlibrary(e1071)\nlibrary(PerformanceAnalytics)\nlibrary(outliers)\nlibrary(xgboost)\nlibrary(ranger)\nlibrary(mice)\nlibrary(DataExplorer)\n\nset.seed(1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5ff2a3de1ab4fb4e8c7807c9f16601b90f07406"},"cell_type":"code","source":"training.dataset <- read.csv(\"../input/train.csv\", stringsAsFactors=FALSE, na.strings = c(\"\",\"NaN\",\" \"))\n#test.dataset  <- read.csv(\"test.csv\",  stringsAsFactors=FALSE, na.strings = c(\"\",\"NaN\",\" \"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea44259af20e8552603b30ba8075826aba6a445f"},"cell_type":"code","source":"str(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6add1c3575b83f88a2343bb22b05f057183a2c18"},"cell_type":"code","source":"plot_missing(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f91fc38213c6084790c4a47c3528fcfd1c8b4c3"},"cell_type":"code","source":"plot_histogram(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aec17b701bd283541ae3cf557e4819ae1ee89e0"},"cell_type":"code","source":"plot_bar(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0faa640bf665068befe0b0433b0fe3968850740"},"cell_type":"code","source":"plot_correlation(training.dataset, title=\"Correlation Analysis\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f409c7359ce1c1908cd229846cee6b13f7037a4b"},"cell_type":"markdown","source":"***\n# Initial observations\n\n### NA's?\n* _Age_ has some NA's.  Use \"mice\" to impute.\n* _Embarked_ is missing a few values.  Use \"mice\" to impute.\n* _Cabin_ is missing >70% of its values - unusable, so it will be removed.\n\n### Outliers?\n* None.\n\n### Unbalanced data?\n* None.\n\n### Useless fields?\n* _PassengerID_ and _Name_ and _Ticket_ are unique identifiers and hold no information for this study, and will be removed.\n\n"},{"metadata":{"_uuid":"677e46ef09e4bbb131a2ff0ba5325356fc056832"},"cell_type":"markdown","source":"***\n# Cleaning the data\n"},{"metadata":{"trusted":true,"_uuid":"71080f7c30d184e3a8deb064ab17b04715ad55a8"},"cell_type":"code","source":"# reclass target variable\ntraining.dataset$Survived <- ifelse(training.dataset$Survived == '0', 'No', 'Yes')\ntraining.dataset$Survived <- as.factor(training.dataset$Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2675b2d90107d3923f5dca79806a24e5a8eff875"},"cell_type":"code","source":"# remove the 3 id fields and the useless Cabin field\ntraining.dataset <- training.dataset %>% \n  select(-c('PassengerId', 'Name', 'Ticket', 'Cabin')) %>%\n  filter(!is.na(training.dataset$Embarked))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19335b57229c1179d860376ef613b05551da0ccb"},"cell_type":"code","source":"# convert to factors\ntraining.dataset$Pclass <- as.factor(training.dataset$Pclass)\ntraining.dataset$Sex <- as.factor(training.dataset$Sex)\ntraining.dataset$Embarked <- as.factor(training.dataset$Embarked)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29206b0f7c9d749c00d8438b77360f62991e2ace"},"cell_type":"code","source":"# impute mean age where NA\ntraining.dataset$Age[is.na(training.dataset$Age)] <- mean(training.dataset$Age, na.rm=TRUE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc77db709d16bf4b453aedee805486b2bad58a81"},"cell_type":"code","source":"# examine cleaned dataset\nstr(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bc1a6fa970a26408b324a6f464d02874f8357b8"},"cell_type":"code","source":"plot_missing(training.dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88d61eaebdd47cfb85b1127ecc7d8eb227873000"},"cell_type":"markdown","source":"No more missing data."},{"metadata":{"trusted":true,"_uuid":"18bb1d5bcc0738294a0e7cdca3d51499d1c5f747"},"cell_type":"code","source":"plot_correlation(training.dataset, title=\"Correlation Analysis\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0abfd4e2866853ad22f0e7b8471b655e8e142d43"},"cell_type":"markdown","source":"***\n# Observations about the data\n\n* Strong correlation between being male and not surviving, and being female and surviving.  \"Women and children first\" in effect.\n* Strong correlation between Pclass_1 and survival. The upper class must have gotten to the lifeboats sooner.\n"},{"metadata":{"_uuid":"82594f0c88b1cb31ccfa8ebcecf2775d4d42999c"},"cell_type":"markdown","source":"***\n# Train models RF, SVM, kNN, and XGBoost\n"},{"metadata":{"trusted":true,"_uuid":"a1a4636a50992a7ee3e06612a4d9d6978fda8111"},"cell_type":"code","source":"fit.control <- trainControl(\n    method = 'cv',                   # k-fold cross validation\n    number = 5,\n    savePredictions = 'final',       # saves predictions for optimal tuning parameter\n    classProbs = T#,                 # should class probabilities be returned\n) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5556a91abb384026238fb617d5100e36ac56ac54"},"cell_type":"code","source":"# train random forest\nmodel.rf = train(Survived ~ ., \n                 data=training.dataset,\n                 method='rf', \n                 tuneLength=8, \n                 trControl=fit.control)\nmodel.rf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"740dc7869512a8ac8d9f045e6aad1a99f73749de"},"cell_type":"code","source":"# train SVM\nmodel.svm = train(Survived ~ ., \n                  data=training.dataset, \n                  method='svmRadial', \n                  tuneLength=10, \n                  trControl=fit.control)\nmodel.svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a4161b89207c52f3d68ab5a622fd19f4fe1520c"},"cell_type":"code","source":"# train k-nearest neighbors\nmodel.knn = train(Survived ~ ., \n                  data=training.dataset, \n                  method='knn', \n                  tuneLength=10, \n                  trControl=fit.control)\nmodel.knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0100425805c0ec83b152560571ad95fa78b9c76","scrolled":true},"cell_type":"code","source":"# train xgboost\n\n# setup the xgb tune grid\ntune.grid.for.xgb <- expand.grid(nrounds          = c(10,50),\n                                 max_depth        = c(5, 10, 15), \n                                 eta              = c(0.01, 0.001, 0.0001), \n                                 gamma            = c(1, 2, 3), \n                                 colsample_bytree = c(0.4, 0.7, 1.0), \n                                 min_child_weight = c(0.5, 1, 1.5),\n                                 subsample        = 1\n)\n\nmodel.xgb <- train(Survived ~., \n                   data=training.dataset,\n                   method=\"xgbTree\",\n                   trControl=fit.control,\n                   tuneGrid=tune.grid.for.xgb\n                   )\nmodel.xgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed535bf356bfbb23ebba7b52d84f5fdd7175fc84"},"cell_type":"markdown","source":"***\n# Evaluate the models\n"},{"metadata":{"trusted":true,"_uuid":"4564ea680c06d5af5932b29e375a2299e3489a48"},"cell_type":"code","source":"# compare model performances using resample()\nmodels.compared <- resamples(list(`Random Forest`=model.rf, \n                                  `SVM`=model.svm,\n                                  `kNN`=model.knn,\n                                  `XGBoost`=model.xgb\n                                  ))\n\n# summary of the models performances\nsummary(models.compared)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdb3b49cffbb5f8e2e9dbc89b5ae92a1237a1d9e"},"cell_type":"markdown","source":"At first, it seems Random Forest will provide the best accuracy.  Let's do some more feature engineering and see what more we can do."},{"metadata":{"_uuid":"6b4958aa47fda7a5944a05e9601a58beca860fda"},"cell_type":"markdown","source":"***\n# More feature engineering\n\nI got some ideas after reading other kernels.  I employed some of them here.\n\n### Reload the data and apply what's already been engineered\n"},{"metadata":{"trusted":true,"_uuid":"a4e5442b2e24a40f44e26b41133c3443aed61c96"},"cell_type":"code","source":"training.dataset <- read.csv(\"../input/train.csv\", stringsAsFactors=FALSE, na.strings = c(\"\",\"NaN\",\" \"))\n\n# reclass target variable\ntraining.dataset$Survived <- ifelse(training.dataset$Survived == '0', 'No', 'Yes')\ntraining.dataset$Survived <- as.factor(training.dataset$Survived)\n\n# remove the 3 id fields and the useless Cabin field\ntraining.dataset <- training.dataset %>% \n  select(-c('PassengerId', 'Name', 'Ticket', 'Cabin')) %>%\n  filter(!is.na(training.dataset$Embarked))\n\n# convert to factors\ntraining.dataset$Pclass <- as.factor(training.dataset$Pclass)\ntraining.dataset$Sex <- as.factor(training.dataset$Sex)\ntraining.dataset$Embarked <- as.factor(training.dataset$Embarked)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24a62c0644111cf4e1863f26abe2430ca1369eed"},"cell_type":"markdown","source":"### Add feature \"family size\" \n\nA significant learning for me was that you add features that are aggregates or even \"counts\" of related rows.  This makes each row wider, but can add predicitve power to row, which can aid the machine learning effectiveness.\n\nHere, I saw one kernel created a feature by adding two exsiting features.  This has the effect of making the gradient larger.\n"},{"metadata":{"trusted":true,"_uuid":"a178608e933925e65bb89d03fe35103758a3d719"},"cell_type":"code","source":"training.dataset$FamilySize <- training.dataset$Parch + training.dataset$SibSp\n\ntraining.dataset <- training.dataset %>% \n  select(-c('Parch', 'SibSp')) \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c9a56b7a8e1c68089a3cb4b18115b2f929a4c85"},"cell_type":"markdown","source":"### Impute Age better using MICE"},{"metadata":{"trusted":true,"_uuid":"dab18e9e56a27e80821c00a24158091f0b927529"},"cell_type":"code","source":"summary(training.dataset$Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b5a5c96ba96f3fc41228d843d76d4487934e9773"},"cell_type":"code","source":"mi <- mice(training.dataset)\ntraining.dataset <- complete(mi)\nsummary(training.dataset$Age)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"407f5bc17cb1d41771c7cc7de510cee2c53dc97a"},"cell_type":"markdown","source":"### Re-run models after feature engineering and re-evaluate"},{"metadata":{"trusted":true,"_uuid":"c240611bf5e97e10aec23d4ba7cdc07d3e2a48b6"},"cell_type":"code","source":"# train random forest\nmodel.rf = train(Survived ~ ., \n                 data=training.dataset,\n                 method='rf', \n                 tuneLength=7, \n                 trControl=fit.control)\n\t\t\t\t \n# train SVM\nmodel.svm = train(Survived ~ ., \n                  data=training.dataset, \n                  method='svmRadial', \n                  tuneLength=7, \n                  trControl=fit.control)\n\n# train k-nearest neighbors\nmodel.knn = train(Survived ~ ., \n                  data=training.dataset, \n                  method='knn', \n                  tuneLength=7, \n                  trControl=fit.control)\n\n# train xgb\nmodel.xgb <- train(Survived ~., \n                   data=training.dataset,\n                   method=\"xgbTree\",\n                   trControl=fit.control,\n                   tuneGrid=tune.grid.for.xgb\n                   )\n\n# compare model performances using resample()\nmodels.compared <- resamples(list(`Random Forest`=model.rf, \n                                  `SVM`=model.svm,\n                                  `kNN`=model.knn,\n                                  `XGBoost`=model.xgb\n                                  ))\n\n# summary of the models performances\nsummary(models.compared)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b81635bbf2147ed14aed14554daa8381b997a79f"},"cell_type":"markdown","source":"***\n# Conclusion - Achieved accuracy of 84.1% using tuned XGBoost\n"},{"metadata":{"trusted":true,"_uuid":"deaa877f317207a251ff4bef7e7224f477b4ca27"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}