---
title: 'Titanic Dataset'
author: 'David Barron'
date: '12 March 2017'
output:
  html_document
---

```{r setup, echo = TRUE, message=FALSE}
knitr::opts_knit$set(width = 100)
knitr::opts_chunk$set(comment =  '', echo=TRUE)
knitr::opts_chunk$set(fig.align = 'center', fig.width = 6, fig.asp = 0.618, out.width = '80%')
```

# Introduction
My first attempt at a Kaggle competition, using the Titanic data.

## Load and check data

```{r, message = FALSE}
# Load packages
library(tidyverse)
library(stringr)
library(forcats)
library(randomForest)
library(missForest)
```

Now that our packages are loaded, let's read in and take a peek at the data.

```{r, message=FALSE, warning=FALSE}
train <- read_csv('../input/train.csv')
test  <- read_csv('../input/test.csv')

full  <- bind_rows(list(train=train, test=test), .id = 'id') 


glimpse(full)
```


# Create variables
 

Calculate `Title` using the method by Megan L. Risdal, but using the `stringr` package. 

```{r, message=FALSE, warning=FALSE}
# Grab title from passenger names
Title <- str_extract(full$Name, '(, .+\\.)')
Title <- str_sub(Title, 3, -2)
Title[514] <- str_sub(Title[514], 1, 3)
```

Check that this makes sense by making a crosstab of Sex and Title.

```{r}
# Show title counts by sex
xtabs(~ Sex + Title, full)
```

Convert French titles into equivalent English ones, and combine rare titles into an "Other" category.

```{r}
# Titles with very low cell counts to be combined to "Other" level

# Also reassign mlle, ms, and mme accordingly
Title[Title == 'Mlle']        <- 'Miss' 
Title[Title == 'Ms']          <- 'Miss'
Title[Title == 'Mme']         <- 'Mrs' 

Title <- fct_lump(Title, n = 4)

# Show title counts by sex again
xtabs(~Sex + Title, full)
```

## Family size

Calculate family size from number of siblings, parents and children on board.

```{r}
# Create a family size variable including the passenger themselves
full <- full %>% mutate(Fsize = SibSp + Parch + 1)

full <- data.frame(full, Title)
```

What does our family size variable look like? To help us understand how it may relate to survival, let's plot it among the training data.

```{r, message=FALSE, warning=FALSE}
# Use ggplot2 to visualize the relationship between family size & survival
full %>% filter(id == 'train') %>%
  ggplot(aes(x = Fsize, fill = factor(Survived))) +
    geom_bar(stat = 'count', position = 'dodge') +
    scale_x_continuous(breaks = c(1:11)) +
    scale_fill_discrete('Survived') +
    labs(x = 'Family Size') +
    theme_bw()
```

Singles and people in large families seem to have less chance of survival.  Create family size variable with three categories.

```{r}

full$FsizeD <- case_when(full$Fsize == 1 ~ 'singleton',
                    full$Fsize < 5 ~ 'small',
                    full$Fsize > 4 ~ 'large')


# Show family size by survival using a mosaic plot
mosaicplot(xtabs(~ FsizeD + Survived, full), shade = TRUE)
```

## Deck

The `Cabin` variable starts with a letter that identifies the Deck.  Unfortunately, there's a lot of missing data.

```{r}
sum(is.na(full$Cabin))

full$Deck <- factor(str_sub(full$Cabin, 1, 1))
```


# Dealing with missing values

```{r}
mice::md.pattern(full)
```
We can see that there are 2 cases of the `Embarked` variable that have missing values, and one case of the `Fare` variable.  Start with `Embarked`.

## Missing values in Embarked

```{r}
ix_embark <- which(is.na(full$Embarked))
# Passengers 62 and 830 are missing Embarkment
full[ix_embark, ]
```

Their embarkation point can be inferred from the fare that they paid and class of cabin they travelled in.

Case 62 paid `r full[62, 'Fare']` and case 839 paid `r full[830, 'Fare']`.  Case 62 wasd in class `r full[62, 'Pclass']` and case 830 in class `r full[830, 'Pclass']`.

So, let's see where people who paid that fare embarked:

```{r}
full %>% filter(Pclass == 1) %>% 
  group_by(Embarked) %>%
  summarise(median(Fare))
```


Among first class passengers, those embarking at Cherbourg paid fares close to 80, so let's take this as the embarkation point for those two missing cases.

```{r}
full$Embarked[c(62, 830)] <- 'C'
```
## Missing value in Fare

Case 1044 has an `NA` Fare value.

```{r, message=FALSE, warning=FALSE}
full[1044, ]
```
Replace this with the median fare for people who embarked from Southampton in class 3.

```{r}
imp_val <- full %>% filter(Embarked == 'S' & Pclass == 3) %>%
  summarise(median(Fare, na.rm = TRUE))

full[1044, 'Fare'] <- as.double(imp_val)
```


## Missing values in Age

Lots of missing values in Age.

```{r}
# Show number of missing Age values
sum(is.na(full$Age))
```
I calculate imputed values of `Age` using the `missForest` function (an implementation of `randomForest` for imputation).

```{r, message=FALSE, warning=FALSE}
# Make variables factors into factors
factor_vars <- c('PassengerId','Pclass','Sex','Embarked',
                 'Title','FsizeD')

full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))

ix <- is.na(full$Age)

mfAge <- full %>%
  select(Age, Pclass, SibSp, Parch, Fare, Title, Fsize) %>%
  missForest(.)

Age_imputed <- ifelse(ix, mfAge$ximp$Age, full$Age)

```

Compare the imputed and original Age variables.

```{r, out.width='45%'}
# Plot age distributions
plot_dta <- data.frame(Age_original = full$Age, Age_imputed = Age_imputed)
plot_dta <- plot_dta %>% tidyr::gather(source, Age) %>%
  mutate(source = str_sub(source, 5))

ggplot(full, aes(x = Age, y = ..density..)) + geom_histogram(binwidth = 1) 
ggplot(full[!ix, ], aes(x = Age, y = ..density..)) + geom_histogram(binwidth = 1)

```

Looks fine.
```{r}
full$Age <- Age_imputed

```

Check all fixed.

```{r}
mice::md.pattern(full)
```
## Interactions

We know sex is a major factor, perhaps it also interacts with other variable.  So, construct interactions with Pclass, Age, SibSp and Fare.

```{r}
full <- full %>%
  mutate(SexNum = if_else(Sex == 'male', 0, 1),
         PclassSex = as.integer(Pclass) * SexNum,
         AgeSex = Age * SexNum,
         SibSpSex = SibSp * SexNum,
         FareSex = Fare * SexNum,
    #     FsizeDSex = as.integer(as.character(FsizeD)) * SexNum,
    #     ParchEmb = as.integer(as.character(Embarked)) * Parch,
      #   AgeEmb = as.integer(as.character(Embarked)) * Age,
         AgeFare = Age * Fare,
         PclassFare = as.integer(Pclass) * Fare)
     #    PclassFsizeD = as.integer(Pclass) * as.integer(as.character(FsizeD)))

```

# Prediction
Use `randomForest` to make predictions.

## Split into training & test sets

Split the data back into test and training sets.

```{r}
# Split the data back into a train set and a test set
train <- filter(full, id == 'train')
test <- filter(full, id == 'test')
```

## Building the model 

We then build our model using `randomForest` on the training set.

```{r}
# Set a random seed
set.seed(999)

rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + PclassSex + Age + AgeSex + SibSp +
                           Parch + Fare + Embarked + Title + FsizeD,
                           data = train, ntree = 2000)


as_data_frame(rf_model$err.rate) %>% 
  mutate(Tree = row_number()) %>%
  tidyr::gather(Type, Error, -Tree) %>%
  ggplot(aes(x = Tree, y = Error, colour = Type)) + geom_line() + 
  theme_bw()

```

## Variable importance

Let's look at relative variable importance by plotting the mean decrease in accuracy calculated across all trees.

```{r, message=FALSE, warning=FALSE}
# Get importance
importance    <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,'MeanDecreaseGini'], 2))

# Create a rank variable based on importance
varImportance %>%
  mutate(Rank = paste0('#', dense_rank(desc(Importance)))) %>%
  ggplot(aes(x = reorder(Variables, Importance), 
      y = Importance, fill = Importance)) +
    geom_bar(stat='identity') + 
    geom_text(aes(x = Variables, y = 0.5, label = Rank),
      hjust=0, vjust=0.55, size = 4, colour = 'red') +
    labs(x = 'Variables') +
    coord_flip() + guides(fill = FALSE) +
    theme_bw()
```

This suggests that several of the interactions are indeed important.

## Caret

See if caret can do any better.

```{r}
library(caret)
ctrl <- trainControl(method = "repeatedcv",
                      repeats = 3,
                      classProbs = TRUE,
                      summaryFunction = twoClassSummary)

car1 <- train(factor(Survived, labels = c('died', 'survived')) ~ Pclass + Sex + PclassSex + Age + AgeSex + SibSp +
  Parch + Fare + Embarked + Title + FsizeD + SibSpSex +
  FareSex + AgeFare + PclassFare, data = train,
  method = 'pls', preProc = c('center', 'scale'),
  tuneLength = 20,
  trControl = ctrl,
  metric = 'ROC')

print(car1)
```

## Prediction


```{r}

prediction <- predict(car1, test) 
prediction <- ifelse(prediction == 'died', 0L, 1L)


# Save the solution to a dataframe with two columns: PassengerId and Survived (prediction)
solution <- data.frame(PassengerID = as.integer(test$PassengerId), Survived = prediction)

#write_csv(solution, path = 'Solution4.csv')
```
