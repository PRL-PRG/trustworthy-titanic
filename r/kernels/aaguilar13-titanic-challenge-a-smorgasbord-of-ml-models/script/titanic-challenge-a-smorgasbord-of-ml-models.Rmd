---
title: "Predicting Titanic Survivors"
author: "Ariel Aguilar Gonzalez"
date: "June 28, 2017"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: lumen
    highlight: tango
---
```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, collapse = TRUE)
```

# Introduction

This is my first foray into Kaggle. I picked the Titanic challenge because you have to be creative and also work with messy data. For this challenge, I've cleaned the data a little, created some new features, and tested out a smorgasbord of classification models.

## Libraries and Data

```{r}
library(ggplot2) # visualization
library(rms) # model evaluation
library(MASS) # data modelling
library(class) # data modelling
library(e1071) # data modelling
library(dummies) # data modelling
library(randomForest) # data modelling
library(ROCR) # model evaluation
```

```{r}
train <- read.csv("../input/train.csv")
test <- read.csv("../input/test.csv")
```

Combine the datasets for the next couple of sections
```{r}
test$Survived <- NA
c_data <- rbind(train,test)
```

# Value Imputation

## What's Missing?

What are the variables in the data and how are they populated?

```{r}
summary(c_data)
```

Overall, there is an 38.4% survival rating. About two thirds of passangers are men.
The variables missing a lot of values are Cabin (missing n = 1014), Age (263), Embarked (2), and Fare (1). Cabin is very sparsely populated, don't think I can do anything there. There are fewer tickets than passengers, people seem to be sharing tickets. 

Let's look at filling in that one missing Fare variable.

## Riding Solo

```{r echo=FALSE, results='asis'}
library(knitr)
kable(c_data[is.na(c_data$Fare),])
```

We can see that Passenger 1044 is missing his fare. He embarked from Port S, in 3rd class and on ticket number 3701.

I'll check if he shared his ticket, by limiting all data rows to ticket number 3701.

```{r, include=FALSE}
c_data$Ticket <- as.character(c_data$Ticket)
```

```{r echo=FALSE, results='asis'}
library(knitr)
kable(c_data[c_data$Ticket == "3701",])
```

Looks like he's riding solo.

Let's find the median fare for 3rd class passangers departing from Port S. Set that as the fare for our solo traveller.

```{r}
s_p3_solo <- c_data[c_data$Pclass == 3 & c_data$Embarked == "S" & c_data$SibSp == 0 & c_data$Parch == 0,]
s_p3_solo_clean <- s_p3_solo[!is.na(s_p3_solo$Fare),] # $7.90
c_data$Fare[1044] <- median(s_p3_solo_clean$Fare)
```

## All Aboard!

Now let's check out those missing departures.

```{r echo=FALSE, results='asis'}
library(knitr)
kable(c_data[c_data$Embarked == "",])
```

Passengers 62 and 830 are missing their port of departure. Both in the same cabin, paid a fare of $80 and in first class. 

Use a box plot to explore the distribution of fare and class by port.

```{r}
embark <- c_data[c_data$Embarked != "",]

ggplot(embark, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
             colour='red', linetype='dashed', lwd=2) +
  theme_bw()
```

Looks like passangers 62 and 830 can be safely categorized into port C

```{r}
c_data$Embarked[c(62,830)] <- 'C'
```

# Feature Engineering

## Titles Breed Features

The title prefix in the Name variable can give a lot of information. I can determine the gender, age, and marital status (for women at least, is there a Miss Mr yet?) for each person.

Extract the title using a simple regular expression:

```{r}
c_data$Title <- gsub('(.*, )|(\\..*)','',c_data$Name)
unique(c_data$Title)
```

Let's clean up the French titles and the more exotic titles (what's a Jonkheer??)

```{r}
c_data$Title[c_data$Title == "Mme"] <- "Mrs"
c_data$Title[c_data$Title == "Mlle"] <- "Miss"
c_data$Title[c_data$Title == "Ms"] <- "Miss"

other_list <- unique(c_data$Title)
other_list <- other_list[5:15]
c_data$Title[c_data$Title %in% other_list] <- "Other"
```

The new Title variable can serve as a handy proxy for age, a variable for which there are 263 missing observations.

## Families + Travel Buddies

Its possible that families or people travelling together might have a better chance of survival. I can use the Sibling/Spouse, Parent/Children, and Ticket variables to define if someone is in a family or travelling with someone.

```{r}
# family size variable
c_data$nFamily <- c_data$SibSp + c_data$Parch + 1

# shared ticket variable
c_data$sharedTix <- ifelse(c_data$Ticket %in% c_data$Ticket[duplicated(c_data$Ticket)], 1, 0)
```

I can also use the new Title variable to define mother and children variables.

```{r}
# Mother variable
c_data$mother <- ifelse(c_data$Parch > 0 & c_data$Title == "Mrs",1,0)

# Child variable using Title as a proxy when Age is missing
c_data$child <- ifelse(c_data$Age > 18 & !is.na(c_data$Age) | c_data$Title %in% c("Other", "Mr", "Mrs"),0,1)
```

# Analyzing Variables

Because a lot of these variables are categorical, its not possible to calculate a simple correlation matrix to see which variables may be highly predictive. For now, I'll look at each variable and its relationship with survived to see if any obvious patterns come up. Later, I'll use a logistic regression model to select the most important variables.

```{r}
train_new <- c_data[1:891,]
```

## Stuck In Lower Class?

Look at relationship between P class and Survival.

```{r}
ggplot(train_new, aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(min(train_new$Pclass):max(train_new$Pclass))) +
  labs(x = 'P class') +
  theme_bw()
```

The survival rate looks fairly stable across P classes 1 and 2. Third class looks to be suffering much lower rates of survival (probably why Jack died)

Continue to do this for the rest of the variables. The most interesting relationship is looking at size of family and its connection with shared ticket.

## Do Families Stick Together?

Let's see if the theory I suggested about family size and survival pans out in this data.

```{r}
ggplot(train_new, aes(x = nFamily, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(min(train_new$nFamily):max(train_new$nFamily))) +
  labs(x = 'Family Size') +
  theme_bw()
```

It appears that family sizes of 1 and >4 are more likely to not survive. So having family members is useful up to a point of being too large.

However, its possible that its not so much being part of a family per se that's important for survival, but having travel companions to look out for you.

```{r}
table(train_new$sharedTix, train_new$Survived)
```

Very few solo travellers actually survived. Combining the shared ticket and family sizer variables would probably give a more accurate reprsentation of who's actually travelling alone and those with travel companions.

```{r}
c_data$travelParty <- ifelse(c_data$sharedTix == 0 & c_data$nFamily == 1, "Single",
                             ifelse(c_data$sharedTix == 1 & c_data$nFamily == 1 |   c_data$nFamily < 5,"Small","Large"))

train_new <- c_data[1:891,]

ggplot(train_new, aes(x = travelParty, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  labs(x = 'Travel Party Size') +
  theme_bw()
```

# Classification Models

Now that I've finished value imputation and feature engineering, I can move on to the fun stuff, creating classification models! I've tried out a lot of different models just for practice and to get used to the different syntaxes of each of them. One important thing to consider is that a few variables are highly colinear (i.e gender and title), so linear models will probably not do very well in terms of final predictions.

To train and test my models, I'll a create two subsets of the training data to be the new training and cross validation sets respectively.

```{r}
fact_var <- c('Survived','Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Title', 'nFamily', 'travelParty')

train_new[fact_var] <- lapply(train_new[fact_var], function(x) as.factor(x))

all_vars <- c('Pclass', 'Sex','SibSp', 'Parch','Fare','Embarked','sharedTix', 'Title', 
              'nFamily','travelParty','mother', 'child')

n_train <- round((nrow(train_new)*2)/3,0)

set.seed(1912)

model_train <- sample(1:nrow(train_new), n_train)

cv <- train_new[-model_train,]
```

## Logistic Regression

As I've said before, I probably don't want to settle for a linear model because of likely multicollinearity issues, but a logistic regression model can be useful for specifically identifying more parsimonious models. 

I'll do this by first specifying a logit model using all of the dataset variables. Then I'll employ the step function to identify the best model judging by the AIC criteria.

```{r, results='hide'}
fm_all <- as.formula(paste("Survived ~ ", paste(all_vars, collapse= "+")))
logit_model_all <- glm(fm_all, data = train_new, family = binomial, subset = model_train)
step_fit <- step(logit_model_all)
```

The model with the lowest AIC turns out to be:

Survived ~ Pclass + Sex + Fare + Embarked + Title + travelParty

Nice to see two of my feature engineered variables coming in use!

Define this new model:

```{r}
vars_low <- c('Pclass', 'Sex', 'Fare', 'Embarked', 'Title', 'travelParty')
fm_low <- as.formula(paste("Survived ~ ", paste(vars_low, collapse= "+")))
logit_model_low <- glm(fm_low, data = train_new, family = binomial, subset = model_train)
```

Using this susbset of variables, I'll estimate a whole bunch of different models before evaluating them against each other on the CV dataset.

## K Nearest Neighbours

To specify KNN and a couple of other models, I'll have to one hot encode the categorical variables. Additionally, the Fare variable will have to be scaled so that it doesn't have an outsized influence in the model.

```{r}
# Preform one hot encoding
onehot_var <- c('Pclass', 'Sex', 'Embarked', 'Title', 'travelParty')
onehot_encode <- dummy.data.frame(train_new, names = onehot_var, sep="_")

# Scale fare variable
onehot_encode$Fare <- scale(onehot_encode$Fare)

# Take out extra variables
delete <- c("Survived","PassengerId", "Name", "Age", "Ticket", "Cabin")
onehot_encode_preds <- onehot_encode[,!(names(onehot_encode) %in% delete)]
low_preds <- c(names(onehot_encode_preds)[grepl("Psize",names(onehot_encode_preds))], 
               names(onehot_encode_preds)[grepl("Sex",names(onehot_encode_preds))],
               names(onehot_encode_preds)[grepl("Embarked",names(onehot_encode_preds))], 
               names(onehot_encode_preds)[grepl("Title",names(onehot_encode_preds))],
               names(onehot_encode_preds)[grepl("travelParty",names(onehot_encode_preds))], "Fare")
```

I define the KNN model specifying k=12, which is not a robust estimate just a parameter I chose after a few trials with different levels of k.

```{r}
# Define KNN class labels and predictors
knn_class_train <- onehot_encode[,2][model_train]
knn_class_cv <- onehot_encode[,2][-model_train]
knn_preds_train <- onehot_encode_preds[model_train,low_preds]
knn_preds_cv <- onehot_encode_preds[-model_train,low_preds]

set.seed(1912)
knn_model <- knn(knn_preds_train,knn_preds_cv,knn_class_train, k=12)
```

## Support Vector Machines

I define a non-linear SVM model using varying paramters for cost and gamma to optimize their values.

```{r}
svm_train <- data.frame(cbind(knn_class_train, knn_preds_train))
svm_cv <- data.frame(cbind(knn_class_cv, knn_preds_cv))

colnames(svm_train)[1] <- "Survived" 
colnames(svm_cv)[1] <- "Survived"

set.seed(1912)
svm_low_fm <- as.formula(paste("Survived ~ ", paste(low_preds, collapse= "+")))
svm_low <- tune(svm, svm_low_fm, data = svm_train, kernel="radial",
                ranges=list(cost=c(0.1,1,10,100,1000),
                            gamma=c(0.5,1,2,3,4)))
```

## Random Forest Model

Finally, I specify a Random Forest model.

```{r}
set.seed(1912)
rf_model <- randomForest(fm_low, data=train_new, subset=model_train, importance=TRUE)
```

# Evaluating Models

## Prediction Accuracy

I'll assess these models based on their prediction accuracy. Because I'm only worried about correctly predicting survival, I'll rank the models based on the true positive rate.

Logit prediction accuracy:

```{r}
logit_model_low_probs <- predict(logit_model_low, cv, type = "response")

logit_modellow_preds <- rep(0,297)
logit_modellow_preds[logit_model_low_probs>.5] <- 1

logit_tp <- mean(logit_modellow_preds ==cv$Survived)
```

KNN prediction accuracy:

```{r}
knn_tp <- mean(knn_class_cv==knn_model)
```

SVM prediction accuracy:

```{r}
svm_low_preds <- predict(svm_low$best.model, newdata = svm_cv)
svm_tp <- mean(svm_low_preds ==svm_cv$Survived)
```

RF prediction accuracy:

```{r}
rf_pred <- predict(rf_model,newdata=cv,type="class")
rf_tp <- mean(rf_pred == cv$Survived)
```

Let's look at the top models by accuracy rate:

```{r echo=FALSE, results='asis'}
library(knitr)
tp_rates <- data.frame(c("Logit", "KNN", "SVM", "RF"))
tp_rates$Accuracy <- c(logit_tp, knn_tp, svm_tp, rf_tp)
colnames(tp_rates)[1] <- "Model"
tp_rates <- tp_rates[order(tp_rates$Accuracy, decreasing = TRUE),]
kable(tp_rates)
```

Looks like the Random Forest model has the highest accuracy.

## ROC Curves Rock!

Another way to evaluate models is through an ROC curve. Since most people in the dataset are likely to not survive, I'll look at the tradeoff between the false negative and true negative rate.

I'll limit to the three top performing models to simplify the plot.

```{r}
logitpred <- prediction(logit_modellow_preds, cv$Survived)
logitperf <- performance(logitpred, "tnr", "fnr")

svmpred <- prediction(as.numeric(svm_low_preds)-1, cv$Survived)
svmperf <- performance(svmpred, "tnr", "fnr")

rfpred <- prediction(as.numeric(rf_pred)-1, cv$Survived)
rfperf <- performance(rfpred, "tnr", "fnr")

plot(logitperf,col="green",lwd=2,main="ROC Curve for Titanic Survival Models")
plot(svmperf, add = TRUE, col="blue")
plot(rfperf, add=TRUE, col="red")
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```

Looks like the Random Forest curve performs the best overall!

# Final Prediction + Submission

With the final model selected, I'll train the model on the entire training set and create my final predictions for the Titanic test set!

```{r}
test_feat <- c_data[c(892:1309),]
test_feat[fact_var] <- lapply(test_feat[fact_var], function(x) as.factor(x))

set.seed(1912)
rf_final <- randomForest(fm_low, data=train_new)
rf_final_pred <- predict(rf_final,test_feat)
rf_solution <- data.frame(PassengerID = test_feat$PassengerId, Survived = rf_final_pred)
```

I hope this script was useful. As a newbie to Kaggle, I'm happy to receive any tips for improvement!