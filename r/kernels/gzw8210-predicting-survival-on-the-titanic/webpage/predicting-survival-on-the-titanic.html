<!DOCTYPE html>
<html lang="en">
<head>
    <title>Predicting Survival on the Titanic | Kaggle</title>
    <meta charset="utf-8" />
    <meta name="robots" content="index, follow" />
    <meta name="turbolinks-cache-control" content="no-cache" />
                <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0">    <meta name="theme-color" content="#008ABC" />
    <script type="text/javascript">
        window["initialPageLoadStartTime"] = new Date().getTime();
    </script>
    <link rel="dns-prefetch" href="https://www.google-analytics.com" /><link rel="dns-prefetch" href="https://stats.g.doubleclick.net" /><link rel="dns-prefetch" href="https://js.intercomcdn.com" /><link rel="dns-prefetch" href="https://storage.googleapis.com/" />
    <link href="/static/images/favicon.ico" rel="shortcut icon" type="image/x-icon" />
    <link rel="manifest" href="/static/json/manifest.json">
    <link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,300italic,400italic,600,600italic,700,700italic" rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet" type='text/css'/>
        <link rel="canonical" href="/gzw8210/predicting-survival-on-the-titanic" />                    <link rel="stylesheet" type="text/css" href="/static/assets/vendor.css?v=632d145d8598" />
        <link rel="stylesheet" type="text/css" href="/static/assets/app.css?v=9a450b84054a" />
    
    
 
        <script>
        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement("style");
        d.appendChild(s.createTextNode(""));s.head.appendChild(d);d=d.sheet;
        y=y.map(x => d.insertRule(x + "{ opacity: 0 !important }"));
        h.start=1*new Date;h.end=i=function(){y.forEach(x => d.deleteRule(x))};
        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;
        })(window,document,['.site-header-react__nav'],'dataLayer',2000,{'GTM-52LNT9S':true});}catch{}
    </script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'UA-12629138-1', {
            'optimize_id': 'GTM-52LNT9S',
            'displayFeaturesTask': null,
            'send_page_view': false
        });
    </script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-12629138-1"></script>

    
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
            n.callMethod.apply(n,arguments):n.queue.push(arguments)};
        if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
        n.queue=[];t=b.createElement(e);t.async=!0;
        t.src=v;s=b.getElementsByTagName(e)[0];
        s.parentNode.insertBefore(t,s)}(window,document,'script',
        'https://connect.facebook.net/en_US/fbevents.js');
    fbq("set", "autoConfig", "false", "136809193586742");
    fbq('init', '136809193586742'); 
    fbq('track', 'PageView');
</script>
<noscript>
    <img height="1" width="1" src="https://www.facebook.com/tr?id=136809193586742&ev=PageView&noscript=1"/>
</noscript>

<script>window.intercomSettings = {"app_id":"koj6gxx6"};</script>        <script>(function () { var w = window; var ic = w.Intercom; if (typeof ic === "function") { ic('reattach_activator'); ic('update', intercomSettings); } else { var d = document; var i = function () { i.c(arguments) }; i.q = []; i.c = function (args) { i.q.push(args) }; w.Intercom = i; function l() { var s = d.createElement('script'); s.type = 'text/javascript'; s.async = true; s.src = 'https://widget.intercom.io/widget/koj6gxx6'; var x = d.getElementsByTagName('script')[0]; x.parentNode.insertBefore(s, x); } if (w.attachEvent) { w.attachEvent('onload', l); } else { w.addEventListener('load', l, false); } } })()</script>
    
    
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="@kaggledatasets" />
    <meta name="og:url" content="https://kaggle.com/gzw8210/predicting-survival-on-the-titanic" />
    <meta name="og:title" content="Predicting Survival on the Titanic" />
    <meta name="og:description" content="Using data from Titanic: Machine Learning from Disaster" />
    <meta name="og:image" content="https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png" />


    
    

    
    
    
<script type="text/javascript">
    var Kaggle = Kaggle || {};

    Kaggle.Current = {
        antiForgeryToken: 'CfDJ8LdUzqlsSWBPr4Ce3rb9VL9dZ9yCYNLZD95EAmN-EPRruOh9UHUgcmLaXKOIDshOogOFjn2LUixRHOvka7iWVArgcjQMMRofzuxDxDYEfPwIgNDz3bdmz_hA4TC0YCE3oRZ3ya9oqDMdJVnc4pUAfac',
        isAnonymous: true,
        analyticsToken: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1NjAzNzgxMjksIlVzZXJJZCI6MH0.28gniaJ__gWu2RLobO6Dz8yRrsot0GiuRK77MrlyMo4',
        analyticsTokenExpiry: 15,
        internetKernelsEnabled: false,
        
        
        
        
        
        
        
        
        
        
        
    }
        Kaggle.Current.log = function(){};
        Kaggle.Current.warn = function(){};

    var decodeUserDisplayName = function () {
        var escapedUserDisplayName = Kaggle.Current.userDisplayNameEscaped || "";
        try {
            var textVersion = new DOMParser().parseFromString(escapedUserDisplayName, "text/html").documentElement.textContent;
            if (textVersion) {
                return textVersion;
            }
        } catch(ex) {}
        return escapedUserDisplayName;
    }
    Kaggle.Current.userDisplayName = decodeUserDisplayName();
</script>

    

<script type="text/javascript">
    var Kaggle = Kaggle || {};
    Kaggle.PageMessages = [];
</script>

    
<script type="text/javascript">
/* <![CDATA[ */
goog_snippet_vars = function() {
    var w = window;
    w.google_conversion_id = 955616553;
    w.google_conversion_label = "QSjvCKDksHMQqZrWxwM";
    w.google_conversion_value = 0.00;
    w.google_conversion_currency = "USD";
    w.google_remarketing_only = false;
    w.google_conversion_language = "en";
    w.google_conversion_format = "3";
    w.google_conversion_color = "ffffff";
}
// DO NOT CHANGE THE CODE BELOW.
goog_report_conversion = function(url) {
    goog_snippet_vars();
    window.google_conversion_format = "3";
    var opt = new Object();
    opt.onload_callback = function() {
        if (typeof(url) != 'undefined') {
            window.location = url;
        }
    }
    var conv_handler = window['google_trackConversion'];
    if (typeof(conv_handler) == 'function') {
        conv_handler(opt);
    }
}
/* ]]> */
</script>
<script type="text/javascript"
src="//www.googleadservices.com/pagead/conversion_async.js">
</script>



        <script>window['useKaggleAnalytics'] = true;</script>

    <script src="/static/assets/vendor.js?v=4721d2c14786" data-turbolinks-track="reload"></script>
    <script src="/static/assets/app.js?v=6bcf0584652b" data-turbolinks-track="reload"></script>
        <script>
            (function() {
                if ('serviceWorker' in navigator) {
                    navigator.serviceWorker.register("/static/assets/service-worker.js").then(function(reg) {
                        reg.onupdatefound = function() {
                            var installingWorker = reg.installing;
                            installingWorker.onstatechange = function() {
                                switch (installingWorker.state) {
                                case 'installed':
                                    if (navigator.serviceWorker.controller) {
                                        console.log('New or updated content is available.');
                                    } else {
                                        console.log('Content is now available offline!');
                                    }
                                    break;
                                case 'redundant':
                                    console.error('The installing service worker became redundant.');
                                    break;
                                }
                            };
                        };
                    }).catch(function(e) {
                      console.error('Error during service worker registration:', e);
                    });
                }
            })();
        </script>
    <script>
        function handleClientLoad() {
            try {
                gapi.load('client:auth2');
            } catch (e) {
                // In Opera, readystatechange is an unreliable detection of script load, causing
                // this function to be called before gapi exists on the window. The onload callback
                // is still called at the correct time, so the feature works as expected - it's
                // just generating noisy errors.
            }
        }
    </script>
    <script async defer src="https://apis.google.com/js/api.js"
            onload="this.googleApiOnLoad=function(){};handleClientLoad()"
            onreadystatechange="if (this.readyState === 'complete') this.googleApiOnLoad()">
    </script>
</head>
<body data-turbolinks="true">
    <main>
        






<div class="site-layout">
        <div class="site-layout__header">
            <div data-component-name="SiteHeaderContainer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark("SiteHeaderContainer.componentCouldBootstrap");</script>
        </div>

    <div class="site-layout__main-content">
        

<div data-component-name="KernelViewer" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({"kernel":{"id":124658,"title":"Predicting Survival on the Titanic","forkParent":{"kernelId":115085,"runId":435935,"url":"/amberthomas/predicting-survival-on-the-titanic","title":"Predicting Survival on the Titanic","author":{"id":778478,"displayName":"AmberThomas","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"amberthomas","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/778478-fb.jpg","profileUrl":"/amberthomas","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"diff":{"linesInserted":0,"linesDeleted":0,"linesChanged":0,"linesUnchanged":0,"newTotalLines":0,"url":"/gzw8210/predicting-survival-on-the-titanic/versions#base=435935\u0026new=474349"},"isRedacted":false,"dateCreated":"2016-11-09T02:08:37.097Z","outputFilesTotalSizeBytes":3997479,"workerStatus":"complete","isolatorResults":null,"languageId":5},"currentRunId":474349,"mostRecentRunId":474349,"url":"/gzw8210/predicting-survival-on-the-titanic","tags":[],"commentCount":0,"upvoteCount":1,"viewCount":420,"forkCount":1,"bestPublicScore":null,"author":{"id":593198,"displayName":"eric_guo","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"gzw8210","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","profileUrl":"/gzw8210","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"isPrivate":false,"updatedTime":"2016-11-30T06:43:44.7866667Z","selfLink":"/kernels/124658","pinnedDockerImageVersionId":null,"isLanguageTemplate":false,"medal":null,"topicId":null,"readGroupId":null,"writeGroupId":null,"slug":"predicting-survival-on-the-titanic"},"kernelBlob":{"id":4863092,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"r","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Titanic Survival\u0022\nauthor: \u0022Amber Thomas\u0022\noutput: \n  html_document:\n    theme: cosmo\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Introduction\n\nThis is my first project on Kaggle and my first attempt at machine learning.  I\u0027ll do my best to illustrate what I\u0027ve down and the logic behind my actions, but feedback is very much welcome and appreciated!\n\n### Loading Necessary Packages\n\n\n```{r message = FALSE}\n# For data manipulation and tidying\nlibrary(dplyr)\n\n# For data visualizations\nlibrary(ggplot2)\n\n# For modeling and predictions\nlibrary(caret)\nlibrary(glmnet)\nlibrary(ranger)\nlibrary(e1071)\n```\n\n### Importing Data\n\nThe data were downloaded directly from the [Kaggle Website](https://www.kaggle.com/c/titanic/data).  Before binding the training and test sets into a single data file, I added a column called \u0022Dataset\u0022 and labelled rows from the training file \u0022train\u0022 and rows from the testing file \u0022test\u0022.\n\n```{r}\ntrain \u003c- read.csv(\u0027../input/train.csv\u0027, header = TRUE, stringsAsFactors = FALSE)\ntrain$Dataset \u003c- \u0022train\u0022\n\ntest \u003c- read.csv(\u0027../input/test.csv\u0027, header = TRUE, stringsAsFactors = FALSE)\ntest$Dataset \u003c- \u0022test\u0022\n\nfull \u003c- bind_rows(train, test)\n```\n\n\nThe full dataset can then be inspected:\n```{r}\nstr(full)\n```\n\nIt appears that several of these variables should be represented as factors and thus should be reclassified. \n\n```{r}\nfactor_variables \u003c- c(\u0027PassengerId\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Sex\u0027, \u0027Embarked\u0027, \u0027Dataset\u0027)\nfull[factor_variables] \u003c- lapply(full[factor_variables], function(x) as.factor(x))\n```\n\nWe are now left with the following variables:\n\n* **Passenger ID** : A seemingly unique number assigned to each passenger\n\n* **Survived** : A binary indicator of survival (0 = died, 1 = survived)\n\n* **Pclass** : A proxy for socio-economic status (1 = upper, 3 = lower)\n\n* **Name** : Passenger\u0027s Name. For wedded women, her husband\u0027s name appears first and her maiden name appears in parentheses\n\n* **Sex** : General indication of passenger\u0027s sex\n\n* **Age** : Age of passenger (or approximate age).  Passengers under the age of 1 year have fractional ages\n\n* **SibSp** : A count of the passenger\u0027s siblings or spouses aboard\n\n* **Parch** : A count of the passenger\u0027s parents or siblings aboard\n\n* **Ticket** : The number printed on the ticket.  The numbering system is not immediately apparent\n\n* **Fare** : The price for the ticket (presumably in pounds, shillings, and pennies)\n\n* **Cabin** : Cabin number occupied by the passenger (this field is quite empty)\n\n* **Embarked** : The port from which the passenger boarded the ship\n\n* **Dataset** : Whether this particular row was a part of the training or testing dataset\n\n## Feature Engineering\n\n### Names and Titles\n\nAt first glance, the \u0022Name\u0022 column doesn\u0027t help too much as there are 1307 unique names, however, this column also includes embedded title information that may be of interest.  I decided to use [regular expressions](https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf) and the `gsub()` functions to extract the titles into a new variable.\n\n```{r}\nnames \u003c- full$Name\n\ntitles \u003c-  gsub(\u0022^.*, (.*?)\\\\..*$\u0022, \u0022\\\\1\u0022, names)\n\nfull$Titles \u003c- titles\n\nunique(full$Titles)\n```\n\nThat\u0027s a bit more manageable: only 18 unique titles. Time to see how many times each title was used.  I decided to make a table separated by sex. \n\n```{r}\ntable(full$Sex, full$Title)\n```\n\nIt looks like Captain, Don, Dona, Jonkheer, Lady, Madame, Sir and the Countess were each only used once.  I\u0027ll leave Captain separate, but the rest should be combined with similar categories.\n\n* **Don** : A Spanish/Portuguese/Italian title used with, but not instead of, a name.\n* **Dona** : Female version of \u0022Don\u0022\n* **Jonkheer** : Dutch honorific of nobility\n* **Lady** : English honorific of nobility\n* **Madame** : French, polite form of address for a woman\n* **Sir** : Honorific address (male)\n* **the Countess** : Rank of nobility (female)\n\nIt seems that most of the rarely used titles indicate some form of nobility.  That\u0027s easy to check with another table comparing `Pclass` and `Titles`.\n\n```{r}\ntable(full$Pclass, full$Titles)\n```\n\nSince Don, Jonkheer, and Sir are all of similar usage, and each represent only one first-class man, I combined them into the category \u0022Sir\u0022.  Dona, Lady, Madame, and the Countess each only represent one first-class woman, so I combined them into the category \u0022Lady\u0022.  These values were substituted using the `gsub` function.\n\n```{r}\nfull$Titles \u003c- gsub(\u0022Dona|Lady|Madame|the Countess\u0022, \u0022Lady\u0022, full$Titles)\nfull$Titles \u003c- gsub(\u0022Don|Jonkheer|Sir\u0022, \u0022Sir\u0022, full$Titles)\n\nunique(full$Titles)\n```\n\n**Warning**: If you are planning to replicate the above substitution without any RegEx, make sure that you substitute \u0022Dona\u0022 before substituting \u0022Don\u0022! Otherwise, \u0022Dona\u0022 becomes \u0022Sira\u0022 (as the \u0022Don\u0022 part was replaced with \u0022Sir\u0022) and your second substitution won\u0027t find or replace \u0022Dona\u0022. \n\nLastly for the titles, they should be factors, not character strings. \n\n```{r}\nfull$Titles \u003c- as.factor(full$Titles)\n```\n\nThese titles could certainly be condensed more, but for the time being, I am going to leave them separated as is. \n\nI have some thoughts about wanting to split up the names further to find family groups, but since many familial relationships (cousins, nieces/nephews, aunts/uncles, fiances, mistresses, in-laws, children with a nanny or close friends) aren\u0027t reported in any way in this data set, I\u0027ll have to think a little longer about the most appropriate way to find actual family groups. \n\n### SibSp and Parch for Family Size\n\nSince the SibSp and Parch variables each give some indication as to close family members that were also aboard the ship, it would make sense to calculate family size as a combination of SibSp, Parch and the passenger in question.  \n\n```{r}\nfull \u003c- mutate(full, FamilySize = SibSp + Parch + 1)\n```\n\nLet\u0027s visualize family size\n\n```{r echo = FALSE}\nhist(full$FamilySize, \n     main = \u0022Family Group Size\u0022, \n     xlab = \u0022People per Family Group\u0022, \n     col = \u0022#56B4E9\u0022,\n     xlim = c(1,11),\n     breaks = 11)\n```\n \n Wow! Lots of people without immediate family with them.  Perhaps these people were traveling with other family members/friends that weren\u0027t captured in the SibSp / Parch variables. \n \n### Ticket Numbers and Travel Groups\n\nI\u0027ve decided that another possible way to discern groups that were travelling together is to look at the ticket numbers.  It appears that families or groups who purchased their tickets together have identical ticket numbers, thus quantifying the number of families or traveling groups.  A quick look at the unique ticket numbers indicates there are 929 of them in the full data set (out of a possible 1309 passengers).  \n\nIt seems the easiest way to separate these tickets is to create a new column:\n\n```{r}\nfull$TravelGroup \u003c- NA\n```\n\nThen arrange the data by ticket number using the `arrange()` function from the `dplyr` package.\n\n```{r results = \u0027hide\u0027}\nfull2 \u003c- arrange(full, Ticket)\n```\n\nTake a look at the first few rows of results\n```{r}\nhead(full2)\n```\n\nTo verify that this is working so far, I inspected the first ticket number listed (110152) on the [Titanic Passenger and Crew](https://www.encyclopedia-titanica.org/titanic-passengers-and-crew/) table of Encyclopedia Titanica.  That dataset lists the same three passengers owned those tickets, verified that the 3 women were traveling together, and indicated that two of the women (Miss Gladys Cherry and the Countess of Rothes) were cousins and the 3rd woman in their party (Miss Roberta Elizabeth Mary Maioni) was their servant. Looking at unique Ticket ID may be the only way to know that these women were travelling together.  I\u0027m feeling good that unique ticket numbers may be a good way to look at family/traveling groups, so full steam ahead!\n\nNext, I need to generate a \u0022TravelGroup\u0022 number.  To do this, I will use the `transform` function looking for matching unique Ticket numbers.\n\n```{r}\nfull2 \u003c- (transform(full2, TravelGroup = match(Ticket, unique(Ticket))))\n\n# Can\u0027t forget to make those Travel Groups into factors!\nfull2$TravelGroup \u003c- as.factor(full2$TravelGroup)\n```\n\nThis generates 929 unique Travel Groups, which is the same number of unique Ticket numbers.  So far so good. \n\n\nIt may also be of interest to look at group size. We can generate this using the `group_by()` and `mutate` functions in `dplyr`.\n\n\n```{r}\nfull3 \u003c- full2 %\u003e% \n            group_by(TravelGroup) %\u003e% \n            mutate(GroupSize = n()) %\u003e%\n            ungroup()\n```\n\nHow does Travel Group Size compare to Family Group Size that we calculated earlier?\n\n```{r echo = FALSE, fig.show = \u0027hold\u0027, fig.width = 4, fig.height = 3.5}\n\nhist(full3$FamilySize, \n     main = \u0022Family Group Size\u0022, \n     xlab = \u0022People per Family Group\u0022, \n     col = \u0022#56B4E9\u0022,\n     xlim = c(1,11),\n     breaks = 11)\nhist(full3$GroupSize, \n     main = \u0022Travel Group Size\u0022, \n     xlab = \u0022People per Travel Group\u0022, \n     col = \u0022#D55E00\u0022,\n     xlim = c(1,11),\n     breaks = 11)\n```\n\nThey look pretty close, again showing that most people were potentially travelling alone. \n\nNow to check if those with the unique Ticket IDs were really travelling alone:\n\n```{r}\nfiltered \u003c- filter(full3, GroupSize == 1)\n\n# How many were listed as being onboard with siblings or spouses?\nfSibSp \u003c- filtered[filtered$SibSp \u003e 0, ]\nnrow(fSibSp)\n\n# How many were listed as being onboard with parents or children?\nfParch \u003c- filtered[filtered$Parch \u003e 0, ]\nnrow(fParch)\n\n# How many of those people overlapped both groups?\nsum(fSibSp$PassengerId %in% fParch$PassengerId)\n```\n\nOops! Looks like we were counting 50 passengers as solo-riders when they were actually riding with family.  Given the current information, I\u0027m not sure how to know to tell who was travelling together.  Manually summing SibSp and Parch to estimate family size doesn\u0027t account for other types of groups that were travelling together and looking only at unique Ticket Number doesn\u0027t account for some travelling with family who purchased a separate ticket. I could override the GroupSize for those 50 that weren\u0027t actually riding solo, but their TravelGroup number won\u0027t be accurate.  For the time being, I\u0027m going to leave TravelGroup and GroupSize as is. \n\n## Missing Data\n\nAt this point, I\u0027m feeling pretty good about the Feature Engineering that I\u0027ve done so far.  Time to correct for missing data!\n\nLet\u0027s take a look at what has NA values:\n\n```{r}\nsummary(full3)\n```\n\nLooks like we are missing values in the \u0022Survived\u0022 variable (which is to be expected since this is a combination of the training and test datasets), \u0022Fare\u0022, \u0022Embarked\u0022, and quite a few in the \u0022Age\u0022 column.  We\u0027ll start with \u0022Fare\u0022. \n\n### Missing Fare\n\nWhich passenger has no fare information?\n```{r}\nfull3[(which(is.na(full3$Fare))) , 1]\n```\n\nLooks like Passenger number 1044 has no listed Fare.  \n\n```{r}\n# Resort the dataset by Passenger Number\nfull4 \u003c- arrange(full3, PassengerId)\n\n# Where did this passenger leave from? What was their class?\nfull4[1044, c(3, 12)]\n```\n\nLooks like he left from \u0027S\u0027 (Southampton) as a 3rd class passenger. Let\u0027s see what other people of the same class and embarkment port paid for their tickets. \n\n```{r echo = FALSE, warning = FALSE}\n\nggplot(full4[full4$Pclass == \u00273\u0027 \u0026 full$Embarked == \u0027S\u0027, ], \n  aes(x = Fare)) +\n  geom_density(fill = \u0027#56B4E9\u0027, alpha = 0.4) + \n  geom_vline(aes(xintercept = median(Fare, na.rm = T)),\n    colour = \u0027#D55E00\u0027, linetype = \u0027dotted\u0027, lwd = 1) +\n  scale_x_continuous() +\n  theme(panel.grid.major = element_blank())\n\n```\n\n```{r}\nfull4 %\u003e%\n  filter(Pclass == \u00273\u0027 \u0026 Embarked == \u0027S\u0027) %\u003e%\n  summarise(missing_fare = median(Fare, na.rm = TRUE))\n\n```\n\nLooks like the median cost for a 3rd class passenger leaving out of Southampton was 8.05. That seems like a logical value for this passenger to have paid.\n\nTime to replace that NA with 8.05\n\n```{r}\nfull4$Fare[1044] \u003c- 8.05\n\nsummary(full4$Fare)\n```\n\nHooray! No more NA values for Fare. \n\n### Missing Embarkment\n\nWhich passengers have no listed embarkment port?\n```{r}\nfull4$Embarked[full4$Embarked == \u0022\u0022] \u003c- NA\n\nfull4[(which(is.na(full4$Embarked))), 1]\n```\n\nOk, so Passenger numbers 62 and 830 are each missing their embarkment ports. Let\u0027s look at their class of ticket and their fare. \n\n```{r}\nfull4[c(62, 830), c(1,3,10)]\n```\n\nBoth passengers had first class tickets that they spent 80 (pounds?) on. Let\u0027s see the embarkment ports of others who bought similar kinds of tickets. \n\n```{r}\nfull4 %\u003e%\n  group_by(Embarked, Pclass) %\u003e%\n  filter(Pclass == \u00221\u0022) %\u003e%\n  summarise(mfare = median(Fare),\n            n = n())\n```\n\nLooks like the median price for a first class ticket departing from \u0027C\u0027 (Charbourg) was 77 (in comparison to our 80).  While first class tickets departing from \u0027Q\u0027 were only slightly more expensive (median price 90), only 3 first class passengers departed from that port.  It seems far more likely that passengers 62 and 830 departed with the other 141 first-class passengers from Charbourg. \n\nNow to replace their NA values with \u0027C\u0027. And drop any unused levels.\n```{r}\n# Assign empty embark ports to \u0027C\u0027\nfull4$Embarked[c(62,830)] \u003c- \u0027C\u0027\n\n# Drop unused levels (since there should be no more blanks)\nfull4$Embarked \u003c- droplevels(full4$Embarked)\n\n# Check to make sure there are no NA\u0027s or blanks\nlevels(full4$Embarked)\n```\n\nYay! No more NA values for Embarked. \n\n### Missing Age\n\nThis one is a bit trickier. 263 passengers have no age listed.  Taking a median age of all passengers doesn\u0027t seem like the best way to solve this problem, so it may be easiest to try to predict the passengers\u0027 age based on other known information. \n\nI\u0027ve decided to use the `caret` package for predicting age. \n\nGenerate a random forest model on the full dataset (minus the age values that are NA)\n \n```{r results = \u0027hide\u0027}\npredicted_age \u003c- train(\n  Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + GroupSize,\n  tuneGrid = data.frame(mtry = c(2, 3, 7)),\n  data = full4[!is.na(full4$Age), ],\n  method = \u0022ranger\u0022,\n  trControl = trainControl(\n      method = \u0022cv\u0022, number = 10,\n      repeats = 10, verboseIter = TRUE),\n  importance = \u0027impurity\u0027\n  )\n\n```\n\nLet\u0027s look at what factors were the most important in modeling age:\n\n```{r echo = FALSE}\n# Creating a Variable Importance variable\n vimp \u003c- varImp(predicted_age)\n\n# Plotting \u0022vimp\u0022\n ggplot(vimp, \n        top = dim(vimp$importance)[1]\n        )\n```\n\nWow! Looks like it was a good idea to split out Titles!\n\nNow to use this information to predict the ages of passengers with missing ages and filling in their NA values.\n\n```{r}\nfull4$Age[is.na(full4$Age)] \u003c- predict(predicted_age, full4[is.na(full4$Age),])\n\n# Check the summary to make sure there are no more NA values\nsummary(full4$Age)\n```\n\nLet\u0027s take a quick look at the age distribution of passengers with originally known ages, and the age distribution of the entire group (known and predicted ages) to make sure we didn\u0027t terribly skew the distribution. \n\n```{r echo = FALSE, fig.show = \u0027hold\u0027, fig.width = 4, fig.height = 3.5 }\nhist(full3$Age, \n     main = \u0022Known Age Distribution\u0022, \n     xlab = \u0022Known Age\u0022, \n     col = \u0022#56B4E9\u0022,\n     breaks = 20)\nhist(full4$Age,\n     main = \u0022Known + Predicted Age Distribution\u0022,\n     xlab = \u0022Known Age\u0022,\n     col = \u0022#D55E00\u0022,\n     breaks = 20)\n```\n\nHmm, seems to have shifted a bit, but that could be due to a greater lack of age information collected for middle-aged passengers. \n\n## Modeling for Survival\n\nFirst things first, I need to split out the test and training data back into separate data sets, now called `train_complete` and `test_complete`. \n\n```{r}\ntrain_complete \u003c- full4[full4$Dataset == \u0027train\u0027, ]\ntest_complete \u003c- full4[full4$Dataset == \u0027test\u0027, ]\n```\n\nBecause I plan on using the `caret` package for all of my modeling, I\u0027m going to generate a standard `trainControl` so that those tuning parameters remain consistent throughout the various models.\n\n### Creating trainControl\nI will create a system that will perform 10 repeats of a 10-Fold cross-validation of the data. \n```{r}\nmyControl \u003c- trainControl(\n\t  method = \u0022cv\u0022, \n\t  number = 10,\n\t  repeats = 10, \n\t  verboseIter = TRUE\n  )\n```\n\n### Fitting a random forest model\n\nThe first type of model I\u0027d like to use is a random forest model (using the `ranger` and `caret` packages).\n\n```{r results = \u0027hide\u0027}\nrf_model \u003c- train(\n    Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + \n      TravelGroup + GroupSize,\n    tuneGrid = data.frame(mtry = c(2, 5, 8, 10, 15)),\n    data = train_complete, \n    method = \u0022ranger\u0022, \n    trControl = myControl,\n    importance = \u0027impurity\u0027\n)\n```\n\n### Fitting a glmnet model\n\nNext, we\u0027ll try a glmnet model, also from the `caret` package. \n\n```{r results = \u0027hide\u0027}\nglm_model \u003c- train(\n    Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + \n      TravelGroup + GroupSize, \n    method = \u0022glmnet\u0022,\n    tuneGrid = expand.grid(alpha = 0:1,\n      lambda = seq(0.0001, 1, length = 20)),\n    data = train_complete,\n    trControl = myControl\n)\n```\n\n### Comparing model fit\n\nNow that we have a random forest model and a glmnet model, it\u0027s time to compare their fit.  \n\n```{r}\n# Create a list of models\nmodels \u003c- list(rf = rf_model, glmnet = glm_model)\n\n# Resample the models\nresampled \u003c- resamples(models)\n\n# Generate a summary\nsummary(resampled)\n\n# Plot the differences between model fits\ndotplot(resampled, metric = \u0022Accuracy\u0022)\n```\n\nLooks like the glmnet model is slightly more accurate than the random forest model, so we\u0027ll use that to predict the survival rate.\n\nOk, time to make some predictions. \n\n## Predicting Survival\n\nAlthough I generated two models above, the glmnet model provided higher accuracy, so I\u0027ll use that model to predict survival in the test set. \n\n```{r}\n# Reorder the data by Passenger ID number\ntest_complete \u003c- test_complete %\u003e%\n                  arrange(PassengerId)\n\n# Make predicted survival values\nmy_prediction \u003c- predict(glm_model, test_complete)\n```\n\n### Preparing the prediction for Kaggle\n\nThe instructions on Kaggle indicate that they are expecting a csv file with 2 columns: Passenger ID and Survived.  I need to make sure that my data are arranged properly. \n\n```{r}\n# Create a data frame with two columns: PassengerId \u0026 Survived where Survived contains my predictions.\nmy_solution_5 \u003c- data.frame(PassengerID = test$PassengerId, Survived = my_prediction)\n\n# Write the solution to a csv file \nwrite.csv(my_solution_5, file = \u0022my_solution_5.csv\u0022, row.names = FALSE)\n```\n\n### Testing with Kaggle\n\nLooks like that submission scored 0.80383! Not bad!!\n\n*I\u0027d love to hear any feedback you may have on this process. Thanks in advance!*\n\n","dateCreated":"2016-11-30T06:43:45.283Z"},"kernelRun":{"id":474349,"kernelId":124658,"status":"error","type":"batch","sourceType":"script","language":"r","title":"Predicting Survival on the Titanic","dateCreated":"2016-11-30T06:43:45.283Z","dateEvaluated":"2016-11-30T06:43:44.787Z","workerContainerPort":null,"workerUptimeSeconds":1045444,"workerIPAddress":"10.3.0.8       ","scriptLanguageId":1,"scriptLanguageName":"R","renderedOutputUrl":null,"commit":{"id":4863092,"settings":{"dockerImageVersionId":null,"dataSources":[{"sourceType":"Competition","sourceId":3136,"databundleVersionId":null}],"sourceType":"script","language":"r","isGpuEnabled":false,"isInternetEnabled":false},"source":"---\ntitle: \u0022Titanic Survival\u0022\nauthor: \u0022Amber Thomas\u0022\noutput: \n  html_document:\n    theme: cosmo\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Introduction\n\nThis is my first project on Kaggle and my first attempt at machine learning.  I\u0027ll do my best to illustrate what I\u0027ve down and the logic behind my actions, but feedback is very much welcome and appreciated!\n\n### Loading Necessary Packages\n\n\n```{r message = FALSE}\n# For data manipulation and tidying\nlibrary(dplyr)\n\n# For data visualizations\nlibrary(ggplot2)\n\n# For modeling and predictions\nlibrary(caret)\nlibrary(glmnet)\nlibrary(ranger)\nlibrary(e1071)\n```\n\n### Importing Data\n\nThe data were downloaded directly from the [Kaggle Website](https://www.kaggle.com/c/titanic/data).  Before binding the training and test sets into a single data file, I added a column called \u0022Dataset\u0022 and labelled rows from the training file \u0022train\u0022 and rows from the testing file \u0022test\u0022.\n\n```{r}\ntrain \u003c- read.csv(\u0027../input/train.csv\u0027, header = TRUE, stringsAsFactors = FALSE)\ntrain$Dataset \u003c- \u0022train\u0022\n\ntest \u003c- read.csv(\u0027../input/test.csv\u0027, header = TRUE, stringsAsFactors = FALSE)\ntest$Dataset \u003c- \u0022test\u0022\n\nfull \u003c- bind_rows(train, test)\n```\n\n\nThe full dataset can then be inspected:\n```{r}\nstr(full)\n```\n\nIt appears that several of these variables should be represented as factors and thus should be reclassified. \n\n```{r}\nfactor_variables \u003c- c(\u0027PassengerId\u0027, \u0027Survived\u0027, \u0027Pclass\u0027, \u0027Sex\u0027, \u0027Embarked\u0027, \u0027Dataset\u0027)\nfull[factor_variables] \u003c- lapply(full[factor_variables], function(x) as.factor(x))\n```\n\nWe are now left with the following variables:\n\n* **Passenger ID** : A seemingly unique number assigned to each passenger\n\n* **Survived** : A binary indicator of survival (0 = died, 1 = survived)\n\n* **Pclass** : A proxy for socio-economic status (1 = upper, 3 = lower)\n\n* **Name** : Passenger\u0027s Name. For wedded women, her husband\u0027s name appears first and her maiden name appears in parentheses\n\n* **Sex** : General indication of passenger\u0027s sex\n\n* **Age** : Age of passenger (or approximate age).  Passengers under the age of 1 year have fractional ages\n\n* **SibSp** : A count of the passenger\u0027s siblings or spouses aboard\n\n* **Parch** : A count of the passenger\u0027s parents or siblings aboard\n\n* **Ticket** : The number printed on the ticket.  The numbering system is not immediately apparent\n\n* **Fare** : The price for the ticket (presumably in pounds, shillings, and pennies)\n\n* **Cabin** : Cabin number occupied by the passenger (this field is quite empty)\n\n* **Embarked** : The port from which the passenger boarded the ship\n\n* **Dataset** : Whether this particular row was a part of the training or testing dataset\n\n## Feature Engineering\n\n### Names and Titles\n\nAt first glance, the \u0022Name\u0022 column doesn\u0027t help too much as there are 1307 unique names, however, this column also includes embedded title information that may be of interest.  I decided to use [regular expressions](https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf) and the `gsub()` functions to extract the titles into a new variable.\n\n```{r}\nnames \u003c- full$Name\n\ntitles \u003c-  gsub(\u0022^.*, (.*?)\\\\..*$\u0022, \u0022\\\\1\u0022, names)\n\nfull$Titles \u003c- titles\n\nunique(full$Titles)\n```\n\nThat\u0027s a bit more manageable: only 18 unique titles. Time to see how many times each title was used.  I decided to make a table separated by sex. \n\n```{r}\ntable(full$Sex, full$Title)\n```\n\nIt looks like Captain, Don, Dona, Jonkheer, Lady, Madame, Sir and the Countess were each only used once.  I\u0027ll leave Captain separate, but the rest should be combined with similar categories.\n\n* **Don** : A Spanish/Portuguese/Italian title used with, but not instead of, a name.\n* **Dona** : Female version of \u0022Don\u0022\n* **Jonkheer** : Dutch honorific of nobility\n* **Lady** : English honorific of nobility\n* **Madame** : French, polite form of address for a woman\n* **Sir** : Honorific address (male)\n* **the Countess** : Rank of nobility (female)\n\nIt seems that most of the rarely used titles indicate some form of nobility.  That\u0027s easy to check with another table comparing `Pclass` and `Titles`.\n\n```{r}\ntable(full$Pclass, full$Titles)\n```\n\nSince Don, Jonkheer, and Sir are all of similar usage, and each represent only one first-class man, I combined them into the category \u0022Sir\u0022.  Dona, Lady, Madame, and the Countess each only represent one first-class woman, so I combined them into the category \u0022Lady\u0022.  These values were substituted using the `gsub` function.\n\n```{r}\nfull$Titles \u003c- gsub(\u0022Dona|Lady|Madame|the Countess\u0022, \u0022Lady\u0022, full$Titles)\nfull$Titles \u003c- gsub(\u0022Don|Jonkheer|Sir\u0022, \u0022Sir\u0022, full$Titles)\n\nunique(full$Titles)\n```\n\n**Warning**: If you are planning to replicate the above substitution without any RegEx, make sure that you substitute \u0022Dona\u0022 before substituting \u0022Don\u0022! Otherwise, \u0022Dona\u0022 becomes \u0022Sira\u0022 (as the \u0022Don\u0022 part was replaced with \u0022Sir\u0022) and your second substitution won\u0027t find or replace \u0022Dona\u0022. \n\nLastly for the titles, they should be factors, not character strings. \n\n```{r}\nfull$Titles \u003c- as.factor(full$Titles)\n```\n\nThese titles could certainly be condensed more, but for the time being, I am going to leave them separated as is. \n\nI have some thoughts about wanting to split up the names further to find family groups, but since many familial relationships (cousins, nieces/nephews, aunts/uncles, fiances, mistresses, in-laws, children with a nanny or close friends) aren\u0027t reported in any way in this data set, I\u0027ll have to think a little longer about the most appropriate way to find actual family groups. \n\n### SibSp and Parch for Family Size\n\nSince the SibSp and Parch variables each give some indication as to close family members that were also aboard the ship, it would make sense to calculate family size as a combination of SibSp, Parch and the passenger in question.  \n\n```{r}\nfull \u003c- mutate(full, FamilySize = SibSp + Parch + 1)\n```\n\nLet\u0027s visualize family size\n\n```{r echo = FALSE}\nhist(full$FamilySize, \n     main = \u0022Family Group Size\u0022, \n     xlab = \u0022People per Family Group\u0022, \n     col = \u0022#56B4E9\u0022,\n     xlim = c(1,11),\n     breaks = 11)\n```\n \n Wow! Lots of people without immediate family with them.  Perhaps these people were traveling with other family members/friends that weren\u0027t captured in the SibSp / Parch variables. \n \n### Ticket Numbers and Travel Groups\n\nI\u0027ve decided that another possible way to discern groups that were travelling together is to look at the ticket numbers.  It appears that families or groups who purchased their tickets together have identical ticket numbers, thus quantifying the number of families or traveling groups.  A quick look at the unique ticket numbers indicates there are 929 of them in the full data set (out of a possible 1309 passengers).  \n\nIt seems the easiest way to separate these tickets is to create a new column:\n\n```{r}\nfull$TravelGroup \u003c- NA\n```\n\nThen arrange the data by ticket number using the `arrange()` function from the `dplyr` package.\n\n```{r results = \u0027hide\u0027}\nfull2 \u003c- arrange(full, Ticket)\n```\n\nTake a look at the first few rows of results\n```{r}\nhead(full2)\n```\n\nTo verify that this is working so far, I inspected the first ticket number listed (110152) on the [Titanic Passenger and Crew](https://www.encyclopedia-titanica.org/titanic-passengers-and-crew/) table of Encyclopedia Titanica.  That dataset lists the same three passengers owned those tickets, verified that the 3 women were traveling together, and indicated that two of the women (Miss Gladys Cherry and the Countess of Rothes) were cousins and the 3rd woman in their party (Miss Roberta Elizabeth Mary Maioni) was their servant. Looking at unique Ticket ID may be the only way to know that these women were travelling together.  I\u0027m feeling good that unique ticket numbers may be a good way to look at family/traveling groups, so full steam ahead!\n\nNext, I need to generate a \u0022TravelGroup\u0022 number.  To do this, I will use the `transform` function looking for matching unique Ticket numbers.\n\n```{r}\nfull2 \u003c- (transform(full2, TravelGroup = match(Ticket, unique(Ticket))))\n\n# Can\u0027t forget to make those Travel Groups into factors!\nfull2$TravelGroup \u003c- as.factor(full2$TravelGroup)\n```\n\nThis generates 929 unique Travel Groups, which is the same number of unique Ticket numbers.  So far so good. \n\n\nIt may also be of interest to look at group size. We can generate this using the `group_by()` and `mutate` functions in `dplyr`.\n\n\n```{r}\nfull3 \u003c- full2 %\u003e% \n            group_by(TravelGroup) %\u003e% \n            mutate(GroupSize = n()) %\u003e%\n            ungroup()\n```\n\nHow does Travel Group Size compare to Family Group Size that we calculated earlier?\n\n```{r echo = FALSE, fig.show = \u0027hold\u0027, fig.width = 4, fig.height = 3.5}\n\nhist(full3$FamilySize, \n     main = \u0022Family Group Size\u0022, \n     xlab = \u0022People per Family Group\u0022, \n     col = \u0022#56B4E9\u0022,\n     xlim = c(1,11),\n     breaks = 11)\nhist(full3$GroupSize, \n     main = \u0022Travel Group Size\u0022, \n     xlab = \u0022People per Travel Group\u0022, \n     col = \u0022#D55E00\u0022,\n     xlim = c(1,11),\n     breaks = 11)\n```\n\nThey look pretty close, again showing that most people were potentially travelling alone. \n\nNow to check if those with the unique Ticket IDs were really travelling alone:\n\n```{r}\nfiltered \u003c- filter(full3, GroupSize == 1)\n\n# How many were listed as being onboard with siblings or spouses?\nfSibSp \u003c- filtered[filtered$SibSp \u003e 0, ]\nnrow(fSibSp)\n\n# How many were listed as being onboard with parents or children?\nfParch \u003c- filtered[filtered$Parch \u003e 0, ]\nnrow(fParch)\n\n# How many of those people overlapped both groups?\nsum(fSibSp$PassengerId %in% fParch$PassengerId)\n```\n\nOops! Looks like we were counting 50 passengers as solo-riders when they were actually riding with family.  Given the current information, I\u0027m not sure how to know to tell who was travelling together.  Manually summing SibSp and Parch to estimate family size doesn\u0027t account for other types of groups that were travelling together and looking only at unique Ticket Number doesn\u0027t account for some travelling with family who purchased a separate ticket. I could override the GroupSize for those 50 that weren\u0027t actually riding solo, but their TravelGroup number won\u0027t be accurate.  For the time being, I\u0027m going to leave TravelGroup and GroupSize as is. \n\n## Missing Data\n\nAt this point, I\u0027m feeling pretty good about the Feature Engineering that I\u0027ve done so far.  Time to correct for missing data!\n\nLet\u0027s take a look at what has NA values:\n\n```{r}\nsummary(full3)\n```\n\nLooks like we are missing values in the \u0022Survived\u0022 variable (which is to be expected since this is a combination of the training and test datasets), \u0022Fare\u0022, \u0022Embarked\u0022, and quite a few in the \u0022Age\u0022 column.  We\u0027ll start with \u0022Fare\u0022. \n\n### Missing Fare\n\nWhich passenger has no fare information?\n```{r}\nfull3[(which(is.na(full3$Fare))) , 1]\n```\n\nLooks like Passenger number 1044 has no listed Fare.  \n\n```{r}\n# Resort the dataset by Passenger Number\nfull4 \u003c- arrange(full3, PassengerId)\n\n# Where did this passenger leave from? What was their class?\nfull4[1044, c(3, 12)]\n```\n\nLooks like he left from \u0027S\u0027 (Southampton) as a 3rd class passenger. Let\u0027s see what other people of the same class and embarkment port paid for their tickets. \n\n```{r echo = FALSE, warning = FALSE}\n\nggplot(full4[full4$Pclass == \u00273\u0027 \u0026 full$Embarked == \u0027S\u0027, ], \n  aes(x = Fare)) +\n  geom_density(fill = \u0027#56B4E9\u0027, alpha = 0.4) + \n  geom_vline(aes(xintercept = median(Fare, na.rm = T)),\n    colour = \u0027#D55E00\u0027, linetype = \u0027dotted\u0027, lwd = 1) +\n  scale_x_continuous() +\n  theme(panel.grid.major = element_blank())\n\n```\n\n```{r}\nfull4 %\u003e%\n  filter(Pclass == \u00273\u0027 \u0026 Embarked == \u0027S\u0027) %\u003e%\n  summarise(missing_fare = median(Fare, na.rm = TRUE))\n\n```\n\nLooks like the median cost for a 3rd class passenger leaving out of Southampton was 8.05. That seems like a logical value for this passenger to have paid.\n\nTime to replace that NA with 8.05\n\n```{r}\nfull4$Fare[1044] \u003c- 8.05\n\nsummary(full4$Fare)\n```\n\nHooray! No more NA values for Fare. \n\n### Missing Embarkment\n\nWhich passengers have no listed embarkment port?\n```{r}\nfull4$Embarked[full4$Embarked == \u0022\u0022] \u003c- NA\n\nfull4[(which(is.na(full4$Embarked))), 1]\n```\n\nOk, so Passenger numbers 62 and 830 are each missing their embarkment ports. Let\u0027s look at their class of ticket and their fare. \n\n```{r}\nfull4[c(62, 830), c(1,3,10)]\n```\n\nBoth passengers had first class tickets that they spent 80 (pounds?) on. Let\u0027s see the embarkment ports of others who bought similar kinds of tickets. \n\n```{r}\nfull4 %\u003e%\n  group_by(Embarked, Pclass) %\u003e%\n  filter(Pclass == \u00221\u0022) %\u003e%\n  summarise(mfare = median(Fare),\n            n = n())\n```\n\nLooks like the median price for a first class ticket departing from \u0027C\u0027 (Charbourg) was 77 (in comparison to our 80).  While first class tickets departing from \u0027Q\u0027 were only slightly more expensive (median price 90), only 3 first class passengers departed from that port.  It seems far more likely that passengers 62 and 830 departed with the other 141 first-class passengers from Charbourg. \n\nNow to replace their NA values with \u0027C\u0027. And drop any unused levels.\n```{r}\n# Assign empty embark ports to \u0027C\u0027\nfull4$Embarked[c(62,830)] \u003c- \u0027C\u0027\n\n# Drop unused levels (since there should be no more blanks)\nfull4$Embarked \u003c- droplevels(full4$Embarked)\n\n# Check to make sure there are no NA\u0027s or blanks\nlevels(full4$Embarked)\n```\n\nYay! No more NA values for Embarked. \n\n### Missing Age\n\nThis one is a bit trickier. 263 passengers have no age listed.  Taking a median age of all passengers doesn\u0027t seem like the best way to solve this problem, so it may be easiest to try to predict the passengers\u0027 age based on other known information. \n\nI\u0027ve decided to use the `caret` package for predicting age. \n\nGenerate a random forest model on the full dataset (minus the age values that are NA)\n \n```{r results = \u0027hide\u0027}\npredicted_age \u003c- train(\n  Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + GroupSize,\n  tuneGrid = data.frame(mtry = c(2, 3, 7)),\n  data = full4[!is.na(full4$Age), ],\n  method = \u0022ranger\u0022,\n  trControl = trainControl(\n      method = \u0022cv\u0022, number = 10,\n      repeats = 10, verboseIter = TRUE),\n  importance = \u0027impurity\u0027\n  )\n\n```\n\nLet\u0027s look at what factors were the most important in modeling age:\n\n```{r echo = FALSE}\n# Creating a Variable Importance variable\n vimp \u003c- varImp(predicted_age)\n\n# Plotting \u0022vimp\u0022\n ggplot(vimp, \n        top = dim(vimp$importance)[1]\n        )\n```\n\nWow! Looks like it was a good idea to split out Titles!\n\nNow to use this information to predict the ages of passengers with missing ages and filling in their NA values.\n\n```{r}\nfull4$Age[is.na(full4$Age)] \u003c- predict(predicted_age, full4[is.na(full4$Age),])\n\n# Check the summary to make sure there are no more NA values\nsummary(full4$Age)\n```\n\nLet\u0027s take a quick look at the age distribution of passengers with originally known ages, and the age distribution of the entire group (known and predicted ages) to make sure we didn\u0027t terribly skew the distribution. \n\n```{r echo = FALSE, fig.show = \u0027hold\u0027, fig.width = 4, fig.height = 3.5 }\nhist(full3$Age, \n     main = \u0022Known Age Distribution\u0022, \n     xlab = \u0022Known Age\u0022, \n     col = \u0022#56B4E9\u0022,\n     breaks = 20)\nhist(full4$Age,\n     main = \u0022Known + Predicted Age Distribution\u0022,\n     xlab = \u0022Known Age\u0022,\n     col = \u0022#D55E00\u0022,\n     breaks = 20)\n```\n\nHmm, seems to have shifted a bit, but that could be due to a greater lack of age information collected for middle-aged passengers. \n\n## Modeling for Survival\n\nFirst things first, I need to split out the test and training data back into separate data sets, now called `train_complete` and `test_complete`. \n\n```{r}\ntrain_complete \u003c- full4[full4$Dataset == \u0027train\u0027, ]\ntest_complete \u003c- full4[full4$Dataset == \u0027test\u0027, ]\n```\n\nBecause I plan on using the `caret` package for all of my modeling, I\u0027m going to generate a standard `trainControl` so that those tuning parameters remain consistent throughout the various models.\n\n### Creating trainControl\nI will create a system that will perform 10 repeats of a 10-Fold cross-validation of the data. \n```{r}\nmyControl \u003c- trainControl(\n\t  method = \u0022cv\u0022, \n\t  number = 10,\n\t  repeats = 10, \n\t  verboseIter = TRUE\n  )\n```\n\n### Fitting a random forest model\n\nThe first type of model I\u0027d like to use is a random forest model (using the `ranger` and `caret` packages).\n\n```{r results = \u0027hide\u0027}\nrf_model \u003c- train(\n    Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + \n      TravelGroup + GroupSize,\n    tuneGrid = data.frame(mtry = c(2, 5, 8, 10, 15)),\n    data = train_complete, \n    method = \u0022ranger\u0022, \n    trControl = myControl,\n    importance = \u0027impurity\u0027\n)\n```\n\n### Fitting a glmnet model\n\nNext, we\u0027ll try a glmnet model, also from the `caret` package. \n\n```{r results = \u0027hide\u0027}\nglm_model \u003c- train(\n    Survived ~ Age + Pclass + Sex + SibSp + Parch + Fare + Embarked + Titles + FamilySize + \n      TravelGroup + GroupSize, \n    method = \u0022glmnet\u0022,\n    tuneGrid = expand.grid(alpha = 0:1,\n      lambda = seq(0.0001, 1, length = 20)),\n    data = train_complete,\n    trControl = myControl\n)\n```\n\n### Comparing model fit\n\nNow that we have a random forest model and a glmnet model, it\u0027s time to compare their fit.  \n\n```{r}\n# Create a list of models\nmodels \u003c- list(rf = rf_model, glmnet = glm_model)\n\n# Resample the models\nresampled \u003c- resamples(models)\n\n# Generate a summary\nsummary(resampled)\n\n# Plot the differences between model fits\ndotplot(resampled, metric = \u0022Accuracy\u0022)\n```\n\nLooks like the glmnet model is slightly more accurate than the random forest model, so we\u0027ll use that to predict the survival rate.\n\nOk, time to make some predictions. \n\n## Predicting Survival\n\nAlthough I generated two models above, the glmnet model provided higher accuracy, so I\u0027ll use that model to predict survival in the test set. \n\n```{r}\n# Reorder the data by Passenger ID number\ntest_complete \u003c- test_complete %\u003e%\n                  arrange(PassengerId)\n\n# Make predicted survival values\nmy_prediction \u003c- predict(glm_model, test_complete)\n```\n\n### Preparing the prediction for Kaggle\n\nThe instructions on Kaggle indicate that they are expecting a csv file with 2 columns: Passenger ID and Survived.  I need to make sure that my data are arranged properly. \n\n```{r}\n# Create a data frame with two columns: PassengerId \u0026 Survived where Survived contains my predictions.\nmy_solution_5 \u003c- data.frame(PassengerID = test$PassengerId, Survived = my_prediction)\n\n# Write the solution to a csv file \nwrite.csv(my_solution_5, file = \u0022my_solution_5.csv\u0022, row.names = FALSE)\n```\n\n### Testing with Kaggle\n\nLooks like that submission scored 0.80383! Not bad!!\n\n*I\u0027d love to hear any feedback you may have on this process. Thanks in advance!*\n\n","dateCreated":"2016-11-30T06:43:45.283Z"},"resources":null,"isolatorResults":"\u003cresults\u003e\u003cdisk_kb_free\u003e472988\u003c/disk_kb_free\u003e\u003cdocker_image_id\u003esha256:f8c9d3c9ec14286f3cbf5524d8480d50f2af5d7dd9430956edfe39e57af36ceb\u003c/docker_image_id\u003e\u003cdocker_image_name\u003ekaggle/rstats\u003c/docker_image_name\u003e\u003cexit_code\u003e1\u003c/exit_code\u003e\u003cfailure_message\u003eThe kernel returned an unsuccessful exit code (1).\u003c/failure_message\u003e\u003cout_of_memory\u003eFalse\u003c/out_of_memory\u003e\u003crun_time_seconds\u003e0.781443127081729\u003c/run_time_seconds\u003e\u003csucceeded\u003eFalse\u003c/succeeded\u003e\u003ctimeout_exceeded\u003eFalse\u003c/timeout_exceeded\u003e\u003cused_all_space\u003eFalse\u003c/used_all_space\u003e\u003cwas_killed\u003eFalse\u003c/was_killed\u003e\u003c/results\u003e","runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageDigest":null,"dockerImageId":"sha256:f8c9d3c9ec14286f3cbf5524d8480d50f2af5d7dd9430956edfe39e57af36ceb","dockerImageName":"kaggle/rstats","diskKbFree":472988,"failureMessage":"The kernel returned an unsuccessful exit code (1).","exitCode":1,"queuedSeconds":0,"outputSizeBytes":0,"runTimeSeconds":0.781443127081729,"usedAllSpace":false,"timeoutExceeded":false,"isValidStatus":false,"wasGpuEnabled":false,"wasInternetEnabled":false,"outOfMemory":false,"invalidPathErrors":false,"succeeded":false,"wasKilled":false},"outputFilesTotalSizeBytes":0,"dockerImageVersionId":null,"usedCustomDockerImage":false},"author":{"id":593198,"displayName":"eric_guo","email":null,"editedEmail":null,"editedEmailCode":null,"userName":"gzw8210","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","profileUrl":"/gzw8210","registerDate":"0001-01-01T00:00:00Z","lastVisitDate":"0001-01-01T00:00:00Z","statusId":0,"performanceTier":0,"userRoles":null,"userLogins":null,"groupIds":null,"duplicateUsers":null,"hasPhoneVerifications":false,"failedNerdchas":0,"hasPendingNerdcha":false,"deleteRequests":null,"userAttributes":null,"isAdmin":false,"isTvc":false,"isKaggleBot":false,"isAdminOrTvc":false,"isAnonymous":false,"canAct":false,"canBeSeen":false,"thumbnailName":null,"activationCode":"00000000-0000-0000-0000-000000000000","isPhoneVerified":false},"baseUrl":"/gzw8210/predicting-survival-on-the-titanic","collaborators":{"owner":{"userId":593198,"groupId":null,"groupMemberCount":null,"profileUrl":"/gzw8210","thumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","name":"eric_guo","slug":"gzw8210","userTier":0,"joinDate":null,"type":"owner","isUser":true,"isGroup":false},"collaborators":[]},"initialTab":null,"log":"[{\n  \u0022data\u0022: \u0022Error in -title : invalid argument to unary operator\\nExecution halted\\n\u0022,\n  \u0022stream_name\u0022: \u0022stderr\u0022,\n  \u0022time\u0022: 0.5624728350667283\n}]","outputFiles":[],"outputFilesCropped":false,"ouputFilesOwnerInfo":{"databundleVersionId":0,"dataset":null,"competition":null,"kernel":{"kernelId":124658,"kernelVersionId":474349,"dataviewToken":"eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..hyCAiV2iO3YRhDbg1uB2YQ.yN3rrEzm5PJF0k4uHrDJMwemA3h-0_TUNRt61rgeTsEhANIcq6lLNG4adJWFXViRTSy4qxUtuJGGYnXAudDPLLRFK8o2rIxAOt2n2kLqOnd5Ea2FydQgKnyGEg-S_qsUx8P345cLFXBxNTfXG4pOPSlttcnCeLtZRNfbhGblhENd5TA5J0y0UD1rSW-s1Q_KMAQfJWsXB4zBOeZi9EnXQvHNjMlcz0oYQgWFRnIGbKrHv5o96SSAWdRn6Y1SaPE8P4wBFOnP9orF0eOEphSR7WTF67or0JqfP7Zw1WFl0KmVRKYpAyebHmeYjgC4kB8_60eErWTH_9Bmwnlb_gfpU0OqrQc3mH4prYgFHMEwWys7T3nFB5RJX8aIYacHJSyXGSeZRxI3irmF-fXpdyozafaNTZkSFocQX7suiwylp-s2oJY3GkNYgkMOMPGhTo0J0KWUoGMIv4wxT4kOtCfEcRzmsTeGyoABapF95fyAZkU.5N5-7RQdsbNCtpONZ6Ni5Q","scope":"gzw8210/predicting-survival-on-the-titanic"},"previewsDisabled":false},"pageMessages":[],"dataSources":[{"imageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","sourceUrl":"/c/titanic","slug":"titanic","lastUpdated":"2012-09-28T21:13:33.55Z","overview":"Start here! Predict survival on the Titanic and get familiar with ML basics","sourceType":"competition","sourceVersionType":null,"sourceId":3136,"sourceVersionNumber":null,"maxVersionNumber":null,"descriptionMimeType":"text/html","deleted":false,"private":false,"privateButVisible":false,"ownerInfo":{"databundleVersionId":26502,"dataset":null,"competition":{"competitionId":3136,"dataviewToken":null,"scope":"c/titanic"},"kernel":null,"previewsDisabled":true},"type":"dataSource","collapsed":false,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"id":63842,"blobFileId":37991,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/gender_submission.csv","creationDate":"2017-02-01T01:49:18Z","isDummy":false,"size":3258,"fullPath":"../input/gender_submission.csv","previewUrl":"kernels/competition-preview/3136?relativePath=gender_submission.csv","downloadUrl":"/c/titanic/download/gender_submission.csv","fileType":".csv","contentLength":3258,"contentType":"text/csv","contentMD5":"MNEHO5ZKXYFUMexgOg3jUw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"892\n893\n894\n895\n896\n897\n898\n899\n900\n901\n902\n903\n904\n905\n906\n907\n908\n909\n910\n911\n912\n913\n914\n915\n916\n917\n918\n919\n920\n921\n922\n923\n924\n925\n926\n927\n928\n929\n930\n931\n932\n933\n934\n935\n936\n937\n938\n939\n940\n941\n942\n943\n944\n945\n946\n947\n948\n949\n950\n951\n952\n953\n954\n955\n956\n957\n958\n959\n960\n961\n962\n963\n964\n965\n966\n967\n968\n969\n970\n971\n972\n973\n974\n975\n976\n977\n978\n979\n980\n981\n982\n983\n984\n985\n986\n987\n988\n989\n990\n991\n992\n993\n994\n995\n996\n997\n998\n999\n1000\n1001\n1002\n1003\n1004\n1005\n1006\n1007\n1008\n1009\n1010\n1011\n1012\n1013\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n1024\n1025\n1026\n1027\n1028\n1029\n1030\n1031\n1032\n1033\n1034\n1035\n1036\n1037\n1038\n1039\n1040\n1041\n1042\n1043\n1044\n1045\n1046\n1047\n1048\n1049\n1050\n1051\n1052\n1053\n1054\n1055\n1056\n1057\n1058\n1059\n1060\n1061\n1062\n1063\n1064\n1065\n1066\n1067\n1068\n1069\n1070\n1071\n1072\n1073\n1074\n1075\n1076\n1077\n1078\n1079\n1080\n1081\n1082\n1083\n1084\n1085\n1086\n1087\n1088\n1089\n1090\n1091\n1092\n1093\n1094\n1095\n1096\n1097\n1098\n1099\n1100\n1101\n1102\n1103\n1104\n1105\n1106\n1107\n1108\n1109\n1110\n1111\n1112\n1113\n1114\n1115\n1116\n1117\n1118\n1119\n1120\n1121\n1122\n1123\n1124\n1125\n1126\n1127\n1128\n1129\n1130\n1131\n1132\n1133\n1134\n1135\n1136\n1137\n1138\n1139\n1140\n1141\n1142\n1143\n1144\n1145\n1146\n1147\n1148\n1149\n1150\n1151\n1152\n1153\n1154\n1155\n1156\n1157\n1158\n1159\n1160\n1161\n1162\n1163\n1164\n1165\n1166\n1167\n1168\n1169\n1170\n1171\n1172\n1173\n1174\n1175\n1176\n1177\n1178\n1179\n1180\n1181\n1182\n1183\n1184\n1185\n1186\n1187\n1188\n1189\n1190\n1191\n1192\n1193\n1194\n1195\n1196\n1197\n1198\n1199\n1200\n1201\n1202\n1203\n1204\n1205\n1206\n1207\n1208\n1209\n1210\n1211\n1212\n1213\n1214\n1215\n1216\n1217\n1218\n1219\n1220\n1221\n1222\n1223\n1224\n1225\n1226\n1227\n1228\n1229\n1230\n1231\n1232\n1233\n1234\n1235\n1236\n1237\n1238\n1239\n1240\n1241\n1242\n1243\n1244\n1245\n1246\n1247\n1248\n1249\n1250\n1251\n1252\n1253\n1254\n1255\n1256\n1257\n1258\n1259\n1260\n1261\n1262\n1263\n1264\n1265\n1266\n1267\n1268\n1269\n1270\n1271\n1272\n1273\n1274\n1275\n1276\n1277\n1278\n1279\n1280\n1281\n1282\n1283\n1284\n1285\n1286\n1287\n1288\n1289\n1290\n1291\n1292\n1293\n1294\n1295\n1296\n1297\n1298\n1299\n1300\n1301\n1302\n1303\n1304\n1305\n1306\n1307\n1308\n1309\n"},{"order":1,"originalType":"","type":"boolean","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"gender_submission.csv","description":"892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,0\n901,0\n902,0\n903,0\n904,1\n905,0a\n906,1\n907,0\n908,0\n909,0\n910,0\n911,0\n912,1\n913,0\n914,0\n915,0\n916,1\n917,0\n918,0\n919,0\n920,0\n921,0\n922,0\n923,0\n924,0\n925,0\n926,1\n927,0\n928,0\n929,0\n930,0\n931,1\n932,0\n933,0\n934,0\n935,0\n936,1\n937,0\n938,0\n939,0\n940,1\n941,0\n942,1\n943,0\n944,0\n945,1\n946,0\n947,0\n948,0\n949,0\n950,0\n951,1\n952,0\n953,0\n954,0\n955,0\n956,1\n957,0\n958,0\n959,0\n960,0\n961,1\n962,\n963,0\n964,0\n965,0\n966,1\n967,1\n968,0\n969,0\n970,0\n971,0\n972,0\n973,1\n974,0\n975,0\n976,0\n977,0\n978,0\n979,0\n980,0\n981,0\n982,0\n983,0\n984,0\n985,0\n986,0\n987,0\n988,1\n989,0\n990,0\n991,0\n992,1\n993,0\n994,0\n995,0\n996,0\n997,0\n998,0\n999,0\n1000,0\n1001,0\n1002,0\n1003,0\n1004,0\n1005,0\n1006,1\n1007,0\n1008,0\n1009,0\n1010,1\n1011,0\n1012,0\n1013,0\n1014,1\n1015,0\n1016,0\n1017,0\n1018,0\n1019,0\n1020,0\n1021,0\n1022,0\n1023,0\n1024,0\n1025,0\n1026,0\n1027,0\n1028,0\n1029,0\n1030,0\n1031,0\n1032,0\n1033,1\n1034,1\n1035,0\n1036,0\n1037,0\n1038,1\n1039,0\n1040,0\n1041,0\n1042,1\n1043,0\n1044,0\n1045,0\n1046,0\n1047,0\n1048,1\n1049,0\n1050,0\n1051,0\n1052,0\n1053,0\n1054,0\n1055,0\n1056,0\n1057,0\n1058,1\n1059,0\n1060,0\n1061,0\n1062,0\n1063,0\n1064,0\n1065,0\n1066,0\n1067,0\n1068,0\n1069,1\n1070,0\n1071,1\n1072,0\n1073,1\n1074,1\n1075,0\n1076,1\n1077,0\n1078,0\n1079,0\n1080,1\n1081,0\n1082,0\n1083,0\n1084,0\n1085,0\n1086,0\n1087,0\n1088,1\n1089,0\n1090,0\n1091,0\n1092,0\n1093,0\n1094,1\n1095,0\n1096,0\n1097,0\n1098,0\n1099,0\n1100,0\n1101,0\n1102,0\n1103,0\n1104,1\n1105,0\n1106,0\n1107,0\n1108,0\n1109,1\n1110,1\n1111,0\n1112,0\n1113,0\n1114,0\n1115,0\n1116,0\n1117,0\n1118,0\n1119,0\n1120,0\n1121,0\n1122,1\n1123,0\n1124,0\n1125,0\n1126,1\n1127,0\n1128,1\n1129,0\n1130,0\n1131,1\n1132,0\n1133,0\n1134,1\n1135,0\n1136,0\n1137,1\n1138,0\n1139,0\n1140,0\n1141,0\n1142,0\n1143,0\n1144,1\n1145,0\n1146,0\n1147,0\n1148,0\n1149,0\n1150,0\n1151,0\n1152,0\n1153,0\n1154,0\n1155,0\n1156,0\n1157,0\n1158,0\n1159,0\n1160,0\n1161,0\n1162,1\n1163,0\n1164,1\n1165,0\n1166,0\n1167,0\n1168,0\n1169,0\n1170,0\n1171,0\n1172,0\n1173,0\n1174,0\n1175,0\n1176,0\n1177,0\n1178,0\n1179,1\n1180,0\n1181,0\n1182,0\n1183,0\n1184,0\n1185,1\n1186,0\n1187,0\n1188,0\n1189,0\n1190,1\n1191,0\n1192,0\n1193,0\n1194,0\n1195,0\n1196,0\n1197,0\n1198,1\n1199,0\n1200,1\n1201,0\n1202,0\n1203,0\n1204,0\n1205,0\n1206,1\n1207,0\n1208,1\n1209,0\n1210,0\n1211,0\n1212,0\n1213,0\n1214,0\n1215,0\n1216,1\n1217,0\n1218,0\n1219,1\n1220,0\n1221,0\n1222,0\n1223,0\n1224,0\n1225,0\n1226,0\n1227,0\n1228,0\n1229,0\n1230,0\n1231,0\n1232,0\n1233,0\n1234,1\n1235,1\n1236,0\n1237,0\n1238,0\n1239,0\n1240,0\n1241,0\n1242,1\n1243,0\n1244,1\n1245,1\n1246,0\n1247,0\n1248,1\n1249,0\n1250,0\n1251,0\n1252,1\n1253,0\n1254,0\n1255,0\n1256,1\n1257,1\n1258,0\n1259,0\n1260,0\n1261,0\n1262,0\n1263,1\n1264,0\n1265,0\n1266,1\n1267,1\n1268,0\n1269,0\n1270,1\n1271,0\n1272,0\n1273,0\n1274,0\n1275,0\n1276,0\n1277,1\n1278,0\n1279,0\n1280,0\n1281,0\n1282,1\n1283,0\n1284,0\n1285,0\n1286,0\n1287,1\n1288,0\n1289,1\n1290,0\n1291,0\n1292,1\n1293,0\n1294,0\n1295,1\n1296,0\n1297,0\n1298,0\n1299,1\n1300,0\n1301,0\n1302,0\n1303,1\n1304,0\n1305,0\n1306,1\n1307,0\n1308,0\n1309,0"},{"id":63841,"blobFileId":2613,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/test.csv","creationDate":"2013-06-28T13:40:24.227Z","isDummy":false,"size":28629,"fullPath":"../input/test.csv","previewUrl":"kernels/competition-preview/3136?relativePath=test.csv","downloadUrl":"/c/titanic/download/test.csv","fileType":".csv","contentLength":28629,"contentType":"text/csv","contentMD5":"dTO4Lq5LWCYQy9aKpjawFw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":418},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"1"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"1"},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"the name of the passenger"},{"order":3,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":null},{"order":4,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":null},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"of siblings / spouses aboard the Titanic"},{"order":6,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"of parents / children aboard the Titanic"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":"Ticket number"},{"order":8,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":"Passenger fare"},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":"Cabin number"},{"order":10,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"Port of Embarkation"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"test.csv","description":"test data to check the accuracy of the model created\n"},{"id":63840,"blobFileId":2307,"databundleVersionId":26502,"databundleVersionObjectType":"file","url":null,"relativePath":"../input/train.csv","creationDate":"2013-06-28T13:40:25.23Z","isDummy":false,"size":61194,"fullPath":"../input/train.csv","previewUrl":"kernels/competition-preview/3136?relativePath=train.csv","downloadUrl":"/c/titanic/download/train.csv","fileType":".csv","contentLength":61194,"contentType":"text/csv","contentMD5":"IwnMXwR4Ltm7YBbZ9OOBzw==","validationErrors":null,"type":"databundleVersionObject","collapsed":false,"info":{"metrics":{"tableMetrics":{"exception":null,"rowCount":891},"columnMetrics":[]},"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":{"delimiter":",","includesHeader":true},"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[{"columns":[{"order":0,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"PassengerId","description":"type should be integers"},{"order":1,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Survived","description":"Survived or Not "},{"order":2,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Pclass","description":"Class of Travel"},{"order":3,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Name","description":"Name of Passenger"},{"order":4,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Sex","description":"Gender"},{"order":5,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Age","description":"Age of Passengers"},{"order":6,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"SibSp","description":"Number of Sibling/Spouse aboard"},{"order":7,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Parch","description":"Number of Parent/Child aboard"},{"order":8,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Ticket","description":null},{"order":9,"originalType":"","type":"numeric","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Fare","description":null},{"order":10,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Cabin","description":null},{"order":11,"originalType":"","type":"string","extendedType":null,"isNullable":false,"isPrimaryKey":false,"isLabel":false,"info":null,"name":"Embarked","description":"The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown"}],"totalRows":null,"type":"genericTable","collapsed":true,"info":{"metrics":null,"archiveInfo":null,"archiveInfoV2":null,"blobFileInfo":null,"convertCsvInfo":null,"kernelReference":null},"settings":{"csvSettings":null,"bigQuerySettings":null,"bigQueryMirrorSettings":null,"storageSettings":null,"remoteUrlSettings":null,"remoteGithubSettings":null},"render":null,"children":[],"name":"","description":null}],"name":"train.csv","description":"contains data \n"}],"name":"Titanic: Machine Learning from Disaster","description":"\u003ch3\u003eOverview\u003c/h3\u003e\n\u003cp\u003eThe data has been split into two groups:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etraining set (train.csv)\u003c/li\u003e\n\u003cli\u003etest set (test.csv)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cb\u003e The training set \u003c/b\u003eshould be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use \u003ca href=\u0022https://triangleinequality.wordpress.com/2013/09/08/basic-feature-engineering-with-the-titanic-data/\u0022 target=\u0022_blank\u0022\u003e feature engineering \u003c/a\u003eto create new features.\u003c/p\u003e\n\u003cp\u003e\u003cb\u003eThe test set \u003c/b\u003eshould be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\u003c/p\u003e\n\u003cp\u003eWe also include \u003cb\u003egender_submission.csv\u003c/b\u003e, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\u003c/p\u003e\n\u003ch3\u003eData Dictionary\u003c/h3\u003e\n\u003ctable style=\u0022width: 100%;\u0022\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\u003cth\u003e\u003cb\u003eVariable\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eDefinition\u003c/b\u003e\u003c/th\u003e\u003cth\u003e\u003cb\u003eKey\u003c/b\u003e\u003c/th\u003e\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esurvival\u003c/td\u003e\n\u003ctd\u003eSurvival\u003c/td\u003e\n\u003ctd\u003e0 = No, 1 = Yes\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003epclass\u003c/td\u003e\n\u003ctd\u003eTicket class\u003c/td\u003e\n\u003ctd\u003e1 = 1st, 2 = 2nd, 3 = 3rd\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esex\u003c/td\u003e\n\u003ctd\u003eSex\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eAge\u003c/td\u003e\n\u003ctd\u003eAge in years\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003esibsp\u003c/td\u003e\n\u003ctd\u003e# of siblings / spouses aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eparch\u003c/td\u003e\n\u003ctd\u003e# of parents / children aboard the Titanic\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eticket\u003c/td\u003e\n\u003ctd\u003eTicket number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003efare\u003c/td\u003e\n\u003ctd\u003ePassenger fare\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ecabin\u003c/td\u003e\n\u003ctd\u003eCabin number\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eembarked\u003c/td\u003e\n\u003ctd\u003ePort of Embarkation\u003c/td\u003e\n\u003ctd\u003eC = Cherbourg, Q = Queenstown, S = Southampton\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3\u003eVariable Notes\u003c/h3\u003e\n\u003cp\u003e\u003cb\u003epclass\u003c/b\u003e: A proxy for socio-economic status (SES)\u003cbr /\u003e 1st = Upper\u003cbr /\u003e 2nd = Middle\u003cbr /\u003e 3rd = Lower\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eage\u003c/b\u003e: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003esibsp\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Sibling = brother, sister, stepbrother, stepsister\u003cbr /\u003e Spouse = husband, wife (mistresses and fiancés were ignored)\u003cbr /\u003e\u003cbr /\u003e \u003cb\u003eparch\u003c/b\u003e: The dataset defines family relations in this way...\u003cbr /\u003e Parent = mother, father\u003cbr /\u003e Child = daughter, son, stepdaughter, stepson\u003cbr /\u003e Some children travelled only with a nanny, therefore parch=0 for them.\u003c/p\u003e"}],"versions":[{"id":474349,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"R","lastRunTime":"2016-11-30T06:43:45.283Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:f8c9d3c9ec14286f3cbf5524d8480d50f2af5d7dd9430956edfe39e57af36ceb","dockerImageName":"kaggle/rstats","exitCode":1,"failureMessage":"The kernel returned an unsuccessful exit code (1).","isValidStatus":true,"runTimeSeconds":0.781443127081729,"succeeded":false,"timeoutExceeded":false,"usedAllSpace":false},"status":"error","title":"Predicting Survival on the Titanic","url":"/gzw8210/predicting-survival-on-the-titanic?scriptVersionId=474349","versionNumber":2,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":474348,"kernelVersionId":null,"isForkParent":false,"isNotebook":false,"languageName":"Python","lastRunTime":"2016-11-30T06:43:31.5Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":0,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-python/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/python/","dockerImageId":"sha256:f27ad03f22bf24acc165f7ae89bb81e3bbe4c1ab8b66fbeb8492f552d9029a9f","dockerImageName":"kaggle/python","exitCode":1,"failureMessage":"The kernel returned an unsuccessful exit code (1).","isValidStatus":true,"runTimeSeconds":0.727464975090697,"succeeded":false,"timeoutExceeded":false,"usedAllSpace":false},"status":"error","title":"Predicting Survival on the Titanic","url":"/gzw8210/predicting-survival-on-the-titanic?scriptVersionId=474348","versionNumber":1,"hasVersionNumber":true,"isRedacted":false,"versionAuthor":null},{"id":435935,"kernelVersionId":null,"isForkParent":true,"isNotebook":false,"languageName":"RMarkdown","lastRunTime":"2016-11-09T02:08:37.097Z","linesChangedFromPrevious":0,"linesDeletedFromPrevious":0,"linesInsertedFromPrevious":0,"outputFilesTotalSizeBytes":3997479,"runInfo":{"dockerfileUrl":"https://github.com/Kaggle/docker-rstats/blob/master/Dockerfile","dockerHubUrl":"https://registry.hub.docker.com/u/kaggle/rstats/","dockerImageId":"sha256:09c1486443c7339c624fc3f64eb334bb51fa339c8a9b01840b358b7bef8f10c0","dockerImageName":"kaggle/rstats","exitCode":0,"failureMessage":"","isValidStatus":true,"runTimeSeconds":47.7128633839893,"succeeded":true,"timeoutExceeded":false,"usedAllSpace":false},"status":"complete","title":"Predicting Survival on the Titanic","url":"/amberthomas/predicting-survival-on-the-titanic","versionNumber":0,"hasVersionNumber":false,"isRedacted":false,"versionAuthor":null}],"categories":{"categories":[],"type":"script"},"submitToCompetitionInfo":null,"downloadAllFilesUrl":"/kernels/svzip/474349","submission":null,"menuLinks":[{"href":"/gzw8210/predicting-survival-on-the-titanic/code","text":"Code","title":"Code","tab":"code","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/gzw8210/predicting-survival-on-the-titanic/data","text":"Data","title":"Data","tab":"data","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/gzw8210/predicting-survival-on-the-titanic/comments","text":"Comments","title":"Comments","tab":"comments","count":0,"showZeroCountExplicitly":true,"reportEventCategory":null,"reportEventType":null},{"href":"/gzw8210/predicting-survival-on-the-titanic/log","text":"Log","title":"Log","tab":"log","count":null,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/gzw8210/predicting-survival-on-the-titanic/versions","text":"Versions","title":"Versions","tab":"versions","count":2,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null},{"href":"/gzw8210/predicting-survival-on-the-titanic/forks","text":"Forks","title":"Forks","tab":"forks","count":1,"showZeroCountExplicitly":false,"reportEventCategory":null,"reportEventType":null}],"rightMenuLinks":[],"callToAction":{"href":"/kernels/fork-version/474349","text":"Fork Script","title":"Fork Script","tab":null,"count":null,"showZeroCountExplicitly":false,"reportEventCategory":"kernels","reportEventType":"anonymousKernelForkCreation"},"voteButton":{"totalVotes":1,"hasAlreadyVotedUp":false,"hasAlreadyVotedDown":false,"canUpvote":true,"canDownvote":false,"voteUpUrl":"/kernels/vote?id=124658","voteDownUrl":null,"voters":[{"avatarThumbnailUrl":"https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png","displayName":"eric_guo","profileUrl":"/gzw8210","tier":"Novice","tierInt":0,"userId":593198,"userName":"gzw8210"}],"currentUserInfo":null,"showVoters":true,"alwaysShowVoters":true},"parentDataSource":null,"parentName":"Titanic: Machine Learning from Disaster","parentUrl":"/c/titanic","thumbnailImageUrl":"https://storage.googleapis.com/kaggle-competitions/kaggle/3136/logos/thumb76_76.png","canWrite":false,"canAdminister":false,"datasetHidden":false,"forkParentIsRedacted":false,"forkDiffLinesChanged":0,"forkDiffLinesDeleted":0,"forkDiffLinesInserted":0,"forkDiffUrl":null,"forkParentAuthorDisplayName":null,"forkParentAuthorUrl":null,"forkParentTitle":null,"forkParentUrl":null,"canSeeDataExplorerV2":true,"canSeeRevampedViewer":true,"canSeeInnerTableOfContents":true,"canSeeCopyAndEditText":true,"simplifiedViewer":false,"kernelOutputDataset":null});performance && performance.mark && performance.mark("KernelViewer.componentCouldBootstrap");</script>

<form action="/gzw8210/predicting-survival-on-the-titanic" id="__AjaxAntiForgeryForm" method="post"><input name="X-XSRF-TOKEN" type="hidden" value="CfDJ8LdUzqlsSWBPr4Ce3rb9VL9dZ9yCYNLZD95EAmN-EPRruOh9UHUgcmLaXKOIDshOogOFjn2LUixRHOvka7iWVArgcjQMMRofzuxDxDYEfPwIgNDz3bdmz_hA4TC0YCE3oRZ3ya9oqDMdJVnc4pUAfac" /></form>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["STIX", "TeX"],
            linebreaks: {
                automatic: true
            },
            EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
        },
        tex2jax: {
            inlineMath: [["\\(", "\\)"], ["\\\\(", "\\\\)"]],
            displayMath: [["$$", "$$"], ["\\[", "\\]"]],
            processEscapes: true,
            ignoreClass: "tex2jax_ignore|dno"
        },
        TeX: {
            noUndefined: {
                attributes: {
                    mathcolor: "red",
                    mathbackground: "#FFEEEE",
                    mathsize: "90%"
                }
            }
        },
        Macros: {
            href: "{}"
        },
        skipStartupTypeset: true,
        messageStyle: "none"
    });
</script>
<script type="text/javascript" async crossorigin="anonymous" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>



    </div>

        <div class="site-layout__footer">
            <footer class="site-footer">
    <div class="site-footer__content">
        <div class="site-footer__copyright">
            <span>&copy; 2019 Kaggle Inc</span>
        </div>
        <nav class="site-footer__nav">
            <a href="/team">Our Team</a>
            <a href="/terms">Terms</a>
            <a href="/privacy">Privacy</a>
            <a href="/contact">Contact/Support</a>
        </nav>
        <nav class="site-footer__social">
            <div data-component-name="SocialIcons" style="display: flex; flex-direction: column; flex: 1 0 auto;"></div><script>var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push();performance && performance.mark && performance.mark("SocialIcons.componentCouldBootstrap");</script>
        </nav>
    </div>
</footer>

        </div>
</div>




    </main>
</body>
</html>
