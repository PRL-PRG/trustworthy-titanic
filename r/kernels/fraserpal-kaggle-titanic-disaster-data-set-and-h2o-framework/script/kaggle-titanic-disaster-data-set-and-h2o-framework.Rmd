---
title: "Deep Learning Basics over Kaggle Titanic Disaster Data Set with H2O framework"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---
#### Author: Borja Serra
***


## Introduction
H2o Package is an Artificial Intelligence framework developed by [h2o.ai](www.h2o.ai), focused in easy and fast model deployment to production. The main feature is the possibility of running simulations easily along several cores, CPUs and GPUs, boosting training speed. In this notebook, Neural Network models will be applied to predict survivavility in the Titanic Disaster. No distributed computation will be performed as I want to just focus in the basics to show how powerful and easy to use is H2o package. Let's begin!

First, we will import libraries and initialize H2o Cluster. When connection is successful we can see the allowed cores to work, the memory that will be used, number of nodes... these parameters can be modified through the arguments of the initialization function.

```{R}
suppressPackageStartupMessages(library('h2o'))
suppressPackageStartupMessages(library('ggplot2'))
suppressPackageStartupMessages(library('reshape2'))
suppressPackageStartupMessages(library('stringr'))
suppressPackageStartupMessages(library('plyr'))
suppressPackageStartupMessages(library('DT'))

workdir = normalizePath("../input/")

h2o.init()
```

Now we will import trainning and validating csv files previously downloaded from [Kaggle](https://www.kaggle.com/c/titanic/data). Note that the functions used are from H2o package instead of native ones. You will also see that generated objects are H2o-type. This is because all calculations are made at the cluster using its resources (memory, CPUs, GPUs, etc). In this case the cluster is our own laptop (localhost), but clusters can be configured to run in a server outside our equipments. Hence the objects defined will not be stored in our memory but outside. 

```{R}
h2o.no_progress()
train <- h2o.importFile(path = normalizePath(paste(workdir, '/train.csv', sep = "")))
val <- h2o.importFile(path = normalizePath(paste(workdir, '/test.csv', sep = "")))
summary(train)
```
***
## First Approach
To work as simple as possible for now, all features (data frame columns) will be defined as numeric type as the most common way to work with NN is with inputs as continuous numeric variables.Furthermore, some features will be initially excluded from the analysis: "Cabin" because of the large number of NA values, and "Name" because it is an character type and would require further transformation.'Survived' feature will be the one to be predicted (output), so it will be set as categorical for 2-class classification (alive or not).

In fact, converting data types to numrical is not mandatory with h2o package. If features are categorical, defined as factors, h2o engine will automatically convert them to numeric values. But for the common machine learning way to proceed we have converted them.

```{R}
temp = c("Name", "Cabin")
for( i in temp){
  train[, i] <- NULL
  val[, i] <- NULL
}

train <- as.numeric(train)
val <- as.numeric(val)
train$Survived <- as.factor(train$Survived)

summary(train)
```
### Preparing the data
To train and test our model the initial training set "train" will be divided in two parts, one to train the model that is 70% of the initial trraining data set; and a testing one that is 30%. The features used to predict the output are all but "Survived" column.

```{R}
split <- h2o.splitFrame(data = train, ratios = 0.7)
train_split <- split[[1]]
test_split <- split[[2]]

response <- 'Survived'
predictors <- setdiff(names(train_split), response)
```

### Model creation
The Neural Network will be defined and trained now. NN topology is defined by two hidden 10 neurons layers. Most basic arguments are:

  + **x**: Set of features used as inputs, predictors.
  + **y**: Output column to predict.
  + **training_frame**: Data set to train the NN with.
  + **validation_frame**: Data set to evaluate the accuracy of the model.
  + **distribution**: (loss function) The nature of the response desired. In our case, two-case classification , then we can choose between multinomial or bernoulli distributions.
  + **hidden**: In this case, two hidden layers, 10 neurons each.
  + **epochs**: 1 epoch is equivalent to the full training data set to train. 0.5 epochs would be half of the data set, and so on.

```{R}
model_dl <- h2o.deeplearning(x = predictors,
                          y = response,
                          training_frame = train_split,
                          validation_frame = test_split,
                          distribution = 'multinomial',
                          hidden = c(10, 10),
                          epochs = 5)
```

Now we have the model we use it to make prediction over the validation data set using "h2o.predict()" function. The output is a list containing the probability of obtaining a positive result. These results will be traslated to binary form and written down in a csv file to be submitted to Kaggle website.

```{R}

# KAGGLE RESULTS GENERATION
pred <- h2o.predict(model_dl, newdata = val)
pred <- as.list(pred)
class <- as.data.frame(ifelse(pred >= .5,1,0))
passengerid <- as.data.frame(val[,1])
class <- cbind(passengerid, class)
colnames(class) <- c("PassengerId", "Survived")
write.csv(class[1:418,], "submission.csv", row.names=F) # Do not know why, I have more rows than normal in class object.

```

***
## Automatizing tests, and fetching results
After an initial training session, we will go further in our analysis by testing different parameters and studying their effect over the model performance. To do this in a clean way, we will use R function "do.call()", that permits to use a function with several combinations of arguments.

```{R}
# DEEP LEARNING TOPOLOGY TEST FUNCTION
run_DL_test <- function(extra_params) {
  model_test <- do.call(h2o.deeplearning, modifyList(list(x = predictors,
                                                          y = response,
                                                          training_frame = train_split,
                                                          validation_frame = test_split,
                                                          distribution = 'multinomial'),
                                                          extra_params))
  
  idx <- paste(names(extra_params), extra_params, sep = "=", collapse=" ")
  
  # Model Metrics
  sampleshist <- model_test@model$scoring_history$samples
  samples <- sampleshist[length(sampleshist)]
  time <- model_test@model$run_time/1000
  
  training_MSE <- (tail(model_test@model$scoring_history$training_rmse, n=1))^2
  training_logloss <- tail(model_test@model$scoring_history$training_logloss, n=1)
  training_auc <- tail(model_test@model$scoring_history$training_auc, n=1)
  
  test_MSE <- (tail(model_test@model$scoring_history$validation_rmse, n=1))^2
  test_logloss <- tail(model_test@model$scoring_history$validation_logloss, n=1)
  test_auc <- tail(model_test@model$scoring_history$validation_auc, n=1)
  
  
  #print("Deep Learning Model Topology Test Metrics")
  #print(paste0("Parameters        : ", idx))
  #print(paste0("Samples           : ", samples))
  #print(paste0("training speed    : ", samples/time, " samples/sec"))
  #print(paste0("training time     : ", time, " sec"))
  #print(paste0("Training MSE      : ", training_MSE))
  #print(paste0("Training Logloss  : ", training_logloss))
  #print(paste0("Training AUC      : ", training_auc))
  #print(paste0("Validation MSE    : ", test_MSE))
  #print(paste0("Validation Logloss: ", test_logloss))
  #print(paste0("Validation AUC    : ", test_auc))
  #writeLines("\n")
  
  # Group Results
  c(idx, samples, sprintf("%.3f", time), sprintf("%.3f", samples/time), sprintf("%.3f", training_MSE), 
    sprintf("%.3f", training_logloss), sprintf("%.3f", training_auc), sprintf("%.3f", test_MSE), 
    sprintf("%.3f", test_logloss), sprintf("%.3f", test_auc))
}

#########################################################################################

# EXPORT METRICS TO DF and CSV FILE FUNCTION
build_nn_topology_test_results <- function(results, file) {
  table <- matrix(unlist(results), ncol = 10, byrow = TRUE)
  
  colnames(table) <- c("Parameters", "Samples", "Training_Time", "Training_Speed", 
                       "Training_MSE", "Training_Logloss", "Training_AUC",
                       "Validation_MSE", "Validation_Logloss", "Validation_AUC")
  #write.csv(table, file.path(workdir,file), col.names = T, row.names=F, quote=T, sep=",")
  return(as.data.frame(table))

}

```



```{R}

# DEEP LEARNING TOPOLOGY TEST EXECUTION
# Parameters
EPOCHS = 1

NN_topology_test <- list(
list(hidden=c(32),             epochs=EPOCHS),
list(hidden=c(128),            epochs=EPOCHS),
list(hidden=c(256),            epochs=EPOCHS),
list(hidden=c(512),            epochs=EPOCHS),
list(hidden=c(32,32),          epochs=EPOCHS),
list(hidden=c(128,128),        epochs=EPOCHS),
list(hidden=c(256,256),        epochs=EPOCHS),
list(hidden=c(512,512),        epochs=EPOCHS),
list(hidden=c(32,32,32),       epochs=EPOCHS),
list(hidden=c(128,128,128),    epochs=EPOCHS),
list(hidden=c(256,256,256),    epochs=EPOCHS),
list(hidden=c(512,512,512),    epochs=EPOCHS))

# Execution
nn_topology_results_df <- build_nn_topology_test_results(lapply(NN_topology_test, run_DL_test), "network_topology_test.csv")

```

## Ploting Deep Learning Model Topology Test Results
Now we will define a function that will import the csv files containg test results. this fucntion will transform the data as needed to plot it. This code is a good example of "Reshape2" and "ggplot2" libraries use.

```{R}

ploting_nn_topology_test_metrics <- function(df_name) {
  # CSV FILE IMPORT TO DATAFRAME
  # dataframe <- read.csv(file = normalizePath(paste(workdir, file_name, sep = "")), header = T, sep = ",")
  dataframe <- df_name
  
  # MELTED DATAFRAMES TO PLOT
  dataframe2 <- melt(dataframe, id = c(names(dataframe)[!names(dataframe) %in% c("Training_MSE", "Validation_MSE")]))
  dataframe3 <- melt(dataframe, id = c(names(dataframe)[!names(dataframe) %in% c("Training_AUC", "Validation_AUC")]))
  
  # PLOT OBJECT: MSE GRAPH
  plot_MSE <- ggplot(dataframe2, aes(x = Parameters, y = value, fill = variable)) +
    geom_bar(stat = "identity", width = .5, position = "dodge") +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
        labs(x = NULL, y = 'MSE', fill = NULL)

  # PLOT OBJECT: AUC GRAPH
  plot_AUC <- ggplot(dataframe3, aes(x = Parameters, y = value, fill = variable)) +
    geom_bar(stat = "identity", width = .5, position = "dodge") +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
    labs(x = NULL, y = 'AUC', fill = NULL) # +  coord_cartesian(ylim = c(0.75, 0.85))
  
  # PLOT OBJECT: TRAINING SPEED GRAPH
  plot_ts <- ggplot(dataframe, aes(x = Parameters, y = Training_Speed)) +
    geom_point() +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
    labs(x = NULL, y = 'Training Speed [Samples/sec]')

  dl_results <- list("plotMSE" = plot_MSE, "plotAUC" = plot_AUC, "plot_ts" = plot_ts)
  return(dl_results)
}

```

Once the function is defined we just need to call it using the csv file name as argument.

```{R}

dl_results <- ploting_nn_topology_test_metrics(nn_topology_results_df)
dl_results$plotMSE
dl_results$plotAUC
dl_results$plot_ts

```



```{R}

# DEEP LEARNING MODEL FUNCTION
run_dl_model <- function(dl_extra_params) {
  
  model_dl <- do.call(h2o.deeplearning, modifyList(list(x = predictors,
                                                          y = response,
                                                          training_frame = train_split,
                                                          validation_frame = test_split,
                                                          distribution = 'multinomial'),
                                                          dl_extra_params))
  # Metrics  
  dl_auc <- h2o.auc(model_dl)
  dl_mse <- h2o.mse(model_dl)
  dl_time <- model_dl@model$run_time/1000
  
  # Group Results
  idx <- paste(names(dl_extra_params), dl_extra_params, sep = "=", collapse=" ")
  dl_res <- c("DL", idx, sprintf("%.3f", dl_time), sprintf("%.3f", dl_mse), sprintf("%.3f", dl_auc))
  
  # Print Metrics
  #print(paste0("Model: ", 'Deep Learning'))
  #print(paste0("Parameters: ", idx))
  #print(paste0("Time: ", dl_time))
  #print(paste0("MSE: ", dl_mse))
  #print(paste0("AUC: ", dl_auc))
  #writeLines("\n")
  
  return(dl_res)
  
}
  
#########################################################################################

# GENERALIZED LINEAR MODEL FUNCTION
run_glm_model <- function(glm_extra_params) {
  
  model_glm <- do.call(h2o.glm, modifyList(list(x = predictors,
                       y = response,
                       training_frame = train_split,
                       validation_frame = test_split,
                       family = "binomial"),
                       glm_extra_params))
  # Metrics
  glm_auc <- h2o.auc(model_glm)
  glm_mse <- h2o.mse(model_glm)
  glm_time <- model_glm@model$scoring_history$duration[length(model_glm@model$scoring_history$duration)]
  glm_time <- str_extract(glm_time, "\\d+\\.*\\d*")
  
  # Group Results
  idx <- paste(names(glm_extra_params), glm_extra_params, sep = "=", collapse=" ")
  glm_res <- c("GLM", idx, sprintf("%s", glm_time), sprintf("%.3f", glm_mse), sprintf("%.3f", glm_auc))
  
  # Print Metrics
  #print(paste0("Model: ", 'Generalized Linear Model'))
  #print(paste0("Parameters: ", idx))
  #print(paste0("Time: ", glm_time))
  #print(paste0("MSE: ", glm_mse))
  #print(paste0("AUC: ", glm_auc))
  #writeLines("\n")
  
  return(glm_res)
}
  
#########################################################################################

# GRADIENT BOOSTING MACHINE MODEL FUNCTION
run_gbm_model <- function(gbm_extra_params) {

  model_gbm <- do.call(h2o.gbm, modifyList(list(x = predictors,
                       y = response,
                       training_frame = train_split,
                       validation_frame = test_split),
                       gbm_extra_params))
  # Metrics
  gbm_auc  <- h2o.auc(model_gbm)
  gbm_mse  <- h2o.mse(model_gbm)
  gbm_time <- model_gbm@model$scoring_history$duration[length(model_gbm@model$scoring_history$duration)]
  gbm_time <- str_extract(gbm_time, "\\d+\\.*\\d*")
  
  # Group Results
  idx <- paste(names(gbm_extra_params), gbm_extra_params, sep = "=", collapse=" ")
  gbm_res <- c("GBM", idx, sprintf("%s", gbm_time), sprintf("%.3f", gbm_mse), sprintf("%.3f", gbm_auc))
  
  # Print Metrics
  #print(paste0("Model: ", 'Gradient Boosting MAchine'))
  #print(paste0("Parameters: ", idx))
  #print(paste0("Time: ", gbm_time))
  #print(paste0("MSE: ", gbm_mse))
  #print(paste0("AUC: ", gbm_auc))
  #writeLines("\n")
  
  return(gbm_res)
}
  
#########################################################################################

# DISTRIBUTED RANDOM FOREST MODEL FUNCTION
run_drf_model <- function(drf_extra_params) {

  model_drf <- do.call(h2o.randomForest, modifyList(list(x = predictors,
                       y = response,
                       training_frame = train_split,
                       validation_frame = test_split),
                       drf_extra_params))
  # Metrics
  drf_auc  <- h2o.auc(model_drf)
  drf_mse  <- h2o.mse(model_drf)
  drf_time <- model_drf@model$scoring_history$duration[length(model_drf@model$scoring_history$duration)]
  drf_time <- str_extract(drf_time, "\\d+\\.*\\d*")
  
  # Group Results
  idx <- paste(names(drf_extra_params), drf_extra_params, sep = "=", collapse=" ")
  drf_res <- c("DRF", idx, sprintf("%s", drf_time), sprintf("%.3f", drf_mse), sprintf("%.3f", drf_auc))

  # Print Metrics
  #print(paste0("Model: ", 'Distributed Random Forest'))
  #print(paste0("Parameters: ", idx))
  #print(paste0("Time: ", drf_time))
  #print(paste0("MSE: ", drf_mse))
  #print(paste0("AUC: ", drf_auc))
  #writeLines("\n")
  
  return(drf_res)
}

#########################################################################################

# EXPORT METRICS TO CSV FILE
build_model_benchmark_results <- function(results, file) {

  table <- matrix(unlist(results), ncol = 5, byrow = TRUE)
  colnames(table) <- c("Model_type", "Parameters", "Time", "MSE", "AUC")
  
  # write.csv(table, file.path(workdir,file),
  #          col.names = T, row.names=F, quote=T, sep=",")
  
  return(as.data.frame(table))
}

```

```{R}

# BENCHMARK PARAMETERS
DL_params <- list(
  list(hidden=c(20),          epochs=EPOCHS),
  list(hidden=c(20,20,20,20), epochs=EPOCHS))

GLM_params <- list(
  list(alpha=0.0),
  list(alpha=0.5),
  list(alpha=1.0))

GBM_params <- list(
  list(ntrees=10,  balance_classes=F),
  list(ntrees=100, balance_classes=F),
  list(ntrees=10,  balance_classes=T),
  list(ntrees=100, balance_classes=T))

DRF_params <- list(
  list(ntrees=10,  balance_classes=F),
  list(ntrees=100, balance_classes=F),
  list(ntrees=10,  balance_classes=T),
  list(ntrees=100, balance_classes=T))

# TESTS EXECUTION
dl_metrics  <- lapply(DL_params,  run_dl_model)
glm_metrics <- lapply(GLM_params, run_glm_model)
gbm_metrics <- lapply(GBM_params, run_gbm_model)
drf_metrics <- lapply(DRF_params, run_drf_model)

# GROUP ALL RESULTS AND EXPORT THEM TO CSV FILE
total_results <- rbind(dl_metrics, glm_metrics, gbm_metrics, drf_metrics)
model_benchmark_results_df <- build_model_benchmark_results(total_results, 'model_benchmark.csv')
datatable(model_benchmark_results_df)
```
```{R}

ploting_benchmark_metrics <- function(df_name, file_name) {
  # CSV FILE IMPORT TO DATAFRAME
  # dataframe <- read.csv(file = normalizePath(paste(workdir, file_name, sep = "")), header = T, sep = ",")
  dataframe <- df_name
  
  # PLOT OBJECT: MSE GRAPH
  plot_MSE <- ggplot(dataframe, aes(x = paste(Model_type, Parameters), y = MSE)) +
    geom_bar(stat = "identity", width = .5) +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
        labs(x = NULL, y = 'MSE', fill = NULL)

  # PLOT OBJECT: AUC GRAPH
  plot_AUC <- ggplot(dataframe, aes(x = paste(Model_type, Parameters), y = AUC)) +
    geom_bar(stat = "identity", width = .5) +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
    labs(x = NULL, y = 'AUC', fill = NULL) # + coord_cartesian(ylim = c(0.7, 1))
  
  # PLOT OBJECT: TRAINING SPEED GRAPH
  plot_ts <- ggplot(dataframe, aes(x = paste(Model_type, Parameters), y = Time)) +
    geom_bar(stat = "identity", width = .5) +
    theme_minimal() + 
    theme(axis.text.x =  element_text(angle = 45, vjust = 1, size = 12, hjust = 1)) +
    labs(x = NULL, y = 'Training Time [sec]')

  dl_results <- list("plotMSE" = plot_MSE, "plotAUC" = plot_AUC, "plot_ts" = plot_ts)
  return(dl_results)
}

```

```{R}

benchmark_plots <- ploting_benchmark_metrics(model_benchmark_results_df, "/model_benchmark")
benchmark_plots$plotMSE
benchmark_plots$plotAUC
benchmark_plots$plot_ts

```
